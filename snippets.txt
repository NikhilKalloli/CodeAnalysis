Log File Created



=== New Entry ===

<CLUSTER_0>
Number of Code Snippets part of this cluster: 37
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code defines a job processor that handles workspace events, identifies relevant webhooks, sanitizes record data, and enqueues tasks to call these webhooks.
Code Snippet:
import { Logger } from '@nestjs/common';

import { ArrayContains } from 'typeorm';

import { ObjectRecordEvent } from 'src/engine/core-modules/event-emitter/types/object-record-event.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  CallWebhookJob,
  CallWebhookJobData,
} from 'src/modules/webhook/jobs/call-webhook.job';
import { WebhookWorkspaceEntity } from 'src/modules/webhook/standard-objects/webhook.workspace-entity';
import { removeSecretFromWebhookRecord } from 'src/utils/remove-secret-from-webhook-record';

@Processor(MessageQueue.webhookQueue)
export class CallWebhookJobsJob {
  private readonly logger = new Logger(CallWebhookJobsJob.name);

  constructor(
    @InjectMessageQueue(MessageQueue.webhookQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {}

  @Process(CallWebhookJobsJob.name)
  async handle(
    workspaceEventBatch: WorkspaceEventBatch<ObjectRecordEvent>,
  ): Promise<void> {
    // If you change that function, double check it does not break Zapier
    // trigger in packages/twenty-zapier/src/triggers/trigger_record.ts
    // Also change the openApi schema for webhooks
    // packages/twenty-server/src/engine/core-modules/open-api/utils/computeWebhooks.utils.ts

    const webhookRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace<WebhookWorkspaceEntity>(
        workspaceEventBatch.workspaceId,
        'webhook',
      );

    const [nameSingular, operation] = workspaceEventBatch.name.split('.');

    const webhooks = await webhookRepository.find({
      where: [
        { operations: ArrayContains([`${nameSingular}.${operation}`]) },
        { operations: ArrayContains([`*.${operation}`]) },
        { operations: ArrayContains([`${nameSingular}.*`]) },
        { operations: ArrayContains(['*.*']) },
      ],
    });

    for (const eventData of workspaceEventBatch.events) {
      const eventName = workspaceEventBatch.name;
      const objectMetadata = {
        id: eventData.objectMetadata.id,
        nameSingular: eventData.objectMetadata.nameSingular,
      };
      const workspaceId = workspaceEventBatch.workspaceId;
      const record =
        'after' in eventData.properties
          ? eventData.properties.after
          : 'before' in eventData.properties
            ? eventData.properties.before
            : {};
      const updatedFields =
        'updatedFields' in eventData.properties
          ? eventData.properties.updatedFields
          : undefined;

      const isWebhookEvent = nameSingular === 'webhook';
      const sanitizedRecord = removeSecretFromWebhookRecord(
        record,
        isWebhookEvent,
      );

      webhooks.forEach((webhook) => {
        const webhookData = {
          targetUrl: webhook.targetUrl,
          secret: webhook.secret,
          eventName,
          objectMetadata,
          workspaceId,
          webhookId: webhook.id,
          eventDate: new Date(),
          record: sanitizedRecord,
          ...(updatedFields && { updatedFields }),
        };

        this.messageQueueService.add<CallWebhookJobData>(
          CallWebhookJob.name,
          webhookData,
          { retryLimit: 3 },
        );
      });

      webhooks.length > 0 &&
        this.logger.log(
          `CallWebhookJobsJob on eventName '${workspaceEventBatch.name}' triggered webhooks with ids [\n"${webhooks.map((webhook) => webhook.id).join('",\n"')}"\n]`,
        );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener for database events related to the destruction of connected accounts, which then triggers the removal of accounts to reconnect for the associated workspace member.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { AccountsToReconnectService } from 'src/modules/connected-account/services/accounts-to-reconnect.service';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class ConnectedAccountListener {
  constructor(
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    private readonly accountsToReconnectService: AccountsToReconnectService,
  ) {}

  @OnDatabaseBatchEvent('connectedAccount', DatabaseEventAction.DESTROYED)
  async handleDestroyedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordDeleteEvent<ConnectedAccountWorkspaceEntity>
    >,
  ) {
    for (const eventPayload of payload.events) {
      const workspaceMemberId = eventPayload.properties.before.accountOwnerId;
      const workspaceId = payload.workspaceId;
      const workspaceMemberRepository =
        await this.twentyORMGlobalManager.getRepositoryForWorkspace<WorkspaceMemberWorkspaceEntity>(
          workspaceId,
          'workspaceMember',
        );
      const workspaceMember = await workspaceMemberRepository.findOneOrFail({
        where: { id: workspaceMemberId },
      });

      const userId = workspaceMember.userId;

      const connectedAccountId = eventPayload.properties.before.id;

      await this.accountsToReconnectService.removeAccountToReconnect(
        userId,
        workspaceId,
        connectedAccountId,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS processor that handles jobs related to matching participants for calendar events based on workspace data and participant service.
Code Snippet:
import { Scope } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { CalendarEventParticipantWorkspaceEntity } from 'src/modules/calendar/common/standard-objects/calendar-event-participant.workspace-entity';
import { MatchParticipantService } from 'src/modules/match-participant/match-participant.service';

export type CalendarEventParticipantMatchParticipantJobData = {
  workspaceId: string;
  email: string;
  personId?: string;
  workspaceMemberId?: string;
};

@Processor({
  queueName: MessageQueue.calendarQueue,
  scope: Scope.REQUEST,
})
export class CalendarEventParticipantMatchParticipantJob {
  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    private readonly matchParticipantService: MatchParticipantService<CalendarEventParticipantWorkspaceEntity>,
  ) {}

  @Process(CalendarEventParticipantMatchParticipantJob.name)
  async handle(
    data: CalendarEventParticipantMatchParticipantJobData,
  ): Promise<void> {
    const { workspaceId, email, personId, workspaceMemberId } = data;

    const workspace = await this.workspaceRepository.findOne({
      where: {
        id: workspaceId,
      },
    });

    if (workspace?.activationStatus !== 'ACTIVE') {
      return;
    }

    await this.matchParticipantService.matchParticipantsAfterPersonOrWorkspaceMemberCreation(
      email,
      'calendarEventParticipant',
      personId,
      workspaceMemberId,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: Listens for workspace member creation and update events, and enqueues jobs to match or unmatch calendar event participants based on email changes.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { ObjectRecordUpdateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-update.event';
import { objectRecordChangedProperties as objectRecordUpdateEventChangedProperties } from 'src/engine/core-modules/event-emitter/utils/object-record-changed-properties.util';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  CalendarEventParticipantMatchParticipantJob,
  CalendarEventParticipantMatchParticipantJobData,
} from 'src/modules/calendar/calendar-event-participant-manager/jobs/calendar-event-participant-match-participant.job';
import {
  CalendarEventParticipantUnmatchParticipantJob,
  CalendarEventParticipantUnmatchParticipantJobData,
} from 'src/modules/calendar/calendar-event-participant-manager/jobs/calendar-event-participant-unmatch-participant.job';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class CalendarEventParticipantWorkspaceMemberListener {
  constructor(
    @InjectMessageQueue(MessageQueue.calendarQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('workspaceMember', DatabaseEventAction.CREATED)
  async handleCreatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordCreateEvent<WorkspaceMemberWorkspaceEntity>
    >,
  ) {
    for (const eventPayload of payload.events) {
      if (!eventPayload.properties.after.userEmail) {
        continue;
      }

      await this.messageQueueService.add<CalendarEventParticipantMatchParticipantJobData>(
        CalendarEventParticipantMatchParticipantJob.name,
        {
          workspaceId: payload.workspaceId,
          email: eventPayload.properties.after.userEmail,
          workspaceMemberId: eventPayload.recordId,
        },
      );
    }
  }

  @OnDatabaseBatchEvent('workspaceMember', DatabaseEventAction.UPDATED)
  async handleUpdatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordUpdateEvent<WorkspaceMemberWorkspaceEntity>
    >,
  ) {
    for (const eventPayload of payload.events) {
      if (
        objectRecordUpdateEventChangedProperties<WorkspaceMemberWorkspaceEntity>(
          eventPayload.properties.before,
          eventPayload.properties.after,
        ).includes('userEmail')
      ) {
        await this.messageQueueService.add<CalendarEventParticipantUnmatchParticipantJobData>(
          CalendarEventParticipantUnmatchParticipantJob.name,
          {
            workspaceId: payload.workspaceId,
            email: eventPayload.properties.before.userEmail,
            personId: eventPayload.recordId,
          },
        );

        await this.messageQueueService.add<CalendarEventParticipantMatchParticipantJobData>(
          CalendarEventParticipantMatchParticipantJob.name,
          {
            workspaceId: payload.workspaceId,
            email: eventPayload.properties.after.userEmail,
            workspaceMemberId: eventPayload.recordId,
          },
        );
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code listens for database events related to person records and enqueues jobs to match or unmatch calendar event participants based on email changes.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { ObjectRecordUpdateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-update.event';
import { objectRecordChangedProperties as objectRecordUpdateEventChangedProperties } from 'src/engine/core-modules/event-emitter/utils/object-record-changed-properties.util';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  CalendarEventParticipantMatchParticipantJob,
  CalendarEventParticipantMatchParticipantJobData,
} from 'src/modules/calendar/calendar-event-participant-manager/jobs/calendar-event-participant-match-participant.job';
import {
  CalendarEventParticipantUnmatchParticipantJob,
  CalendarEventParticipantUnmatchParticipantJobData,
} from 'src/modules/calendar/calendar-event-participant-manager/jobs/calendar-event-participant-unmatch-participant.job';
import { PersonWorkspaceEntity } from 'src/modules/person/standard-objects/person.workspace-entity';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class CalendarEventParticipantPersonListener {
  constructor(
    @InjectMessageQueue(MessageQueue.calendarQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('person', DatabaseEventAction.CREATED)
  async handleCreatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordCreateEvent<PersonWorkspaceEntity>
    >,
  ) {
    for (const eventPayload of payload.events) {
      if (eventPayload.properties.after.emails?.primaryEmail === null) {
        continue;
      }

      // TODO: modify this job to take an array of participants to match
      await this.messageQueueService.add<CalendarEventParticipantMatchParticipantJobData>(
        CalendarEventParticipantMatchParticipantJob.name,
        {
          workspaceId: payload.workspaceId,
          email: eventPayload.properties.after.emails?.primaryEmail,
          personId: eventPayload.recordId,
        },
      );
    }
  }

  @OnDatabaseBatchEvent('person', DatabaseEventAction.UPDATED)
  async handleUpdatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordUpdateEvent<PersonWorkspaceEntity>
    >,
  ) {
    for (const eventPayload of payload.events) {
      if (
        objectRecordUpdateEventChangedProperties(
          eventPayload.properties.before,
          eventPayload.properties.after,
        ).includes('emails')
      ) {
        // TODO: modify this job to take an array of participants to match
        await this.messageQueueService.add<CalendarEventParticipantUnmatchParticipantJobData>(
          CalendarEventParticipantUnmatchParticipantJob.name,
          {
            workspaceId: payload.workspaceId,
            email: eventPayload.properties.before.emails?.primaryEmail,
            personId: eventPayload.recordId,
          },
        );

        await this.messageQueueService.add<CalendarEventParticipantMatchParticipantJobData>(
          CalendarEventParticipantMatchParticipantJob.name,
          {
            workspaceId: payload.workspaceId,
            email: eventPayload.properties.after.emails?.primaryEmail,
            personId: eventPayload.recordId,
          },
        );
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to manage calendar event participants, including upserting, updating, and deleting participants.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { isDefined } from 'class-validator';
import differenceWith from 'lodash.differencewith';
import { Any } from 'typeorm';

import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { CalendarEventParticipantWorkspaceEntity } from 'src/modules/calendar/common/standard-objects/calendar-event-participant.workspace-entity';
import { CalendarEventParticipantWithCalendarEventId } from 'src/modules/calendar/common/types/calendar-event';
import { MatchParticipantService } from 'src/modules/match-participant/match-participant.service';

@Injectable()
export class CalendarEventParticipantService {
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly matchParticipantService: MatchParticipantService<CalendarEventParticipantWorkspaceEntity>,
  ) {}

  public async upsertAndDeleteCalendarEventParticipants(
    participantsToSave: CalendarEventParticipantWithCalendarEventId[],
    participantsToUpdate: CalendarEventParticipantWithCalendarEventId[],
    transactionManager?: any,
  ): Promise<void> {
    const calendarEventParticipantRepository =
      await this.twentyORMManager.getRepository<CalendarEventParticipantWorkspaceEntity>(
        'calendarEventParticipant',
      );

    const existingCalendarEventParticipants =
      await calendarEventParticipantRepository.find({
        where: {
          calendarEventId: Any(
            participantsToUpdate
              .map((participant) => participant.calendarEventId)
              .filter(isDefined),
          ),
        },
      });

    const { calendarEventParticipantsToUpdate, newCalendarEventParticipants } =
      participantsToUpdate.reduce(
        (acc, calendarEventParticipant) => {
          const existingCalendarEventParticipant =
            existingCalendarEventParticipants.find(
              (existingCalendarEventParticipant) =>
                existingCalendarEventParticipant.handle ===
                  calendarEventParticipant.handle &&
                existingCalendarEventParticipant.calendarEventId ===
                  calendarEventParticipant.calendarEventId,
            );

          if (existingCalendarEventParticipant) {
            acc.calendarEventParticipantsToUpdate.push(
              calendarEventParticipant,
            );
          } else {
            acc.newCalendarEventParticipants.push(calendarEventParticipant);
          }

          return acc;
        },
        {
          calendarEventParticipantsToUpdate:
            [] as CalendarEventParticipantWithCalendarEventId[],
          newCalendarEventParticipants:
            [] as CalendarEventParticipantWithCalendarEventId[],
        },
      );

    const calendarEventParticipantsToDelete = differenceWith(
      existingCalendarEventParticipants,
      participantsToUpdate,
      (existingCalendarEventParticipant, participantToUpdate) =>
        existingCalendarEventParticipant.handle ===
          participantToUpdate.handle &&
        existingCalendarEventParticipant.calendarEventId ===
          participantToUpdate.calendarEventId,
    );

    await calendarEventParticipantRepository.delete(
      {
        id: Any(
          calendarEventParticipantsToDelete.map(
            (calendarEventParticipant) => calendarEventParticipant.id,
          ),
        ),
      },
      transactionManager,
    );

    for (const calendarEventParticipantToUpdate of calendarEventParticipantsToUpdate) {
      await calendarEventParticipantRepository.update(
        {
          calendarEventId: calendarEventParticipantToUpdate.calendarEventId,
          handle: calendarEventParticipantToUpdate.handle,
        },
        {
          ...calendarEventParticipantToUpdate,
        },
        transactionManager,
      );
    }

    participantsToSave.push(...newCalendarEventParticipants);

    const savedParticipants = await calendarEventParticipantRepository.save(
      participantsToSave,
      {},
      transactionManager,
    );

    await this.matchParticipantService.matchParticipants(
      savedParticipants,
      'calendarEventParticipant',
      transactionManager,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for fetching calendar events from Google Calendar, handling pagination and error parsing.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { GaxiosError } from 'gaxios';
import { calendar_v3 as calendarV3 } from 'googleapis';

import { GoogleCalendarClientProvider } from 'src/modules/calendar/calendar-event-import-manager/drivers/google-calendar/providers/google-calendar.provider';
import { formatGoogleCalendarEvents } from 'src/modules/calendar/calendar-event-import-manager/drivers/google-calendar/utils/format-google-calendar-event.util';
import { parseGaxiosError } from 'src/modules/calendar/calendar-event-import-manager/drivers/google-calendar/utils/parse-gaxios-error.util';
import { parseGoogleCalendarError } from 'src/modules/calendar/calendar-event-import-manager/drivers/google-calendar/utils/parse-google-calendar-error.util';
import { GetCalendarEventsResponse } from 'src/modules/calendar/calendar-event-import-manager/services/calendar-get-events.service';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';

@Injectable()
export class GoogleCalendarGetEventsService {
  constructor(
    private readonly googleCalendarClientProvider: GoogleCalendarClientProvider,
  ) {}

  public async getCalendarEvents(
    connectedAccount: Pick<
      ConnectedAccountWorkspaceEntity,
      'provider' | 'refreshToken' | 'id'
    >,
    syncCursor?: string,
  ): Promise<GetCalendarEventsResponse> {
    const googleCalendarClient =
      await this.googleCalendarClientProvider.getGoogleCalendarClient(
        connectedAccount,
      );

    let nextSyncToken: string | null | undefined;
    let nextPageToken: string | undefined;
    const events: calendarV3.Schema$Event[] = [];

    let hasMoreEvents = true;

    while (hasMoreEvents) {
      const googleCalendarEvents = await googleCalendarClient.events
        .list({
          calendarId: 'primary',
          maxResults: 500,
          syncToken: syncCursor,
          pageToken: nextPageToken,
          showDeleted: true,
        })
        .catch(async (error: GaxiosError) => {
          this.handleError(error);

          return {
            data: {
              items: [],
              nextSyncToken: undefined,
              nextPageToken: undefined,
            },
          };
        });

      nextSyncToken = googleCalendarEvents.data.nextSyncToken;
      nextPageToken = googleCalendarEvents.data.nextPageToken || undefined;

      const { items } = googleCalendarEvents.data;

      if (!items || items.length === 0) {
        break;
      }

      events.push(...items);

      if (!nextPageToken) {
        hasMoreEvents = false;
      }
    }

    return {
      fullEvents: true,
      calendarEvents: formatGoogleCalendarEvents(events),
      nextSyncCursor: nextSyncToken || '',
    };
  }

  private handleError(error: GaxiosError) {
    if (
      error.code &&
      [
        'ECONNRESET',
        'ENOTFOUND',
        'ECONNABORTED',
        'ETIMEDOUT',
        'ERR_NETWORK',
      ].includes(error.code)
    ) {
      throw parseGaxiosError(error);
    }
    if (error.response?.status !== 410) {
      const googleCalendarError = {
        code: error.response?.status,
        reason:
          error.response?.data?.error?.errors?.[0].reason ||
          error.response?.data?.error ||
          '',
        message:
          error.response?.data?.error?.errors?.[0].message ||
          error.response?.data?.error_description ||
          '',
      };

      throw parseGoogleCalendarError(googleCalendarError);
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS processor that checks for stale calendar sync operations and resets their status if necessary.
Code Snippet:
import { Logger, Scope } from '@nestjs/common';

import { In } from 'typeorm';

import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { isSyncStale } from 'src/modules/calendar/calendar-event-import-manager/utils/is-sync-stale.util';
import { CalendarChannelSyncStatusService } from 'src/modules/calendar/common/services/calendar-channel-sync-status.service';
import {
  CalendarChannelSyncStage,
  CalendarChannelWorkspaceEntity,
} from 'src/modules/calendar/common/standard-objects/calendar-channel.workspace-entity';

export type CalendarOngoingStaleJobData = {
  workspaceId: string;
};

@Processor({
  queueName: MessageQueue.calendarQueue,
  scope: Scope.REQUEST,
})
export class CalendarOngoingStaleJob {
  private readonly logger = new Logger(CalendarOngoingStaleJob.name);
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly calendarChannelSyncStatusService: CalendarChannelSyncStatusService,
  ) {}

  @Process(CalendarOngoingStaleJob.name)
  async handle(data: CalendarOngoingStaleJobData): Promise<void> {
    const { workspaceId } = data;

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    const calendarChannels = await calendarChannelRepository.find({
      where: {
        syncStage: In([
          CalendarChannelSyncStage.CALENDAR_EVENTS_IMPORT_ONGOING,
          CalendarChannelSyncStage.CALENDAR_EVENT_LIST_FETCH_ONGOING,
        ]),
      },
    });

    for (const calendarChannel of calendarChannels) {
      if (
        calendarChannel.syncStageStartedAt &&
        isSyncStale(calendarChannel.syncStageStartedAt)
      ) {
        this.logger.log(
          `Sync for calendar channel ${calendarChannel.id} and workspace ${workspaceId} is stale. Setting sync stage to pending`,
        );
        await this.calendarChannelSyncStatusService.resetSyncStageStartedAt([
          calendarChannel.id,
        ]);

        switch (calendarChannel.syncStage) {
          case CalendarChannelSyncStage.CALENDAR_EVENT_LIST_FETCH_ONGOING:
            await this.calendarChannelSyncStatusService.schedulePartialCalendarEventListFetch(
              [calendarChannel.id],
            );
            break;
          case CalendarChannelSyncStage.CALENDAR_EVENTS_IMPORT_ONGOING:
            await this.calendarChannelSyncStatusService.scheduleCalendarEventsImport(
              [calendarChannel.id],
            );
            break;
          default:
            break;
        }
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener for database events related to the destruction of connected account records. Upon detection of such events, it enqueues a job to clean up associated calendar data.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  DeleteConnectedAccountAssociatedCalendarDataJob,
  DeleteConnectedAccountAssociatedCalendarDataJobData,
} from 'src/modules/calendar/calendar-event-cleaner/jobs/delete-connected-account-associated-calendar-data.job';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class CalendarEventCleanerConnectedAccountListener {
  constructor(
    @InjectMessageQueue(MessageQueue.calendarQueue)
    private readonly calendarQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('connectedAccount', DatabaseEventAction.DESTROYED)
  async handleDestroyedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordDeleteEvent<ConnectedAccountWorkspaceEntity>
    >,
  ) {
    await Promise.all(
      payload.events.map((eventPayload) =>
        this.calendarQueueService.add<DeleteConnectedAccountAssociatedCalendarDataJobData>(
          DeleteConnectedAccountAssociatedCalendarDataJob.name,
          {
            workspaceId: payload.workspaceId,
            connectedAccountId: eventPayload.recordId,
          },
        ),
      ),
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to clean non-associated calendar events for a given workspace using pagination.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { Any, IsNull } from 'typeorm';

import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { deleteUsingPagination } from 'src/modules/messaging/message-cleaner/utils/delete-using-pagination.util';

@Injectable()
export class CalendarEventCleanerService {
  constructor(private readonly twentyORMManager: TwentyORMManager) {}

  public async cleanWorkspaceCalendarEvents(workspaceId: string) {
    const calendarEventRepository =
      await this.twentyORMManager.getRepository('calendarEvent');

    await deleteUsingPagination(
      workspaceId,
      500,
      async (limit, offset) => {
        const nonAssociatedCalendarEvents = await calendarEventRepository.find({
          where: {
            calendarChannelEventAssociations: {
              id: IsNull(),
            },
          },
          take: limit,
          skip: offset,
        });

        return nonAssociatedCalendarEvents.map(({ id }) => id);
      },
      async (ids) => {
        await calendarEventRepository.delete({ id: Any(ids) });
      },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS processor that handles the deletion of calendar events associated with blocklisted items in a workspace.
Code Snippet:
import { Logger, Scope } from '@nestjs/common';

import { And, Any, ILike, In, Not, Or } from 'typeorm';

import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { BlocklistWorkspaceEntity } from 'src/modules/blocklist/standard-objects/blocklist.workspace-entity';
import { CalendarEventCleanerService } from 'src/modules/calendar/calendar-event-cleaner/services/calendar-event-cleaner.service';
import { CalendarChannelEventAssociationWorkspaceEntity } from 'src/modules/calendar/common/standard-objects/calendar-channel-event-association.workspace-entity';
import { CalendarChannelWorkspaceEntity } from 'src/modules/calendar/common/standard-objects/calendar-channel.workspace-entity';

export type BlocklistItemDeleteCalendarEventsJobData = WorkspaceEventBatch<
  ObjectRecordCreateEvent<BlocklistWorkspaceEntity>
>;

@Processor({
  queueName: MessageQueue.calendarQueue,
  scope: Scope.REQUEST,
})
export class BlocklistItemDeleteCalendarEventsJob {
  private readonly logger = new Logger(
    BlocklistItemDeleteCalendarEventsJob.name,
  );

  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly calendarEventCleanerService: CalendarEventCleanerService,
  ) {}

  @Process(BlocklistItemDeleteCalendarEventsJob.name)
  async handle(data: BlocklistItemDeleteCalendarEventsJobData): Promise<void> {
    const workspaceId = data.workspaceId;

    const blocklistItemIds = data.events.map(
      (eventPayload) => eventPayload.recordId,
    );

    const blocklistRepository =
      await this.twentyORMManager.getRepository<BlocklistWorkspaceEntity>(
        'blocklist',
      );

    const blocklist = await blocklistRepository.find({
      where: {
        id: Any(blocklistItemIds),
      },
    });

    const handlesToDeleteByWorkspaceMemberIdMap = blocklist.reduce(
      (acc, blocklistItem) => {
        const { handle, workspaceMemberId } = blocklistItem;

        if (!acc.has(workspaceMemberId)) {
          acc.set(workspaceMemberId, []);
        }

        acc.get(workspaceMemberId)?.push(handle);

        return acc;
      },
      new Map<string, string[]>(),
    );

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    const calendarChannelEventAssociationRepository =
      await this.twentyORMManager.getRepository<CalendarChannelEventAssociationWorkspaceEntity>(
        'calendarChannelEventAssociation',
      );

    for (const workspaceMemberId of handlesToDeleteByWorkspaceMemberIdMap.keys()) {
      const handles =
        handlesToDeleteByWorkspaceMemberIdMap.get(workspaceMemberId);

      if (!handles) {
        continue;
      }

      this.logger.log(
        `Deleting calendar events from ${handles.join(
          ', ',
        )} in workspace ${workspaceId} for workspace member ${workspaceMemberId}`,
      );

      const calendarChannels = await calendarChannelRepository.find({
        select: {
          id: true,
          handle: true,
          connectedAccount: {
            handleAliases: true,
          },
        },
        where: {
          connectedAccount: {
            accountOwnerId: workspaceMemberId,
          },
        },
        relations: ['connectedAccount'],
      });

      for (const calendarChannel of calendarChannels) {
        const calendarChannelHandles = [calendarChannel.handle];

        if (calendarChannel.connectedAccount.handleAliases) {
          calendarChannelHandles.push(
            ...calendarChannel.connectedAccount.handleAliases.split(','),
          );
        }

        const handleConditions = handles.map((handle) => {
          const isHandleDomain = handle.startsWith('@');

          return isHandleDomain
            ? {
                handle: And(
                  Or(ILike(`%${handle}`), ILike(`%.${handle.slice(1)}`)),
                  Not(In(calendarChannelHandles)),
                ),
              }
            : { handle };
        });

        const calendarEventsAssociationsToDelete =
          await calendarChannelEventAssociationRepository.find({
            where: {
              calendarChannelId: calendarChannel.id,
              calendarEvent: {
                calendarEventParticipants: handleConditions,
              },
            },
          });

        if (calendarEventsAssociationsToDelete.length === 0) {
          continue;
        }

        await calendarChannelEventAssociationRepository.delete(
          calendarEventsAssociationsToDelete.map(({ id }) => id),
        );
      }

      this.logger.log(
        `Deleted calendar events from handle ${handles.join(
          ', ',
        )} in workspace ${workspaceId} for workspace member ${workspaceMemberId}`,
      );
    }

    await this.calendarEventCleanerService.cleanWorkspaceCalendarEvents(
      workspaceId,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener for blocklist events that triggers jobs to manage calendar events based on blocklist changes.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { ObjectRecordUpdateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-update.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { BlocklistWorkspaceEntity } from 'src/modules/blocklist/standard-objects/blocklist.workspace-entity';
import {
  BlocklistItemDeleteCalendarEventsJob,
  BlocklistItemDeleteCalendarEventsJobData,
} from 'src/modules/calendar/blocklist-manager/jobs/blocklist-item-delete-calendar-events.job';
import {
  BlocklistReimportCalendarEventsJob,
  BlocklistReimportCalendarEventsJobData,
} from 'src/modules/calendar/blocklist-manager/jobs/blocklist-reimport-calendar-events.job';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class CalendarBlocklistListener {
  constructor(
    @InjectMessageQueue(MessageQueue.calendarQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('blocklist', DatabaseEventAction.CREATED)
  async handleCreatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordCreateEvent<BlocklistWorkspaceEntity>
    >,
  ) {
    await this.messageQueueService.add<BlocklistItemDeleteCalendarEventsJobData>(
      BlocklistItemDeleteCalendarEventsJob.name,
      payload,
    );
  }

  @OnDatabaseBatchEvent('blocklist', DatabaseEventAction.DELETED)
  async handleDeletedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordDeleteEvent<BlocklistWorkspaceEntity>
    >,
  ) {
    await this.messageQueueService.add<BlocklistReimportCalendarEventsJobData>(
      BlocklistReimportCalendarEventsJob.name,
      payload,
    );
  }

  @OnDatabaseBatchEvent('blocklist', DatabaseEventAction.UPDATED)
  async handleUpdatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordUpdateEvent<BlocklistWorkspaceEntity>
    >,
  ) {
    await this.messageQueueService.add<BlocklistItemDeleteCalendarEventsJobData>(
      BlocklistItemDeleteCalendarEventsJob.name,
      payload,
    );

    await this.messageQueueService.add<BlocklistReimportCalendarEventsJobData>(
      BlocklistReimportCalendarEventsJob.name,
      payload,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener that triggers a job to create companies and contacts in a calendar channel when the auto-creation feature is enabled.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordUpdateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-update.event';
import { objectRecordChangedProperties } from 'src/engine/core-modules/event-emitter/utils/object-record-changed-properties.util';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  CalendarCreateCompanyAndContactAfterSyncJob,
  CalendarCreateCompanyAndContactAfterSyncJobData,
} from 'src/modules/calendar/calendar-event-participant-manager/jobs/calendar-create-company-and-contact-after-sync.job';
import { MessageChannelWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class AutoCompaniesAndContactsCreationCalendarChannelListener {
  constructor(
    @InjectMessageQueue(MessageQueue.calendarQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('calendarChannel', DatabaseEventAction.UPDATED)
  async handleUpdatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordUpdateEvent<MessageChannelWorkspaceEntity>
    >,
  ) {
    await Promise.all(
      payload.events.map((eventPayload) => {
        if (
          objectRecordChangedProperties(
            eventPayload.properties.before,
            eventPayload.properties.after,
          ).includes('isContactAutoCreationEnabled') &&
          eventPayload.properties.after.isContactAutoCreationEnabled
        ) {
          return this.messageQueueService.add<CalendarCreateCompanyAndContactAfterSyncJobData>(
            CalendarCreateCompanyAndContactAfterSyncJob.name,
            {
              workspaceId: payload.workspaceId,
              calendarChannelId: eventPayload.recordId,
            },
          );
        }
      }),
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener for database update events on message channels. When the 'isContactAutoCreationEnabled' property is updated to true, it triggers a job to create companies and contacts.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordUpdateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-update.event';
import { objectRecordChangedProperties } from 'src/engine/core-modules/event-emitter/utils/object-record-changed-properties.util';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { MessageChannelWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import {
  MessagingCreateCompanyAndContactAfterSyncJob,
  MessagingCreateCompanyAndContactAfterSyncJobData,
} from 'src/modules/messaging/message-participant-manager/jobs/messaging-create-company-and-contact-after-sync.job';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class AutoCompaniesAndContactsCreationMessageChannelListener {
  constructor(
    @InjectMessageQueue(MessageQueue.contactCreationQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('messageChannel', DatabaseEventAction.UPDATED)
  async handleUpdatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordUpdateEvent<MessageChannelWorkspaceEntity>
    >,
  ) {
    await Promise.all(
      payload.events.map((eventPayload) => {
        if (
          objectRecordChangedProperties(
            eventPayload.properties.before,
            eventPayload.properties.after,
          ).includes('isContactAutoCreationEnabled') &&
          eventPayload.properties.after.isContactAutoCreationEnabled
        ) {
          return this.messageQueueService.add<MessagingCreateCompanyAndContactAfterSyncJobData>(
            MessagingCreateCompanyAndContactAfterSyncJob.name,
            {
              workspaceId: payload.workspaceId,
              messageChannelId: eventPayload.recordId,
            },
          );
        }
      }),
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a service for matching participants with persons and workspace members in a NestJS application using TypeORM.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { Any, EntityManager, Equal } from 'typeorm';

import { ScopedWorkspaceContextFactory } from 'src/engine/twenty-orm/factories/scoped-workspace-context.factory';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';
import { CalendarEventParticipantWorkspaceEntity } from 'src/modules/calendar/common/standard-objects/calendar-event-participant.workspace-entity';
import { MessageParticipantWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-participant.workspace-entity';
import { PersonWorkspaceEntity } from 'src/modules/person/standard-objects/person.workspace-entity';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';

@Injectable()
export class MatchParticipantService<
  ParticipantWorkspaceEntity extends
    | CalendarEventParticipantWorkspaceEntity
    | MessageParticipantWorkspaceEntity,
> {
  constructor(
    private readonly workspaceEventEmitter: WorkspaceEventEmitter,
    private readonly twentyORMManager: TwentyORMManager,
    private readonly scopedWorkspaceContextFactory: ScopedWorkspaceContextFactory,
  ) {}

  private async getParticipantRepository(
    objectMetadataName: 'messageParticipant' | 'calendarEventParticipant',
  ) {
    if (objectMetadataName === 'messageParticipant') {
      return await this.twentyORMManager.getRepository<MessageParticipantWorkspaceEntity>(
        objectMetadataName,
      );
    }

    return await this.twentyORMManager.getRepository<CalendarEventParticipantWorkspaceEntity>(
      objectMetadataName,
    );
  }

  public async matchParticipants(
    participants: ParticipantWorkspaceEntity[],
    objectMetadataName: 'messageParticipant' | 'calendarEventParticipant',
    transactionManager?: EntityManager,
  ) {
    const participantRepository =
      await this.getParticipantRepository(objectMetadataName);

    const workspaceId = this.scopedWorkspaceContextFactory.create().workspaceId;

    if (!workspaceId) {
      throw new Error('Workspace ID is required');
    }

    const participantIds = participants.map((participant) => participant.id);
    const uniqueParticipantsHandles = [
      ...new Set(participants.map((participant) => participant.handle)),
    ];

    const personRepository =
      await this.twentyORMManager.getRepository<PersonWorkspaceEntity>(
        'person',
      );

    const people = await personRepository.find(
      {
        where: {
          emails: Any(uniqueParticipantsHandles),
        },
      },
      transactionManager,
    );

    const workspaceMemberRepository =
      await this.twentyORMManager.getRepository<WorkspaceMemberWorkspaceEntity>(
        'workspaceMember',
      );

    const workspaceMembers = await workspaceMemberRepository.find(
      {
        where: {
          userEmail: Any(uniqueParticipantsHandles),
        },
      },
      transactionManager,
    );

    for (const handle of uniqueParticipantsHandles) {
      const person = people.find(
        (person) => person.emails?.primaryEmail === handle,
      );

      const workspaceMember = workspaceMembers.find(
        (workspaceMember) => workspaceMember.userEmail === handle,
      );

      await participantRepository.update(
        {
          id: Any(participantIds),
          handle,
        },
        {
          personId: person?.id,
          workspaceMemberId: workspaceMember?.id,
        },
        transactionManager,
      );
    }

    const matchedParticipants = await participantRepository.find(
      {
        where: {
          id: Any(participantIds),
          handle: Any(uniqueParticipantsHandles),
        },
      },
      transactionManager,
    );

    this.workspaceEventEmitter.emitCustomBatchEvent(
      `${objectMetadataName}_matched`,
      [
        {
          workspaceMemberId: null,
          participants: matchedParticipants,
        },
      ],
      workspaceId,
    );
  }

  public async matchParticipantsAfterPersonOrWorkspaceMemberCreation(
    handle: string,
    objectMetadataName: 'messageParticipant' | 'calendarEventParticipant',
    personId?: string,
    workspaceMemberId?: string,
  ) {
    const participantRepository =
      await this.getParticipantRepository(objectMetadataName);

    const workspaceId = this.scopedWorkspaceContextFactory.create().workspaceId;

    if (!workspaceId) {
      throw new Error('Workspace ID is required');
    }

    const participantsToUpdate = await participantRepository.find({
      where: {
        handle: Equal(handle),
      },
    });

    const participantIdsToUpdate = participantsToUpdate.map(
      (participant) => participant.id,
    );

    if (personId) {
      await participantRepository.update(
        {
          id: Any(participantIdsToUpdate),
        },
        {
          person: {
            id: personId,
          },
        },
      );

      const updatedParticipants = await participantRepository.find({
        where: {
          id: Any(participantIdsToUpdate),
        },
      });

      this.workspaceEventEmitter.emitCustomBatchEvent(
        `${objectMetadataName}_matched`,
        [
          {
            workspaceId,
            name: `${objectMetadataName}_matched`,
            workspaceMemberId: null,
            participants: updatedParticipants,
          },
        ],
        workspaceId,
      );
    }

    if (workspaceMemberId) {
      await participantRepository.update(
        {
          id: Any(participantIdsToUpdate),
        },
        {
          workspaceMember: {
            id: workspaceMemberId,
          },
        },
      );
    }
  }

  public async unmatchParticipants(
    handle: string,
    objectMetadataName: 'messageParticipant' | 'calendarEventParticipant',
    personId?: string,
    workspaceMemberId?: string,
  ) {
    const participantRepository =
      await this.getParticipantRepository(objectMetadataName);

    if (personId) {
      await participantRepository.update(
        {
          handle: Equal(handle),
        },
        {
          person: null,
        },
      );
    }
    if (workspaceMemberId) {
      await participantRepository.update(
        {
          handle: Equal(handle),
        },
        {
          workspaceMember: null,
        },
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service to execute a workflow step for sending an email, involving validation, sanitization, and sending the email through a messaging service.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import DOMPurify from 'dompurify';
import { JSDOM } from 'jsdom';
import { isDefined, isValidUuid } from 'twenty-shared';
import { z } from 'zod';

import { WorkflowExecutor } from 'src/modules/workflow/workflow-executor/interfaces/workflow-executor.interface';

import { ScopedWorkspaceContextFactory } from 'src/engine/twenty-orm/factories/scoped-workspace-context.factory';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { MessagingSendMessageService } from 'src/modules/messaging/message-import-manager/services/messaging-send-message.service';
import {
  WorkflowStepExecutorException,
  WorkflowStepExecutorExceptionCode,
} from 'src/modules/workflow/workflow-executor/exceptions/workflow-step-executor.exception';
import { WorkflowExecutorInput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-input';
import { WorkflowExecutorOutput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-output.type';
import { resolveInput } from 'src/modules/workflow/workflow-executor/utils/variable-resolver.util';
import {
  SendEmailActionException,
  SendEmailActionExceptionCode,
} from 'src/modules/workflow/workflow-executor/workflow-actions/mail-sender/exceptions/send-email-action.exception';
import { isWorkflowSendEmailAction } from 'src/modules/workflow/workflow-executor/workflow-actions/mail-sender/guards/is-workflow-send-email-action.guard';
import { WorkflowSendEmailActionInput } from 'src/modules/workflow/workflow-executor/workflow-actions/mail-sender/types/workflow-send-email-action-input.type';

export type WorkflowSendEmailStepOutputSchema = {
  success: boolean;
};

@Injectable()
export class SendEmailWorkflowAction implements WorkflowExecutor {
  private readonly logger = new Logger(SendEmailWorkflowAction.name);
  constructor(
    private readonly scopedWorkspaceContextFactory: ScopedWorkspaceContextFactory,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    private readonly sendMessageService: MessagingSendMessageService,
  ) {}

  private async getConnectedAccount(connectedAccountId: string) {
    if (!isValidUuid(connectedAccountId)) {
      throw new SendEmailActionException(
        `Connected Account ID is not a valid UUID`,
        SendEmailActionExceptionCode.INVALID_CONNECTED_ACCOUNT_ID,
      );
    }

    const { workspaceId } = this.scopedWorkspaceContextFactory.create();

    if (!workspaceId) {
      throw new WorkflowStepExecutorException(
        'Scoped workspace not found',
        WorkflowStepExecutorExceptionCode.SCOPED_WORKSPACE_NOT_FOUND,
      );
    }

    const connectedAccountRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace<ConnectedAccountWorkspaceEntity>(
        workspaceId,
        'connectedAccount',
      );
    const connectedAccount = await connectedAccountRepository.findOneBy({
      id: connectedAccountId,
    });

    if (!isDefined(connectedAccount)) {
      throw new SendEmailActionException(
        `Connected Account '${connectedAccountId}' not found`,
        SendEmailActionExceptionCode.CONNECTED_ACCOUNT_NOT_FOUND,
      );
    }

    return connectedAccount;
  }

  async execute({
    currentStepIndex,
    steps,
    context,
  }: WorkflowExecutorInput): Promise<WorkflowExecutorOutput> {
    const step = steps[currentStepIndex];

    if (!isWorkflowSendEmailAction(step)) {
      throw new WorkflowStepExecutorException(
        'Step is not a send email action',
        WorkflowStepExecutorExceptionCode.INVALID_STEP_TYPE,
      );
    }

    const connectedAccount = await this.getConnectedAccount(
      step.settings.input.connectedAccountId,
    );

    const workflowActionInput = resolveInput(
      step.settings.input,
      context,
    ) as WorkflowSendEmailActionInput;

    const { email, body, subject } = workflowActionInput;

    const emailSchema = z.string().trim().email('Invalid email');

    const result = emailSchema.safeParse(email);

    if (!result.success) {
      throw new SendEmailActionException(
        `Email '${email}' invalid`,
        SendEmailActionExceptionCode.INVALID_EMAIL,
      );
    }

    const window = new JSDOM('').window;
    const purify = DOMPurify(window);
    const safeBody = purify.sanitize(body || '');
    const safeSubject = purify.sanitize(subject || '');

    await this.sendMessageService.sendMessage(
      {
        to: email,
        subject: safeSubject,
        body: safeBody,
      },
      connectedAccount,
    );

    this.logger.log(`Email sent successfully`);

    return {
      result: { success: true } satisfies WorkflowSendEmailStepOutputSchema,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS processor that handles workflow version events (create, status update, delete) by updating workflow statuses and publishing serverless functions as needed.
Code Snippet:
import { Logger, Scope } from '@nestjs/common';

import { isDefined } from 'twenty-shared';

import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { ServerlessFunctionService } from 'src/engine/metadata-modules/serverless-function/serverless-function.service';
import { WorkspaceRepository } from 'src/engine/twenty-orm/repository/workspace.repository';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import {
  WorkflowVersionStatus,
  WorkflowVersionWorkspaceEntity,
} from 'src/modules/workflow/common/standard-objects/workflow-version.workspace-entity';
import { WorkflowWorkspaceEntity } from 'src/modules/workflow/common/standard-objects/workflow.workspace-entity';
import {
  WorkflowAction,
  WorkflowActionType,
} from 'src/modules/workflow/workflow-executor/workflow-actions/types/workflow-action.type';
import { getStatusCombinationFromArray } from 'src/modules/workflow/workflow-status/utils/get-status-combination-from-array.util';
import { getStatusCombinationFromUpdate } from 'src/modules/workflow/workflow-status/utils/get-status-combination-from-update.util';
import { getWorkflowStatusesFromCombination } from 'src/modules/workflow/workflow-status/utils/get-statuses-from-combination.util';
import { ServerlessFunctionExceptionCode } from 'src/engine/metadata-modules/serverless-function/serverless-function.exception';

export enum WorkflowVersionEventType {
  CREATE = 'CREATE',
  STATUS_UPDATE = 'STATUS_UPDATE',
  DELETE = 'DELETE',
}

export type WorkflowVersionBatchEvent = {
  workspaceId: string;
} & (
  | WorkflowVersionBatchCreateEvent
  | WorkflowVersionBatchStatusUpdate
  | WorkflowVersionBatchDelete
);

export type WorkflowVersionBatchCreateEvent = {
  type: WorkflowVersionEventType.CREATE;
} & {
  workflowIds: string[];
};

export type WorkflowVersionStatusUpdate = {
  workflowId: string;
  workflowVersionId: string;
  previousStatus: WorkflowVersionStatus;
  newStatus: WorkflowVersionStatus;
};

export type WorkflowVersionBatchStatusUpdate = {
  type: WorkflowVersionEventType.STATUS_UPDATE;
} & {
  statusUpdates: WorkflowVersionStatusUpdate[];
};

export type WorkflowVersionBatchDelete = {
  type: WorkflowVersionEventType.DELETE;
} & { workflowIds: string[] };

@Processor({ queueName: MessageQueue.workflowQueue, scope: Scope.REQUEST })
export class WorkflowStatusesUpdateJob {
  protected readonly logger = new Logger(WorkflowStatusesUpdateJob.name);

  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly serverlessFunctionService: ServerlessFunctionService,
  ) {}

  @Process(WorkflowStatusesUpdateJob.name)
  async handle(event: WorkflowVersionBatchEvent): Promise<void> {
    switch (event.type) {
      case WorkflowVersionEventType.CREATE:
        await Promise.all(
          event.workflowIds.map((workflowId) =>
            this.handleWorkflowVersionCreated(workflowId),
          ),
        );
        break;
      case WorkflowVersionEventType.STATUS_UPDATE:
        await Promise.all(
          event.statusUpdates.map((statusUpdate) =>
            this.handleWorkflowVersionStatusUpdated(
              statusUpdate,
              event.workspaceId,
            ),
          ),
        );
        break;
      case WorkflowVersionEventType.DELETE:
        await Promise.all(
          event.workflowIds.map((workflowId) =>
            this.handleWorkflowVersionDeleted(workflowId),
          ),
        );
        break;
      default:
        break;
    }
  }

  private async handleWorkflowVersionCreated(
    workflowId: string,
  ): Promise<void> {
    const workflowRepository =
      await this.twentyORMManager.getRepository<WorkflowWorkspaceEntity>(
        'workflow',
      );

    const workflow = await workflowRepository.findOneOrFail({
      where: {
        id: workflowId,
      },
    });

    const currentWorkflowStatusCombination = getStatusCombinationFromArray(
      workflow.statuses || [],
    );

    const newWorkflowStatusCombination = getStatusCombinationFromUpdate(
      currentWorkflowStatusCombination,
      undefined,
      WorkflowVersionStatus.DRAFT,
    );

    if (newWorkflowStatusCombination === currentWorkflowStatusCombination) {
      return;
    }

    await workflowRepository.update(
      {
        id: workflow.id,
      },
      {
        statuses: getWorkflowStatusesFromCombination(
          newWorkflowStatusCombination,
        ),
      },
    );
  }

  private async handlePublishServerlessFunction({
    statusUpdate,
    workspaceId,
    workflowVersion,
    workflowVersionRepository,
  }: {
    statusUpdate: WorkflowVersionStatusUpdate;
    workspaceId: string;
    workflowVersion: WorkflowVersionWorkspaceEntity;
    workflowVersionRepository: WorkspaceRepository<WorkflowVersionWorkspaceEntity>;
  }) {
    const shouldComputeNewSteps =
      statusUpdate.newStatus === WorkflowVersionStatus.ACTIVE &&
      isDefined(workflowVersion.steps) &&
      workflowVersion.steps.filter(
        (step) => step.type === WorkflowActionType.CODE,
      ).length > 0;

    if (shouldComputeNewSteps) {
      const newSteps: WorkflowAction[] = [];

      for (const step of workflowVersion.steps || []) {
        const newStep = { ...step };

        if (step.type === WorkflowActionType.CODE) {
          try {
            await this.serverlessFunctionService.publishOneServerlessFunction(
              step.settings.input.serverlessFunctionId,
              workspaceId,
            );
          } catch (e) {
            // publishOneServerlessFunction throws if no change have been
            // applied between draft and lastPublished version.
            // If no change have been applied, we just use the same
            // serverless function version
            if (
              e.code !==
              ServerlessFunctionExceptionCode.SERVERLESS_FUNCTION_CODE_UNCHANGED
            ) {
              this.logger.error(
                `Error while publishing serverless function '${step.settings.input.serverlessFunctionId}': ${e}`,
              );
            }
          }

          const serverlessFunction =
            await this.serverlessFunctionService.findOneOrFail({
              id: step.settings.input.serverlessFunctionId,
              workspaceId,
            });

          const newStepSettings = { ...step.settings };

          newStepSettings.input.serverlessFunctionVersion =
            serverlessFunction.latestVersion;

          newStep.settings = newStepSettings;
        }
        newSteps.push(newStep);
      }

      await workflowVersionRepository.update(statusUpdate.workflowVersionId, {
        steps: newSteps,
      });
    }
  }

  private async handleWorkflowVersionStatusUpdated(
    statusUpdate: WorkflowVersionStatusUpdate,
    workspaceId: string,
  ): Promise<void> {
    const workflowRepository =
      await this.twentyORMManager.getRepository<WorkflowWorkspaceEntity>(
        'workflow',
      );

    const workflowVersionRepository =
      await this.twentyORMManager.getRepository<WorkflowVersionWorkspaceEntity>(
        'workflowVersion',
      );

    const workflow = await workflowRepository.findOneOrFail({
      where: {
        id: statusUpdate.workflowId,
      },
    });

    const workflowVersion = await workflowVersionRepository.findOneOrFail({
      where: { id: statusUpdate.workflowVersionId },
    });

    await this.handlePublishServerlessFunction({
      workflowVersion,
      workflowVersionRepository,
      workspaceId,
      statusUpdate,
    });

    const currentWorkflowStatusCombination = getStatusCombinationFromArray(
      workflow.statuses || [],
    );

    const newWorkflowStatusCombination = getStatusCombinationFromUpdate(
      currentWorkflowStatusCombination,
      statusUpdate.previousStatus,
      statusUpdate.newStatus,
    );

    if (newWorkflowStatusCombination === currentWorkflowStatusCombination) {
      return;
    }

    await workflowRepository.update(
      {
        id: statusUpdate.workflowId,
      },
      {
        statuses: getWorkflowStatusesFromCombination(
          newWorkflowStatusCombination,
        ),
      },
    );
  }

  private async handleWorkflowVersionDeleted(
    workflowId: string,
  ): Promise<void> {
    const workflowRepository =
      await this.twentyORMManager.getRepository<WorkflowWorkspaceEntity>(
        'workflow',
      );

    const workflow = await workflowRepository.findOneOrFail({
      where: {
        id: workflowId,
      },
    });

    const currentWorkflowStatusCombination = getStatusCombinationFromArray(
      workflow.statuses || [],
    );

    const newWorkflowStatusCombination = getStatusCombinationFromUpdate(
      currentWorkflowStatusCombination,
      WorkflowVersionStatus.DRAFT,
      undefined,
    );

    if (newWorkflowStatusCombination === currentWorkflowStatusCombination) {
      return;
    }

    await workflowRepository.update(
      {
        id: workflowId,
      },
      {
        statuses: getWorkflowStatusesFromCombination(
          newWorkflowStatusCombination,
        ),
      },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener for workflow version events that sends updates to a message queue based on create, update, and delete actions.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  WorkflowVersionStatus,
  WorkflowVersionWorkspaceEntity,
} from 'src/modules/workflow/common/standard-objects/workflow-version.workspace-entity';
import {
  WorkflowStatusesUpdateJob,
  WorkflowVersionBatchEvent,
  WorkflowVersionEventType,
  WorkflowVersionStatusUpdate,
} from 'src/modules/workflow/workflow-status/jobs/workflow-statuses-update.job';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { WORKFLOW_VERSION_STATUS_UPDATED } from 'src/modules/workflow/workflow-status/constants/workflow-version-status-updated.constants';
import { OnCustomBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-custom-batch-event.decorator';

@Injectable()
export class WorkflowVersionStatusListener {
  constructor(
    @InjectMessageQueue(MessageQueue.workflowQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('workflowVersion', DatabaseEventAction.CREATED)
  async handleWorkflowVersionCreated(
    batchEvent: WorkspaceEventBatch<
      ObjectRecordCreateEvent<WorkflowVersionWorkspaceEntity>
    >,
  ): Promise<void> {
    const workflowIds = batchEvent.events
      .filter(
        (event) =>
          !event.properties.after.status ||
          event.properties.after.status === WorkflowVersionStatus.DRAFT,
      )
      .map((event) => event.properties.after.workflowId);

    if (workflowIds.length === 0) {
      return;
    }

    await this.messageQueueService.add<WorkflowVersionBatchEvent>(
      WorkflowStatusesUpdateJob.name,
      {
        type: WorkflowVersionEventType.CREATE,
        workspaceId: batchEvent.workspaceId,
        workflowIds,
      },
    );
  }

  @OnCustomBatchEvent(WORKFLOW_VERSION_STATUS_UPDATED)
  async handleWorkflowVersionUpdated(
    batchEvent: WorkspaceEventBatch<WorkflowVersionStatusUpdate>,
  ): Promise<void> {
    await this.messageQueueService.add<WorkflowVersionBatchEvent>(
      WorkflowStatusesUpdateJob.name,
      {
        type: WorkflowVersionEventType.STATUS_UPDATE,
        workspaceId: batchEvent.workspaceId,
        statusUpdates: batchEvent.events,
      },
    );
  }

  @OnDatabaseBatchEvent('workflowVersion', DatabaseEventAction.DELETED)
  async handleWorkflowVersionDeleted(
    batchEvent: WorkspaceEventBatch<
      ObjectRecordDeleteEvent<WorkflowVersionWorkspaceEntity>
    >,
  ): Promise<void> {
    const workflowIds = batchEvent.events
      .filter(
        (event) =>
          event.properties.before.status === WorkflowVersionStatus.DRAFT,
      )
      .map((event) => event.properties.before.workflowId);

    if (workflowIds.length === 0) {
      return;
    }

    await this.messageQueueService.add<WorkflowVersionBatchEvent>(
      WorkflowStatusesUpdateJob.name,
      {
        type: WorkflowVersionEventType.DELETE,
        workspaceId: batchEvent.workspaceId,
        workflowIds,
      },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service for running and resuming workflows, checking billing usage, and managing workflow runs via a message queue.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { BillingUsageService } from 'src/engine/core-modules/billing/services/billing-usage.service';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { ActorMetadata } from 'src/engine/metadata-modules/field-metadata/composite-types/actor.composite-type';
import {
  RunWorkflowJob,
  RunWorkflowJobData,
} from 'src/modules/workflow/workflow-runner/jobs/run-workflow.job';
import { WorkflowRunWorkspaceService } from 'src/modules/workflow/workflow-runner/workflow-run/workflow-run.workspace-service';

@Injectable()
export class WorkflowRunnerWorkspaceService {
  private readonly logger = new Logger(WorkflowRunnerWorkspaceService.name);
  constructor(
    private readonly workflowRunWorkspaceService: WorkflowRunWorkspaceService,
    @InjectMessageQueue(MessageQueue.workflowQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly billingUsageService: BillingUsageService,
  ) {}

  async run(
    workspaceId: string,
    workflowVersionId: string,
    payload: object,
    source: ActorMetadata,
  ) {
    const canFeatureBeUsed =
      await this.billingUsageService.canFeatureBeUsed(workspaceId);

    if (!canFeatureBeUsed) {
      this.logger.log(
        'Cannot execute billed function, there is no subscription for this workspace',
      );
    }
    const workflowRunId =
      await this.workflowRunWorkspaceService.createWorkflowRun({
        workflowVersionId,
        createdBy: source,
      });

    await this.messageQueueService.add<RunWorkflowJobData>(
      RunWorkflowJob.name,
      {
        workspaceId,
        payload: payload,
        workflowRunId,
      },
    );

    return { workflowRunId };
  }

  async resume({
    workspaceId,
    workflowRunId,
    lastExecutedStepId,
  }: {
    workspaceId: string;
    workflowRunId: string;
    lastExecutedStepId: string;
  }) {
    await this.messageQueueService.add<RunWorkflowJobData>(
      RunWorkflowJob.name,
      {
        workspaceId,
        workflowRunId,
        lastExecutedStepId,
      },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service that listens for database events (create, update, delete, destroy) and triggers workflows based on these events if a feature flag is enabled.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { ObjectRecordDestroyEvent } from 'src/engine/core-modules/event-emitter/types/object-record-destroy.event';
import { ObjectRecordUpdateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-update.event';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { FeatureFlagService } from 'src/engine/core-modules/feature-flag/services/feature-flag.service';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { WorkflowEventListenerWorkspaceEntity } from 'src/modules/workflow/common/standard-objects/workflow-event-listener.workspace-entity';
import {
  WorkflowTriggerJob,
  WorkflowTriggerJobData,
} from 'src/modules/workflow/workflow-trigger/jobs/workflow-trigger.job';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class DatabaseEventTriggerListener {
  private readonly logger = new Logger('DatabaseEventTriggerListener');

  constructor(
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    @InjectMessageQueue(MessageQueue.workflowQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly isFeatureFlagEnabledService: FeatureFlagService,
  ) {}

  @OnDatabaseBatchEvent('*', DatabaseEventAction.CREATED)
  async handleObjectRecordCreateEvent(
    payload: WorkspaceEventBatch<ObjectRecordCreateEvent>,
  ) {
    await this.handleEvent(payload);
  }

  @OnDatabaseBatchEvent('*', DatabaseEventAction.UPDATED)
  async handleObjectRecordUpdateEvent(
    payload: WorkspaceEventBatch<ObjectRecordUpdateEvent>,
  ) {
    await this.handleEvent(payload);
  }

  @OnDatabaseBatchEvent('*', DatabaseEventAction.DELETED)
  async handleObjectRecordDeleteEvent(
    payload: WorkspaceEventBatch<ObjectRecordDeleteEvent>,
  ) {
    await this.handleEvent(payload);
  }

  @OnDatabaseBatchEvent('*', DatabaseEventAction.DESTROYED)
  async handleObjectRecordDestroyEvent(
    payload: WorkspaceEventBatch<ObjectRecordDestroyEvent>,
  ) {
    await this.handleEvent(payload);
  }

  private async handleEvent(
    payload: WorkspaceEventBatch<
      | ObjectRecordCreateEvent
      | ObjectRecordUpdateEvent
      | ObjectRecordDeleteEvent
      | ObjectRecordDestroyEvent
    >,
  ) {
    const workspaceId = payload.workspaceId;
    const eventName = payload.name;

    if (!workspaceId || !eventName) {
      this.logger.error(
        `Missing workspaceId or eventName in payload ${JSON.stringify(
          payload,
        )}`,
      );

      return;
    }

    const isWorkflowEnabled =
      await this.isFeatureFlagEnabledService.isFeatureEnabled(
        FeatureFlagKey.IsWorkflowEnabled,
        workspaceId,
      );

    if (!isWorkflowEnabled) {
      return;
    }

    const workflowEventListenerRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace<WorkflowEventListenerWorkspaceEntity>(
        workspaceId,
        'workflowEventListener',
      );

    const eventListeners = await workflowEventListenerRepository.find({
      where: {
        eventName,
      },
    });

    for (const eventListener of eventListeners) {
      for (const eventPayload of payload.events) {
        this.messageQueueService.add<WorkflowTriggerJobData>(
          WorkflowTriggerJob.name,
          {
            workspaceId,
            workflowId: eventListener.workflowId,
            payload: eventPayload,
          },
          { retryLimit: 3 },
        );
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a processor that handles workspace events to create audit logs from internal events.
Code Snippet:
import { ObjectRecordEvent } from 'src/engine/core-modules/event-emitter/types/object-record-event.event';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { InjectObjectMetadataRepository } from 'src/engine/object-metadata-repository/object-metadata-repository.decorator';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { AuditLogRepository } from 'src/modules/timeline/repositiories/audit-log.repository';
import { AuditLogWorkspaceEntity } from 'src/modules/timeline/standard-objects/audit-log.workspace-entity';
import { WorkspaceMemberRepository } from 'src/modules/workspace-member/repositories/workspace-member.repository';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';

@Processor(MessageQueue.entityEventsToDbQueue)
export class CreateAuditLogFromInternalEvent {
  constructor(
    @InjectObjectMetadataRepository(WorkspaceMemberWorkspaceEntity)
    private readonly workspaceMemberService: WorkspaceMemberRepository,
    @InjectObjectMetadataRepository(AuditLogWorkspaceEntity)
    private readonly auditLogRepository: AuditLogRepository,
  ) {}

  @Process(CreateAuditLogFromInternalEvent.name)
  async handle(
    workspaceEventBatch: WorkspaceEventBatch<ObjectRecordEvent>,
  ): Promise<void> {
    for (const eventData of workspaceEventBatch.events) {
      let workspaceMemberId: string | null = null;

      if (eventData.userId) {
        const workspaceMember = await this.workspaceMemberService.getByIdOrFail(
          eventData.userId,
          workspaceEventBatch.workspaceId,
        );

        workspaceMemberId = workspaceMember.id;
      }

      await this.auditLogRepository.insert(
        workspaceEventBatch.name,
        'diff' in eventData.properties
          ? {
              // we remove "before" and "after" property for a cleaner/slimmer event payload
              diff: eventData.properties.diff,
            }
          : eventData.properties,
        workspaceMemberId,
        workspaceEventBatch.name.split('.')[0],
        eventData.objectMetadata.id,
        eventData.recordId,
        workspaceEventBatch.workspaceId,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a processor class to handle workspace events by upserting timeline activities based on specific conditions.
Code Snippet:
import { ObjectRecordNonDestructiveEvent } from 'src/engine/core-modules/event-emitter/types/object-record-non-destructive-event';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { InjectObjectMetadataRepository } from 'src/engine/object-metadata-repository/object-metadata-repository.decorator';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { TimelineActivityService } from 'src/modules/timeline/services/timeline-activity.service';
import { WorkspaceMemberRepository } from 'src/modules/workspace-member/repositories/workspace-member.repository';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';

@Processor(MessageQueue.entityEventsToDbQueue)
export class UpsertTimelineActivityFromInternalEvent {
  constructor(
    @InjectObjectMetadataRepository(WorkspaceMemberWorkspaceEntity)
    private readonly workspaceMemberService: WorkspaceMemberRepository,
    private readonly timelineActivityService: TimelineActivityService,
  ) {}

  @Process(UpsertTimelineActivityFromInternalEvent.name)
  async handle(
    workspaceEventBatch: WorkspaceEventBatch<ObjectRecordNonDestructiveEvent>,
  ): Promise<void> {
    for (const eventData of workspaceEventBatch.events) {
      if (eventData.userId) {
        const workspaceMember = await this.workspaceMemberService.getByIdOrFail(
          eventData.userId,
          workspaceEventBatch.workspaceId,
        );

        eventData.workspaceMemberId = workspaceMember.id;
      }

      // Temporary
      // We ignore every that is not a LinkedObject or a Business Object
      if (
        eventData.objectMetadata.isSystem &&
        eventData.objectMetadata.nameSingular !== 'noteTarget' &&
        eventData.objectMetadata.nameSingular !== 'taskTarget'
      ) {
        continue;
      }

      await this.timelineActivityService.upsertEvent({
        event:
          // we remove "before" and "after" property for a cleaner/slimmer event payload
          'diff' in eventData.properties && eventData.properties.diff
            ? {
                ...eventData,
                properties: {
                  diff: eventData.properties.diff,
                },
              }
            : eventData,
        eventName: workspaceEventBatch.name,
        workspaceId: workspaceEventBatch.workspaceId,
      });
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for handling timeline activities, transforming events into timeline activities, and upserting them into a repository.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordNonDestructiveEvent } from 'src/engine/core-modules/event-emitter/types/object-record-non-destructive-event';
import { ObjectRecordBaseEvent } from 'src/engine/core-modules/event-emitter/types/object-record.base.event';
import { InjectObjectMetadataRepository } from 'src/engine/object-metadata-repository/object-metadata-repository.decorator';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';
import { TimelineActivityRepository } from 'src/modules/timeline/repositiories/timeline-activity.repository';
import { TimelineActivityWorkspaceEntity } from 'src/modules/timeline/standard-objects/timeline-activity.workspace-entity';

type TimelineActivity = Omit<ObjectRecordNonDestructiveEvent, 'properties'> & {
  name: string;
  objectName?: string;
  linkedRecordCachedName?: string;
  linkedRecordId?: string;
  linkedObjectMetadataId?: string;
  properties: Record<string, any>; // more relaxed conditions than for internal events
};

@Injectable()
export class TimelineActivityService {
  constructor(
    @InjectObjectMetadataRepository(TimelineActivityWorkspaceEntity)
    private readonly timelineActivityRepository: TimelineActivityRepository,
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
  ) {}

  private targetObjects: Record<string, string> = {
    note: 'noteTarget',
    task: 'taskTarget',
  };

  async upsertEvent({
    event,
    eventName,
    workspaceId,
  }: {
    event: ObjectRecordBaseEvent;
    eventName: string;
    workspaceId: string;
  }) {
    const timelineActivities = await this.transformEventToTimelineActivities({
      event,
      workspaceId,
      eventName,
    });

    if (!timelineActivities || timelineActivities.length === 0) return;

    for (const timelineActivity of timelineActivities) {
      await this.timelineActivityRepository.upsertOne(
        timelineActivity.name,
        timelineActivity.properties,
        timelineActivity.objectName ?? event.objectMetadata.nameSingular,
        timelineActivity.recordId,
        workspaceId,
        timelineActivity.workspaceMemberId,
        timelineActivity.linkedRecordCachedName,
        timelineActivity.linkedRecordId,
        timelineActivity.linkedObjectMetadataId,
      );
    }
  }

  private async transformEventToTimelineActivities({
    event,
    workspaceId,
    eventName,
  }: {
    event: ObjectRecordBaseEvent;
    workspaceId: string;
    eventName: string;
  }): Promise<TimelineActivity[] | undefined> {
    if (['note', 'task'].includes(event.objectMetadata.nameSingular)) {
      const linkedTimelineActivities = await this.getLinkedTimelineActivities({
        event,
        workspaceId,
        eventName,
      });

      // 2 timelines, one for the linked object and one for the task/note
      if (linkedTimelineActivities && linkedTimelineActivities?.length > 0)
        return [
          ...linkedTimelineActivities,
          { ...event, name: eventName },
        ] satisfies TimelineActivity[];
    }

    if (
      ['noteTarget', 'taskTarget', 'messageParticipant'].includes(
        event.objectMetadata.nameSingular,
      )
    ) {
      return await this.getLinkedTimelineActivities({
        event,
        workspaceId,
        eventName,
      });
    }

    return [{ ...event, name: eventName }] satisfies TimelineActivity[];
  }

  private async getLinkedTimelineActivities({
    event,
    workspaceId,
    eventName,
  }: {
    event: ObjectRecordBaseEvent;
    workspaceId: string;
    eventName: string;
  }): Promise<TimelineActivity[] | undefined> {
    const dataSourceSchema =
      this.workspaceDataSourceService.getSchemaName(workspaceId);

    switch (event.objectMetadata.nameSingular) {
      case 'noteTarget':
        return this.computeActivityTargets({
          event,
          dataSourceSchema,
          activityType: 'note',
          eventName,
          workspaceId,
        });
      case 'taskTarget':
        return this.computeActivityTargets({
          event,
          dataSourceSchema,
          activityType: 'task',
          eventName,
          workspaceId,
        });
      case 'note':
      case 'task':
        return this.computeActivities({
          event,
          dataSourceSchema,
          activityType: event.objectMetadata.nameSingular,
          eventName,
          workspaceId,
        });
      default:
        return [];
    }
  }

  private async computeActivities({
    event,
    dataSourceSchema,
    activityType,
    eventName,
    workspaceId,
  }: {
    event: ObjectRecordBaseEvent;
    dataSourceSchema: string;
    activityType: string;
    eventName: string;
    workspaceId: string;
  }) {
    const activityTargets =
      await this.workspaceDataSourceService.executeRawQuery(
        `SELECT * FROM ${dataSourceSchema}."${this.targetObjects[activityType]}"
         WHERE "${activityType}Id" = $1`,
        [event.recordId],
        workspaceId,
      );

    const activity = await this.workspaceDataSourceService.executeRawQuery(
      `SELECT * FROM ${dataSourceSchema}."${activityType}"
       WHERE "id" = $1`,
      [event.recordId],
      workspaceId,
    );

    if (activityTargets.length === 0) return;
    if (activity.length === 0) return;

    return activityTargets
      .map((activityTarget) => {
        const targetColumn: string[] = Object.entries(activityTarget)
          .map(([columnName, columnValue]: [string, string]) => {
            if (
              columnName === activityType + 'Id' ||
              !columnName.endsWith('Id')
            )
              return;
            if (columnValue === null) return;

            return columnName;
          })
          .filter((column): column is string => column !== undefined);

        if (targetColumn.length === 0) return;

        return {
          ...event,
          name: 'linked-' + eventName,
          objectName: targetColumn[0].replace(/Id$/, ''),
          recordId: activityTarget[targetColumn[0]],
          linkedRecordCachedName: activity[0].title,
          linkedRecordId: activity[0].id,
          linkedObjectMetadataId: event.objectMetadata.id,
        } satisfies TimelineActivity;
      })
      .filter((event): event is TimelineActivity => event !== undefined);
  }

  private async computeActivityTargets({
    event,
    dataSourceSchema,
    activityType,
    eventName,
    workspaceId,
  }: {
    event: ObjectRecordBaseEvent;
    dataSourceSchema: string;
    activityType: string;
    eventName: string;
    workspaceId: string;
  }): Promise<TimelineActivity[] | undefined> {
    const activityTarget =
      await this.workspaceDataSourceService.executeRawQuery(
        `SELECT * FROM ${dataSourceSchema}."${this.targetObjects[activityType]}"
         WHERE "id" = $1`,
        [event.recordId],
        workspaceId,
      );

    if (activityTarget.length === 0) return;

    const activity = await this.workspaceDataSourceService.executeRawQuery(
      `SELECT * FROM ${dataSourceSchema}."${activityType}"
       WHERE "id" = $1`,
      [activityTarget[0].activityId],
      workspaceId,
    );

    if (activity.length === 0) return;

    const activityObjectMetadataId = event.objectMetadata.fields.find(
      (field) => field.name === activityType,
    )?.toRelationMetadata?.fromObjectMetadataId;

    const targetColumn: string[] = Object.entries(activityTarget[0])
      .map(([columnName, columnValue]: [string, string]) => {
        if (columnName === activityType + 'Id' || !columnName.endsWith('Id'))
          return;
        if (columnValue === null) return;

        return columnName;
      })
      .filter((column): column is string => column !== undefined);

    if (targetColumn.length === 0) return;

    return [
      {
        ...event,
        name: 'linked-' + eventName,
        properties: {},
        objectName: targetColumn[0].replace(/Id$/, ''),
        recordId: activityTarget[0][targetColumn[0]],
        linkedRecordCachedName: activity[0].title,
        linkedRecordId: activity[0].id,
        linkedObjectMetadataId: activityObjectMetadataId,
      } satisfies TimelineActivity,
    ];
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a job processor that creates companies and contacts after a sync operation based on message channel and participant data.
Code Snippet:
import { Logger } from '@nestjs/common';

import { Any, IsNull } from 'typeorm';

import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { FieldActorSource } from 'src/engine/metadata-modules/field-metadata/composite-types/actor.composite-type';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { CreateCompanyAndContactService } from 'src/modules/contact-creation-manager/services/create-company-and-contact.service';
import { MessageDirection } from 'src/modules/messaging/common/enums/message-direction.enum';
import {
  MessageChannelContactAutoCreationPolicy,
  MessageChannelWorkspaceEntity,
} from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import { MessageParticipantWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-participant.workspace-entity';

export type MessagingCreateCompanyAndContactAfterSyncJobData = {
  workspaceId: string;
  messageChannelId: string;
};

@Processor(MessageQueue.messagingQueue)
export class MessagingCreateCompanyAndContactAfterSyncJob {
  private readonly logger = new Logger(
    MessagingCreateCompanyAndContactAfterSyncJob.name,
  );
  constructor(
    private readonly createCompanyAndContactService: CreateCompanyAndContactService,
    private readonly twentyORMManager: TwentyORMManager,
  ) {}

  @Process(MessagingCreateCompanyAndContactAfterSyncJob.name)
  async handle(
    data: MessagingCreateCompanyAndContactAfterSyncJobData,
  ): Promise<void> {
    this.logger.log(
      `create contacts and companies after sync for workspace ${data.workspaceId} and messageChannel ${data.messageChannelId}`,
    );
    const { workspaceId, messageChannelId } = data;

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    const messageChannel = await messageChannelRepository.findOneOrFail({
      where: {
        id: messageChannelId,
      },
    });

    const { contactAutoCreationPolicy, connectedAccountId } = messageChannel;

    if (
      contactAutoCreationPolicy === MessageChannelContactAutoCreationPolicy.NONE
    ) {
      return;
    }

    const connectedAccountRepository =
      await this.twentyORMManager.getRepository<ConnectedAccountWorkspaceEntity>(
        'connectedAccount',
      );

    const connectedAccount = await connectedAccountRepository.findOne({
      where: {
        id: connectedAccountId,
      },
    });

    if (!connectedAccount) {
      throw new Error(
        `Connected account with id ${connectedAccountId} not found in workspace ${workspaceId}`,
      );
    }

    const messageParticipantRepository =
      await this.twentyORMManager.getRepository<MessageParticipantWorkspaceEntity>(
        'messageParticipant',
      );

    const directionFilter =
      contactAutoCreationPolicy ===
      MessageChannelContactAutoCreationPolicy.SENT_AND_RECEIVED
        ? Any([MessageDirection.INCOMING, MessageDirection.OUTGOING])
        : MessageDirection.OUTGOING;

    const contactsToCreate = await messageParticipantRepository.find({
      where: {
        message: {
          messageChannelMessageAssociations: {
            messageChannelId,
            direction: directionFilter,
          },
        },
        personId: IsNull(),
        workspaceMemberId: IsNull(),
      },
    });

    await this.createCompanyAndContactService.createCompaniesAndContactsAndUpdateParticipants(
      connectedAccount,
      contactsToCreate,
      workspaceId,
      FieldActorSource.EMAIL,
    );

    this.logger.log(
      `create contacts and companies after sync for workspace ${data.workspaceId} and messageChannel ${data.messageChannelId} done`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for saving message participants and matching them using an ORM manager and a match participant service.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { EntityManager } from 'typeorm';

import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { MatchParticipantService } from 'src/modules/match-participant/match-participant.service';
import { MessageParticipantWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-participant.workspace-entity';
import { ParticipantWithMessageId } from 'src/modules/messaging/message-import-manager/drivers/gmail/types/gmail-message.type';

@Injectable()
export class MessagingMessageParticipantService {
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly matchParticipantService: MatchParticipantService<MessageParticipantWorkspaceEntity>,
  ) {}

  public async saveMessageParticipants(
    participants: ParticipantWithMessageId[],
    transactionManager?: EntityManager,
  ): Promise<void> {
    const messageParticipantRepository =
      await this.twentyORMManager.getRepository<MessageParticipantWorkspaceEntity>(
        'messageParticipant',
      );

    const savedParticipants = await messageParticipantRepository.save(
      participants.map((participant) => {
        return {
          messageId: participant.messageId,
          role: participant.role,
          handle: participant.handle,
          displayName: participant.displayName,
        };
      }),
      {},
      transactionManager,
    );

    await this.matchParticipantService.matchParticipants(
      savedParticipants,
      'messageParticipant',
      transactionManager,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a command-line command to enqueue a job for importing a single message into a cache, using a message queue service.
Code Snippet:
import { Command, CommandRunner, Option } from 'nest-commander';

import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import {
  MessagingAddSingleMessageToCacheForImportJob,
  MessagingAddSingleMessageToCacheForImportJobData,
} from 'src/modules/messaging/message-import-manager/jobs/messaging-add-single-message-to-cache-for-import.job';

type MessagingSingleMessageImportCommandOptions = {
  messageExternalId: string;
  messageChannelId: string;
  workspaceId: string;
};

@Command({
  name: 'messaging:single-message-import',
  description: 'Enqueue a job to schedule the import of a single message',
})
export class MessagingSingleMessageImportCommand extends CommandRunner {
  constructor(
    @InjectMessageQueue(MessageQueue.messagingQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {
    super();
  }

  async run(
    _passedParam: string[],
    options: MessagingSingleMessageImportCommandOptions,
  ): Promise<void> {
    await this.messageQueueService.add<MessagingAddSingleMessageToCacheForImportJobData>(
      MessagingAddSingleMessageToCacheForImportJob.name,
      {
        messageExternalId: options.messageExternalId,
        messageChannelId: options.messageChannelId,
        workspaceId: options.workspaceId,
      },
    );
  }

  @Option({
    flags: '-m, --message-external-id [message_external_id]',
    description: 'Message external ID',
    required: true,
  })
  parseMessageId(value: string): string {
    return value;
  }

  @Option({
    flags: '-M, --message-channel-id [message_channel_id]',
    description: 'Message channel ID',
    required: true,
  })
  parseMessageChannelId(value: string): string {
    return value;
  }

  @Option({
    flags: '-w, --workspace-id [workspace_id]',
    description: 'Workspace ID',
    required: true,
  })
  parseWorkspaceId(value: string): string {
    return value;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS processor to handle stale messaging sync jobs, checking for ongoing syncs and resetting them if stale.
Code Snippet:
import { Logger, Scope } from '@nestjs/common';

import { In } from 'typeorm';

import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { MessageChannelSyncStatusService } from 'src/modules/messaging/common/services/message-channel-sync-status.service';
import {
  MessageChannelSyncStage,
  MessageChannelWorkspaceEntity,
} from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import { isSyncStale } from 'src/modules/messaging/message-import-manager/utils/is-sync-stale.util';

export type MessagingOngoingStaleJobData = {
  workspaceId: string;
};

@Processor({
  queueName: MessageQueue.messagingQueue,
  scope: Scope.REQUEST,
})
export class MessagingOngoingStaleJob {
  private readonly logger = new Logger(MessagingOngoingStaleJob.name);
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly messageChannelSyncStatusService: MessageChannelSyncStatusService,
  ) {}

  @Process(MessagingOngoingStaleJob.name)
  async handle(data: MessagingOngoingStaleJobData): Promise<void> {
    const { workspaceId } = data;

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    const messageChannels = await messageChannelRepository.find({
      where: {
        syncStage: In([
          MessageChannelSyncStage.MESSAGES_IMPORT_ONGOING,
          MessageChannelSyncStage.MESSAGE_LIST_FETCH_ONGOING,
        ]),
      },
    });

    for (const messageChannel of messageChannels) {
      if (
        messageChannel.syncStageStartedAt &&
        isSyncStale(messageChannel.syncStageStartedAt)
      ) {
        this.logger.log(
          `Sync for message channel ${messageChannel.id} and workspace ${workspaceId} is stale. Setting sync stage to MESSAGES_IMPORT_PENDING`,
        );

        await this.messageChannelSyncStatusService.resetSyncStageStartedAt([
          messageChannel.id,
        ]);

        switch (messageChannel.syncStage) {
          case MessageChannelSyncStage.MESSAGE_LIST_FETCH_ONGOING:
            await this.messageChannelSyncStatusService.schedulePartialMessageListFetch(
              [messageChannel.id],
            );
            break;
          case MessageChannelSyncStage.MESSAGES_IMPORT_ONGOING:
            await this.messageChannelSyncStatusService.scheduleMessagesImport([
              messageChannel.id,
            ]);
            break;
          default:
            break;
        }
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service that listens for database batch events related to the destruction of message channels and enqueues a job to clean the cache for these channels.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { MessageChannelWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import {
  MessagingCleanCacheJob,
  MessagingCleanCacheJobData,
} from 'src/modules/messaging/message-import-manager/jobs/messaging-clean-cache';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class MessagingMessageImportManagerMessageChannelListener {
  constructor(
    @InjectMessageQueue(MessageQueue.messagingQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('messageChannel', DatabaseEventAction.DESTROYED)
  async handleDestroyedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordDeleteEvent<MessageChannelWorkspaceEntity>
    >,
  ) {
    await Promise.all(
      payload.events.map((eventPayload) =>
        this.messageQueueService.add<MessagingCleanCacheJobData>(
          MessagingCleanCacheJob.name,
          {
            workspaceId: payload.workspaceId,
            messageChannelId: eventPayload.recordId,
          },
        ),
      ),
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for handling exceptions during message import operations, managing sync statuses, and interacting with a data repository.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { MessageChannelSyncStatusService } from 'src/modules/messaging/common/services/message-channel-sync-status.service';
import { MessageChannelWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import { MESSAGING_THROTTLE_MAX_ATTEMPTS } from 'src/modules/messaging/message-import-manager/constants/messaging-throttle-max-attempts';
import {
  MessageImportDriverException,
  MessageImportDriverExceptionCode,
} from 'src/modules/messaging/message-import-manager/drivers/exceptions/message-import-driver.exception';
import {
  MessageImportException,
  MessageImportExceptionCode,
} from 'src/modules/messaging/message-import-manager/exceptions/message-import.exception';

export enum MessageImportSyncStep {
  FULL_MESSAGE_LIST_FETCH = 'FULL_MESSAGE_LIST_FETCH',
  PARTIAL_MESSAGE_LIST_FETCH = 'PARTIAL_MESSAGE_LIST_FETCH',
  FULL_OR_PARTIAL_MESSAGE_LIST_FETCH = 'FULL_OR_PARTIAL_MESSAGE_LIST_FETCH',
  MESSAGES_IMPORT = 'MESSAGES_IMPORT',
}

@Injectable()
export class MessageImportExceptionHandlerService {
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly messageChannelSyncStatusService: MessageChannelSyncStatusService,
  ) {}

  public async handleDriverException(
    exception: MessageImportDriverException,
    syncStep: MessageImportSyncStep,
    messageChannel: Pick<
      MessageChannelWorkspaceEntity,
      'id' | 'throttleFailureCount'
    >,
    workspaceId: string,
  ): Promise<void> {
    switch (exception.code) {
      case MessageImportDriverExceptionCode.NOT_FOUND:
        await this.handleNotFoundException(
          syncStep,
          messageChannel,
          workspaceId,
        );
        break;
      case MessageImportDriverExceptionCode.TEMPORARY_ERROR:
        await this.handleTemporaryException(
          syncStep,
          messageChannel,
          workspaceId,
        );
        break;
      case MessageImportDriverExceptionCode.INSUFFICIENT_PERMISSIONS:
        await this.handleInsufficientPermissionsException(
          messageChannel,
          workspaceId,
        );
        break;
      case MessageImportDriverExceptionCode.UNKNOWN:
      case MessageImportDriverExceptionCode.UNKNOWN_NETWORK_ERROR:
        await this.handleUnknownException(
          exception,
          messageChannel,
          workspaceId,
        );
        break;
      case MessageImportDriverExceptionCode.SYNC_CURSOR_ERROR:
        await this.handlePermanentException(
          exception,
          messageChannel,
          workspaceId,
        );
        break;
      default:
        throw exception;
    }
  }

  private async handleTemporaryException(
    syncStep: MessageImportSyncStep,
    messageChannel: Pick<
      MessageChannelWorkspaceEntity,
      'id' | 'throttleFailureCount'
    >,
    workspaceId: string,
  ): Promise<void> {
    if (
      messageChannel.throttleFailureCount >= MESSAGING_THROTTLE_MAX_ATTEMPTS
    ) {
      await this.messageChannelSyncStatusService.markAsFailedUnknownAndFlushMessagesToImport(
        [messageChannel.id],
        workspaceId,
      );
      throw new MessageImportException(
        `Unknown error occurred multiple times while importing messages for message channel ${messageChannel.id} in workspace ${workspaceId}`,
        MessageImportExceptionCode.UNKNOWN,
      );
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.increment(
      { id: messageChannel.id },
      'throttleFailureCount',
      1,
    );

    switch (syncStep) {
      case MessageImportSyncStep.FULL_MESSAGE_LIST_FETCH:
        await this.messageChannelSyncStatusService.scheduleFullMessageListFetch(
          [messageChannel.id],
        );
        break;

      case MessageImportSyncStep.PARTIAL_MESSAGE_LIST_FETCH:
        await this.messageChannelSyncStatusService.schedulePartialMessageListFetch(
          [messageChannel.id],
        );
        break;

      case MessageImportSyncStep.MESSAGES_IMPORT:
        await this.messageChannelSyncStatusService.scheduleMessagesImport([
          messageChannel.id,
        ]);
        break;

      default:
        break;
    }
  }

  private async handleInsufficientPermissionsException(
    messageChannel: Pick<MessageChannelWorkspaceEntity, 'id'>,
    workspaceId: string,
  ): Promise<void> {
    await this.messageChannelSyncStatusService.markAsFailedInsufficientPermissionsAndFlushMessagesToImport(
      [messageChannel.id],
      workspaceId,
    );
  }

  private async handleUnknownException(
    exception: MessageImportDriverException,
    messageChannel: Pick<MessageChannelWorkspaceEntity, 'id'>,
    workspaceId: string,
  ): Promise<void> {
    await this.messageChannelSyncStatusService.markAsFailedUnknownAndFlushMessagesToImport(
      [messageChannel.id],
      workspaceId,
    );

    throw new MessageImportException(
      `Unknown error occurred while importing messages for message channel ${messageChannel.id} in workspace ${workspaceId}: ${exception.message}`,
      MessageImportExceptionCode.UNKNOWN,
    );
  }

  private async handlePermanentException(
    exception: MessageImportDriverException,
    messageChannel: Pick<MessageChannelWorkspaceEntity, 'id'>,
    workspaceId: string,
  ): Promise<void> {
    await this.messageChannelSyncStatusService.markAsFailedUnknownAndFlushMessagesToImport(
      [messageChannel.id],
      workspaceId,
    );

    throw new MessageImportException(
      `Permanent error occurred while importing messages for message channel ${messageChannel.id} in workspace ${workspaceId}: ${exception.message}`,
      MessageImportExceptionCode.UNKNOWN,
    );
  }

  private async handleNotFoundException(
    syncStep: MessageImportSyncStep,
    messageChannel: Pick<MessageChannelWorkspaceEntity, 'id'>,
    workspaceId: string,
  ): Promise<void> {
    if (syncStep === MessageImportSyncStep.FULL_MESSAGE_LIST_FETCH) {
      return;
    }

    await this.messageChannelSyncStatusService.resetAndScheduleFullMessageListFetch(
      [messageChannel.id],
      workspaceId,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener service that triggers a cleanup job in a message queue when a connected account is deleted from the database.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import {
  MessagingConnectedAccountDeletionCleanupJob,
  MessagingConnectedAccountDeletionCleanupJobData,
} from 'src/modules/messaging/message-cleaner/jobs/messaging-connected-account-deletion-cleanup.job';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable()
export class MessagingMessageCleanerConnectedAccountListener {
  constructor(
    @InjectMessageQueue(MessageQueue.messagingQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('connectedAccount', DatabaseEventAction.DESTROYED)
  async handleDestroyedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordDeleteEvent<ConnectedAccountWorkspaceEntity>
    >,
  ) {
    await Promise.all(
      payload.events.map((eventPayload) =>
        this.messageQueueService.add<MessagingConnectedAccountDeletionCleanupJobData>(
          MessagingConnectedAccountDeletionCleanupJob.name,
          {
            workspaceId: payload.workspaceId,
            connectedAccountId: eventPayload.recordId,
          },
        ),
      ),
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code processes a job to delete messages associated with blocklisted items in a workspace.
Code Snippet:
import { Logger, Scope } from '@nestjs/common';

import { And, Any, ILike, In, Not, Or } from 'typeorm';

import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { BlocklistWorkspaceEntity } from 'src/modules/blocklist/standard-objects/blocklist.workspace-entity';
import { MessageChannelMessageAssociationWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel-message-association.workspace-entity';
import { MessageChannelWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import { MessagingMessageCleanerService } from 'src/modules/messaging/message-cleaner/services/messaging-message-cleaner.service';

export type BlocklistItemDeleteMessagesJobData = WorkspaceEventBatch<
  ObjectRecordCreateEvent<BlocklistWorkspaceEntity>
>;

@Processor({
  queueName: MessageQueue.messagingQueue,
  scope: Scope.REQUEST,
})
export class BlocklistItemDeleteMessagesJob {
  private readonly logger = new Logger(BlocklistItemDeleteMessagesJob.name);

  constructor(
    private readonly threadCleanerService: MessagingMessageCleanerService,
    private readonly twentyORMManager: TwentyORMManager,
  ) {}

  @Process(BlocklistItemDeleteMessagesJob.name)
  async handle(data: BlocklistItemDeleteMessagesJobData): Promise<void> {
    const workspaceId = data.workspaceId;

    const blocklistItemIds = data.events.map(
      (eventPayload) => eventPayload.recordId,
    );

    const blocklistRepository =
      await this.twentyORMManager.getRepository<BlocklistWorkspaceEntity>(
        'blocklist',
      );

    const blocklist = await blocklistRepository.find({
      where: {
        id: Any(blocklistItemIds),
      },
    });

    const handlesToDeleteByWorkspaceMemberIdMap = blocklist.reduce(
      (acc, blocklistItem) => {
        const { handle, workspaceMemberId } = blocklistItem;

        if (!acc.has(workspaceMemberId)) {
          acc.set(workspaceMemberId, []);
        }

        acc.get(workspaceMemberId)?.push(handle);

        return acc;
      },
      new Map<string, string[]>(),
    );

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    const messageChannelMessageAssociationRepository =
      await this.twentyORMManager.getRepository<MessageChannelMessageAssociationWorkspaceEntity>(
        'messageChannelMessageAssociation',
      );

    for (const workspaceMemberId of handlesToDeleteByWorkspaceMemberIdMap.keys()) {
      const handles =
        handlesToDeleteByWorkspaceMemberIdMap.get(workspaceMemberId);

      if (!handles) {
        continue;
      }

      this.logger.log(
        `Deleting messages from ${handles.join(
          ', ',
        )} in workspace ${workspaceId} for workspace member ${workspaceMemberId}`,
      );

      const rolesToDelete: ('from' | 'to')[] = ['from', 'to'];

      const messageChannels = await messageChannelRepository.find({
        select: {
          id: true,
          handle: true,
          connectedAccount: {
            handleAliases: true,
          },
        },
        where: {
          connectedAccount: {
            accountOwnerId: workspaceMemberId,
          },
        },
        relations: ['connectedAccount'],
      });

      for (const messageChannel of messageChannels) {
        const messageChannelHandles = [messageChannel.handle];

        if (messageChannel.connectedAccount.handleAliases) {
          messageChannelHandles.push(
            ...messageChannel.connectedAccount.handleAliases.split(','),
          );
        }

        const handleConditions = handles.map((handle) => {
          const isHandleDomain = handle.startsWith('@');

          return isHandleDomain
            ? {
                handle: And(
                  Or(ILike(`%${handle}`), ILike(`%.${handle.slice(1)}`)),
                  Not(In(messageChannelHandles)),
                ),
                role: In(rolesToDelete),
              }
            : { handle, role: In(rolesToDelete) };
        });

        const messageChannelMessageAssociationsToDelete =
          await messageChannelMessageAssociationRepository.find({
            where: {
              messageChannelId: messageChannel.id,
              message: {
                messageParticipants: handleConditions,
              },
            },
          });

        if (messageChannelMessageAssociationsToDelete.length === 0) {
          continue;
        }

        await messageChannelMessageAssociationRepository.delete(
          messageChannelMessageAssociationsToDelete.map(({ id }) => id),
        );
      }

      this.logger.log(
        `Deleted messages from handle ${handles.join(
          ', ',
        )} in workspace ${workspaceId} for workspace member ${workspaceMemberId}`,
      );
    }

    await this.threadCleanerService.cleanWorkspaceThreads(workspaceId);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener service that handles database events for blocklist operations and enqueues messages for processing.
Code Snippet:
import { Injectable, Scope } from '@nestjs/common';

import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { ObjectRecordUpdateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-update.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { BlocklistWorkspaceEntity } from 'src/modules/blocklist/standard-objects/blocklist.workspace-entity';
import {
  BlocklistItemDeleteMessagesJob,
  BlocklistItemDeleteMessagesJobData,
} from 'src/modules/messaging/blocklist-manager/jobs/messaging-blocklist-item-delete-messages.job';
import {
  BlocklistReimportMessagesJob,
  BlocklistReimportMessagesJobData,
} from 'src/modules/messaging/blocklist-manager/jobs/messaging-blocklist-reimport-messages.job';
import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';

@Injectable({ scope: Scope.REQUEST })
export class MessagingBlocklistListener {
  constructor(
    @InjectMessageQueue(MessageQueue.messagingQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('blocklist', DatabaseEventAction.CREATED)
  async handleCreatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordCreateEvent<BlocklistWorkspaceEntity>
    >,
  ) {
    await this.messageQueueService.add<BlocklistItemDeleteMessagesJobData>(
      BlocklistItemDeleteMessagesJob.name,
      payload,
    );
  }

  @OnDatabaseBatchEvent('blocklist', DatabaseEventAction.CREATED)
  async handleDeletedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordDeleteEvent<BlocklistWorkspaceEntity>
    >,
  ) {
    await this.messageQueueService.add<BlocklistReimportMessagesJobData>(
      BlocklistReimportMessagesJob.name,
      payload,
    );
  }

  @OnDatabaseBatchEvent('blocklist', DatabaseEventAction.UPDATED)
  async handleUpdatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordUpdateEvent<BlocklistWorkspaceEntity>
    >,
  ) {
    await this.messageQueueService.add<BlocklistItemDeleteMessagesJobData>(
      BlocklistItemDeleteMessagesJob.name,
      payload,
    );

    await this.messageQueueService.add<BlocklistReimportMessagesJobData>(
      BlocklistReimportMessagesJob.name,
      payload,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS global module for logging, with support for synchronous and asynchronous configuration of a console logger.
Code Snippet:
import { ConsoleLogger, DynamicModule, Global, Module } from '@nestjs/common';

import { LoggerDriverType } from 'src/engine/core-modules/logger/interfaces';
import { LOGGER_DRIVER } from 'src/engine/core-modules/logger/logger.constants';
import {
  ASYNC_OPTIONS_TYPE,
  ConfigurableModuleClass,
  OPTIONS_TYPE,
} from 'src/engine/core-modules/logger/logger.module-definition';
import { LoggerService } from 'src/engine/core-modules/logger/logger.service';

@Global()
@Module({
  providers: [LoggerService],
  exports: [LoggerService],
})
export class LoggerModule extends ConfigurableModuleClass {
  static forRoot(options: typeof OPTIONS_TYPE): DynamicModule {
    const provider = {
      provide: LOGGER_DRIVER,
      useValue:
        options.type === LoggerDriverType.Console
          ? new ConsoleLogger()
          : undefined,
    };
    const dynamicModule = super.forRoot(options);

    return {
      ...dynamicModule,
      providers: [...(dynamicModule.providers ?? []), provider],
    };
  }

  static forRootAsync(options: typeof ASYNC_OPTIONS_TYPE): DynamicModule {
    const provider = {
      provide: LOGGER_DRIVER,
      useFactory: async (...args: any[]) => {
        const config = await options?.useFactory?.(...args);

        if (!config) {
          return null;
        }

        const logLevels = config.logLevels ?? [];

        const logger =
          config?.type === LoggerDriverType.Console
            ? new ConsoleLogger()
            : undefined;

        logger?.setLogLevels(logLevels);

        return logger;
      },
      inject: options.inject || [],
    };
    const dynamicModule = super.forRootAsync(options);

    return {
      ...dynamicModule,
      providers: [...(dynamicModule.providers ?? []), provider],
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a class that captures exceptions and logs them to the console.
Code Snippet:
/* eslint-disable no-console */
import { ExceptionHandlerOptions } from 'src/engine/core-modules/exception-handler/interfaces/exception-handler-options.interface';

import { ExceptionHandlerDriverInterface } from 'src/engine/core-modules/exception-handler/interfaces';

export class ExceptionHandlerConsoleDriver
  implements ExceptionHandlerDriverInterface
{
  captureExceptions(
    exceptions: ReadonlyArray<any>,
    options?: ExceptionHandlerOptions,
  ) {
    console.group('Exception Captured');
    console.info(options);
    console.error(exceptions);
    console.groupEnd();

    return [];
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS module for LLM tracing, which configures and provides a tracing driver based on the provided options.
Code Snippet:
import { Global, DynamicModule } from '@nestjs/common';

import {
  LLMTracingModuleAsyncOptions,
  LLMTracingDriver,
} from 'src/engine/core-modules/llm-tracing/interfaces/llm-tracing.interface';

import { LangfuseDriver } from 'src/engine/core-modules/llm-tracing/drivers/langfuse.driver';
import { ConsoleDriver } from 'src/engine/core-modules/llm-tracing/drivers/console.driver';
import { LLMTracingService } from 'src/engine/core-modules/llm-tracing/llm-tracing.service';
import { LLM_TRACING_DRIVER } from 'src/engine/core-modules/llm-tracing/llm-tracing.constants';

@Global()
export class LLMTracingModule {
  static forRoot(options: LLMTracingModuleAsyncOptions): DynamicModule {
    const provider = {
      provide: LLM_TRACING_DRIVER,
      useFactory: (...args: any[]) => {
        const config = options.useFactory(...args);

        switch (config.type) {
          case LLMTracingDriver.Langfuse: {
            return new LangfuseDriver(config.options);
          }
          case LLMTracingDriver.Console: {
            return new ConsoleDriver();
          }
        }
      },
      inject: options.inject || [],
    };

    return {
      module: LLMTracingModule,
      providers: [LLMTracingService, provider],
      exports: [LLMTracingService],
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a custom callback handler that logs metadata to the console and implements an LLMTracingDriver to provide this handler.
Code Snippet:
/* eslint-disable no-console */
import { BaseCallbackHandler } from '@langchain/core/callbacks/base';
import { Run } from '@langchain/core/tracers/base';
import { ConsoleCallbackHandler } from '@langchain/core/tracers/console';

import { LLMTracingDriver } from 'src/engine/core-modules/llm-tracing/drivers/interfaces/llm-tracing-driver.interface';

class WithMetadataConsoleCallbackHandler extends ConsoleCallbackHandler {
  private metadata: Record<string, unknown>;

  constructor(metadata: Record<string, unknown>) {
    super();
    this.metadata = metadata;
  }

  onChainStart(run: Run) {
    console.log(`Chain metadata: ${JSON.stringify(this.metadata)}`);
    super.onChainStart(run);
  }
}

export class ConsoleDriver implements LLMTracingDriver {
  getCallbackHandler(metadata: Record<string, unknown>): BaseCallbackHandler {
    return new WithMetadataConsoleCallbackHandler(metadata);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS processor job that cleans user variables related to workspace deletion warnings for all members of a specified workspace.
Code Snippet:
import { Logger, Scope } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import chunk from 'lodash.chunk';
import { Repository } from 'typeorm';

import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { UserService } from 'src/engine/core-modules/user/services/user.service';
import { UserVarsService } from 'src/engine/core-modules/user/user-vars/services/user-vars.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { USER_WORKSPACE_DELETION_WARNING_SENT_KEY } from 'src/engine/workspace-manager/workspace-cleaner/constants/user-workspace-deletion-warning-sent-key.constant';

export type CleanWorkspaceDeletionWarningUserVarsJobData = {
  workspaceId: string;
};

@Processor({
  queueName: MessageQueue.workspaceQueue,
  scope: Scope.REQUEST,
})
export class CleanWorkspaceDeletionWarningUserVarsJob {
  protected readonly logger = new Logger(
    CleanWorkspaceDeletionWarningUserVarsJob.name,
  );

  constructor(
    private readonly userService: UserService,
    private readonly userVarsService: UserVarsService,
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
  ) {}

  @Process(CleanWorkspaceDeletionWarningUserVarsJob.name)
  async handle(
    data: CleanWorkspaceDeletionWarningUserVarsJobData,
  ): Promise<void> {
    this.logger.log(`Job running...`);

    const { workspaceId } = data;

    try {
      const workspace = await this.workspaceRepository.findOneOrFail({
        where: { id: workspaceId },
      });

      const workspaceMembers =
        await this.userService.loadWorkspaceMembers(workspace);

      const workspaceMembersChunks = chunk(workspaceMembers, 5);

      for (const workspaceMembersChunk of workspaceMembersChunks) {
        await Promise.all(
          workspaceMembersChunk.map(async (workspaceMember) => {
            await this.userVarsService.delete({
              userId: workspaceMember.userId,
              workspaceId: workspace.id,
              key: USER_WORKSPACE_DELETION_WARNING_SENT_KEY,
            });
            this.logger.log(
              `Successfully cleaned user vars for ${workspaceMember.userId} user in ${workspace.id} workspace`,
            );
          }),
        );
      }
      this.logger.log(`Job done!`);
    } catch (error) {
      this.logger.error(
        `Failed to clean ${workspaceId} workspace users deletion warning user vars: ${error.message}`,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_0>



=== New Entry ===

<CLUSTER_1>
Number of Code Snippets part of this cluster: 31
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener that handles the removal of workspace members and triggers a job to clean up connected accounts for those members.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { ObjectRecordDestroyEvent } from 'src/engine/core-modules/event-emitter/types/object-record-destroy.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  DeleteWorkspaceMemberConnectedAccountsCleanupJob,
  DeleteWorkspaceMemberConnectedAccountsCleanupJobData,
} from 'src/modules/connected-account/jobs/delete-workspace-member-connected-accounts.job';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';

@Injectable()
export class ConnectedAccountWorkspaceMemberListener {
  constructor(
    @InjectMessageQueue(MessageQueue.deleteCascadeQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('workspaceMember', DatabaseEventAction.DESTROYED)
  @OnDatabaseBatchEvent('workspaceMember', DatabaseEventAction.DELETED)
  async handleWorkspaceMemberRemovalEvent(
    payload: WorkspaceEventBatch<
      | ObjectRecordDeleteEvent<WorkspaceMemberWorkspaceEntity>
      | ObjectRecordDestroyEvent<WorkspaceMemberWorkspaceEntity>
    >,
  ) {
    await Promise.all(
      payload.events.map((eventPayload) =>
        this.messageQueueService.add<DeleteWorkspaceMemberConnectedAccountsCleanupJobData>(
          DeleteWorkspaceMemberConnectedAccountsCleanupJob.name,
          {
            workspaceId: payload.workspaceId,
            workspaceMemberId: eventPayload.recordId,
          },
        ),
      ),
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a pre-query hook for deleting a connected account, which also deletes associated message channels and emits events for each deleted message channel.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { WorkspaceQueryHookInstance } from 'src/engine/api/graphql/workspace-query-runner/workspace-query-hook/interfaces/workspace-query-hook.interface';
import { DeleteOneResolverArgs } from 'src/engine/api/graphql/workspace-resolver-builder/interfaces/workspace-resolvers-builder.interface';

import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { WorkspaceQueryHook } from 'src/engine/api/graphql/workspace-query-runner/workspace-query-hook/decorators/workspace-query-hook.decorator';
import { AuthContext } from 'src/engine/core-modules/auth/types/auth-context.type';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';
import { MessageChannelWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';

@WorkspaceQueryHook(`connectedAccount.destroyOne`)
export class ConnectedAccountDeleteOnePreQueryHook
  implements WorkspaceQueryHookInstance
{
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly workspaceEventEmitter: WorkspaceEventEmitter,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
  ) {}

  async execute(
    authContext: AuthContext,
    objectName: string,
    payload: DeleteOneResolverArgs,
  ): Promise<DeleteOneResolverArgs> {
    const connectedAccountId = payload.id;

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    const messageChannels = await messageChannelRepository.findBy({
      connectedAccountId,
    });

    const objectMetadata = await this.objectMetadataRepository.findOneOrFail({
      where: {
        nameSingular: 'messageChannel',
        workspaceId: authContext.workspace.id,
      },
    });

    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: 'messageChannel',
      action: DatabaseEventAction.DESTROYED,
      events: messageChannels.map((messageChannel) => ({
        recordId: messageChannel.id,
        objectMetadata,
        properties: {
          before: messageChannel,
        },
      })),
      workspaceId: authContext.workspace.id,
    });

    return payload;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to create companies and contacts in a workspace, filtering out duplicates and handling batches of contacts.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import chunk from 'lodash.chunk';
import compact from 'lodash.compact';
import { Any, EntityManager, Repository } from 'typeorm';

import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { FieldActorSource } from 'src/engine/metadata-modules/field-metadata/composite-types/actor.composite-type';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { InjectObjectMetadataRepository } from 'src/engine/object-metadata-repository/object-metadata-repository.decorator';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';
import { STANDARD_OBJECT_IDS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-object-ids';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { CONTACTS_CREATION_BATCH_SIZE } from 'src/modules/contact-creation-manager/constants/contacts-creation-batch-size.constant';
import { CreateCompanyService } from 'src/modules/contact-creation-manager/services/create-company.service';
import { CreateContactService } from 'src/modules/contact-creation-manager/services/create-contact.service';
import { Contact } from 'src/modules/contact-creation-manager/types/contact.type';
import { filterOutSelfAndContactsFromCompanyOrWorkspace } from 'src/modules/contact-creation-manager/utils/filter-out-contacts-from-company-or-workspace.util';
import { getDomainNameFromHandle } from 'src/modules/contact-creation-manager/utils/get-domain-name-from-handle.util';
import { getUniqueContactsAndHandles } from 'src/modules/contact-creation-manager/utils/get-unique-contacts-and-handles.util';
import { PersonWorkspaceEntity } from 'src/modules/person/standard-objects/person.workspace-entity';
import { WorkspaceMemberRepository } from 'src/modules/workspace-member/repositories/workspace-member.repository';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';
import { isWorkDomain, isWorkEmail } from 'src/utils/is-work-email';

@Injectable()
export class CreateCompanyAndContactService {
  constructor(
    private readonly createContactService: CreateContactService,
    private readonly createCompaniesService: CreateCompanyService,
    @InjectObjectMetadataRepository(WorkspaceMemberWorkspaceEntity)
    private readonly workspaceMemberRepository: WorkspaceMemberRepository,
    private readonly workspaceEventEmitter: WorkspaceEventEmitter,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {}

  private async createCompaniesAndPeople(
    connectedAccount: ConnectedAccountWorkspaceEntity,
    contactsToCreate: Contact[],
    workspaceId: string,
    source: FieldActorSource,
    transactionManager?: EntityManager,
  ): Promise<DeepPartial<PersonWorkspaceEntity>[]> {
    if (!contactsToCreate || contactsToCreate.length === 0) {
      return [];
    }

    const personRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace(
        workspaceId,
        PersonWorkspaceEntity,
      );

    const workspaceMembers =
      await this.workspaceMemberRepository.getAllByWorkspaceId(
        workspaceId,
        transactionManager,
      );

    const contactsToCreateFromOtherCompanies =
      filterOutSelfAndContactsFromCompanyOrWorkspace(
        contactsToCreate,
        connectedAccount,
        workspaceMembers,
      );

    const { uniqueContacts, uniqueHandles } = getUniqueContactsAndHandles(
      contactsToCreateFromOtherCompanies,
    );

    if (uniqueHandles.length === 0) {
      return [];
    }

    const alreadyCreatedContacts = await personRepository.find({
      withDeleted: true,
      where: {
        emails: { primaryEmail: Any(uniqueHandles) },
      },
    });

    const alreadyCreatedContactEmails: string[] = alreadyCreatedContacts?.map(
      ({ emails }) => emails?.primaryEmail,
    );

    const filteredContactsToCreate = uniqueContacts.filter(
      (participant) =>
        !alreadyCreatedContactEmails.includes(participant.handle) &&
        participant.handle.includes('@'),
    );

    const filteredContactsToCreateWithCompanyDomainNames =
      filteredContactsToCreate?.map((participant) => ({
        handle: participant.handle,
        displayName: participant.displayName,
        companyDomainName: isWorkEmail(participant.handle)
          ? getDomainNameFromHandle(participant.handle)
          : undefined,
      }));

    const domainNamesToCreate = compact(
      filteredContactsToCreateWithCompanyDomainNames
        .filter((participant) => participant.companyDomainName)
        .map((participant) => ({
          domainName: participant.companyDomainName,
          createdBySource: source,
          createdByWorkspaceMember: connectedAccount.accountOwner,
        })),
    );

    const workDomainNamesToCreate = domainNamesToCreate.filter(
      (domainName) =>
        domainName?.domainName && isWorkDomain(domainName.domainName),
    );

    const workDomainNamesToCreateFormatted = workDomainNamesToCreate.map(
      (domainName) => ({
        ...domainName,
        createdBySource: source,
        createdByWorkspaceMember: connectedAccount.accountOwner,
        createdByContext: {
          provider: connectedAccount.provider,
        },
      }),
    );

    const companiesObject = await this.createCompaniesService.createCompanies(
      workDomainNamesToCreateFormatted,
      workspaceId,
      transactionManager,
    );

    const formattedContactsToCreate =
      filteredContactsToCreateWithCompanyDomainNames.map((contact) => ({
        handle: contact.handle,
        displayName: contact.displayName,
        companyId:
          contact.companyDomainName && contact.companyDomainName !== ''
            ? companiesObject[contact.companyDomainName]
            : undefined,
        createdBySource: source,
        createdByWorkspaceMember: connectedAccount.accountOwner,
        createdByContext: {
          provider: connectedAccount.provider,
        },
      }));

    return this.createContactService.createPeople(
      formattedContactsToCreate,
      workspaceId,
      transactionManager,
    );
  }

  async createCompaniesAndContactsAndUpdateParticipants(
    connectedAccount: ConnectedAccountWorkspaceEntity,
    contactsToCreate: Contact[],
    workspaceId: string,
    source: FieldActorSource,
  ) {
    const contactsBatches = chunk(
      contactsToCreate,
      CONTACTS_CREATION_BATCH_SIZE,
    );

    // TODO: Remove this when events are emitted directly inside TwentyORM

    const objectMetadata = await this.objectMetadataRepository.findOne({
      where: {
        standardId: STANDARD_OBJECT_IDS.person,
        workspaceId,
      },
    });

    if (!objectMetadata) {
      throw new Error('Object metadata not found');
    }

    // In some jobs the accountOwner is not populated
    if (!connectedAccount.accountOwner) {
      const workspaceMemberRepository =
        await this.twentyORMGlobalManager.getRepositoryForWorkspace(
          workspaceId,
          WorkspaceMemberWorkspaceEntity,
        );

      const workspaceMember = await workspaceMemberRepository.findOne({
        where: {
          id: connectedAccount.accountOwnerId,
        },
      });

      if (!workspaceMember) {
        throw new Error(
          `Workspace member with id ${connectedAccount.accountOwnerId} not found in workspace ${workspaceId}`,
        );
      }

      connectedAccount.accountOwner = workspaceMember;
    }

    for (const contactsBatch of contactsBatches) {
      const createdPeople = await this.createCompaniesAndPeople(
        connectedAccount,
        contactsBatch,
        workspaceId,
        source,
      );

      this.workspaceEventEmitter.emitDatabaseBatchEvent({
        objectMetadataNameSingular: 'person',
        action: DatabaseEventAction.CREATED,
        events: createdPeople.map((createdPerson) => ({
          // Fix ' as string': TypeORM typing issue... id is always returned when using save
          recordId: createdPerson.id as string,
          objectMetadata,
          properties: {
            after: createdPerson,
          },
        })),
        workspaceId,
      });
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service that listens for database delete events and enqueues a job to handle the deletion of associated favorites.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { ObjectRecordDeleteEvent } from 'src/engine/core-modules/event-emitter/types/object-record-delete.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  FavoriteDeletionJob,
  FavoriteDeletionJobData,
} from 'src/modules/favorite/jobs/favorite-deletion.job';

@Injectable()
export class FavoriteDeletionListener {
  constructor(
    @InjectMessageQueue(MessageQueue.deleteCascadeQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('*', DatabaseEventAction.DELETED)
  async handleDeletedEvent(
    payload: WorkspaceEventBatch<ObjectRecordDeleteEvent>,
  ) {
    const deletedRecordIds = payload.events.map(({ recordId }) => recordId);

    await this.messageQueueService.add<FavoriteDeletionJobData>(
      FavoriteDeletionJob.name,
      {
        workspaceId: payload.workspaceId,
        deletedRecordIds,
      },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service that executes a workflow step to create a record in a database using TypeORM.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { WorkflowExecutor } from 'src/modules/workflow/workflow-executor/interfaces/workflow-executor.interface';

import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { FieldActorSource } from 'src/engine/metadata-modules/field-metadata/composite-types/actor.composite-type';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { ScopedWorkspaceContextFactory } from 'src/engine/twenty-orm/factories/scoped-workspace-context.factory';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';
import {
  WorkflowStepExecutorException,
  WorkflowStepExecutorExceptionCode,
} from 'src/modules/workflow/workflow-executor/exceptions/workflow-step-executor.exception';
import { WorkflowExecutorInput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-input';
import { WorkflowExecutorOutput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-output.type';
import { resolveInput } from 'src/modules/workflow/workflow-executor/utils/variable-resolver.util';
import {
  RecordCRUDActionException,
  RecordCRUDActionExceptionCode,
} from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/exceptions/record-crud-action.exception';
import { isWorkflowCreateRecordAction } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/guards/is-workflow-create-record-action.guard';
import { WorkflowCreateRecordActionInput } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/types/workflow-record-crud-action-input.type';

@Injectable()
export class CreateRecordWorkflowAction implements WorkflowExecutor {
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    private readonly workspaceEventEmitter: WorkspaceEventEmitter,
    private readonly scopedWorkspaceContextFactory: ScopedWorkspaceContextFactory,
  ) {}

  async execute({
    currentStepIndex,
    steps,
    context,
  }: WorkflowExecutorInput): Promise<WorkflowExecutorOutput> {
    const step = steps[currentStepIndex];

    if (!isWorkflowCreateRecordAction(step)) {
      throw new WorkflowStepExecutorException(
        'Step is not a create record action',
        WorkflowStepExecutorExceptionCode.INVALID_STEP_TYPE,
      );
    }

    const workspaceId = this.scopedWorkspaceContextFactory.create().workspaceId;

    if (!workspaceId) {
      throw new RecordCRUDActionException(
        'Failed to create: Workspace ID is required',
        RecordCRUDActionExceptionCode.INVALID_REQUEST,
      );
    }

    const workflowActionInput = resolveInput(
      step.settings.input,
      context,
    ) as WorkflowCreateRecordActionInput;

    const repository = await this.twentyORMManager.getRepository(
      workflowActionInput.objectName,
    );

    const objectMetadata = await this.objectMetadataRepository.findOne({
      where: {
        nameSingular: workflowActionInput.objectName,
      },
    });

    if (!objectMetadata) {
      throw new RecordCRUDActionException(
        'Failed to create: Object metadata not found',
        RecordCRUDActionExceptionCode.INVALID_REQUEST,
      );
    }

    const objectRecord = await repository.save({
      ...workflowActionInput.objectRecord,
      createdBy: {
        source: FieldActorSource.WORKFLOW,
        name: 'Workflow',
      },
    });

    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: workflowActionInput.objectName,
      action: DatabaseEventAction.CREATED,
      events: [
        {
          recordId: objectRecord.id,
          objectMetadata,
          properties: {
            after: objectRecord,
          },
        },
      ],
      workspaceId,
    });

    return {
      result: objectRecord,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service that deletes a record from a database based on workflow input. It uses TypeORM for database operations and emits events upon successful deletion.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { WorkflowExecutor } from 'src/modules/workflow/workflow-executor/interfaces/workflow-executor.interface';

import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { ScopedWorkspaceContextFactory } from 'src/engine/twenty-orm/factories/scoped-workspace-context.factory';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';
import {
  WorkflowStepExecutorException,
  WorkflowStepExecutorExceptionCode,
} from 'src/modules/workflow/workflow-executor/exceptions/workflow-step-executor.exception';
import { WorkflowExecutorInput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-input';
import { WorkflowExecutorOutput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-output.type';
import { resolveInput } from 'src/modules/workflow/workflow-executor/utils/variable-resolver.util';
import {
  RecordCRUDActionException,
  RecordCRUDActionExceptionCode,
} from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/exceptions/record-crud-action.exception';
import { isWorkflowDeleteRecordAction } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/guards/is-workflow-delete-record-action.guard';
import { WorkflowDeleteRecordActionInput } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/types/workflow-record-crud-action-input.type';

@Injectable()
export class DeleteRecordWorkflowAction implements WorkflowExecutor {
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    private readonly workspaceEventEmitter: WorkspaceEventEmitter,
    private readonly scopedWorkspaceContextFactory: ScopedWorkspaceContextFactory,
  ) {}

  async execute({
    currentStepIndex,
    steps,
    context,
  }: WorkflowExecutorInput): Promise<WorkflowExecutorOutput> {
    const step = steps[currentStepIndex];

    if (!isWorkflowDeleteRecordAction(step)) {
      throw new WorkflowStepExecutorException(
        'Step is not a delete record action',
        WorkflowStepExecutorExceptionCode.INVALID_STEP_TYPE,
      );
    }

    const workflowActionInput = resolveInput(
      step.settings.input,
      context,
    ) as WorkflowDeleteRecordActionInput;

    const repository = await this.twentyORMManager.getRepository(
      workflowActionInput.objectName,
    );

    const workspaceId = this.scopedWorkspaceContextFactory.create().workspaceId;

    if (!workspaceId) {
      throw new RecordCRUDActionException(
        'Failed to delete: Workspace ID is required',
        RecordCRUDActionExceptionCode.INVALID_REQUEST,
      );
    }

    const objectMetadata = await this.objectMetadataRepository.findOne({
      where: {
        nameSingular: workflowActionInput.objectName,
      },
    });

    if (!objectMetadata) {
      throw new RecordCRUDActionException(
        'Failed to delete: Object metadata not found',
        RecordCRUDActionExceptionCode.INVALID_REQUEST,
      );
    }

    const objectRecord = await repository.findOne({
      where: {
        id: workflowActionInput.objectRecordId,
      },
    });

    if (!objectRecord) {
      throw new RecordCRUDActionException(
        `Failed to delete: Record ${workflowActionInput.objectName} with id ${workflowActionInput.objectRecordId} not found`,
        RecordCRUDActionExceptionCode.RECORD_NOT_FOUND,
      );
    }

    await repository.softDelete(workflowActionInput.objectRecordId);

    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: workflowActionInput.objectName,
      action: DatabaseEventAction.DELETED,
      events: [
        {
          recordId: objectRecord.id,
          objectMetadata,
          properties: {
            before: objectRecord,
          },
        },
      ],
      workspaceId,
    });

    return {
      result: objectRecord,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a workflow action to update a record in a database using TypeORM, handling exceptions and emitting events.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { WorkflowExecutor } from 'src/modules/workflow/workflow-executor/interfaces/workflow-executor.interface';

import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { getObjectMetadataMapItemByNameSingular } from 'src/engine/metadata-modules/utils/get-object-metadata-map-item-by-name-singular.util';
import { ScopedWorkspaceContextFactory } from 'src/engine/twenty-orm/factories/scoped-workspace-context.factory';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { formatData } from 'src/engine/twenty-orm/utils/format-data.util';
import { WorkspaceCacheStorageService } from 'src/engine/workspace-cache-storage/workspace-cache-storage.service';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';
import {
  WorkflowStepExecutorException,
  WorkflowStepExecutorExceptionCode,
} from 'src/modules/workflow/workflow-executor/exceptions/workflow-step-executor.exception';
import { WorkflowExecutorInput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-input';
import { WorkflowExecutorOutput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-output.type';
import { resolveInput } from 'src/modules/workflow/workflow-executor/utils/variable-resolver.util';
import {
  RecordCRUDActionException,
  RecordCRUDActionExceptionCode,
} from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/exceptions/record-crud-action.exception';
import { isWorkflowUpdateRecordAction } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/guards/is-workflow-update-record-action.guard';
import { WorkflowUpdateRecordActionInput } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/types/workflow-record-crud-action-input.type';

@Injectable()
export class UpdateRecordWorkflowAction implements WorkflowExecutor {
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly workspaceCacheStorageService: WorkspaceCacheStorageService,
    private readonly scopedWorkspaceContextFactory: ScopedWorkspaceContextFactory,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    private readonly workspaceEventEmitter: WorkspaceEventEmitter,
  ) {}

  async execute({
    currentStepIndex,
    steps,
    context,
  }: WorkflowExecutorInput): Promise<WorkflowExecutorOutput> {
    const step = steps[currentStepIndex];

    if (!isWorkflowUpdateRecordAction(step)) {
      throw new WorkflowStepExecutorException(
        'Step is not an update record action',
        WorkflowStepExecutorExceptionCode.INVALID_STEP_TYPE,
      );
    }

    const workflowActionInput = resolveInput(
      step.settings.input,
      context,
    ) as WorkflowUpdateRecordActionInput;

    const repository = await this.twentyORMManager.getRepository(
      workflowActionInput.objectName,
    );

    const workspaceId = this.scopedWorkspaceContextFactory.create().workspaceId;

    if (!workspaceId) {
      throw new RecordCRUDActionException(
        'Failed to update: Workspace ID is required',
        RecordCRUDActionExceptionCode.INVALID_REQUEST,
      );
    }

    const objectMetadata = await this.objectMetadataRepository.findOne({
      where: {
        nameSingular: workflowActionInput.objectName,
      },
    });

    if (!objectMetadata) {
      throw new RecordCRUDActionException(
        'Failed to update: Object metadata not found',
        RecordCRUDActionExceptionCode.INVALID_REQUEST,
      );
    }

    const previousObjectRecord = await repository.findOne({
      where: {
        id: workflowActionInput.objectRecordId,
      },
    });

    if (!previousObjectRecord) {
      throw new RecordCRUDActionException(
        `Failed to update: Record ${workflowActionInput.objectName} with id ${workflowActionInput.objectRecordId} not found`,
        RecordCRUDActionExceptionCode.RECORD_NOT_FOUND,
      );
    }

    const currentCacheVersion =
      await this.workspaceCacheStorageService.getMetadataVersion(workspaceId);

    if (currentCacheVersion === undefined) {
      throw new RecordCRUDActionException(
        'Failed to read: Metadata cache version not found',
        RecordCRUDActionExceptionCode.INVALID_REQUEST,
      );
    }

    const objectMetadataMaps =
      await this.workspaceCacheStorageService.getObjectMetadataMaps(
        workspaceId,
        currentCacheVersion,
      );

    if (!objectMetadataMaps) {
      throw new RecordCRUDActionException(
        'Failed to read: Object metadata collection not found',
        RecordCRUDActionExceptionCode.INVALID_REQUEST,
      );
    }

    const objectMetadataItemWithFieldsMaps =
      getObjectMetadataMapItemByNameSingular(
        objectMetadataMaps,
        workflowActionInput.objectName,
      );

    if (!objectMetadataItemWithFieldsMaps) {
      throw new RecordCRUDActionException(
        `Failed to read: Object ${workflowActionInput.objectName} not found`,
        RecordCRUDActionExceptionCode.INVALID_REQUEST,
      );
    }

    if (workflowActionInput.fieldsToUpdate.length === 0) {
      return {
        result: previousObjectRecord,
      };
    }

    const objectRecordWithFilteredFields = Object.keys(
      workflowActionInput.objectRecord,
    ).reduce((acc, key) => {
      if (workflowActionInput.fieldsToUpdate.includes(key)) {
        return {
          ...acc,
          [key]: workflowActionInput.objectRecord[key],
        };
      }

      return acc;
    }, {});

    const objectRecordFormatted = formatData(
      objectRecordWithFilteredFields,
      objectMetadataItemWithFieldsMaps,
    );

    await repository.update(workflowActionInput.objectRecordId, {
      ...objectRecordFormatted,
    });

    const updatedObjectRecord = {
      ...previousObjectRecord,
      ...objectRecordWithFilteredFields,
    };

    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: workflowActionInput.objectName,
      action: DatabaseEventAction.UPDATED,
      events: [
        {
          recordId: previousObjectRecord.id,
          objectMetadata,
          properties: {
            before: previousObjectRecord,
            after: updatedObjectRecord,
          },
        },
      ],
      workspaceId,
    });

    return {
      result: updatedObjectRecord,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for creating a draft workflow version from an existing one, copying its trigger and steps, and emitting an event for the creation of the draft.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { isDefined } from 'twenty-shared';
import { Repository } from 'typeorm';

import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';
import {
  WorkflowVersionStepException,
  WorkflowVersionStepExceptionCode,
} from 'src/modules/workflow/common/exceptions/workflow-version-step.exception';
import {
  WorkflowVersionStatus,
  WorkflowVersionWorkspaceEntity,
} from 'src/modules/workflow/common/standard-objects/workflow-version.workspace-entity';
import { assertWorkflowVersionHasSteps } from 'src/modules/workflow/common/utils/assert-workflow-version-has-steps';
import { assertWorkflowVersionIsDraft } from 'src/modules/workflow/common/utils/assert-workflow-version-is-draft.util';
import { assertWorkflowVersionTriggerIsDefined } from 'src/modules/workflow/common/utils/assert-workflow-version-trigger-is-defined.util';
import { WorkflowVersionStepWorkspaceService } from 'src/modules/workflow/workflow-builder/workflow-step/workflow-version-step.workspace-service';
import { WorkflowAction } from 'src/modules/workflow/workflow-executor/workflow-actions/types/workflow-action.type';

@Injectable()
export class WorkflowVersionWorkspaceService {
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly workflowVersionStepWorkspaceService: WorkflowVersionStepWorkspaceService,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    private readonly workspaceEventEmitter: WorkspaceEventEmitter,
  ) {}

  async createDraftFromWorkflowVersion({
    workspaceId,
    workflowId,
    workflowVersionIdToCopy,
  }: {
    workspaceId: string;
    workflowId: string;
    workflowVersionIdToCopy: string;
  }) {
    const workflowVersionRepository =
      await this.twentyORMManager.getRepository<WorkflowVersionWorkspaceEntity>(
        'workflowVersion',
      );

    const workflowVersionToCopy = await workflowVersionRepository.findOne({
      where: {
        id: workflowVersionIdToCopy,
        workflowId,
      },
    });

    if (!isDefined(workflowVersionToCopy)) {
      throw new WorkflowVersionStepException(
        'WorkflowVersion to copy not found',
        WorkflowVersionStepExceptionCode.NOT_FOUND,
      );
    }

    assertWorkflowVersionTriggerIsDefined(workflowVersionToCopy);
    assertWorkflowVersionHasSteps(workflowVersionToCopy);

    let draftWorkflowVersion = await workflowVersionRepository.findOne({
      where: {
        workflowId,
        status: WorkflowVersionStatus.DRAFT,
      },
    });

    if (!isDefined(draftWorkflowVersion)) {
      const workflowVersionsCount = await workflowVersionRepository.count({
        where: {
          workflowId,
        },
      });

      draftWorkflowVersion = await workflowVersionRepository.save({
        workflowId,
        name: `v${workflowVersionsCount + 1}`,
        status: WorkflowVersionStatus.DRAFT,
      });

      await this.emitWorkflowVersionCreationEvent({
        workflowVersion: draftWorkflowVersion,
        workspaceId,
      });
    }

    assertWorkflowVersionIsDraft(draftWorkflowVersion);

    const newWorkflowVersionTrigger = workflowVersionToCopy.trigger;
    const newWorkflowVersionSteps: WorkflowAction[] = [];

    for (const step of workflowVersionToCopy.steps) {
      const duplicatedStep =
        await this.workflowVersionStepWorkspaceService.duplicateStep({
          step,
          workspaceId,
        });

      newWorkflowVersionSteps.push(duplicatedStep);
    }

    await workflowVersionRepository.update(draftWorkflowVersion.id, {
      steps: newWorkflowVersionSteps,
      trigger: newWorkflowVersionTrigger,
    });

    return draftWorkflowVersion.id;
  }

  private async emitWorkflowVersionCreationEvent({
    workflowVersion,
    workspaceId,
  }: {
    workflowVersion: WorkflowVersionWorkspaceEntity;
    workspaceId: string;
  }) {
    const objectMetadata = await this.objectMetadataRepository.findOne({
      where: {
        nameSingular: 'workflowVersion',
        workspaceId,
      },
    });

    if (!objectMetadata) {
      throw new WorkflowVersionStepException(
        'Object metadata not found',
        WorkflowVersionStepExceptionCode.FAILURE,
      );
    }

    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: 'workflowVersion',
      action: DatabaseEventAction.CREATED,
      events: [
        {
          recordId: workflowVersion.id,
          objectMetadata,
          properties: {
            after: workflowVersion,
          },
        },
      ],
      workspaceId,
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This service manages workflow versions, including activation, deactivation, and running workflows. It interacts with a database and a message queue to handle workflow triggers and events.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { EntityManager, Repository } from 'typeorm';

import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { buildCreatedByFromFullNameMetadata } from 'src/engine/core-modules/actor/utils/build-created-by-from-full-name-metadata.util';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { User } from 'src/engine/core-modules/user/user.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { ScopedWorkspaceContextFactory } from 'src/engine/twenty-orm/factories/scoped-workspace-context.factory';
import { WorkspaceRepository } from 'src/engine/twenty-orm/repository/workspace.repository';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';
import {
  WorkflowVersionStatus,
  WorkflowVersionWorkspaceEntity,
} from 'src/modules/workflow/common/standard-objects/workflow-version.workspace-entity';
import { WorkflowWorkspaceEntity } from 'src/modules/workflow/common/standard-objects/workflow.workspace-entity';
import { assertWorkflowVersionTriggerIsDefined } from 'src/modules/workflow/common/utils/assert-workflow-version-trigger-is-defined.util';
import { WorkflowCommonWorkspaceService } from 'src/modules/workflow/common/workspace-services/workflow-common.workspace-service';
import { WorkflowRunnerWorkspaceService } from 'src/modules/workflow/workflow-runner/workspace-services/workflow-runner.workspace-service';
import { WORKFLOW_VERSION_STATUS_UPDATED } from 'src/modules/workflow/workflow-status/constants/workflow-version-status-updated.constants';
import { WorkflowVersionStatusUpdate } from 'src/modules/workflow/workflow-status/jobs/workflow-statuses-update.job';
import { DatabaseEventTriggerService } from 'src/modules/workflow/workflow-trigger/database-event-trigger/database-event-trigger.service';
import {
  WorkflowTriggerException,
  WorkflowTriggerExceptionCode,
} from 'src/modules/workflow/workflow-trigger/exceptions/workflow-trigger.exception';
import {
  WorkflowTriggerJob,
  WorkflowTriggerJobData,
} from 'src/modules/workflow/workflow-trigger/jobs/workflow-trigger.job';
import { WorkflowTriggerType } from 'src/modules/workflow/workflow-trigger/types/workflow-trigger.type';
import { assertVersionCanBeActivated } from 'src/modules/workflow/workflow-trigger/utils/assert-version-can-be-activated.util';
import { computeCronPatternFromSchedule } from 'src/modules/workflow/workflow-trigger/utils/compute-cron-pattern-from-schedule';
import { assertNever } from 'src/utils/assert';

@Injectable()
export class WorkflowTriggerWorkspaceService {
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    private readonly workflowCommonWorkspaceService: WorkflowCommonWorkspaceService,
    private readonly scopedWorkspaceContextFactory: ScopedWorkspaceContextFactory,
    private readonly workflowRunnerWorkspaceService: WorkflowRunnerWorkspaceService,
    private readonly databaseEventTriggerService: DatabaseEventTriggerService,
    private readonly workspaceEventEmitter: WorkspaceEventEmitter,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    @InjectMessageQueue(MessageQueue.workflowQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  private getWorkspaceId() {
    const workspaceId = this.scopedWorkspaceContextFactory.create().workspaceId;

    if (!workspaceId) {
      throw new WorkflowTriggerException(
        'No workspace id found',
        WorkflowTriggerExceptionCode.INTERNAL_ERROR,
      );
    }

    return workspaceId;
  }

  async runWorkflowVersion(
    workflowVersionId: string,
    payload: object,
    workspaceMemberId: string,
    { firstName, lastName }: User,
  ) {
    await this.workflowCommonWorkspaceService.getWorkflowVersionOrFail(
      workflowVersionId,
    );

    return await this.workflowRunnerWorkspaceService.run(
      this.getWorkspaceId(),
      workflowVersionId,
      payload,
      buildCreatedByFromFullNameMetadata({
        fullNameMetadata: { firstName, lastName },
        workspaceMemberId,
      }),
    );
  }

  async activateWorkflowVersion(workflowVersionId: string) {
    const workflowVersionRepository =
      await this.twentyORMManager.getRepository<WorkflowVersionWorkspaceEntity>(
        'workflowVersion',
      );

    const workflowVersionNullable = await workflowVersionRepository.findOne({
      where: { id: workflowVersionId },
    });

    const workflowVersion =
      await this.workflowCommonWorkspaceService.getValidWorkflowVersionOrFail(
        workflowVersionNullable,
      );

    const workflowRepository =
      await this.twentyORMManager.getRepository<WorkflowWorkspaceEntity>(
        'workflow',
      );

    const workflow = await workflowRepository.findOne({
      where: { id: workflowVersion.workflowId },
    });

    if (!workflow) {
      throw new WorkflowTriggerException(
        'No workflow found',
        WorkflowTriggerExceptionCode.INVALID_WORKFLOW_VERSION,
      );
    }

    assertVersionCanBeActivated(workflowVersion, workflow);

    const workspaceDataSource = await this.twentyORMManager.getDatasource();
    const queryRunner = workspaceDataSource.createQueryRunner();

    await queryRunner.connect();
    await queryRunner.startTransaction();

    const manager = queryRunner.manager;

    try {
      await this.performActivationSteps(
        workflow,
        workflowVersion,
        workflowRepository,
        workflowVersionRepository,
        manager,
      );

      await queryRunner.commitTransaction();

      return true;
    } catch (error) {
      await queryRunner.rollbackTransaction();
      throw error;
    } finally {
      await queryRunner.release();
    }
  }

  async deactivateWorkflowVersion(workflowVersionId: string) {
    const workspaceDataSource = await this.twentyORMManager.getDatasource();
    const queryRunner = workspaceDataSource.createQueryRunner();

    await queryRunner.connect();
    await queryRunner.startTransaction();

    try {
      const workflowVersionRepository =
        await this.twentyORMManager.getRepository<WorkflowVersionWorkspaceEntity>(
          'workflowVersion',
        );

      await this.performDeactivationSteps(
        workflowVersionId,
        workflowVersionRepository,
        queryRunner.manager,
      );

      await queryRunner.commitTransaction();

      return true;
    } catch (error) {
      await queryRunner.rollbackTransaction();
      throw error;
    } finally {
      await queryRunner.release();
    }
  }

  private async performActivationSteps(
    workflow: WorkflowWorkspaceEntity,
    workflowVersion: WorkflowVersionWorkspaceEntity,
    workflowRepository: WorkspaceRepository<WorkflowWorkspaceEntity>,
    workflowVersionRepository: WorkspaceRepository<WorkflowVersionWorkspaceEntity>,
    manager: EntityManager,
  ) {
    if (
      workflow.lastPublishedVersionId &&
      workflowVersion.id !== workflow.lastPublishedVersionId
    ) {
      await this.performDeactivationSteps(
        workflow.lastPublishedVersionId,
        workflowVersionRepository,
        manager,
      );
    }

    await this.upgradeWorkflowVersion(
      workflow,
      workflowVersion.id,
      workflowRepository,
      workflowVersionRepository,
      manager,
    );

    await this.setActiveVersionStatus(
      workflowVersion,
      workflowVersionRepository,
      manager,
    );

    await this.enableTrigger(workflowVersion, manager);
  }

  private async performDeactivationSteps(
    workflowVersionId: string,
    workflowVersionRepository: WorkspaceRepository<WorkflowVersionWorkspaceEntity>,
    manager: EntityManager,
  ) {
    const workflowVersionNullable = await workflowVersionRepository.findOne({
      where: { id: workflowVersionId },
    });

    const workflowVersion =
      await this.workflowCommonWorkspaceService.getValidWorkflowVersionOrFail(
        workflowVersionNullable,
      );

    if (workflowVersion.status !== WorkflowVersionStatus.ACTIVE) {
      return;
    }

    await this.setDeactivatedVersionStatus(
      workflowVersion,
      workflowVersionRepository,
      manager,
    );

    await this.disableTrigger(workflowVersion, manager);
  }

  private async setActiveVersionStatus(
    workflowVersion: WorkflowVersionWorkspaceEntity,
    workflowVersionRepository: WorkspaceRepository<WorkflowVersionWorkspaceEntity>,
    manager: EntityManager,
  ) {
    const activeWorkflowVersions = await workflowVersionRepository.find(
      {
        where: {
          workflowId: workflowVersion.workflowId,
          status: WorkflowVersionStatus.ACTIVE,
        },
      },
      manager,
    );

    if (activeWorkflowVersions.length > 0) {
      throw new WorkflowTriggerException(
        'Cannot have more than one active workflow version',
        WorkflowTriggerExceptionCode.FORBIDDEN,
      );
    }

    await workflowVersionRepository.update(
      { id: workflowVersion.id },
      { status: WorkflowVersionStatus.ACTIVE },
      manager,
    );

    await this.emitStatusUpdateEvents(
      workflowVersion,
      WorkflowVersionStatus.ACTIVE,
      this.getWorkspaceId(),
    );
  }

  private async setDeactivatedVersionStatus(
    workflowVersion: WorkflowVersionWorkspaceEntity,
    workflowVersionRepository: WorkspaceRepository<WorkflowVersionWorkspaceEntity>,
    manager: EntityManager,
  ) {
    if (workflowVersion.status !== WorkflowVersionStatus.ACTIVE) {
      throw new WorkflowTriggerException(
        'Cannot disable non-active workflow version',
        WorkflowTriggerExceptionCode.FORBIDDEN,
      );
    }

    await workflowVersionRepository.update(
      { id: workflowVersion.id },
      { status: WorkflowVersionStatus.DEACTIVATED },
      manager,
    );

    await this.emitStatusUpdateEvents(
      workflowVersion,
      WorkflowVersionStatus.DEACTIVATED,
      this.getWorkspaceId(),
    );
  }

  private async upgradeWorkflowVersion(
    workflow: WorkflowWorkspaceEntity,
    newPublishedVersionId: string,
    workflowRepository: WorkspaceRepository<WorkflowWorkspaceEntity>,
    workflowVersionRepository: WorkspaceRepository<WorkflowVersionWorkspaceEntity>,
    manager: EntityManager,
  ) {
    if (workflow.lastPublishedVersionId === newPublishedVersionId) {
      return;
    }

    if (workflow.lastPublishedVersionId) {
      await workflowVersionRepository.update(
        { id: workflow.lastPublishedVersionId },
        { status: WorkflowVersionStatus.ARCHIVED },
        manager,
      );
    }

    await workflowRepository.update(
      { id: workflow.id },
      { lastPublishedVersionId: newPublishedVersionId },
      manager,
    );
  }

  private async enableTrigger(
    workflowVersion: WorkflowVersionWorkspaceEntity,
    manager: EntityManager,
  ) {
    assertWorkflowVersionTriggerIsDefined(workflowVersion);

    switch (workflowVersion.trigger.type) {
      case WorkflowTriggerType.DATABASE_EVENT:
        await this.databaseEventTriggerService.createEventListener(
          workflowVersion.workflowId,
          workflowVersion.trigger,
          manager,
        );

        return;
      case WorkflowTriggerType.MANUAL:
        return;
      case WorkflowTriggerType.CRON: {
        const pattern = computeCronPatternFromSchedule(workflowVersion.trigger);

        await this.messageQueueService.addCron<WorkflowTriggerJobData>({
          jobName: WorkflowTriggerJob.name,
          jobId: workflowVersion.workflowId,
          data: {
            workspaceId: this.getWorkspaceId(),
            workflowId: workflowVersion.workflowId,
            payload: {},
          },
          options: {
            repeat: {
              pattern,
            },
          },
        });

        return;
      }
      default: {
        assertNever(workflowVersion.trigger);
      }
    }
  }

  private async disableTrigger(
    workflowVersion: WorkflowVersionWorkspaceEntity,
    manager: EntityManager,
  ) {
    assertWorkflowVersionTriggerIsDefined(workflowVersion);

    switch (workflowVersion.trigger.type) {
      case WorkflowTriggerType.DATABASE_EVENT:
        await this.databaseEventTriggerService.deleteEventListener(
          workflowVersion.workflowId,
          manager,
        );

        return;
      case WorkflowTriggerType.MANUAL:
        return;
      case WorkflowTriggerType.CRON:
        await this.messageQueueService.removeCron({
          jobName: WorkflowTriggerJob.name,
          jobId: workflowVersion.workflowId,
        });

        return;
      default:
        assertNever(workflowVersion.trigger);
    }
  }

  private async emitStatusUpdateEvents(
    workflowVersion: WorkflowVersionWorkspaceEntity,
    newStatus: WorkflowVersionStatus,
    workspaceId: string,
  ) {
    const objectMetadata = await this.objectMetadataRepository.findOneOrFail({
      where: {
        nameSingular: 'workflowVersion',
        workspaceId,
      },
    });

    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: 'workflowVersion',
      action: DatabaseEventAction.UPDATED,
      events: [
        {
          recordId: workflowVersion.id,
          objectMetadata,
          properties: {
            before: workflowVersion,
            after: { ...workflowVersion, status: newStatus },
            updatedFields: ['status'],
            diff: {
              status: { before: workflowVersion.status, after: newStatus },
            },
          },
        },
      ],
      workspaceId,
    });

    this.workspaceEventEmitter.emitCustomBatchEvent<WorkflowVersionStatusUpdate>(
      WORKFLOW_VERSION_STATUS_UPDATED,
      [
        {
          workflowId: workflowVersion.workflowId,
          workflowVersionId: workflowVersion.id,
          previousStatus: workflowVersion.status,
          newStatus,
        },
      ],
      workspaceId,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing fields in views within a workspace, including adding, removing, and resetting fields.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { isDefined } from 'class-validator';
import isEmpty from 'lodash.isempty';

import { AGGREGATE_OPERATIONS } from 'src/engine/api/graphql/graphql-query-runner/constants/aggregate-operations.constant';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';

@Injectable()
export class ViewService {
  private readonly logger = new Logger(ViewService.name);
  constructor(
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {}

  async addFieldToViews({
    workspaceId,
    fieldId,
    viewsIds,
    positions,
    size,
  }: {
    workspaceId: string;
    fieldId: string;
    viewsIds: string[];
    positions?: {
      [viewId: string]: number;
    }[];
    size?: number;
  }) {
    const viewFieldRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace(
        workspaceId,
        'viewField',
      );

    for (const viewId of viewsIds) {
      const position = positions?.[viewId];
      const newFieldInThisView = await viewFieldRepository.findBy({
        fieldMetadataId: fieldId,
        viewId: viewId as string,
        isVisible: true,
      });

      if (!isEmpty(newFieldInThisView)) {
        continue;
      }

      this.logger.log(
        `Adding new field ${fieldId} to view ${viewId} for workspace ${workspaceId}...`,
      );
      const newViewField = viewFieldRepository.create({
        viewId: viewId,
        fieldMetadataId: fieldId,
        isVisible: true,
        ...(isDefined(position) && { position: position }),
        ...(isDefined(size) && { size: size }),
      });

      await viewFieldRepository.save(newViewField);
      this.logger.log(
        `New field successfully added to view ${viewId} for workspace ${workspaceId}`,
      );
    }
  }

  async removeFieldFromViews({
    workspaceId,
    fieldId,
  }: {
    workspaceId: string;
    fieldId: string;
  }) {
    const viewFieldRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace(
        workspaceId,
        'viewField',
      );
    const viewsWithField = await viewFieldRepository.find({
      where: {
        fieldMetadataId: fieldId,
        isVisible: true,
      },
    });

    for (const viewWithField of viewsWithField) {
      const viewId = viewWithField.viewId;

      this.logger.log(
        `Removing field ${fieldId} from view ${viewId} for workspace ${workspaceId}...`,
      );
      await viewFieldRepository.delete({
        viewId: viewWithField.viewId as string,
        fieldMetadataId: fieldId,
      });

      this.logger.log(
        `Field ${fieldId} successfully removed from view ${viewId} for workspace ${workspaceId}`,
      );
    }
  }

  async getViewsIdsForObjectMetadataId({
    workspaceId,
    objectMetadataId,
  }: {
    workspaceId: string;
    objectMetadataId: string;
  }) {
    const viewRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace(
        workspaceId,
        'view',
      );

    return viewRepository
      .find({
        where: {
          objectMetadataId: objectMetadataId,
        },
      })
      .then((views) => views.map((view) => view.id));
  }

  async resetKanbanAggregateOperationByFieldMetadataId({
    workspaceId,
    fieldMetadataId,
  }: {
    workspaceId: string;
    fieldMetadataId: string;
  }) {
    const viewRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace(
        workspaceId,
        'view',
      );

    await viewRepository.update(
      { kanbanAggregateOperationFieldMetadataId: fieldMetadataId },
      {
        kanbanAggregateOperationFieldMetadataId: null,
        kanbanAggregateOperation: AGGREGATE_OPERATIONS.count,
      },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a repository class for managing timeline activities, including upserting, finding, updating, and inserting activities into a database.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { EntityManager } from 'typeorm';

import { ObjectRecord } from 'src/engine/api/graphql/workspace-query-builder/interfaces/object-record.interface';

import { objectRecordDiffMerge } from 'src/engine/core-modules/event-emitter/utils/object-record-diff-merge';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';

@Injectable()
export class TimelineActivityRepository {
  constructor(
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
  ) {}

  async upsertOne(
    name: string,
    properties: Partial<ObjectRecord>,
    objectName: string,
    recordId: string,
    workspaceId: string,
    workspaceMemberId?: string,
    linkedRecordCachedName?: string,
    linkedRecordId?: string,
    linkedObjectMetadataId?: string,
  ) {
    const dataSourceSchema =
      this.workspaceDataSourceService.getSchemaName(workspaceId);

    const recentTimelineActivity = await this.findRecentTimelineActivity(
      dataSourceSchema,
      name,
      objectName,
      recordId,
      workspaceMemberId,
      linkedRecordId,
      workspaceId,
    );

    // If the diff is empty, we don't need to insert or update an activity
    // this should be handled differently, events should not be triggered when we will use proper DB events.
    const isDiffEmpty =
      properties.diff !== null &&
      properties.diff &&
      Object.keys(properties.diff).length === 0;

    if (isDiffEmpty) {
      return;
    }

    if (recentTimelineActivity.length !== 0) {
      const newProps = objectRecordDiffMerge(
        recentTimelineActivity[0].properties,
        properties,
      );

      return this.updateTimelineActivity(
        dataSourceSchema,
        recentTimelineActivity[0].id,
        newProps,
        workspaceMemberId,
        workspaceId,
      );
    }

    return this.insertTimelineActivity(
      dataSourceSchema,
      name,
      properties,
      objectName,
      recordId,
      workspaceMemberId,
      linkedRecordCachedName ?? '',
      linkedRecordId,
      linkedObjectMetadataId,
      workspaceId,
    );
  }

  private async findRecentTimelineActivity(
    dataSourceSchema: string,
    name: string,
    objectName: string,
    recordId: string,
    workspaceMemberId: string | undefined,
    linkedRecordId: string | undefined,
    workspaceId: string,
  ) {
    return this.workspaceDataSourceService.executeRawQuery(
      `SELECT * FROM ${dataSourceSchema}."timelineActivity"
      WHERE "${objectName}Id" = $1
      AND "name" = $2
      AND "workspaceMemberId" = $3
      AND ${
        linkedRecordId ? `"linkedRecordId" = $4` : `"linkedRecordId" IS NULL`
      }
      AND "createdAt" >= NOW() - interval '10 minutes'`,
      linkedRecordId
        ? [recordId, name, workspaceMemberId, linkedRecordId]
        : [recordId, name, workspaceMemberId],
      workspaceId,
    );
  }

  private async updateTimelineActivity(
    dataSourceSchema: string,
    id: string,
    properties: Partial<ObjectRecord>,
    workspaceMemberId: string | undefined,
    workspaceId: string,
  ) {
    return this.workspaceDataSourceService.executeRawQuery(
      `UPDATE ${dataSourceSchema}."timelineActivity"
      SET "properties" = $2, "workspaceMemberId" = $3
      WHERE "id" = $1`,
      [id, properties, workspaceMemberId],
      workspaceId,
    );
  }

  private async insertTimelineActivity(
    dataSourceSchema: string,
    name: string,
    properties: Partial<ObjectRecord>,
    objectName: string,
    recordId: string,
    workspaceMemberId: string | undefined,
    linkedRecordCachedName: string,
    linkedRecordId: string | undefined,
    linkedObjectMetadataId: string | undefined,
    workspaceId: string,
  ) {
    return this.workspaceDataSourceService.executeRawQuery(
      `INSERT INTO ${dataSourceSchema}."timelineActivity"
    ("name", "properties", "workspaceMemberId", "${objectName}Id", "linkedRecordCachedName", "linkedRecordId", "linkedObjectMetadataId")
    VALUES ($1, $2, $3, $4, $5, $6, $7)`,
      [
        name,
        properties,
        workspaceMemberId,
        recordId,
        linkedRecordCachedName ?? '',
        linkedRecordId,
        linkedObjectMetadataId,
      ],
      workspaceId,
    );
  }

  public async insertTimelineActivitiesForObject(
    objectName: string,
    activities: {
      name: string;
      properties: Partial<ObjectRecord> | null;
      workspaceMemberId: string | undefined;
      recordId: string | null;
      linkedRecordCachedName: string;
      linkedRecordId: string | null | undefined;
      linkedObjectMetadataId: string | undefined;
    }[],
    workspaceId: string,
    transactionManager?: EntityManager,
  ) {
    if (activities.length === 0) {
      return;
    }

    const dataSourceSchema =
      this.workspaceDataSourceService.getSchemaName(workspaceId);

    return this.workspaceDataSourceService.executeRawQuery(
      `INSERT INTO ${dataSourceSchema}."timelineActivity"
    ("name", "properties", "workspaceMemberId", "${objectName}Id", "linkedRecordCachedName", "linkedRecordId", "linkedObjectMetadataId")
    VALUES ${activities
      .map(
        (_, index) =>
          `($${index * 7 + 1}, $${index * 7 + 2}, $${index * 7 + 3}, $${
            index * 7 + 4
          }, $${index * 7 + 5}, $${index * 7 + 6}, $${index * 7 + 7})`,
      )
      .join(',')}`,
      activities
        .map((activity) => [
          activity.name,
          activity.properties,
          activity.workspaceMemberId,
          activity.recordId,
          activity.linkedRecordCachedName ?? '',
          activity.linkedRecordId,
          activity.linkedObjectMetadataId,
        ])
        .flat(),
      workspaceId,
      transactionManager,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener for workspace member creation and update events, checking workspace activation status, and enqueuing jobs to match or unmatch participants based on user email changes.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { WorkspaceActivationStatus } from 'twenty-shared';
import { Repository } from 'typeorm';

import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { ObjectRecordUpdateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-update.event';
import { objectRecordChangedProperties as objectRecordUpdateEventChangedProperties } from 'src/engine/core-modules/event-emitter/utils/object-record-changed-properties.util';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  MessageParticipantMatchParticipantJob,
  MessageParticipantMatchParticipantJobData,
} from 'src/modules/messaging/message-participant-manager/jobs/message-participant-match-participant.job';
import {
  MessageParticipantUnmatchParticipantJob,
  MessageParticipantUnmatchParticipantJobData,
} from 'src/modules/messaging/message-participant-manager/jobs/message-participant-unmatch-participant.job';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';
@Injectable()
export class MessageParticipantWorkspaceMemberListener {
  constructor(
    @InjectMessageQueue(MessageQueue.messagingQueue)
    private readonly messageQueueService: MessageQueueService,
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
  ) {}

  @OnDatabaseBatchEvent('workspaceMember', DatabaseEventAction.CREATED)
  async handleCreatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordCreateEvent<WorkspaceMemberWorkspaceEntity>
    >,
  ) {
    const workspace = await this.workspaceRepository.findOneBy({
      id: payload.workspaceId,
    });

    if (
      !workspace ||
      workspace.activationStatus !== WorkspaceActivationStatus.ACTIVE
    ) {
      return;
    }

    for (const eventPayload of payload.events) {
      if (!eventPayload.properties.after.userEmail) {
        continue;
      }

      await this.messageQueueService.add<MessageParticipantMatchParticipantJobData>(
        MessageParticipantMatchParticipantJob.name,
        {
          workspaceId: payload.workspaceId,
          email: eventPayload.properties.after.userEmail,
          workspaceMemberId: eventPayload.recordId,
        },
      );
    }
  }

  @OnDatabaseBatchEvent('workspaceMember', DatabaseEventAction.UPDATED)
  async handleUpdatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordUpdateEvent<WorkspaceMemberWorkspaceEntity>
    >,
  ) {
    for (const eventPayload of payload.events) {
      if (
        objectRecordUpdateEventChangedProperties<WorkspaceMemberWorkspaceEntity>(
          eventPayload.properties.before,
          eventPayload.properties.after,
        ).includes('userEmail')
      ) {
        await this.messageQueueService.add<MessageParticipantUnmatchParticipantJobData>(
          MessageParticipantUnmatchParticipantJob.name,
          {
            workspaceId: payload.workspaceId,
            email: eventPayload.properties.before.userEmail,
            personId: eventPayload.recordId,
          },
        );

        await this.messageQueueService.add<MessageParticipantMatchParticipantJobData>(
          MessageParticipantMatchParticipantJob.name,
          {
            workspaceId: payload.workspaceId,
            email: eventPayload.properties.after.userEmail,
            workspaceMemberId: eventPayload.recordId,
          },
        );
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener for person entity creation and update events, which triggers message queue jobs to match or unmatch participants based on email changes.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { ObjectRecordUpdateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-update.event';
import { objectRecordChangedProperties as objectRecordUpdateEventChangedProperties } from 'src/engine/core-modules/event-emitter/utils/object-record-changed-properties.util';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import {
  MessageParticipantMatchParticipantJob,
  MessageParticipantMatchParticipantJobData,
} from 'src/modules/messaging/message-participant-manager/jobs/message-participant-match-participant.job';
import {
  MessageParticipantUnmatchParticipantJob,
  MessageParticipantUnmatchParticipantJobData,
} from 'src/modules/messaging/message-participant-manager/jobs/message-participant-unmatch-participant.job';
import { PersonWorkspaceEntity } from 'src/modules/person/standard-objects/person.workspace-entity';

@Injectable()
export class MessageParticipantPersonListener {
  constructor(
    @InjectMessageQueue(MessageQueue.messagingQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('person', DatabaseEventAction.CREATED)
  async handleCreatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordCreateEvent<PersonWorkspaceEntity>
    >,
  ) {
    for (const eventPayload of payload.events) {
      if (!eventPayload.properties.after.emails?.primaryEmail) {
        continue;
      }

      await this.messageQueueService.add<MessageParticipantMatchParticipantJobData>(
        MessageParticipantMatchParticipantJob.name,
        {
          workspaceId: payload.workspaceId,
          email: eventPayload.properties.after.emails?.primaryEmail,
          personId: eventPayload.recordId,
        },
      );
    }
  }

  @OnDatabaseBatchEvent('person', DatabaseEventAction.UPDATED)
  async handleUpdatedEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordUpdateEvent<PersonWorkspaceEntity>
    >,
  ) {
    for (const eventPayload of payload.events) {
      if (
        objectRecordUpdateEventChangedProperties(
          eventPayload.properties.before,
          eventPayload.properties.after,
        ).includes('emails')
      ) {
        await this.messageQueueService.add<MessageParticipantUnmatchParticipantJobData>(
          MessageParticipantUnmatchParticipantJob.name,
          {
            workspaceId: payload.workspaceId,
            email: eventPayload.properties.before.emails?.primaryEmail,
            personId: eventPayload.recordId,
          },
        );

        await this.messageQueueService.add<MessageParticipantMatchParticipantJobData>(
          MessageParticipantMatchParticipantJob.name,
          {
            workspaceId: payload.workspaceId,
            email: eventPayload.properties.after.emails?.primaryEmail,
            personId: eventPayload.recordId,
          },
        );
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing remote servers, including creating, updating, and deleting them, while handling foreign data wrappers and user mappings.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectDataSource, InjectRepository } from '@nestjs/typeorm';

import isEmpty from 'lodash.isempty';
import { DataSource, EntityManager, Repository } from 'typeorm';
import { v4 } from 'uuid';

import { ForeignDataWrapperServerQueryFactory } from 'src/engine/api/graphql/workspace-query-builder/factories/foreign-data-wrapper-server-query.factory';
import { encryptText } from 'src/engine/core-modules/auth/auth.util';
import { FeatureFlag } from 'src/engine/core-modules/feature-flag/feature-flag.entity';
import { JwtWrapperService } from 'src/engine/core-modules/jwt/services/jwt-wrapper.service';
import { CreateRemoteServerInput } from 'src/engine/metadata-modules/remote-server/dtos/create-remote-server.input';
import { UpdateRemoteServerInput } from 'src/engine/metadata-modules/remote-server/dtos/update-remote-server.input';
import {
  RemoteServerEntity,
  RemoteServerType,
} from 'src/engine/metadata-modules/remote-server/remote-server.entity';
import {
  RemoteServerException,
  RemoteServerExceptionCode,
} from 'src/engine/metadata-modules/remote-server/remote-server.exception';
import { RemoteTableService } from 'src/engine/metadata-modules/remote-server/remote-table/remote-table.service';
import { buildUpdateRemoteServerRawQuery } from 'src/engine/metadata-modules/remote-server/utils/build-update-remote-server-raw-query.utils';
import {
  validateObjectAgainstInjections,
  validateStringAgainstInjections,
} from 'src/engine/metadata-modules/remote-server/utils/validate-remote-server-input.utils';
import { validateRemoteServerType } from 'src/engine/metadata-modules/remote-server/utils/validate-remote-server-type.util';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';

@Injectable()
export class RemoteServerService<T extends RemoteServerType> {
  constructor(
    @InjectRepository(RemoteServerEntity, 'metadata')
    private readonly remoteServerRepository: Repository<
      RemoteServerEntity<RemoteServerType>
    >,
    @InjectDataSource('metadata')
    private readonly metadataDataSource: DataSource,
    private readonly jwtWrapperService: JwtWrapperService,
    private readonly foreignDataWrapperServerQueryFactory: ForeignDataWrapperServerQueryFactory,
    private readonly remoteTableService: RemoteTableService,
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
    @InjectRepository(FeatureFlag, 'core')
    private readonly featureFlagRepository: Repository<FeatureFlag>,
  ) {}

  public async createOneRemoteServer(
    remoteServerInput: CreateRemoteServerInput<T>,
    workspaceId: string,
  ): Promise<RemoteServerEntity<RemoteServerType>> {
    this.validateRemoteServerInputAgainstInjections(remoteServerInput);

    validateRemoteServerType(
      remoteServerInput.foreignDataWrapperType,
      this.featureFlagRepository,
      workspaceId,
    );

    const foreignDataWrapperId = v4();

    let remoteServerToCreate = {
      ...remoteServerInput,
      workspaceId,
      foreignDataWrapperId,
    };

    if (remoteServerInput.userMappingOptions) {
      remoteServerToCreate = {
        ...remoteServerToCreate,
        userMappingOptions: {
          ...remoteServerInput.userMappingOptions,
          password: this.encryptPassword(
            remoteServerInput.userMappingOptions.password,
            workspaceId,
          ),
        },
      };
    }

    return this.metadataDataSource.transaction(
      async (entityManager: EntityManager) => {
        const createdRemoteServer = entityManager.create(
          RemoteServerEntity,
          remoteServerToCreate,
        );

        const foreignDataWrapperQuery =
          this.foreignDataWrapperServerQueryFactory.createForeignDataWrapperServer(
            createdRemoteServer.foreignDataWrapperId,
            remoteServerInput.foreignDataWrapperType,
            remoteServerInput.foreignDataWrapperOptions,
          );

        await entityManager.query(foreignDataWrapperQuery);

        if (remoteServerInput.userMappingOptions) {
          const userMappingQuery =
            this.foreignDataWrapperServerQueryFactory.createUserMapping(
              createdRemoteServer.foreignDataWrapperId,
              remoteServerInput.userMappingOptions,
            );

          await entityManager.query(userMappingQuery);
        }

        await entityManager.save(RemoteServerEntity, createdRemoteServer);

        return createdRemoteServer;
      },
    );
  }

  public async updateOneRemoteServer(
    remoteServerInput: UpdateRemoteServerInput<T>,
    workspaceId: string,
  ): Promise<RemoteServerEntity<RemoteServerType>> {
    this.validateRemoteServerInputAgainstInjections(remoteServerInput);

    const remoteServer = await this.findOneByIdWithinWorkspace(
      remoteServerInput.id,
      workspaceId,
    );

    if (!remoteServer) {
      throw new RemoteServerException(
        'Remote server does not exist',
        RemoteServerExceptionCode.REMOTE_SERVER_NOT_FOUND,
      );
    }

    const currentRemoteTablesForServer =
      await this.remoteTableService.findRemoteTablesByServerId({
        remoteServerId: remoteServer.id,
        workspaceId,
      });

    if (currentRemoteTablesForServer.length > 0) {
      throw new RemoteServerException(
        'Cannot update remote server with synchronized tables',
        RemoteServerExceptionCode.REMOTE_SERVER_MUTATION_NOT_ALLOWED,
      );
    }

    const foreignDataWrapperId = remoteServer.foreignDataWrapperId;

    let partialRemoteServerWithUpdates = {
      ...remoteServerInput,
      workspaceId,
      foreignDataWrapperId,
    };

    if (partialRemoteServerWithUpdates?.userMappingOptions?.password) {
      partialRemoteServerWithUpdates = {
        ...partialRemoteServerWithUpdates,
        userMappingOptions: {
          ...partialRemoteServerWithUpdates.userMappingOptions,
          password: this.encryptPassword(
            partialRemoteServerWithUpdates.userMappingOptions.password,
            workspaceId,
          ),
        },
      };
    }

    return this.metadataDataSource.transaction(
      async (entityManager: EntityManager) => {
        const updatedRemoteServer = await this.updateRemoteServer(
          partialRemoteServerWithUpdates,
        );

        if (
          !isEmpty(partialRemoteServerWithUpdates.foreignDataWrapperOptions)
        ) {
          const foreignDataWrapperQuery =
            this.foreignDataWrapperServerQueryFactory.updateForeignDataWrapperServer(
              {
                foreignDataWrapperId,
                foreignDataWrapperOptions:
                  partialRemoteServerWithUpdates.foreignDataWrapperOptions,
              },
            );

          await entityManager.query(foreignDataWrapperQuery);
        }

        if (!isEmpty(partialRemoteServerWithUpdates.userMappingOptions)) {
          const userMappingQuery =
            this.foreignDataWrapperServerQueryFactory.updateUserMapping(
              foreignDataWrapperId,
              partialRemoteServerWithUpdates.userMappingOptions,
            );

          await entityManager.query(userMappingQuery);
        }

        return updatedRemoteServer;
      },
    );
  }

  public async deleteOneRemoteServer(
    id: string,
    workspaceId: string,
  ): Promise<RemoteServerEntity<RemoteServerType>> {
    validateStringAgainstInjections(id);

    const remoteServer = await this.remoteServerRepository.findOne({
      where: {
        id,
        workspaceId,
      },
    });

    if (!remoteServer) {
      throw new RemoteServerException(
        'Remote server does not exist',
        RemoteServerExceptionCode.REMOTE_SERVER_NOT_FOUND,
      );
    }

    await this.remoteTableService.unsyncAll(workspaceId, remoteServer);

    return this.metadataDataSource.transaction(
      async (entityManager: EntityManager) => {
        await entityManager.query(
          `DROP SERVER "${remoteServer.foreignDataWrapperId}" CASCADE`,
        );
        await entityManager.delete(RemoteServerEntity, id);

        return remoteServer;
      },
    );
  }

  public async findOneByIdWithinWorkspace(id: string, workspaceId: string) {
    return this.remoteServerRepository.findOne({
      where: {
        id,
        workspaceId,
      },
    });
  }

  public async findManyByTypeWithinWorkspace<T extends RemoteServerType>(
    foreignDataWrapperType: T,
    workspaceId: string,
  ) {
    return this.remoteServerRepository.find({
      where: {
        foreignDataWrapperType,
        workspaceId,
      },
    });
  }

  private encryptPassword(password: string, workspaceId: string) {
    const key = this.jwtWrapperService.generateAppSecret(
      'REMOTE_SERVER',
      workspaceId,
    );

    return encryptText(password, key);
  }

  private async updateRemoteServer(
    remoteServerToUpdate: DeepPartial<RemoteServerEntity<RemoteServerType>> &
      Pick<RemoteServerEntity<RemoteServerType>, 'workspaceId' | 'id'>,
  ): Promise<RemoteServerEntity<RemoteServerType>> {
    const [parameters, rawQuery] =
      buildUpdateRemoteServerRawQuery(remoteServerToUpdate);

    const updateResult = await this.workspaceDataSourceService.executeRawQuery(
      rawQuery,
      parameters,
      remoteServerToUpdate.workspaceId,
    );

    return updateResult[0][0];
  }

  private validateRemoteServerInputAgainstInjections(
    remoteServerInput: CreateRemoteServerInput<T> | UpdateRemoteServerInput<T>,
  ) {
    if (remoteServerInput.foreignDataWrapperOptions) {
      validateObjectAgainstInjections(
        remoteServerInput.foreignDataWrapperOptions,
      );
    }

    if (remoteServerInput.userMappingOptions) {
      validateObjectAgainstInjections(remoteServerInput.userMappingOptions);
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a GraphQL resolver for file and image uploads, handling file streams, converting them to buffers, and uploading them to a specified workspace and folder.
Code Snippet:
import { UseGuards } from '@nestjs/common';
import { Args, Mutation, Resolver } from '@nestjs/graphql';

import { FileUpload, GraphQLUpload } from 'graphql-upload';

import { FileFolder } from 'src/engine/core-modules/file/interfaces/file-folder.interface';

import { FileUploadService } from 'src/engine/core-modules/file/file-upload/services/file-upload.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { AuthWorkspace } from 'src/engine/decorators/auth/auth-workspace.decorator';
import { WorkspaceAuthGuard } from 'src/engine/guards/workspace-auth.guard';
import { streamToBuffer } from 'src/utils/stream-to-buffer';

@UseGuards(WorkspaceAuthGuard)
@Resolver()
export class FileUploadResolver {
  constructor(private readonly fileUploadService: FileUploadService) {}

  @Mutation(() => String)
  async uploadFile(
    @AuthWorkspace() { id: workspaceId }: Workspace,
    @Args({ name: 'file', type: () => GraphQLUpload })
    { createReadStream, filename, mimetype }: FileUpload,
    @Args('fileFolder', { type: () => FileFolder, nullable: true })
    fileFolder: FileFolder,
  ): Promise<string> {
    const stream = createReadStream();
    const buffer = await streamToBuffer(stream);

    const { path } = await this.fileUploadService.uploadFile({
      file: buffer,
      filename,
      mimeType: mimetype,
      fileFolder,
      workspaceId,
    });

    return path;
  }

  @Mutation(() => String)
  async uploadImage(
    @AuthWorkspace() { id: workspaceId }: Workspace,
    @Args({ name: 'file', type: () => GraphQLUpload })
    { createReadStream, filename, mimetype }: FileUpload,
    @Args('fileFolder', { type: () => FileFolder, nullable: true })
    fileFolder: FileFolder,
  ): Promise<string> {
    const stream = createReadStream();
    const buffer = await streamToBuffer(stream);

    const { paths } = await this.fileUploadService.uploadImage({
      file: buffer,
      filename,
      mimeType: mimetype,
      fileFolder,
      workspaceId,
    });

    return paths[0];
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener that triggers file deletion jobs when workspace members are destroyed, specifically targeting the deletion of avatar files.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { ObjectRecordDestroyEvent } from 'src/engine/core-modules/event-emitter/types/object-record-destroy.event';
import {
  FileDeletionJob,
  FileDeletionJobData,
} from 'src/engine/core-modules/file/jobs/file-deletion.job';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';

@Injectable()
export class FileWorkspaceMemberListener {
  constructor(
    @InjectMessageQueue(MessageQueue.deleteCascadeQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('workspaceMember', DatabaseEventAction.DESTROYED)
  async handleDestroyEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordDestroyEvent<WorkspaceMemberWorkspaceEntity>
    >,
  ) {
    for (const event of payload.events) {
      const avatarUrl = event.properties.before.avatarUrl;

      if (!avatarUrl) {
        continue;
      }

      this.messageQueueService.add<FileDeletionJobData>(FileDeletionJob.name, {
        workspaceId: payload.workspaceId,
        fullPath: event.properties.before.avatarUrl,
      });
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service that listens for database destroy events on attachment records and adds file deletion jobs to a message queue.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { ObjectRecordDestroyEvent } from 'src/engine/core-modules/event-emitter/types/object-record-destroy.event';
import {
  FileDeletionJob,
  FileDeletionJobData,
} from 'src/engine/core-modules/file/jobs/file-deletion.job';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { AttachmentWorkspaceEntity } from 'src/modules/attachment/standard-objects/attachment.workspace-entity';

@Injectable()
export class FileAttachmentListener {
  constructor(
    @InjectMessageQueue(MessageQueue.deleteCascadeQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  @OnDatabaseBatchEvent('attachment', DatabaseEventAction.DESTROYED)
  async handleDestroyEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordDestroyEvent<AttachmentWorkspaceEntity>
    >,
  ) {
    for (const event of payload.events) {
      await this.messageQueueService.add<FileDeletionJobData>(
        FileDeletionJob.name,
        {
          workspaceId: payload.workspaceId,
          fullPath: event.properties.before.fullPath,
        },
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a NestJS module for managing workspaces, including entities, services, and resolvers.
Code Snippet:
import { Module } from '@nestjs/common';
import { TypeOrmModule } from '@nestjs/typeorm';

import { NestjsQueryGraphQLModule } from '@ptc-org/nestjs-query-graphql';
import { NestjsQueryTypeOrmModule } from '@ptc-org/nestjs-query-typeorm';

import { TypeORMModule } from 'src/database/typeorm/typeorm.module';
import { TokenModule } from 'src/engine/core-modules/auth/token/token.module';
import { BillingModule } from 'src/engine/core-modules/billing/billing.module';
import { BillingSubscription } from 'src/engine/core-modules/billing/entities/billing-subscription.entity';
import { DomainManagerModule } from 'src/engine/core-modules/domain-manager/domain-manager.module';
import { FeatureFlagModule } from 'src/engine/core-modules/feature-flag/feature-flag.module';
import { FileUploadModule } from 'src/engine/core-modules/file/file-upload/file-upload.module';
import { FileModule } from 'src/engine/core-modules/file/file.module';
import { OnboardingModule } from 'src/engine/core-modules/onboarding/onboarding.module';
import { UserWorkspace } from 'src/engine/core-modules/user-workspace/user-workspace.entity';
import { UserWorkspaceModule } from 'src/engine/core-modules/user-workspace/user-workspace.module';
import { User } from 'src/engine/core-modules/user/user.entity';
import { WorkspaceWorkspaceMemberListener } from 'src/engine/core-modules/workspace/workspace-workspace-member.listener';
import { WorkspaceResolver } from 'src/engine/core-modules/workspace/workspace.resolver';
import { DataSourceModule } from 'src/engine/metadata-modules/data-source/data-source.module';
import { PermissionsModule } from 'src/engine/metadata-modules/permissions/permissions.module';
import { RoleModule } from 'src/engine/metadata-modules/role/role.module';
import { WorkspaceMetadataCacheModule } from 'src/engine/metadata-modules/workspace-metadata-cache/workspace-metadata-cache.module';
import { WorkspaceCacheStorageModule } from 'src/engine/workspace-cache-storage/workspace-cache-storage.module';
import { WorkspaceManagerModule } from 'src/engine/workspace-manager/workspace-manager.module';

import { workspaceAutoResolverOpts } from './workspace.auto-resolver-opts';
import { Workspace } from './workspace.entity';

import { WorkspaceService } from './services/workspace.service';

@Module({
  imports: [
    TypeORMModule,
    TypeOrmModule.forFeature([BillingSubscription], 'core'),
    NestjsQueryGraphQLModule.forFeature({
      imports: [
        DomainManagerModule,
        BillingModule,
        FileModule,
        TokenModule,
        FileUploadModule,
        WorkspaceMetadataCacheModule,
        NestjsQueryTypeOrmModule.forFeature(
          [User, Workspace, UserWorkspace],
          'core',
        ),
        UserWorkspaceModule,
        WorkspaceManagerModule,
        FeatureFlagModule,
        DataSourceModule,
        OnboardingModule,
        TypeORMModule,
        PermissionsModule,
        WorkspaceCacheStorageModule,
        RoleModule,
      ],
      services: [WorkspaceService],
      resolvers: workspaceAutoResolverOpts,
    }),
  ],
  exports: [WorkspaceService],
  providers: [
    WorkspaceResolver,
    WorkspaceService,
    WorkspaceWorkspaceMemberListener,
  ],
})
export class WorkspaceModule {}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a plugin for Sentry tracing in a GraphQL application, capturing details of operations, users, and documents.
Code Snippet:
import * as Sentry from '@sentry/node';
import {
  handleStreamOrSingleExecutionResult,
  Plugin,
  getDocumentString,
} from '@envelop/core';
import { OperationDefinitionNode, Kind, print } from 'graphql';

import { GraphQLContext } from 'src/engine/api/graphql/graphql-config/graphql-config.service';

export const useSentryTracing = <
  PluginContext extends GraphQLContext,
>(): Plugin<PluginContext> => {
  return {
    onExecute({ args }) {
      const transactionName = args.operationName || 'Anonymous Operation';
      const rootOperation = args.document.definitions.find(
        (o) => o.kind === Kind.OPERATION_DEFINITION,
      ) as OperationDefinitionNode;
      const operationType = rootOperation.operation;

      const user = args.contextValue.user;
      const workspace = args.contextValue.workspace;
      const document = getDocumentString(args.document, print);

      Sentry.setTags({
        operationName: transactionName,
        operation: operationType,
      });

      const scope = Sentry.getCurrentScope();

      scope.setTransactionName(transactionName);

      if (user) {
        scope.setUser({
          id: user.id,
          email: user.email,
          firstName: user.firstName,
          lastName: user.lastName,
          workspaceId: workspace?.id,
          workspaceDisplayName: workspace?.displayName,
        });
      }

      if (document) {
        scope.setExtra('document', document);
      }

      return {
        onExecuteDone(payload) {
          return handleStreamOrSingleExecutionResult(payload, () => {});
        },
      };
    },
  };
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a listener for workspace member creation and deletion events, which triggers a job to update subscription quantities if billing is enabled.
Code Snippet:
/* @license Enterprise */

import { Injectable } from '@nestjs/common';

import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import {
  UpdateSubscriptionQuantityJob,
  UpdateSubscriptionQuantityJobData,
} from 'src/engine/core-modules/billing/jobs/update-subscription-quantity.job';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';

@Injectable()
export class BillingWorkspaceMemberListener {
  constructor(
    @InjectMessageQueue(MessageQueue.billingQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly environmentService: EnvironmentService,
  ) {}

  @OnDatabaseBatchEvent('workspaceMember', DatabaseEventAction.CREATED)
  @OnDatabaseBatchEvent('workspaceMember', DatabaseEventAction.DELETED)
  async handleCreateOrDeleteEvent(
    payload: WorkspaceEventBatch<
      ObjectRecordCreateEvent<WorkspaceMemberWorkspaceEntity>
    >,
  ) {
    if (!this.environmentService.get('IS_BILLING_ENABLED')) {
      return;
    }

    await this.messageQueueService.add<UpdateSubscriptionQuantityJobData>(
      UpdateSubscriptionQuantityJob.name,
      { workspaceId: payload.workspaceId },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to create a GraphQL schema for a workspace, utilizing metadata and caching mechanisms.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { makeExecutableSchema } from '@graphql-tools/schema';
import chalk from 'chalk';
import { GraphQLSchema, printSchema } from 'graphql';
import { gql } from 'graphql-tag';

import {
  GraphqlQueryRunnerException,
  GraphqlQueryRunnerExceptionCode,
} from 'src/engine/api/graphql/graphql-query-runner/errors/graphql-query-runner.exception';
import { ScalarsExplorerService } from 'src/engine/api/graphql/services/scalars-explorer.service';
import { workspaceResolverBuilderMethodNames } from 'src/engine/api/graphql/workspace-resolver-builder/factories/factories';
import { WorkspaceResolverFactory } from 'src/engine/api/graphql/workspace-resolver-builder/workspace-resolver.factory';
import { WorkspaceGraphQLSchemaFactory } from 'src/engine/api/graphql/workspace-schema-builder/workspace-graphql-schema.factory';
import { AuthContext } from 'src/engine/core-modules/auth/types/auth-context.type';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { FeatureFlagService } from 'src/engine/core-modules/feature-flag/services/feature-flag.service';
import { DataSourceService } from 'src/engine/metadata-modules/data-source/data-source.service';
import { WorkspaceMetadataCacheService } from 'src/engine/metadata-modules/workspace-metadata-cache/services/workspace-metadata-cache.service';
import { WorkspaceCacheStorageService } from 'src/engine/workspace-cache-storage/workspace-cache-storage.service';

@Injectable()
export class WorkspaceSchemaFactory {
  constructor(
    private readonly dataSourceService: DataSourceService,
    private readonly scalarsExplorerService: ScalarsExplorerService,
    private readonly workspaceGraphQLSchemaFactory: WorkspaceGraphQLSchemaFactory,
    private readonly workspaceResolverFactory: WorkspaceResolverFactory,
    private readonly workspaceCacheStorageService: WorkspaceCacheStorageService,
    private readonly workspaceMetadataCacheService: WorkspaceMetadataCacheService,
    private readonly featureFlagService: FeatureFlagService,
  ) {}

  async createGraphQLSchema(authContext: AuthContext): Promise<GraphQLSchema> {
    if (!authContext.workspace?.id) {
      return new GraphQLSchema({});
    }

    const cachedIsNewRelationEnabled =
      await this.workspaceCacheStorageService.getIsNewRelationEnabled(
        authContext.workspace.id,
      );

    const isNewRelationEnabled = await this.featureFlagService.isFeatureEnabled(
      FeatureFlagKey.IsNewRelationEnabled,
      authContext.workspace.id,
    );

    if (isNewRelationEnabled) {
      // eslint-disable-next-line no-console
      console.log(
        chalk.yellow(' New relation schema generation is enabled '),
      );
    }

    const dataSourcesMetadata =
      await this.dataSourceService.getDataSourcesMetadataFromWorkspaceId(
        authContext.workspace.id,
      );

    if (!dataSourcesMetadata || dataSourcesMetadata.length === 0) {
      return new GraphQLSchema({});
    }

    const currentCacheVersion =
      await this.workspaceCacheStorageService.getMetadataVersion(
        authContext.workspace.id,
      );

    if (currentCacheVersion === undefined) {
      await this.workspaceMetadataCacheService.recomputeMetadataCache({
        workspaceId: authContext.workspace.id,
      });

      throw new GraphqlQueryRunnerException(
        'Metadata cache version not found',
        GraphqlQueryRunnerExceptionCode.METADATA_CACHE_VERSION_NOT_FOUND,
      );
    }

    // TODO: remove this after the feature flag is droped
    if (
      (isNewRelationEnabled && cachedIsNewRelationEnabled === undefined) ||
      (isNewRelationEnabled !== cachedIsNewRelationEnabled &&
        cachedIsNewRelationEnabled !== undefined)
    ) {
      // eslint-disable-next-line no-console
      console.log(
        chalk.yellow('Recomputing due to new relation feature flag'),
        {
          isNewRelationEnabled,
        },
      );

      await this.workspaceCacheStorageService.setIsNewRelationEnabled(
        authContext.workspace.id,
        isNewRelationEnabled,
      );

      await this.workspaceMetadataCacheService.recomputeMetadataCache({
        workspaceId: authContext.workspace.id,
      });

      throw new GraphqlQueryRunnerException(
        'Metadata cache recomputation required due to relation feature flag change',
        GraphqlQueryRunnerExceptionCode.METADATA_CACHE_FEATURE_FLAG_RECOMPUTATION_REQUIRED,
      );
    }

    const objectMetadataMaps =
      await this.workspaceCacheStorageService.getObjectMetadataMaps(
        authContext.workspace.id,
        currentCacheVersion,
      );

    if (!objectMetadataMaps) {
      await this.workspaceMetadataCacheService.recomputeMetadataCache({
        workspaceId: authContext.workspace.id,
      });
      throw new GraphqlQueryRunnerException(
        'Object metadata collection not found',
        GraphqlQueryRunnerExceptionCode.METADATA_CACHE_VERSION_NOT_FOUND,
      );
    }

    const objectMetadataCollection = Object.values(objectMetadataMaps.byId).map(
      (objectMetadataItem) => ({
        ...objectMetadataItem,
        fields: objectMetadataItem.fields,
        indexes: objectMetadataItem.indexMetadatas,
      }),
    );

    // Get typeDefs from cache
    let typeDefs = await this.workspaceCacheStorageService.getGraphQLTypeDefs(
      authContext.workspace.id,
      currentCacheVersion,
    );
    let usedScalarNames =
      await this.workspaceCacheStorageService.getGraphQLUsedScalarNames(
        authContext.workspace.id,
        currentCacheVersion,
      );

    // If typeDefs are not cached, generate them
    if (!typeDefs || !usedScalarNames) {
      const autoGeneratedSchema =
        await this.workspaceGraphQLSchemaFactory.create(
          objectMetadataCollection,
          workspaceResolverBuilderMethodNames,
        );

      usedScalarNames =
        this.scalarsExplorerService.getUsedScalarNames(autoGeneratedSchema);
      typeDefs = printSchema(autoGeneratedSchema);

      await this.workspaceCacheStorageService.setGraphQLTypeDefs(
        authContext.workspace.id,
        currentCacheVersion,
        typeDefs,
      );
      await this.workspaceCacheStorageService.setGraphQLUsedScalarNames(
        authContext.workspace.id,
        currentCacheVersion,
        usedScalarNames,
      );
    }

    const autoGeneratedResolvers = await this.workspaceResolverFactory.create(
      authContext,
      objectMetadataMaps,
      workspaceResolverBuilderMethodNames,
    );
    const scalarsResolvers =
      this.scalarsExplorerService.getScalarResolvers(usedScalarNames);

    const executableSchema = makeExecutableSchema({
      typeDefs: gql`
        ${typeDefs}
      `,
      resolvers: {
        ...scalarsResolvers,
        ...autoGeneratedResolvers,
      },
    });

    return executableSchema;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a service for creating multiple records via GraphQL, handling both insert and upsert operations, and emitting creation events.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { In, InsertResult } from 'typeorm';

import {
  GraphqlQueryBaseResolverService,
  GraphqlQueryResolverExecutionArgs,
} from 'src/engine/api/graphql/graphql-query-runner/interfaces/base-resolver-service';
import { ObjectRecord } from 'src/engine/api/graphql/workspace-query-builder/interfaces/object-record.interface';
import { WorkspaceQueryRunnerOptions } from 'src/engine/api/graphql/workspace-query-runner/interfaces/query-runner-option.interface';
import { CreateManyResolverArgs } from 'src/engine/api/graphql/workspace-resolver-builder/interfaces/workspace-resolvers-builder.interface';

import { QUERY_MAX_RECORDS } from 'src/engine/api/graphql/graphql-query-runner/constants/query-max-records.constant';
import { ObjectRecordsToGraphqlConnectionHelper } from 'src/engine/api/graphql/graphql-query-runner/helpers/object-records-to-graphql-connection.helper';
import { assertIsValidUuid } from 'src/engine/api/graphql/workspace-query-runner/utils/assert-is-valid-uuid.util';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { assertMutationNotOnRemoteObject } from 'src/engine/metadata-modules/object-metadata/utils/assert-mutation-not-on-remote-object.util';
import { formatResult } from 'src/engine/twenty-orm/utils/format-result.util';

@Injectable()
export class GraphqlQueryCreateManyResolverService extends GraphqlQueryBaseResolverService<
  CreateManyResolverArgs,
  ObjectRecord[]
> {
  async resolve(
    executionArgs: GraphqlQueryResolverExecutionArgs<CreateManyResolverArgs>,
    featureFlagsMap: Record<FeatureFlagKey, boolean>,
  ): Promise<ObjectRecord[]> {
    const { authContext, objectMetadataItemWithFieldMaps, objectMetadataMaps } =
      executionArgs.options;

    const objectRecords: InsertResult = !executionArgs.args.upsert
      ? await executionArgs.repository.insert(executionArgs.args.data)
      : await executionArgs.repository.upsert(executionArgs.args.data, {
          conflictPaths: ['id'],
          skipUpdateIfNoValuesChanged: true,
        });

    const queryBuilder = executionArgs.repository.createQueryBuilder(
      objectMetadataItemWithFieldMaps.nameSingular,
    );

    const nonFormattedUpsertedRecords = await queryBuilder
      .where({
        id: In(objectRecords.generatedMaps.map((record) => record.id)),
      })
      .take(QUERY_MAX_RECORDS)
      .getMany();

    const upsertedRecords = formatResult<ObjectRecord[]>(
      nonFormattedUpsertedRecords,
      objectMetadataItemWithFieldMaps,
      objectMetadataMaps,
    );

    this.apiEventEmitterService.emitCreateEvents(
      upsertedRecords,
      authContext,
      objectMetadataItemWithFieldMaps,
    );

    if (executionArgs.graphqlQuerySelectedFieldsResult.relations) {
      await this.processNestedRelationsHelper.processNestedRelations({
        objectMetadataMaps,
        parentObjectMetadataItem: objectMetadataItemWithFieldMaps,
        parentObjectRecords: upsertedRecords,
        relations: executionArgs.graphqlQuerySelectedFieldsResult.relations,
        limit: QUERY_MAX_RECORDS,
        authContext,
        dataSource: executionArgs.dataSource,
        isNewRelationEnabled:
          featureFlagsMap[FeatureFlagKey.IsNewRelationEnabled],
      });
    }

    const typeORMObjectRecordsParser =
      new ObjectRecordsToGraphqlConnectionHelper(
        objectMetadataMaps,
        featureFlagsMap,
      );

    return upsertedRecords.map((record: ObjectRecord) =>
      typeORMObjectRecordsParser.processRecord({
        objectRecord: record,
        objectName: objectMetadataItemWithFieldMaps.nameSingular,
        take: 1,
        totalCount: 1,
      }),
    );
  }

  async validate<T extends ObjectRecord>(
    args: CreateManyResolverArgs<Partial<T>>,
    options: WorkspaceQueryRunnerOptions,
  ): Promise<void> {
    assertMutationNotOnRemoteObject(options.objectMetadataItemWithFieldMaps);

    args.data.forEach((record) => {
      if (record?.id) {
        assertIsValidUuid(record.id);
      }
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for updating multiple records via a GraphQL query, including validation and formatting of data.
Code Snippet:
import { Injectable } from '@nestjs/common';

import isEmpty from 'lodash.isempty';

import {
  GraphqlQueryBaseResolverService,
  GraphqlQueryResolverExecutionArgs,
} from 'src/engine/api/graphql/graphql-query-runner/interfaces/base-resolver-service';
import { ObjectRecord } from 'src/engine/api/graphql/workspace-query-builder/interfaces/object-record.interface';
import { WorkspaceQueryRunnerOptions } from 'src/engine/api/graphql/workspace-query-runner/interfaces/query-runner-option.interface';
import { UpdateManyResolverArgs } from 'src/engine/api/graphql/workspace-resolver-builder/interfaces/workspace-resolvers-builder.interface';

import { QUERY_MAX_RECORDS } from 'src/engine/api/graphql/graphql-query-runner/constants/query-max-records.constant';
import {
  GraphqlQueryRunnerException,
  GraphqlQueryRunnerExceptionCode,
} from 'src/engine/api/graphql/graphql-query-runner/errors/graphql-query-runner.exception';
import { ObjectRecordsToGraphqlConnectionHelper } from 'src/engine/api/graphql/graphql-query-runner/helpers/object-records-to-graphql-connection.helper';
import { assertIsValidUuid } from 'src/engine/api/graphql/workspace-query-runner/utils/assert-is-valid-uuid.util';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { assertMutationNotOnRemoteObject } from 'src/engine/metadata-modules/object-metadata/utils/assert-mutation-not-on-remote-object.util';
import { formatData } from 'src/engine/twenty-orm/utils/format-data.util';
import { formatResult } from 'src/engine/twenty-orm/utils/format-result.util';
import { computeTableName } from 'src/engine/utils/compute-table-name.util';

@Injectable()
export class GraphqlQueryUpdateManyResolverService extends GraphqlQueryBaseResolverService<
  UpdateManyResolverArgs,
  ObjectRecord[]
> {
  async resolve(
    executionArgs: GraphqlQueryResolverExecutionArgs<UpdateManyResolverArgs>,
    featureFlagsMap: Record<FeatureFlagKey, boolean>,
  ): Promise<ObjectRecord[]> {
    const { authContext, objectMetadataItemWithFieldMaps, objectMetadataMaps } =
      executionArgs.options;

    const queryBuilder = executionArgs.repository.createQueryBuilder(
      objectMetadataItemWithFieldMaps.nameSingular,
    );

    const existingRecordsBuilder = queryBuilder.clone();

    executionArgs.graphqlQueryParser.applyFilterToBuilder(
      existingRecordsBuilder,
      objectMetadataItemWithFieldMaps.nameSingular,
      executionArgs.args.filter,
    );

    const existingRecords = await existingRecordsBuilder.getMany();

    const formattedExistingRecords = formatResult<ObjectRecord[]>(
      existingRecords,
      objectMetadataItemWithFieldMaps,
      objectMetadataMaps,
    );

    if (isEmpty(formattedExistingRecords)) {
      throw new GraphqlQueryRunnerException(
        'Records not found',
        GraphqlQueryRunnerExceptionCode.RECORD_NOT_FOUND,
      );
    }

    const tableName = computeTableName(
      objectMetadataItemWithFieldMaps.nameSingular,
      objectMetadataItemWithFieldMaps.isCustom,
    );

    executionArgs.graphqlQueryParser.applyFilterToBuilder(
      queryBuilder,
      tableName,
      executionArgs.args.filter,
    );

    const data = formatData(
      executionArgs.args.data,
      objectMetadataItemWithFieldMaps,
    );

    const nonFormattedUpdatedObjectRecords = await queryBuilder
      .update(data)
      .returning('*')
      .execute();

    const formattedUpdatedRecords = formatResult<ObjectRecord[]>(
      nonFormattedUpdatedObjectRecords.raw,
      objectMetadataItemWithFieldMaps,
      objectMetadataMaps,
    );

    this.apiEventEmitterService.emitUpdateEvents(
      formattedExistingRecords,
      formattedUpdatedRecords,
      Object.keys(executionArgs.args.data),
      authContext,
      objectMetadataItemWithFieldMaps,
    );

    if (executionArgs.graphqlQuerySelectedFieldsResult.relations) {
      await this.processNestedRelationsHelper.processNestedRelations({
        objectMetadataMaps,
        parentObjectMetadataItem: objectMetadataItemWithFieldMaps,
        parentObjectRecords: formattedUpdatedRecords,
        relations: executionArgs.graphqlQuerySelectedFieldsResult.relations,
        limit: QUERY_MAX_RECORDS,
        authContext,
        dataSource: executionArgs.dataSource,
        isNewRelationEnabled:
          featureFlagsMap[FeatureFlagKey.IsNewRelationEnabled],
      });
    }

    const typeORMObjectRecordsParser =
      new ObjectRecordsToGraphqlConnectionHelper(
        objectMetadataMaps,
        featureFlagsMap,
      );

    return formattedUpdatedRecords.map((record: ObjectRecord) =>
      typeORMObjectRecordsParser.processRecord({
        objectRecord: record,
        objectName: objectMetadataItemWithFieldMaps.nameSingular,
        take: 1,
        totalCount: 1,
      }),
    );
  }

  async validate(
    args: UpdateManyResolverArgs<Partial<ObjectRecord>>,
    options: WorkspaceQueryRunnerOptions,
  ): Promise<void> {
    assertMutationNotOnRemoteObject(options.objectMetadataItemWithFieldMaps);
    if (!args.filter) {
      throw new Error('Filter is required');
    }

    args.filter.id?.in?.forEach((id: string) => assertIsValidUuid(id));
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This service handles the creation of a single object record through a GraphQL resolver, supporting both insert and upsert operations, and emits create events.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { In, InsertResult } from 'typeorm';

import {
  GraphqlQueryBaseResolverService,
  GraphqlQueryResolverExecutionArgs,
} from 'src/engine/api/graphql/graphql-query-runner/interfaces/base-resolver-service';
import { ObjectRecord } from 'src/engine/api/graphql/workspace-query-builder/interfaces/object-record.interface';
import { WorkspaceQueryRunnerOptions } from 'src/engine/api/graphql/workspace-query-runner/interfaces/query-runner-option.interface';
import { CreateOneResolverArgs } from 'src/engine/api/graphql/workspace-resolver-builder/interfaces/workspace-resolvers-builder.interface';

import { QUERY_MAX_RECORDS } from 'src/engine/api/graphql/graphql-query-runner/constants/query-max-records.constant';
import { ObjectRecordsToGraphqlConnectionHelper } from 'src/engine/api/graphql/graphql-query-runner/helpers/object-records-to-graphql-connection.helper';
import { assertIsValidUuid } from 'src/engine/api/graphql/workspace-query-runner/utils/assert-is-valid-uuid.util';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { assertMutationNotOnRemoteObject } from 'src/engine/metadata-modules/object-metadata/utils/assert-mutation-not-on-remote-object.util';
import { formatResult } from 'src/engine/twenty-orm/utils/format-result.util';

@Injectable()
export class GraphqlQueryCreateOneResolverService extends GraphqlQueryBaseResolverService<
  CreateOneResolverArgs,
  ObjectRecord
> {
  async resolve(
    executionArgs: GraphqlQueryResolverExecutionArgs<CreateOneResolverArgs>,
    featureFlagsMap: Record<FeatureFlagKey, boolean>,
  ): Promise<ObjectRecord> {
    const { authContext, objectMetadataMaps, objectMetadataItemWithFieldMaps } =
      executionArgs.options;

    const objectRecords: InsertResult = !executionArgs.args.upsert
      ? await executionArgs.repository.insert(executionArgs.args.data)
      : await executionArgs.repository.upsert(executionArgs.args.data, {
          conflictPaths: ['id'],
          skipUpdateIfNoValuesChanged: true,
        });

    const queryBuilder = executionArgs.repository.createQueryBuilder(
      objectMetadataItemWithFieldMaps.nameSingular,
    );

    const nonFormattedUpsertedRecords = await queryBuilder
      .where({
        id: In(objectRecords.generatedMaps.map((record) => record.id)),
      })
      .take(QUERY_MAX_RECORDS)
      .getMany();

    const upsertedRecords = formatResult<ObjectRecord[]>(
      nonFormattedUpsertedRecords,
      objectMetadataItemWithFieldMaps,
      objectMetadataMaps,
    );

    this.apiEventEmitterService.emitCreateEvents(
      upsertedRecords,
      authContext,
      objectMetadataItemWithFieldMaps,
    );

    if (executionArgs.graphqlQuerySelectedFieldsResult.relations) {
      await this.processNestedRelationsHelper.processNestedRelations({
        objectMetadataMaps,
        parentObjectMetadataItem: objectMetadataItemWithFieldMaps,
        parentObjectRecords: upsertedRecords,
        relations: executionArgs.graphqlQuerySelectedFieldsResult.relations,
        limit: QUERY_MAX_RECORDS,
        authContext,
        dataSource: executionArgs.dataSource,
        isNewRelationEnabled:
          featureFlagsMap[FeatureFlagKey.IsNewRelationEnabled],
      });
    }

    const typeORMObjectRecordsParser =
      new ObjectRecordsToGraphqlConnectionHelper(
        objectMetadataMaps,
        featureFlagsMap,
      );

    return typeORMObjectRecordsParser.processRecord({
      objectRecord: upsertedRecords[0],
      objectName: objectMetadataItemWithFieldMaps.nameSingular,
      take: 1,
      totalCount: 1,
    });
  }

  async validate(
    args: CreateOneResolverArgs<Partial<ObjectRecord>>,
    options: WorkspaceQueryRunnerOptions,
  ): Promise<void> {
    assertMutationNotOnRemoteObject(options.objectMetadataItemWithFieldMaps);

    if (args.data?.id) {
      assertIsValidUuid(args.data.id);
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: Parses selected GraphQL fields to identify and accumulate available aggregations based on field metadata.
Code Snippet:
import { FieldMetadataInterface } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata.interface';

import { GraphqlQuerySelectedFieldsResult } from 'src/engine/api/graphql/graphql-query-runner/graphql-query-parsers/graphql-query-selected-fields/graphql-selected-fields.parser';
import {
  AggregationField,
  getAvailableAggregationsFromObjectFields,
} from 'src/engine/api/graphql/workspace-schema-builder/utils/get-available-aggregations-from-object-fields.util';

export class GraphqlQuerySelectedFieldsAggregateParser {
  parse(
    graphqlSelectedFields: Partial<Record<string, any>>,
    fieldMetadataMapByName: Record<string, FieldMetadataInterface>,
    accumulator: GraphqlQuerySelectedFieldsResult,
  ): void {
    const availableAggregations: Record<string, AggregationField> =
      getAvailableAggregationsFromObjectFields(
        Object.values(fieldMetadataMapByName),
      );

    for (const selectedField of Object.keys(graphqlSelectedFields)) {
      const selectedAggregation = availableAggregations[selectedField];

      if (!selectedAggregation) {
        continue;
      }

      accumulator.aggregate[selectedField] = selectedAggregation;
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for emitting database events (create, update, delete, restore, destroy) for object records in a workspace context.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ObjectRecord } from 'src/engine/api/graphql/workspace-query-builder/interfaces/object-record.interface';
import { ObjectMetadataInterface } from 'src/engine/metadata-modules/field-metadata/interfaces/object-metadata.interface';

import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { AuthContext } from 'src/engine/core-modules/auth/types/auth-context.type';
import { objectRecordChangedValues } from 'src/engine/core-modules/event-emitter/utils/object-record-changed-values';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';

@Injectable()
export class ApiEventEmitterService {
  constructor(private readonly workspaceEventEmitter: WorkspaceEventEmitter) {}

  public emitCreateEvents<T extends ObjectRecord>(
    records: T[],
    authContext: AuthContext,
    objectMetadataItem: ObjectMetadataInterface,
  ): void {
    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: objectMetadataItem.nameSingular,
      action: DatabaseEventAction.CREATED,
      events: records.map((record) => ({
        userId: authContext.user?.id,
        recordId: record.id,
        objectMetadata: objectMetadataItem,
        properties: {
          before: null,
          after: record,
        },
      })),
      workspaceId: authContext.workspace.id,
    });
  }

  public emitUpdateEvents<T extends ObjectRecord>(
    existingRecords: T[],
    records: T[],
    updatedFields: string[],
    authContext: AuthContext,
    objectMetadataItem: ObjectMetadataInterface,
  ): void {
    const mappedExistingRecords = existingRecords.reduce(
      (acc, { id, ...record }) => ({
        ...acc,
        [id]: record,
      }),
      {},
    );

    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: objectMetadataItem.nameSingular,
      action: DatabaseEventAction.UPDATED,
      events: records.map((record) => {
        const before = mappedExistingRecords[record.id];
        const after = record;
        const diff = objectRecordChangedValues(
          before,
          after,
          updatedFields,
          objectMetadataItem,
        );

        return {
          userId: authContext.user?.id,
          recordId: record.id,
          objectMetadata: objectMetadataItem,
          properties: {
            before,
            after,
            updatedFields,
            diff,
          },
        };
      }),
      workspaceId: authContext.workspace.id,
    });
  }

  public emitDeletedEvents<T extends ObjectRecord>(
    records: T[],
    authContext: AuthContext,
    objectMetadataItem: ObjectMetadataInterface,
  ): void {
    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: objectMetadataItem.nameSingular,
      action: DatabaseEventAction.DELETED,
      events: records.map((record) => {
        return {
          userId: authContext.user?.id,
          recordId: record.id,
          objectMetadata: objectMetadataItem,
          properties: {
            before: record,
            after: null,
          },
        };
      }),
      workspaceId: authContext.workspace.id,
    });
  }

  public emitRestoreEvents<T extends ObjectRecord>(
    records: T[],
    authContext: AuthContext,
    objectMetadataItem: ObjectMetadataInterface,
  ): void {
    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: objectMetadataItem.nameSingular,
      action: DatabaseEventAction.RESTORED,
      events: records.map((record) => {
        return {
          userId: authContext.user?.id,
          recordId: record.id,
          objectMetadata: objectMetadataItem,
          properties: {
            before: null,
            after: record,
          },
        };
      }),
      workspaceId: authContext.workspace.id,
    });
  }

  public emitDestroyEvents<T extends ObjectRecord>(
    records: T[],
    authContext: AuthContext,
    objectMetadataItem: ObjectMetadataInterface,
  ): void {
    this.workspaceEventEmitter.emitDatabaseBatchEvent({
      objectMetadataNameSingular: objectMetadataItem.nameSingular,
      action: DatabaseEventAction.DESTROYED,
      events: records.map((record) => {
        return {
          userId: authContext.user?.id,
          recordId: record.id,
          objectMetadata: objectMetadataItem,
          properties: {
            before: record,
            after: null,
          },
        };
      }),
      workspaceId: authContext.workspace.id,
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: Defines a NestJS module for handling workspace query operations, including authentication, data sources, metadata, and telemetry.
Code Snippet:
import { Module } from '@nestjs/common';
import { TypeOrmModule } from '@nestjs/typeorm';

import { WorkspaceQueryBuilderModule } from 'src/engine/api/graphql/workspace-query-builder/workspace-query-builder.module';
import { workspaceQueryRunnerFactories } from 'src/engine/api/graphql/workspace-query-runner/factories';
import { TelemetryListener } from 'src/engine/api/graphql/workspace-query-runner/listeners/telemetry.listener';
import { WorkspaceQueryHookModule } from 'src/engine/api/graphql/workspace-query-runner/workspace-query-hook/workspace-query-hook.module';
import { AnalyticsModule } from 'src/engine/core-modules/analytics/analytics.module';
import { AuthModule } from 'src/engine/core-modules/auth/auth.module';
import { FeatureFlag } from 'src/engine/core-modules/feature-flag/feature-flag.entity';
import { FeatureFlagModule } from 'src/engine/core-modules/feature-flag/feature-flag.module';
import { FileModule } from 'src/engine/core-modules/file/file.module';
import { TelemetryModule } from 'src/engine/core-modules/telemetry/telemetry.module';
import { ObjectMetadataRepositoryModule } from 'src/engine/object-metadata-repository/object-metadata-repository.module';
import { WorkspaceDataSourceModule } from 'src/engine/workspace-datasource/workspace-datasource.module';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';

import { EntityEventsToDbListener } from './listeners/entity-events-to-db.listener';

@Module({
  imports: [
    AuthModule,
    WorkspaceQueryBuilderModule,
    WorkspaceDataSourceModule,
    WorkspaceQueryHookModule,
    ObjectMetadataRepositoryModule.forFeature([WorkspaceMemberWorkspaceEntity]),
    TypeOrmModule.forFeature([FeatureFlag], 'core'),
    AnalyticsModule,
    TelemetryModule,
    FileModule,
    FeatureFlagModule,
  ],
  providers: [
    ...workspaceQueryRunnerFactories,
    EntityEventsToDbListener,
    TelemetryListener,
  ],
  exports: [...workspaceQueryRunnerFactories],
})
export class WorkspaceQueryRunnerModule {}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service that listens for database and custom batch events, specifically handling creation events and user signup events, and sends telemetry and analytics data based on these events.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { OnDatabaseBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-database-batch-event.decorator';
import { DatabaseEventAction } from 'src/engine/api/graphql/graphql-query-runner/enums/database-event-action';
import { AnalyticsService } from 'src/engine/core-modules/analytics/analytics.service';
import { ObjectRecordCreateEvent } from 'src/engine/core-modules/event-emitter/types/object-record-create.event';
import { TelemetryService } from 'src/engine/core-modules/telemetry/telemetry.service';
import { WorkspaceEventBatch } from 'src/engine/workspace-event-emitter/types/workspace-event.type';
import { USER_SIGNUP_EVENT_NAME } from 'src/engine/api/graphql/workspace-query-runner/constants/user-signup-event-name.constants';
import { OnCustomBatchEvent } from 'src/engine/api/graphql/graphql-query-runner/decorators/on-custom-batch-event.decorator';

@Injectable()
export class TelemetryListener {
  constructor(
    private readonly analyticsService: AnalyticsService,
    private readonly telemetryService: TelemetryService,
  ) {}

  @OnDatabaseBatchEvent('*', DatabaseEventAction.CREATED)
  async handleAllCreate(payload: WorkspaceEventBatch<ObjectRecordCreateEvent>) {
    await Promise.all(
      payload.events.map((eventPayload) =>
        this.analyticsService.create(
          {
            action: payload.name,
            payload: {},
          },
          eventPayload.userId,
          payload.workspaceId,
        ),
      ),
    );
  }

  @OnCustomBatchEvent(USER_SIGNUP_EVENT_NAME)
  async handleUserSignup(
    payload: WorkspaceEventBatch<ObjectRecordCreateEvent>,
  ) {
    await Promise.all(
      payload.events.map(async (eventPayload) => {
        this.analyticsService.create(
          {
            action: USER_SIGNUP_EVENT_NAME,
            payload: {},
          },
          eventPayload.userId,
          payload.workspaceId,
        );

        this.telemetryService.create(
          {
            action: USER_SIGNUP_EVENT_NAME,
            payload: {
              payload,
              userId: undefined,
              workspaceId: undefined,
            },
          },
          eventPayload.userId,
          payload.workspaceId,
        );
      }),
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to backfill record positions for a given workspace, identifying records without a position and updating them accordingly.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { isDefined } from 'class-validator';
import { FieldMetadataType } from 'twenty-shared';
import { Repository } from 'typeorm';

import {
  RecordPositionQueryFactory,
  RecordPositionQueryType,
} from 'src/engine/api/graphql/workspace-query-builder/factories/record-position-query.factory';
import { RecordPositionFactory } from 'src/engine/api/graphql/workspace-query-runner/factories/record-position.factory';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';

@Injectable()
export class RecordPositionBackfillService {
  private readonly logger = new Logger(RecordPositionBackfillService.name);
  constructor(
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    private readonly recordPositionFactory: RecordPositionFactory,
    private readonly recordPositionQueryFactory: RecordPositionQueryFactory,
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
  ) {}

  async backfill(workspaceId: string, dryRun: boolean) {
    this.logger.log(
      `Starting backfilling record positions for workspace ${workspaceId}`,
    );

    const dataSourceSchema =
      this.workspaceDataSourceService.getSchemaName(workspaceId);

    const objectMetadataCollection = await this.objectMetadataRepository.find({
      where: {
        workspaceId,
        fields: {
          name: 'position',
          type: FieldMetadataType.POSITION,
        },
      },
      relations: {
        fields: true,
      },
    });

    for (const objectMetadata of objectMetadataCollection) {
      const [recordsWithoutPositionQuery, recordsWithoutPositionQueryParams] =
        this.recordPositionQueryFactory.create(
          {
            recordPositionQueryType: RecordPositionQueryType.FIND_BY_POSITION,
            positionValue: null,
          },
          objectMetadata,
          dataSourceSchema,
        );

      const recordsWithoutPosition =
        await this.workspaceDataSourceService.executeRawQuery(
          recordsWithoutPositionQuery,
          recordsWithoutPositionQueryParams,
          workspaceId,
        );

      if (
        !isDefined(recordsWithoutPosition) ||
        recordsWithoutPosition?.length === 0
      ) {
        this.logger.log(
          `No records without position for ${objectMetadata.nameSingular}`,
        );
        continue;
      }

      const position = await this.recordPositionFactory.create({
        objectMetadata: {
          isCustom: objectMetadata.isCustom,
          nameSingular: objectMetadata.nameSingular,
        },
        value: 'last',
        workspaceId,
      });

      for (
        let recordIndex = 0;
        recordIndex < recordsWithoutPosition.length;
        recordIndex++
      ) {
        const recordId = recordsWithoutPosition[recordIndex].id;

        if (!recordId) {
          this.logger.log(
            `Fetched record without id for ${objectMetadata.nameSingular}`,
          );
          continue;
        }

        const backfilledPosition = position + recordIndex;

        this.logger.log(
          `Backfilling position ${backfilledPosition} for ${objectMetadata.nameSingular} ${recordId}`,
        );

        if (dryRun) {
          continue;
        }

        const [query, params] = this.recordPositionQueryFactory.create(
          {
            recordPositionQueryType: RecordPositionQueryType.UPDATE_POSITION,
            recordId: recordsWithoutPosition[recordIndex].id,
            positionValue: position + recordIndex,
          },
          objectMetadata,
          dataSourceSchema,
        );

        await this.workspaceDataSourceService.executeRawQuery(
          query,
          params,
          workspaceId,
        );
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for generating GraphQL type definitions based on metadata, including composite and dynamic objects, enums, and input types.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import chalk from 'chalk';

import { CompositeType } from 'src/engine/metadata-modules/field-metadata/interfaces/composite-type.interface';
import { ObjectMetadataInterface } from 'src/engine/metadata-modules/field-metadata/interfaces/object-metadata.interface';

import { CompositeEnumTypeDefinitionFactory } from 'src/engine/api/graphql/workspace-schema-builder/factories/composite-enum-type-definition.factory';
import { CompositeInputTypeDefinitionFactory } from 'src/engine/api/graphql/workspace-schema-builder/factories/composite-input-type-definition.factory';
import { CompositeObjectTypeDefinitionFactory } from 'src/engine/api/graphql/workspace-schema-builder/factories/composite-object-type-definition.factory';
import { EnumTypeDefinitionFactory } from 'src/engine/api/graphql/workspace-schema-builder/factories/enum-type-definition.factory';
import { ExtendObjectTypeDefinitionV2Factory } from 'src/engine/api/graphql/workspace-schema-builder/factories/extend-object-type-definition-v2.factory';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { FeatureFlagService } from 'src/engine/core-modules/feature-flag/services/feature-flag.service';
import { compositeTypeDefinitions } from 'src/engine/metadata-modules/field-metadata/composite-types';

import { ConnectionTypeDefinitionFactory } from './factories/connection-type-definition.factory';
import { EdgeTypeDefinitionFactory } from './factories/edge-type-definition.factory';
import { ExtendObjectTypeDefinitionFactory } from './factories/extend-object-type-definition.factory';
import {
  InputTypeDefinitionFactory,
  InputTypeDefinitionKind,
} from './factories/input-type-definition.factory';
import {
  ObjectTypeDefinitionFactory,
  ObjectTypeDefinitionKind,
} from './factories/object-type-definition.factory';
import { WorkspaceBuildSchemaOptions } from './interfaces/workspace-build-schema-optionts.interface';
import { TypeDefinitionsStorage } from './storages/type-definitions.storage';
import { objectContainsRelationField } from './utils/object-contains-relation-field';

@Injectable()
export class TypeDefinitionsGenerator {
  private readonly logger = new Logger(TypeDefinitionsGenerator.name);

  constructor(
    private readonly typeDefinitionsStorage: TypeDefinitionsStorage,
    private readonly objectTypeDefinitionFactory: ObjectTypeDefinitionFactory,
    private readonly compositeObjectTypeDefinitionFactory: CompositeObjectTypeDefinitionFactory,
    private readonly enumTypeDefinitionFactory: EnumTypeDefinitionFactory,
    private readonly compositeEnumTypeDefinitionFactory: CompositeEnumTypeDefinitionFactory,
    private readonly inputTypeDefinitionFactory: InputTypeDefinitionFactory,
    private readonly compositeInputTypeDefinitionFactory: CompositeInputTypeDefinitionFactory,
    private readonly edgeTypeDefinitionFactory: EdgeTypeDefinitionFactory,
    private readonly connectionTypeDefinitionFactory: ConnectionTypeDefinitionFactory,
    private readonly extendObjectTypeDefinitionFactory: ExtendObjectTypeDefinitionFactory,
    private readonly extendObjectTypeDefinitionV2Factory: ExtendObjectTypeDefinitionV2Factory,
    private readonly featureFlagService: FeatureFlagService,
  ) {}

  async generate(
    objectMetadataCollection: ObjectMetadataInterface[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    // Generate composite type objects first because they can be used in dynamic objects
    await this.generateCompositeTypeDefs(options);
    // Generate metadata objects
    await this.generateMetadataTypeDefs(objectMetadataCollection, options);
  }

  /**
   * GENERATE COMPOSITE TYPE OBJECTS
   */
  private async generateCompositeTypeDefs(
    options: WorkspaceBuildSchemaOptions,
  ) {
    const compositeTypeCollection = [...compositeTypeDefinitions.values()];

    this.logger.log(
      `Generating composite type objects: [${compositeTypeCollection
        .map((compositeType) => compositeType.type)
        .join(', ')}]`,
    );

    // Generate composite types first because they can be used in metadata objects
    this.generateCompositeEnumTypeDefs(compositeTypeCollection, options);
    this.generateCompositeObjectTypeDefs(compositeTypeCollection, options);
    this.generateCompositeInputTypeDefs(compositeTypeCollection, options);
  }

  private generateCompositeEnumTypeDefs(
    compositeTypes: CompositeType[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    const enumTypeDefs = compositeTypes
      .map((compositeType) =>
        this.compositeEnumTypeDefinitionFactory.create(compositeType, options),
      )
      .flat();

    this.typeDefinitionsStorage.addEnumTypes(enumTypeDefs);
  }

  private generateCompositeObjectTypeDefs(
    compositeTypes: CompositeType[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    const compositeObjectTypeDefs = compositeTypes.map((compositeType) =>
      this.compositeObjectTypeDefinitionFactory.create(compositeType, options),
    );

    this.typeDefinitionsStorage.addObjectTypes(compositeObjectTypeDefs);
  }

  private generateCompositeInputTypeDefs(
    compisteTypes: CompositeType[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    const inputTypeDefs = compisteTypes
      .map((compositeType) => {
        const optionalExtendedObjectMetadata = {
          ...compositeType,
          properties: compositeType.properties.map((property) => ({
            ...property,
            isRequired: false,
          })),
        };

        return [
          // Input type for create
          this.compositeInputTypeDefinitionFactory.create(
            compositeType,
            InputTypeDefinitionKind.Create,
            options,
          ),
          // Input type for update
          this.compositeInputTypeDefinitionFactory.create(
            optionalExtendedObjectMetadata,
            InputTypeDefinitionKind.Update,
            options,
          ),
          // Filter input type
          this.compositeInputTypeDefinitionFactory.create(
            optionalExtendedObjectMetadata,
            InputTypeDefinitionKind.Filter,
            options,
          ),
          // OrderBy input type
          this.compositeInputTypeDefinitionFactory.create(
            optionalExtendedObjectMetadata,
            InputTypeDefinitionKind.OrderBy,
            options,
          ),
        ];
      })
      .flat();

    this.typeDefinitionsStorage.addInputTypes(inputTypeDefs);
  }

  /**
   * GENERATE METADATA OBJECTS
   */

  private async generateMetadataTypeDefs(
    dynamicObjectMetadataCollection: ObjectMetadataInterface[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    this.logger.log(
      `Generating metadata objects: [${dynamicObjectMetadataCollection
        .map((object) => object.nameSingular)
        .join(', ')}]`,
    );

    // Generate dynamic objects
    this.generateEnumTypeDefs(dynamicObjectMetadataCollection, options);
    this.generateObjectTypeDefs(dynamicObjectMetadataCollection, options);
    this.generatePaginationTypeDefs(dynamicObjectMetadataCollection, options);
    this.generateInputTypeDefs(dynamicObjectMetadataCollection, options);
    await this.generateExtendedObjectTypeDefs(
      dynamicObjectMetadataCollection,
      options,
    );
  }

  private generateObjectTypeDefs(
    objectMetadataCollection: ObjectMetadataInterface[] | CompositeType[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    const objectTypeDefs = objectMetadataCollection.map((objectMetadata) =>
      this.objectTypeDefinitionFactory.create(
        objectMetadata,
        ObjectTypeDefinitionKind.Plain,
        options,
      ),
    );

    this.typeDefinitionsStorage.addObjectTypes(objectTypeDefs);
  }

  private generatePaginationTypeDefs(
    objectMetadataCollection: ObjectMetadataInterface[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    const edgeTypeDefs = objectMetadataCollection.map((objectMetadata) =>
      this.edgeTypeDefinitionFactory.create(objectMetadata, options),
    );

    this.typeDefinitionsStorage.addObjectTypes(edgeTypeDefs);

    // Connection type defs are using edge type defs
    const connectionTypeDefs = objectMetadataCollection.map((objectMetadata) =>
      this.connectionTypeDefinitionFactory.create(objectMetadata, options),
    );

    this.typeDefinitionsStorage.addObjectTypes(connectionTypeDefs);
  }

  private generateInputTypeDefs(
    objectMetadataCollection: ObjectMetadataInterface[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    const inputTypeDefs = objectMetadataCollection
      .map((objectMetadata) => {
        const optionalExtendedObjectMetadata = {
          ...objectMetadata,
          fields: objectMetadata.fields.map((field) => ({
            ...field,
            isNullable: true,
          })),
        };

        return [
          // Input type for create
          this.inputTypeDefinitionFactory.create(
            objectMetadata,
            InputTypeDefinitionKind.Create,
            options,
          ),
          // Input type for update
          this.inputTypeDefinitionFactory.create(
            optionalExtendedObjectMetadata,
            InputTypeDefinitionKind.Update,
            options,
          ),
          // Filter input type
          this.inputTypeDefinitionFactory.create(
            optionalExtendedObjectMetadata,
            InputTypeDefinitionKind.Filter,
            options,
          ),
          // OrderBy input type
          this.inputTypeDefinitionFactory.create(
            optionalExtendedObjectMetadata,
            InputTypeDefinitionKind.OrderBy,
            options,
          ),
        ];
      })
      .flat();

    this.typeDefinitionsStorage.addInputTypes(inputTypeDefs);
  }

  private generateEnumTypeDefs(
    objectMetadataCollection: ObjectMetadataInterface[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    const enumTypeDefs = objectMetadataCollection
      .map((objectMetadata) =>
        this.enumTypeDefinitionFactory.create(objectMetadata, options),
      )
      .flat();

    this.typeDefinitionsStorage.addEnumTypes(enumTypeDefs);
  }

  private async generateExtendedObjectTypeDefs(
    objectMetadataCollection: ObjectMetadataInterface[],
    options: WorkspaceBuildSchemaOptions,
  ) {
    // Generate extended object type defs only for objects that contain composite fields
    const objectMetadataCollectionWithCompositeFields =
      objectMetadataCollection.filter(objectContainsRelationField);
    const workspaceId =
      objectMetadataCollectionWithCompositeFields[0]?.workspaceId;

    if (!workspaceId) {
      throw new Error('Workspace ID not found');
    }

    const isNewRelationEnabled = await this.featureFlagService.isFeatureEnabled(
      FeatureFlagKey.IsNewRelationEnabled,
      workspaceId,
    );

    if (!isNewRelationEnabled) {
      const objectTypeDefs = objectMetadataCollectionWithCompositeFields.map(
        (objectMetadata) =>
          this.extendObjectTypeDefinitionFactory.create(
            objectMetadata,
            options,
          ),
      );

      this.typeDefinitionsStorage.addObjectTypes(objectTypeDefs);
    } else {
      this.logger.log(
        chalk.green('Extend object type definition with new relation fields'),
      );
      const objectTypeDefsV2 = objectMetadataCollectionWithCompositeFields.map(
        (objectMetadata) =>
          this.extendObjectTypeDefinitionV2Factory.create(
            objectMetadata,
            options,
          ),
      );

      this.typeDefinitionsStorage.addObjectTypes(objectTypeDefsV2);
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to create GraphQL enum type definitions based on field metadata.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { GraphQLEnumType } from 'graphql';

import { WorkspaceBuildSchemaOptions } from 'src/engine/api/graphql/workspace-schema-builder/interfaces/workspace-build-schema-optionts.interface';
import { FieldMetadataInterface } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata.interface';
import { ObjectMetadataInterface } from 'src/engine/metadata-modules/field-metadata/interfaces/object-metadata.interface';

import {
  FieldMetadataComplexOption,
  FieldMetadataDefaultOption,
} from 'src/engine/metadata-modules/field-metadata/dtos/options.input';
import { isEnumFieldMetadataType } from 'src/engine/metadata-modules/field-metadata/utils/is-enum-field-metadata-type.util';
import { transformEnumValue } from 'src/engine/utils/transform-enum-value';
import { pascalCase } from 'src/utils/pascal-case';

export interface EnumTypeDefinition {
  target: string;
  type: GraphQLEnumType;
}

@Injectable()
export class EnumTypeDefinitionFactory {
  private readonly logger = new Logger(EnumTypeDefinitionFactory.name);

  public create(
    objectMetadata: ObjectMetadataInterface,
    options: WorkspaceBuildSchemaOptions,
  ): EnumTypeDefinition[] {
    const enumTypeDefinitions: EnumTypeDefinition[] = [];

    for (const fieldMetadata of objectMetadata.fields) {
      if (!isEnumFieldMetadataType(fieldMetadata.type)) {
        continue;
      }

      enumTypeDefinitions.push({
        target: fieldMetadata.id,
        type: this.generateEnum(
          objectMetadata.nameSingular,
          fieldMetadata,
          options,
        ),
      });
    }

    return enumTypeDefinitions;
  }

  private generateEnum(
    objectName: string,
    fieldMetadata: FieldMetadataInterface,
    options: WorkspaceBuildSchemaOptions,
  ): GraphQLEnumType {
    // FixMe: It's a hack until Typescript get fixed on union types for reduce function
    // https://github.com/microsoft/TypeScript/issues/36390
    const enumOptions = transformEnumValue(fieldMetadata.options) as Array<
      FieldMetadataDefaultOption | FieldMetadataComplexOption
    >;

    if (!enumOptions) {
      this.logger.error(
        `Enum options are not defined for ${fieldMetadata.name}`,
        {
          fieldMetadata,
          options,
        },
      );

      throw new Error(`Enum options are not defined for ${fieldMetadata.name}`);
    }

    return new GraphQLEnumType({
      name: `${pascalCase(objectName)}${pascalCase(fieldMetadata.name)}Enum`,
      description: fieldMetadata.description,
      values: enumOptions.reduce(
        (acc, enumOption) => {
          // Key must match this regex: /^[_A-Za-z][_0-9A-Za-z]+$/
          acc[enumOption.value] = {
            value: enumOption.value,
            description: enumOption.label,
          };

          return acc;
        },
        {} as { [key: string]: { value: string; description: string } },
      ),
    });
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_1>



=== New Entry ===

<CLUSTER_2>
Number of Code Snippets part of this cluster: 30
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code defines functions to seed and delete feature flags in a database using TypeORM.
Code Snippet:
import { DataSource } from 'typeorm';

import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';

const tableName = 'featureFlag';

export const seedFeatureFlags = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, ['key', 'workspaceId', 'value'])
    .orIgnore()
    .values([
      {
        key: FeatureFlagKey.IsAirtableIntegrationEnabled,
        workspaceId: workspaceId,
        value: true,
      },
      {
        key: FeatureFlagKey.IsPostgreSQLIntegrationEnabled,
        workspaceId: workspaceId,
        value: true,
      },
      {
        key: FeatureFlagKey.IsEventObjectEnabled,
        workspaceId: workspaceId,
        value: false,
      },
      {
        key: FeatureFlagKey.IsStripeIntegrationEnabled,
        workspaceId: workspaceId,
        value: true,
      },
      {
        key: FeatureFlagKey.IsWorkflowEnabled,
        workspaceId: workspaceId,
        value: true,
      },
      {
        key: FeatureFlagKey.IsAnalyticsV2Enabled,
        workspaceId: workspaceId,
        value: true,
      },
      {
        key: FeatureFlagKey.IsCustomDomainEnabled,
        workspaceId: workspaceId,
        value: false,
      },
      {
        key: FeatureFlagKey.IsApprovedAccessDomainsEnabled,
        workspaceId: workspaceId,
        value: true,
      },
      {
        key: FeatureFlagKey.IsUniqueIndexesEnabled,
        workspaceId: workspaceId,
        value: false,
      },
      {
        key: FeatureFlagKey.IsAdvancedFiltersEnabled,
        workspaceId: workspaceId,
        value: false,
      },
      {
        key: FeatureFlagKey.IsCommandMenuV2Enabled,
        workspaceId: workspaceId,
        value: true,
      },
      {
        key: FeatureFlagKey.IsNewRelationEnabled,
        workspaceId: workspaceId,
        value: false,
      },
    ])
    .execute();
};

export const deleteFeatureFlags = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .delete()
    .from(`${schemaName}.${tableName}`)
    .where(`"${tableName}"."workspaceId" = :workspaceId`, { workspaceId })
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines functions to seed and delete workspaces in a database using TypeORM. It includes workspace data models and interacts with a data source.
Code Snippet:
import { WorkspaceActivationStatus } from 'twenty-shared';
import { DataSource } from 'typeorm';

import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';

const tableName = 'workspace';

export const SEED_APPLE_WORKSPACE_ID = '20202020-1c25-4d02-bf25-6aeccf7ea419';
export const SEED_ACME_WORKSPACE_ID = '3b8e6458-5fc1-4e63-8563-008ccddaa6db';

export const seedWorkspaces = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  const workspaces: {
    [key: string]: Pick<
      Workspace,
      | 'id'
      | 'displayName'
      | 'inviteHash'
      | 'logo'
      | 'subdomain'
      | 'activationStatus'
    >;
  } = {
    [SEED_APPLE_WORKSPACE_ID]: {
      id: workspaceId,
      displayName: 'Apple',
      subdomain: 'apple',
      inviteHash: 'apple.dev-invite-hash',
      logo: 'https://twentyhq.github.io/placeholder-images/workspaces/apple-logo.png',
      activationStatus: WorkspaceActivationStatus.ACTIVE,
    },
    [SEED_ACME_WORKSPACE_ID]: {
      id: workspaceId,
      displayName: 'Acme',
      subdomain: 'acme',
      inviteHash: 'acme.dev-invite-hash',
      logo: 'https://logos-world.net/wp-content/uploads/2022/05/Acme-Logo-700x394.png',
      activationStatus: WorkspaceActivationStatus.ACTIVE,
    },
  };

  await workspaceDataSource
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'displayName',
      'subdomain',
      'inviteHash',
      'logo',
      'activationStatus',
    ])
    .orIgnore()
    .values(workspaces[workspaceId])
    .execute();
};

export const deleteWorkspaces = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .delete()
    .from(`${schemaName}.${tableName}`)
    .where(`${tableName}."id" = :id`, { id: workspaceId })
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines functions to seed and delete user workspace data in a database using TypeORM.
Code Snippet:
import { DataSource } from 'typeorm';

import { DEV_SEED_USER_IDS } from 'src/database/typeorm-seeds/core/users';
import {
  SEED_ACME_WORKSPACE_ID,
  SEED_APPLE_WORKSPACE_ID,
} from 'src/database/typeorm-seeds/core/workspaces';
import { UserWorkspace } from 'src/engine/core-modules/user-workspace/user-workspace.entity';

const tableName = 'userWorkspace';

export const DEV_SEED_USER_WORKSPACE_IDS = {
  TIM: '20202020-9e3b-46d4-a556-88b9ddc2b035',
  JONY: '20202020-3957-4908-9c36-2929a23f8353',
  PHIL: '20202020-7169-42cf-bc47-1cfef15264b1',
  TIM_ACME: '20202020-e10a-4c27-a90b-b08c57b02d44',
};

export const seedUserWorkspaces = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  let userWorkspaces: Pick<UserWorkspace, 'id' | 'userId' | 'workspaceId'>[] =
    [];

  if (workspaceId === SEED_APPLE_WORKSPACE_ID) {
    userWorkspaces = [
      {
        id: DEV_SEED_USER_WORKSPACE_IDS.TIM,
        userId: DEV_SEED_USER_IDS.TIM,
        workspaceId,
      },
      {
        id: DEV_SEED_USER_WORKSPACE_IDS.JONY,
        userId: DEV_SEED_USER_IDS.JONY,
        workspaceId,
      },
      {
        id: DEV_SEED_USER_WORKSPACE_IDS.PHIL,
        userId: DEV_SEED_USER_IDS.PHIL,
        workspaceId,
      },
    ];
  }

  if (workspaceId === SEED_ACME_WORKSPACE_ID) {
    userWorkspaces = [
      {
        id: DEV_SEED_USER_WORKSPACE_IDS.TIM_ACME,
        userId: DEV_SEED_USER_IDS.TIM,
        workspaceId,
      },
    ];
  }
  await workspaceDataSource
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, ['id', 'userId', 'workspaceId'])
    .orIgnore()
    .values(userWorkspaces)
    .execute();
};

export const deleteUserWorkspaces = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .delete()
    .from(`${schemaName}.${tableName}`)
    .where(`"${tableName}"."workspaceId" = :workspaceId`, {
      workspaceId,
    })
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a function to seed user data into a database table using TypeORM.
Code Snippet:
import { DataSource } from 'typeorm';

const tableName = 'user';

export const DEV_SEED_USER_IDS = {
  TIM: '20202020-9e3b-46d4-a556-88b9ddc2b034',
  JONY: '20202020-3957-4908-9c36-2929a23f8357',
  PHIL: '20202020-7169-42cf-bc47-1cfef15264b8',
};

export const seedUsers = async (
  workspaceDataSource: DataSource,
  schemaName: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'firstName',
      'lastName',
      'email',
      'passwordHash',
      'canImpersonate',
      'canAccessFullAdminPanel',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_USER_IDS.TIM,
        firstName: 'Tim',
        lastName: 'Apple',
        email: 'tim@apple.dev',
        passwordHash:
          '$2b$10$66d.6DuQExxnrfI9rMqOg.U1XIYpagr6Lv05uoWLYbYmtK0HDIvS6', // Applecar2025
        canImpersonate: true,
        canAccessFullAdminPanel: true,
      },
      {
        id: DEV_SEED_USER_IDS.JONY,
        firstName: 'Jony',
        lastName: 'Ive',
        email: 'jony.ive@apple.dev',
        passwordHash:
          '$2b$10$66d.6DuQExxnrfI9rMqOg.U1XIYpagr6Lv05uoWLYbYmtK0HDIvS6', // Applecar2025
        canImpersonate: true,
        canAccessFullAdminPanel: true,
      },
      {
        id: DEV_SEED_USER_IDS.PHIL,
        firstName: 'Phil',
        lastName: 'Schiler',
        email: 'phil.schiler@apple.dev',
        passwordHash:
          '$2b$10$66d.6DuQExxnrfI9rMqOg.U1XIYpagr6Lv05uoWLYbYmtK0HDIvS6', // Applecar2025
        canImpersonate: true,
        canAccessFullAdminPanel: true,
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines functions to seed and delete workspace records in a database using TypeORM.
Code Snippet:
import { WorkspaceActivationStatus } from 'twenty-shared';
import { DataSource } from 'typeorm';

const tableName = 'workspace';

export const seedWorkspaces = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'displayName',
      'domainName',
      'inviteHash',
      'logo',
      'subdomain',
      'activationStatus',
    ])
    .orIgnore()
    .values([
      {
        id: workspaceId,
        displayName: 'Demo',
        domainName: 'demo.dev',
        inviteHash: 'demo.dev-invite-hash',
        logo: 'https://twentyhq.github.io/placeholder-images/workspaces/apple-logo.png',
        subdomain: 'demo',
        activationStatus: WorkspaceActivationStatus.ACTIVE,
      },
    ])
    .execute();
};

export const deleteWorkspaces = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .delete()
    .from(`${schemaName}.${tableName}`)
    .where(`${tableName}."id" = :id`, { id: workspaceId })
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines functions to seed and delete user workspaces in a database using TypeORM.
Code Snippet:
import { DataSource } from 'typeorm';

import { DEMO_SEED_USER_IDS } from 'src/database/typeorm-seeds/core/demo/users';

const tableName = 'userWorkspace';

export const DEV_SEED_USER_WORKSPACE_IDS = {
  NOAH: '20202020-9e3b-46d4-a556-88b9ddc2b534',
  HUGO: '20202020-3957-4908-9c36-2929a23f8457',
  TIM: '20202020-9e3b-46d4-a556-88b9ddc2b015',
};

export const seedUserWorkspaces = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, ['id', 'userId', 'workspaceId'])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_USER_WORKSPACE_IDS.NOAH,
        userId: DEMO_SEED_USER_IDS.NOAH,
        workspaceId: workspaceId,
      },
      {
        id: DEV_SEED_USER_WORKSPACE_IDS.HUGO,
        userId: DEMO_SEED_USER_IDS.HUGO,
        workspaceId: workspaceId,
      },
      {
        id: DEV_SEED_USER_WORKSPACE_IDS.TIM,
        userId: DEMO_SEED_USER_IDS.TIM,
        workspaceId: workspaceId,
      },
    ])
    .execute();
};

export const deleteUserWorkspaces = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .delete()
    .from(`${schemaName}.${tableName}`)
    .where(`"${tableName}"."workspaceId" = :workspaceId`, {
      workspaceId,
    })
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines functions to seed and delete users in a specified schema and table using a TypeORM DataSource.
Code Snippet:
import { DataSource } from 'typeorm';

// import { SeedWorkspaceId } from 'src/database/typeorm-seeds/core/workspaces';

const tableName = 'user';

export const DEMO_SEED_USER_IDS = {
  NOAH: '20202020-9e3b-46d4-a556-88b9ddc2b035',
  HUGO: '20202020-3957-4908-9c36-2929a23f8358',
  TIM: '20202020-9e3b-46d4-a556-88b9ddc2b034',
};

export const seedUsers = async (
  workspaceDataSource: DataSource,
  schemaName: string,
) => {
  await workspaceDataSource
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'firstName',
      'lastName',
      'email',
      'passwordHash',
    ])
    .orIgnore()
    .values([
      {
        id: DEMO_SEED_USER_IDS.NOAH,
        firstName: 'Noah',
        lastName: 'A',
        email: 'noah@demo.dev',
        passwordHash:
          '$2b$10$66d.6DuQExxnrfI9rMqOg.U1XIYpagr6Lv05uoWLYbYmtK0HDIvS6', // Applecar2025
      },
      {
        id: DEMO_SEED_USER_IDS.HUGO,
        firstName: 'Hugo',
        lastName: 'I',
        email: 'hugo@demo.dev',
        passwordHash:
          '$2b$10$66d.6DuQExxnrfI9rMqOg.U1XIYpagr6Lv05uoWLYbYmtK0HDIvS6', // Applecar2025
      },
      {
        id: DEMO_SEED_USER_IDS.TIM,
        firstName: 'Tim',
        lastName: 'Apple',
        email: 'tim@apple.dev',
        passwordHash:
          '$2b$10$66d.6DuQExxnrfI9rMqOg.U1XIYpagr6Lv05uoWLYbYmtK0HDIvS6', // Applecar2025
      },
    ])
    .execute();
};

export const deleteUsersByWorkspace = async (
  dataSource: DataSource,
  schemaName: string,
  workspaceId: string,
) => {
  const user = await dataSource
    .createQueryBuilder(`${schemaName}.${tableName}`, 'user')
    .leftJoinAndSelect('user.workspaces', 'userWorkspace')
    .where(`userWorkspace."workspaceId" = :workspaceId`, {
      workspaceId,
    })
    .getMany();

  await dataSource
    .createQueryBuilder()
    .delete()
    .from(`${schemaName}.${tableName}`)
    .where(`"${tableName}"."id" IN (:...ids)`, { ids: user.map((u) => u.id) })
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code seeds data into a table named 'calendarChannelEventAssociation' in a specified schema using TypeORM's query builder.
Code Snippet:
import { EntityManager } from 'typeorm';

const tableName = 'calendarChannelEventAssociation';

export const seedCalendarChannelEventAssociations = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'calendarChannelId',
      'calendarEventId',
      'eventExternalId',
      'recurringEventExternalId',
    ])
    .orIgnore()
    .values([
      {
        id: 'e1ab9e1b-df6e-438e-a788-11c96dcecdd3',
        calendarChannelId: '59efdefe-a40f-4faf-bb9f-c6f9945b8203',
        calendarEventId: '86083141-1c0e-494c-a1b6-85b1c6fefaa5',
        eventExternalId: 'exampleExternalId',
        recurringEventExternalId: 'exampleRecurringExternalId',
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a seed function to insert message participant records into a database table using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEV_SEED_MESSAGE_IDS } from 'src/database/typeorm-seeds/workspace/messages';
import { DEV_SEED_PERSON_IDS } from 'src/database/typeorm-seeds/workspace/seedPeople';
import { DEV_SEED_WORKSPACE_MEMBER_IDS } from 'src/database/typeorm-seeds/workspace/workspace-members';

const tableName = 'messageParticipant';

export const DEV_SEED_MESSAGE_PARTICIPANT_IDS = {
  MESSAGE_PARTICIPANT_1: '20202020-0f2a-49d8-8aa2-ec8786153a0b',
  MESSAGE_PARTICIPANT_2: '20202020-4e83-41ec-93e2-fd70ff09f68c',
  MESSAGE_PARTICIPANT_3: '20202020-e716-4dd5-ac61-3315bc559e2d',
  MESSAGE_PARTICIPANT_4: '20202020-fc7d-4ad8-9aea-b78bcbf79cdd',
  MESSAGE_PARTICIPANT_5: '20202020-564c-4a3c-abbf-e942e8c3f9c9',
  MESSAGE_PARTICIPANT_6: '20202020-7e4a-489a-ba6b-1ae6b7d721ac',
};

export const seedMessageParticipant = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'createdAt',
      'updatedAt',
      'deletedAt',
      'workspaceMemberId',
      'personId',
      'displayName',
      'handle',
      'role',
      'messageId',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_MESSAGE_PARTICIPANT_IDS.MESSAGE_PARTICIPANT_1,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        workspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        personId: DEV_SEED_PERSON_IDS.CHRISTOPH,
        displayName: 'Christoph',
        handle: 'outgoing',
        role: 'from',
        messageId: DEV_SEED_MESSAGE_IDS.MESSAGE_1,
      },
      {
        id: DEV_SEED_MESSAGE_PARTICIPANT_IDS.MESSAGE_PARTICIPANT_2,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        workspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        personId: DEV_SEED_PERSON_IDS.SYLVIE,
        displayName: 'Sylvie',
        handle: 'incoming',
        role: 'to',
        messageId: DEV_SEED_MESSAGE_IDS.MESSAGE_1,
      },
      {
        id: DEV_SEED_MESSAGE_PARTICIPANT_IDS.MESSAGE_PARTICIPANT_3,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        workspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        personId: DEV_SEED_PERSON_IDS.CHRISTOPHER_G,
        displayName: 'Christopher',
        handle: 'incoming',
        role: 'to',
        messageId: DEV_SEED_MESSAGE_IDS.MESSAGE_1,
      },
      {
        id: DEV_SEED_MESSAGE_PARTICIPANT_IDS.MESSAGE_PARTICIPANT_4,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        workspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        personId: DEV_SEED_PERSON_IDS.CHRISTOPH,
        displayName: 'Christoph',
        handle: 'outgoing',
        role: 'from',
        messageId: DEV_SEED_MESSAGE_IDS.MESSAGE_2,
      },
      {
        id: DEV_SEED_MESSAGE_PARTICIPANT_IDS.MESSAGE_PARTICIPANT_5,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        workspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        personId: DEV_SEED_PERSON_IDS.SYLVIE,
        displayName: 'Sylvie',
        handle: 'incoming',
        role: 'to',
        messageId: DEV_SEED_MESSAGE_IDS.MESSAGE_2,
      },
      {
        id: DEV_SEED_MESSAGE_PARTICIPANT_IDS.MESSAGE_PARTICIPANT_6,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        workspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        personId: DEV_SEED_PERSON_IDS.CHRISTOPHER_G,
        displayName: 'Christopher',
        handle: 'incoming',
        role: 'to',
        messageId: DEV_SEED_MESSAGE_IDS.MESSAGE_2,
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines seed data for a 'person' table and inserts it into a database using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEV_SEED_COMPANY_IDS } from 'src/database/typeorm-seeds/workspace/companies';
import { DEV_SEED_WORKSPACE_MEMBER_IDS } from 'src/database/typeorm-seeds/workspace/workspace-members';

const tableName = 'person';

export const DEV_SEED_PERSON_IDS = {
  CHRISTOPH: '20202020-1c0e-494c-a1b6-85b1c6fefaa5',
  SYLVIE: '20202020-ac73-4797-824e-87a1f5aea9e0',
  CHRISTOPHER_G: '20202020-f517-42fd-80ae-14173b3b70ae',
  ASHLEY: '20202020-eee1-4690-ad2c-8619e5b56a2e',
  NICHOLAS: '20202020-6784-4449-afdf-dc62cb8702f2',
  ISABELLA: '20202020-490f-4466-8391-733cfd66a0c8',
  MATTHEW: '20202020-80f1-4dff-b570-a74942528de3',
  ELIZABETH: '20202020-338b-46df-8811-fa08c7d19d35',
  CHRISTOPHER_N: '20202020-64ad-4b0e-bbfd-e9fd795b7016',
  AVERY: '20202020-5d54-41b7-ba36-f0d20e1417ae',
  ETHAN: '20202020-623d-41fe-92e7-dd45b7c568e1',
  MADISON: '20202020-2d40-4e49-8df4-9c6a049190ef',
  BERTRAND: '20202020-2d40-4e49-8df4-9c6a049190df',
  LOUIS: '20202020-2d40-4e49-8df4-9c6a049191de',
  LORIE: '20202020-2d40-4e49-8df4-9c6a049191df',
};

export const seedPeople = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'nameFirstName',
      'nameLastName',
      'phonesPrimaryPhoneCountryCode',
      'phonesPrimaryPhoneCallingCode',
      'phonesPrimaryPhoneNumber',
      'city',
      'companyId',
      'emailsPrimaryEmail',
      'position',
      'whatsappPrimaryPhoneCountryCode',
      'whatsappPrimaryPhoneCallingCode',
      'whatsappPrimaryPhoneNumber',
      'createdBySource',
      'createdByWorkspaceMemberId',
      'createdByName',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_PERSON_IDS.CHRISTOPH,
        nameFirstName: 'Christoph',
        nameLastName: 'Callisto',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '789012345',
        city: 'Seattle',
        companyId: DEV_SEED_COMPANY_IDS.LINKEDIN,
        emailsPrimaryEmail: 'christoph.calisto@linkedin.com',
        position: 1,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '789012345',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.SYLVIE,
        nameFirstName: 'Sylvie',
        nameLastName: 'Palmer',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '780123456',
        city: 'Los Angeles',
        companyId: DEV_SEED_COMPANY_IDS.LINKEDIN,
        emailsPrimaryEmail: 'sylvie.palmer@linkedin.com',
        position: 2,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '780123456',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.CHRISTOPHER_G,
        nameFirstName: 'Christopher',
        nameLastName: 'Gonzalez',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '789012345',
        city: 'Seattle',
        companyId: DEV_SEED_COMPANY_IDS.QONTO,
        emailsPrimaryEmail: 'christopher.gonzalez@qonto.com',
        position: 3,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '789012345',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.ASHLEY,
        nameFirstName: 'Ashley',
        nameLastName: 'Parker',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '780123456',
        city: 'Los Angeles',
        companyId: DEV_SEED_COMPANY_IDS.QONTO,
        emailsPrimaryEmail: 'ashley.parker@qonto.com',
        position: 4,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '780123456',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.NICHOLAS,
        nameFirstName: 'Nicholas',
        nameLastName: 'Wright',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '781234567',
        city: 'Seattle',
        companyId: DEV_SEED_COMPANY_IDS.MICROSOFT,
        emailsPrimaryEmail: 'nicholas.wright@microsoft.com',
        position: 5,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '781234567',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.ISABELLA,
        nameFirstName: 'Isabella',
        nameLastName: 'Scott',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '782345678',
        city: 'New York',
        companyId: DEV_SEED_COMPANY_IDS.MICROSOFT,
        emailsPrimaryEmail: 'isabella.scott@microsoft.com',
        position: 6,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '782345678',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.MATTHEW,
        nameFirstName: 'Matthew',
        nameLastName: 'Green',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '783456789',
        city: 'Seattle',
        companyId: DEV_SEED_COMPANY_IDS.MICROSOFT,
        emailsPrimaryEmail: 'matthew.green@microsoft.com',
        position: 7,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '783456789',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.ELIZABETH,
        nameFirstName: 'Elizabeth',
        nameLastName: 'Baker',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '784567890',
        city: 'New York',
        companyId: DEV_SEED_COMPANY_IDS.AIRBNB,
        emailsPrimaryEmail: 'elizabeth.baker@airbnb.com',
        position: 8,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '784567890',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.CHRISTOPHER_N,
        nameFirstName: 'Christopher',
        nameLastName: 'Nelson',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '785678901',
        city: 'San Francisco',
        companyId: DEV_SEED_COMPANY_IDS.AIRBNB,
        emailsPrimaryEmail: 'christopher.nelson@airbnb.com',
        position: 9,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '785678901',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.AVERY,
        nameFirstName: 'Avery',
        nameLastName: 'Carter',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '786789012',
        city: 'New York',
        companyId: DEV_SEED_COMPANY_IDS.AIRBNB,
        emailsPrimaryEmail: 'avery.carter@airbnb.com',
        position: 10,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '786789012',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.ETHAN,
        nameFirstName: 'Ethan',
        nameLastName: 'Mitchell',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '787890123',
        city: 'Los Angeles',
        companyId: DEV_SEED_COMPANY_IDS.GOOGLE,
        emailsPrimaryEmail: 'ethan.mitchell@google.com',
        position: 11,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '787890123',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.MADISON,
        nameFirstName: 'Madison',
        nameLastName: 'Perez',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '788901234',
        city: 'Seattle',
        companyId: DEV_SEED_COMPANY_IDS.GOOGLE,
        emailsPrimaryEmail: 'madison.perez@google.com',
        position: 12,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '788901234',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.BERTRAND,
        nameFirstName: 'Bertrand',
        nameLastName: 'Voulzy',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '788901234',
        city: 'Seattle',
        companyId: DEV_SEED_COMPANY_IDS.GOOGLE,
        emailsPrimaryEmail: 'bertrand.voulzy@google.com',
        position: 13,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '788901234',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.LOUIS,
        nameFirstName: 'Louis',
        nameLastName: 'Duss',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '789012345',
        city: 'Seattle',
        companyId: DEV_SEED_COMPANY_IDS.GOOGLE,
        emailsPrimaryEmail: 'louis.duss@google.com',
        position: 14,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '789012345',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
      {
        id: DEV_SEED_PERSON_IDS.LORIE,
        nameFirstName: 'Lorie',
        nameLastName: 'Vladim',
        phonesPrimaryPhoneCountryCode: 'FR',
        phonesPrimaryPhoneCallingCode: '+33',
        phonesPrimaryPhoneNumber: '788901235',
        city: 'Seattle',
        companyId: DEV_SEED_COMPANY_IDS.GOOGLE,
        emailsPrimaryEmail: 'lorie.vladim@google.com',
        position: 15,
        whatsappPrimaryPhoneCountryCode: 'FR',
        whatsappPrimaryPhoneCallingCode: '+33',
        whatsappPrimaryPhoneNumber: '788901235',
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a function to seed messages into a database table using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEV_SEED_MESSAGE_THREAD_IDS } from 'src/database/typeorm-seeds/workspace/message-threads';

const tableName = 'message';

export const DEV_SEED_MESSAGE_IDS = {
  MESSAGE_1: '20202020-2b8a-405d-8f42-e820ca921421',
  MESSAGE_2: '20202020-04c8-4f24-93f2-764948e95014',
  MESSAGE_3: '20202020-ac6b-4f86-87a2-5f5f9d1b6481',
};

export const seedMessage = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'createdAt',
      'updatedAt',
      'deletedAt',
      'receivedAt',
      'text',
      'subject',
      'messageThreadId',
      'headerMessageId',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_MESSAGE_IDS.MESSAGE_1,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        receivedAt: new Date(),
        text: 'Hello, \n I hope this email finds you well. I am writing to request a meeting. I believe it would be beneficial for both parties to collaborate and explore potential opportunities. Would you be available for a meeting sometime next week? Please let me know your availability, and I will arrange a suitable time. \n Looking forward to your response.\n Best regards',
        subject: 'Meeting Request',
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_1,
        headerMessageId: '99ef24a8-2b8a-405d-8f42-e820ca921421',
      },
      {
        id: DEV_SEED_MESSAGE_IDS.MESSAGE_2,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        receivedAt: new Date(),
        text: 'Good Morning,\n I am writing to inquire about information. Could you please provide me with details regarding this topic? \n Your assistance in this matter would be greatly appreciated. Thank you in advance for your prompt response. \n Best regards,Tim',
        subject: 'Inquiry Regarding Topic',
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_2,
        headerMessageId: '8f804a9a-04c8-4f24-93f2-764948e95014',
      },
      {
        id: DEV_SEED_MESSAGE_IDS.MESSAGE_3,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        receivedAt: new Date(),
        text: 'Good Evening,\nI wanted to extend my sincere gratitude for taking the time to meet with me earlier today. It was a pleasure discussing with you, and I am excited about the potential opportunities for collaboration. \n Please feel free to reach out if you have any further questions or require additional information. I look forward to our continued communication. Best regards.',
        subject: 'Thank You for the Meeting',
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_1,
        headerMessageId: '3939d68a-ac6b-4f86-87a2-5f5f9d1b6481',
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a function to seed a 'messageThread' table with specific message thread IDs in a database using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

const tableName = 'messageThread';

export const DEV_SEED_MESSAGE_THREAD_IDS = {
  MESSAGE_THREAD_1: '20202020-8bfa-453b-b99b-bc435a7d4da8',
  MESSAGE_THREAD_2: '20202020-634a-4fde-aa7c-28a0eaf203ca',
  MESSAGE_THREAD_3: '20202020-1b56-4f10-a2fa-2ccaddf81f6c',
  MESSAGE_THREAD_4: '20202020-d51c-485a-b1b6-ed7c63e05d72',
  MESSAGE_THREAD_5: '20202020-3f74-492d-a101-2a70f50a1645',
};

export const seedMessageThread = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'createdAt',
      'updatedAt',
      'deletedAt',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_1,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
      },
      {
        id: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_2,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
      },
      {
        id: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_3,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
      },
      {
        id: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_4,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines an asynchronous function to seed workspace favorites into a database using TypeORM. It inserts records into the 'favorite' table with unique IDs, associated view IDs, and positions.
Code Snippet:
import { EntityManager } from 'typeorm';
import { v4 } from 'uuid';

const tableName = 'favorite';

export const seedWorkspaceFavorites = async (
  viewIds: string[],
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, ['id', 'viewId', 'position'])
    .values(
      viewIds.map((viewId, index) => ({
        id: v4(),
        viewId,
        position: index,
      })),
    )
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines seed data for a message-channel-message-association table and inserts it into a database using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEV_SEED_MESSAGE_CHANNEL_IDS } from 'src/database/typeorm-seeds/workspace/message-channels';
import { DEV_SEED_MESSAGE_IDS } from 'src/database/typeorm-seeds/workspace/messages';
import { MessageDirection } from 'src/modules/messaging/common/enums/message-direction.enum';

const tableName = 'messageChannelMessageAssociation';

export const DEV_SEED_MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_IDS = {
  MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_1: '20202020-cc69-44ef-a82c-600c0dbf39ba',
  MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_2: '20202020-d80e-4a13-b10b-72ba09082668',
  MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_3: '20202020-e6ec-4c8a-b431-0901eaf395a9',
};

export const seedMessageChannelMessageAssociation = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'createdAt',
      'updatedAt',
      'deletedAt',
      'messageThreadExternalId',
      'messageExternalId',
      'messageId',
      'messageChannelId',
      'direction',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_IDS.MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_1,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadExternalId: null,
        messageExternalId: null,
        messageId: DEV_SEED_MESSAGE_IDS.MESSAGE_1,
        messageChannelId: DEV_SEED_MESSAGE_CHANNEL_IDS.TIM,
        direction: MessageDirection.OUTGOING,
      },
      {
        id: DEV_SEED_MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_IDS.MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_2,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadExternalId: null,
        messageExternalId: null,
        messageId: DEV_SEED_MESSAGE_IDS.MESSAGE_2,
        messageChannelId: DEV_SEED_MESSAGE_CHANNEL_IDS.TIM,
        direction: MessageDirection.OUTGOING,
      },
      {
        id: DEV_SEED_MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_IDS.MESSAGE_CHANNEL_MESSAGE_ASSOCIATION_3,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadExternalId: null,
        messageExternalId: null,
        messageId: DEV_SEED_MESSAGE_IDS.MESSAGE_3,
        messageChannelId: DEV_SEED_MESSAGE_CHANNEL_IDS.TIM,
        direction: MessageDirection.INCOMING,
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines seed data for message thread subscribers and inserts it into a database table using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

const tableName = 'messageThreadSubscriber';

export const DEV_SEED_MESSAGE_THREAD_SUBSCRIBERS_IDS = {
  MESSAGE_THREAD_SUBSCRIBER_1: '20202020-cc69-44ef-a82c-600c0dbf39ba',
  MESSAGE_THREAD_SUBSCRIBER_2: '20202020-d80e-4a13-b10b-72ba09082668',
  MESSAGE_THREAD_SUBSCRIBER_3: '20202020-e6ec-4c8a-b431-0901eaf395a9',
  MESSAGE_THREAD_SUBSCRIBER_4: '20202020-1455-4c57-afaf-dd5dc086361d',
  MESSAGE_THREAD_SUBSCRIBER_5: '20202020-f79e-40dd-bd06-c36e6abb4678',
  MESSAGE_THREAD_SUBSCRIBER_6: '20202020-3ec3-4fe3-8997-b76aa0bfa408',
  MESSAGE_THREAD_SUBSCRIBER_7: '20202020-c21e-4ec2-873b-de4264d89025',
};

export const DEV_SEED_MESSAGE_THREAD_IDS = {
  MESSAGE_THREAD_1: '20202020-8bfa-453b-b99b-bc435a7d4da8',
  MESSAGE_THREAD_2: '20202020-634a-4fde-aa7c-28a0eaf203ca',
  MESSAGE_THREAD_3: '20202020-1b56-4f10-a2fa-2ccaddf81f6c',
  MESSAGE_THREAD_4: '20202020-d51c-485a-b1b6-ed7c63e05d72',
};

export const DEV_SEED_USER_IDS = {
  TIM: '20202020-0687-4c41-b707-ed1bfca972a7',
  PHIL: '20202020-1553-45c6-a028-5a9064cce07f',
  JONY: '20202020-77d5-4cb6-b60a-f4a835a85d61',
};

export const seedMessageThreadSubscribers = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'createdAt',
      'updatedAt',
      'deletedAt',
      'messageThreadId',
      'workspaceMemberId',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_MESSAGE_THREAD_SUBSCRIBERS_IDS.MESSAGE_THREAD_SUBSCRIBER_1,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_1,
        workspaceMemberId: DEV_SEED_USER_IDS.PHIL,
      },
      {
        id: DEV_SEED_MESSAGE_THREAD_SUBSCRIBERS_IDS.MESSAGE_THREAD_SUBSCRIBER_2,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_1,
        workspaceMemberId: DEV_SEED_USER_IDS.JONY,
      },
      {
        id: DEV_SEED_MESSAGE_THREAD_SUBSCRIBERS_IDS.MESSAGE_THREAD_SUBSCRIBER_3,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_2,
        workspaceMemberId: DEV_SEED_USER_IDS.TIM,
      },
      {
        id: DEV_SEED_MESSAGE_THREAD_SUBSCRIBERS_IDS.MESSAGE_THREAD_SUBSCRIBER_4,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_3,
        workspaceMemberId: DEV_SEED_USER_IDS.JONY,
      },
      {
        id: DEV_SEED_MESSAGE_THREAD_SUBSCRIBERS_IDS.MESSAGE_THREAD_SUBSCRIBER_5,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_4,
        workspaceMemberId: DEV_SEED_USER_IDS.TIM,
      },
      {
        id: DEV_SEED_MESSAGE_THREAD_SUBSCRIBERS_IDS.MESSAGE_THREAD_SUBSCRIBER_6,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_4,
        workspaceMemberId: DEV_SEED_USER_IDS.PHIL,
      },
      {
        id: DEV_SEED_MESSAGE_THREAD_SUBSCRIBERS_IDS.MESSAGE_THREAD_SUBSCRIBER_7,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        messageThreadId: DEV_SEED_MESSAGE_THREAD_IDS.MESSAGE_THREAD_4,
        workspaceMemberId: DEV_SEED_USER_IDS.JONY,
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code seeds opportunity data into a database table using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEV_SEED_COMPANY_IDS } from 'src/database/typeorm-seeds/workspace/companies';
import { DEV_SEED_PERSON_IDS } from 'src/database/typeorm-seeds/workspace/seedPeople';
import { DEV_SEED_WORKSPACE_MEMBER_IDS } from 'src/database/typeorm-seeds/workspace/workspace-members';

const tableName = 'opportunity';

export const DEV_SEED_OPPORTUNITY_IDS = {
  OPPORTUNITY_1: '20202020-be10-422b-a663-16bd3c2228e1',
  OPPORTUNITY_2: '20202020-0543-4cc2-9f96-95cc699960f2',
  OPPORTUNITY_3: '20202020-2f89-406f-90ea-180f433b2445',
  OPPORTUNITY_4: '20202020-35b1-4045-9cde-42f715148954',
};

export const seedOpportunity = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'name',
      'amountAmountMicros',
      'amountCurrencyCode',
      'closeDate',
      'stage',
      'position',
      'pointOfContactId',
      'companyId',
      'createdBySource',
      'createdByWorkspaceMemberId',
      'createdByName',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_OPPORTUNITY_IDS.OPPORTUNITY_1,
        name: 'Opportunity 1',
        amountAmountMicros: 100000,
        amountCurrencyCode: 'USD',
        closeDate: new Date(),
        stage: 'NEW',
        position: 1,
        pointOfContactId: DEV_SEED_PERSON_IDS.CHRISTOPH,
        companyId: DEV_SEED_COMPANY_IDS.LINKEDIN,
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Cook',
      },
      {
        id: DEV_SEED_OPPORTUNITY_IDS.OPPORTUNITY_2,
        name: 'Opportunity 2',
        amountAmountMicros: 2000000,
        amountCurrencyCode: 'USD',
        closeDate: new Date(),
        stage: 'MEETING',
        position: 2,
        pointOfContactId: DEV_SEED_PERSON_IDS.CHRISTOPHER_G,
        companyId: DEV_SEED_COMPANY_IDS.FACEBOOK,
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Cook',
      },
      {
        id: DEV_SEED_OPPORTUNITY_IDS.OPPORTUNITY_3,
        name: 'Opportunity 3',
        amountAmountMicros: 300000,
        amountCurrencyCode: 'USD',
        closeDate: new Date(),
        stage: 'PROPOSAL',
        position: 3,
        pointOfContactId: DEV_SEED_PERSON_IDS.NICHOLAS,
        companyId: DEV_SEED_COMPANY_IDS.MICROSOFT,
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Cook',
      },
      {
        id: DEV_SEED_OPPORTUNITY_IDS.OPPORTUNITY_4,
        name: 'Opportunity 4',
        amountAmountMicros: 4000000,
        amountCurrencyCode: 'USD',
        closeDate: new Date(),
        stage: 'PROPOSAL',
        position: 4,
        pointOfContactId: DEV_SEED_PERSON_IDS.MATTHEW,
        companyId: DEV_SEED_COMPANY_IDS.MICROSOFT,
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: null,
        createdByName: '',
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a function to seed data into a 'messageChannel' table using TypeORM's EntityManager.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEV_SEED_CONNECTED_ACCOUNT_IDS } from 'src/database/typeorm-seeds/workspace/connected-account';
import {
  MessageChannelSyncStage,
  MessageChannelVisibility,
} from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';

const tableName = 'messageChannel';

export const DEV_SEED_MESSAGE_CHANNEL_IDS = {
  TIM: '20202020-9b80-4c2c-a597-383db48de1d6',
  JONY: '20202020-5ffe-4b32-814a-983d5e4911cd',
  PHIL: '20202020-e2f1-49b5-85d2-5d3a3386990c',
};

export const seedMessageChannel = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'createdAt',
      'updatedAt',
      'deletedAt',
      'isContactAutoCreationEnabled',
      'type',
      'connectedAccountId',
      'handle',
      'isSyncEnabled',
      'visibility',
      'syncStage',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_MESSAGE_CHANNEL_IDS.TIM,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        isContactAutoCreationEnabled: true,
        type: 'email',
        connectedAccountId: DEV_SEED_CONNECTED_ACCOUNT_IDS.TIM,
        handle: 'tim@apple.dev',
        isSyncEnabled: false,
        visibility: MessageChannelVisibility.SHARE_EVERYTHING,
        syncStage: MessageChannelSyncStage.FULL_MESSAGE_LIST_FETCH_PENDING,
      },
      {
        id: DEV_SEED_MESSAGE_CHANNEL_IDS.JONY,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        isContactAutoCreationEnabled: true,
        type: 'email',
        connectedAccountId: DEV_SEED_CONNECTED_ACCOUNT_IDS.JONY,
        handle: 'jony.ive@apple.dev',
        isSyncEnabled: false,
        visibility: MessageChannelVisibility.SHARE_EVERYTHING,
        syncStage: MessageChannelSyncStage.FULL_MESSAGE_LIST_FETCH_PENDING,
      },
      {
        id: DEV_SEED_MESSAGE_CHANNEL_IDS.PHIL,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        isContactAutoCreationEnabled: true,
        type: 'email',
        connectedAccountId: DEV_SEED_CONNECTED_ACCOUNT_IDS.PHIL,
        handle: 'phil.schiler@apple.dev',
        isSyncEnabled: false,
        visibility: MessageChannelVisibility.SHARE_EVERYTHING,
        syncStage: MessageChannelSyncStage.FULL_MESSAGE_LIST_FETCH_PENDING,
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code seeds calendar channel data into a database table using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEV_SEED_CONNECTED_ACCOUNT_IDS } from 'src/database/typeorm-seeds/workspace/connected-account';
import { CalendarChannelVisibility } from 'src/modules/calendar/common/standard-objects/calendar-channel.workspace-entity';

const tableName = 'calendarChannel';

export const seedCalendarChannels = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'connectedAccountId',
      'handle',
      'visibility',
      'isContactAutoCreationEnabled',
      'isSyncEnabled',
    ])
    .orIgnore()
    .values([
      {
        id: '59efdefe-a40f-4faf-bb9f-c6f9945b8203',
        connectedAccountId: DEV_SEED_CONNECTED_ACCOUNT_IDS.TIM,
        handle: 'tim@apple.com',
        visibility: CalendarChannelVisibility.SHARE_EVERYTHING,
        isContactAutoCreationEnabled: true,
        isSyncEnabled: true,
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code inserts a calendar event into a database table using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

const tableName = 'calendarEvent';

export const seedCalendarEvents = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'title',
      'isCanceled',
      'isFullDay',
      'startsAt',
      'endsAt',
      'externalCreatedAt',
      'externalUpdatedAt',
      'description',
      'location',
      'iCalUID',
      'conferenceSolution',
      'conferenceLinkPrimaryLinkLabel',
      'conferenceLinkPrimaryLinkUrl',
    ])
    .orIgnore()
    .values([
      {
        id: '86083141-1c0e-494c-a1b6-85b1c6fefaa5',
        title: 'Meeting with Christoph',
        isCanceled: false,
        isFullDay: false,
        startsAt: new Date(new Date().setHours(10, 0)).toISOString(),
        endsAt: new Date(new Date().setHours(11, 0)).toISOString(),
        externalCreatedAt: new Date().toISOString(),
        externalUpdatedAt: new Date().toISOString(),
        description: 'Discuss project progress',
        location: 'Seattle',
        iCalUID: 'event1@calendar.com',
        conferenceSolution: 'Zoom',
        conferenceLinkPrimaryLinkLabel: 'https://zoom.us/j/1234567890',
        conferenceLinkPrimaryLinkUrl: 'https://zoom.us/j/1234567890',
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code seeds calendar event participants into a database table using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEV_SEED_PERSON_IDS } from 'src/database/typeorm-seeds/workspace/seedPeople';
import { DEV_SEED_WORKSPACE_MEMBER_IDS } from 'src/database/typeorm-seeds/workspace/workspace-members';
import { CalendarEventParticipantResponseStatus } from 'src/modules/calendar/common/standard-objects/calendar-event-participant.workspace-entity';

const tableName = 'calendarEventParticipant';

export const seedCalendarEventParticipants = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'calendarEventId',
      'handle',
      'displayName',
      'isOrganizer',
      'responseStatus',
      'personId',
      'workspaceMemberId',
    ])
    .orIgnore()
    .values([
      {
        id: 'da8f47c3-8055-49ad-b7e4-9c9d5bbc1ecc',
        calendarEventId: '86083141-1c0e-494c-a1b6-85b1c6fefaa5',
        handle: 'christoph.calisto@linkedin.com',
        displayName: 'Christoph Calisto',
        isOrganizer: true,
        responseStatus: CalendarEventParticipantResponseStatus.ACCEPTED,
        personId: DEV_SEED_PERSON_IDS.CHRISTOPH,
        workspaceMemberId: null,
      },
      {
        id: 'e1ab9e1b-df6e-438e-a788-11c96dcecdd3',
        calendarEventId: '86083141-1c0e-494c-a1b6-85b1c6fefaa5',
        handle: 'tim@apple.com',
        displayName: 'Tim Apple',
        isOrganizer: false,
        responseStatus: CalendarEventParticipantResponseStatus.ACCEPTED,
        personId: null,
        workspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code seeds workspace members into a database table using TypeORM, based on the provided workspace ID.
Code Snippet:
import { EntityManager } from 'typeorm';

import {
  SEED_APPLE_WORKSPACE_ID,
  SEED_ACME_WORKSPACE_ID,
} from 'src/database/typeorm-seeds/core/workspaces';
import { WorkspaceMember } from 'src/engine/core-modules/user/dtos/workspace-member.dto';
import { DEV_SEED_USER_IDS } from 'src/database/typeorm-seeds/core/users';

const tableName = 'workspaceMember';

export const DEV_SEED_WORKSPACE_MEMBER_IDS = {
  TIM: '20202020-0687-4c41-b707-ed1bfca972a7',
  JONY: '20202020-77d5-4cb6-b60a-f4a835a85d61',
  PHIL: '20202020-1553-45c6-a028-5a9064cce07f',
};

type WorkspaceMembers = Pick<
  WorkspaceMember,
  'id' | 'locale' | 'colorScheme'
> & {
  nameFirstName: string;
  nameLastName: string;
  userEmail: string;
  userId: string;
};

export const seedWorkspaceMember = async (
  entityManager: EntityManager,
  schemaName: string,
  workspaceId: string,
) => {
  let workspaceMembers: WorkspaceMembers[] = [];

  if (workspaceId === SEED_APPLE_WORKSPACE_ID) {
    workspaceMembers = [
      {
        id: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        nameFirstName: 'Tim',
        nameLastName: 'Apple',
        locale: 'en',
        colorScheme: 'Light',
        userEmail: 'tim@apple.dev',
        userId: DEV_SEED_USER_IDS.TIM,
      },
      {
        id: DEV_SEED_WORKSPACE_MEMBER_IDS.JONY,
        nameFirstName: 'Jony',
        nameLastName: 'Ive',
        locale: 'en',
        colorScheme: 'Light',
        userEmail: 'jony.ive@apple.dev',
        userId: DEV_SEED_USER_IDS.JONY,
      },
      {
        id: DEV_SEED_WORKSPACE_MEMBER_IDS.PHIL,
        nameFirstName: 'Phil',
        nameLastName: 'Schiler',
        locale: 'en',
        colorScheme: 'Light',
        userEmail: 'phil.schiler@apple.dev',
        userId: DEV_SEED_USER_IDS.PHIL,
      },
    ];
  }

  if (workspaceId === SEED_ACME_WORKSPACE_ID) {
    workspaceMembers = [
      {
        id: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        nameFirstName: 'Tim',
        nameLastName: 'Apple',
        locale: 'en',
        colorScheme: 'Light',
        userEmail: 'tim@apple.dev',
        userId: DEV_SEED_USER_IDS.TIM,
      },
    ];
  }
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'nameFirstName',
      'nameLastName',
      'locale',
      'colorScheme',
      'userEmail',
      'userId',
    ])
    .orIgnore()
    .values(workspaceMembers)
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a seed function to insert sample data into a 'connectedAccount' table using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEV_SEED_WORKSPACE_MEMBER_IDS } from 'src/database/typeorm-seeds/workspace/workspace-members';

const tableName = 'connectedAccount';

export const DEV_SEED_CONNECTED_ACCOUNT_IDS = {
  TIM: '20202020-9ac0-4390-9a1a-ab4d2c4e1bb7',
  JONY: '20202020-0cc8-4d60-a3a4-803245698908',
  PHIL: '20202020-cafc-4323-908d-e5b42ad69fdf',
};

export const seedConnectedAccount = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'createdAt',
      'updatedAt',
      'deletedAt',
      'lastSyncHistoryId',
      'accountOwnerId',
      'refreshToken',
      'accessToken',
      'provider',
      'handle',
    ])
    .orIgnore()
    .values([
      {
        id: DEV_SEED_CONNECTED_ACCOUNT_IDS.TIM,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        lastSyncHistoryId: 'exampleLastSyncHistory',
        accountOwnerId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        refreshToken: 'exampleRefreshToken',
        accessToken: 'exampleAccessToken',
        provider: 'google',
        handle: 'tim@apple.dev',
      },
      {
        id: DEV_SEED_CONNECTED_ACCOUNT_IDS.JONY,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        lastSyncHistoryId: 'exampleLastSyncHistory',
        accountOwnerId: DEV_SEED_WORKSPACE_MEMBER_IDS.JONY,
        refreshToken: 'exampleRefreshToken',
        accessToken: 'exampleAccessToken',
        provider: 'google',
        handle: 'jony.ive@apple.dev',
      },
      {
        id: DEV_SEED_CONNECTED_ACCOUNT_IDS.PHIL,
        createdAt: new Date(),
        updatedAt: new Date(),
        deletedAt: null,
        lastSyncHistoryId: 'exampleLastSyncHistory',
        accountOwnerId: DEV_SEED_WORKSPACE_MEMBER_IDS.PHIL,
        refreshToken: 'exampleRefreshToken',
        accessToken: 'exampleAccessToken',
        provider: 'google',
        handle: 'phil.schiler@apple.dev',
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a function to format a thread participant from a workspace entity into a timeline thread participant DTO.
Code Snippet:
import { TimelineThreadParticipant } from 'src/engine/core-modules/messaging/dtos/timeline-thread-participant.dto';
import { MessageParticipantWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-participant.workspace-entity';

export const formatThreadParticipant = (
  threadParticipant: MessageParticipantWorkspaceEntity,
): TimelineThreadParticipant => ({
  personId: threadParticipant.personId,
  workspaceMemberId: threadParticipant.workspaceMemberId,
  firstName:
    threadParticipant.person?.name?.firstName ||
    threadParticipant.workspaceMember?.name.firstName ||
    '',
  lastName:
    threadParticipant.person?.name?.lastName ||
    threadParticipant.workspaceMember?.name.lastName ||
    '',
  displayName:
    threadParticipant.person?.name?.firstName ||
    threadParticipant.person?.name?.lastName ||
    threadParticipant.workspaceMember?.name.firstName ||
    threadParticipant.workspaceMember?.name.lastName ||
    threadParticipant.displayName ||
    threadParticipant.handle ||
    '',
  avatarUrl:
    threadParticipant.person?.avatarUrl ||
    threadParticipant.workspaceMember?.avatarUrl ||
    '',
  handle: threadParticipant.handle,
});

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code generates and seeds opportunity data into a database table using random values and data from existing company and person records.
Code Snippet:
import { DEMO_SEED_WORKSPACE_MEMBER_IDS } from 'src/engine/workspace-manager/demo-objects-prefill-data/seed-workspace-member-with-demo-data';
import { EntityManager } from 'typeorm';
import { v4 } from 'uuid';

const tableName = 'opportunity';

const getRandomStage = () => {
  const stages = ['NEW', 'SCREENING', 'MEETING', 'PROPOSAL', 'CUSTOMER'];

  return stages[Math.floor(Math.random() * stages.length)];
};

const generateRandomAmountMicros = () => {
  const firstDigit = Math.floor(Math.random() * 9) + 1;

  return firstDigit * 10000000000;
};

const generateOpportunities = (companies) => {
  return companies.map((company) => ({
    id: v4(),
    name: company.name,
    amountAmountMicros: generateRandomAmountMicros(),
    amountCurrencyCode: 'USD',
    closeDate: new Date(),
    stage: getRandomStage(),
    pointOfContactId: company.personId,
    companyId: company.id,
    createdBySource: 'MANUAL',
    createdByWorkspaceMemberId: DEMO_SEED_WORKSPACE_MEMBER_IDS.NOAH,
    createdByName: 'Noah A',
  }));
};

export const seedOpportunityWithDemoData = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  const companiesWithPeople = await entityManager?.query(
    `SELECT company.*, person.id AS "personId"
     FROM ${schemaName}.company
     LEFT JOIN ${schemaName}.person ON company.id = "person"."companyId"
     LIMIT 50`,
  );

  const opportunities = generateOpportunities(companiesWithPeople);

  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.${tableName}`, [
      'id',
      'name',
      'amountAmountMicros',
      'amountCurrencyCode',
      'closeDate',
      'stage',
      'pointOfContactId',
      'companyId',
      'createdBySource',
      'createdByWorkspaceMemberId',
      'createdByName',
      'position',
    ])
    .orIgnore()
    .values(
      opportunities.map((opportunity, index) => ({
        ...opportunity,
        position: index,
      })),
    )
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code seeds demo person data into a database using TypeORM, associating each person with a company from the database.
Code Snippet:
import { EntityManager } from 'typeorm';

import { peopleDemo } from 'src/engine/workspace-manager/demo-objects-prefill-data/people-demo.json';

export const seedPersonWithDemoData = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  const companies = await entityManager?.query(
    `SELECT * FROM ${schemaName}.company`,
  );

  // Iterate through the array and add a UUID for each person
  const people = peopleDemo.map((person, index) => ({
    nameFirstName: person.firstName,
    nameLastName: person.lastName,
    emailsPrimaryEmail: person.email,
    linkedinLinkPrimaryLinkUrl: person.linkedinUrl,
    jobTitle: person.jobTitle,
    city: person.city,
    avatarUrl: person.avatarUrl,
    companyId: companies[Math.floor(index / 2)].id,
    createdBySource: person.createdBySource,
    createdByWorkspaceMemberId: person.createdByWorkspaceMemberId,
    createdByName: person.createdByName,
    position: index
  }));

  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.person`, [
      'nameFirstName',
      'nameLastName',
      'emailsPrimaryEmail',
      'linkedinLinkPrimaryLinkUrl',
      'jobTitle',
      'city',
      'avatarUrl',
      'companyId',
      'createdBySource',
      'createdByWorkspaceMemberId',
      'createdByName',
      'position',
    ])
    .orIgnore()
    .values(people)
    .returning('*')
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code seeds workspace member data into a database using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { DEMO_SEED_USER_IDS } from 'src/database/typeorm-seeds/core/demo/users';
import { SOURCE_LOCALE } from 'twenty-shared';

export const DEMO_SEED_WORKSPACE_MEMBER_IDS = {
  NOAH: '20202020-0687-4c41-b707-ed1bfca972a2',
  HUGO: '20202020-77d5-4cb6-b60a-f4a835a85d62',
  TIM: '20202020-1553-45c6-a028-5a9064cce07e',
};

export const seedWorkspaceMemberWithDemoData = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.workspaceMember`, [
      'id',
      'nameFirstName',
      'nameLastName',
      'locale',
      'colorScheme',
      'userEmail',
      'userId',
    ])
    .orIgnore()
    .values([
      {
        id: DEMO_SEED_WORKSPACE_MEMBER_IDS.NOAH,
        nameFirstName: 'Noah',
        nameLastName: 'A',
        locale: SOURCE_LOCALE,
        colorScheme: 'Light',
        userEmail: 'noah@demo.dev',
        userId: DEMO_SEED_USER_IDS.NOAH,
      },
      {
        id: DEMO_SEED_WORKSPACE_MEMBER_IDS.HUGO,
        nameFirstName: 'Hugo',
        nameLastName: 'I',
        locale: SOURCE_LOCALE,
        colorScheme: 'Light',
        userEmail: 'hugo@demo.dev',
        userId: DEMO_SEED_USER_IDS.HUGO,
      },
      {
        id: DEMO_SEED_WORKSPACE_MEMBER_IDS.TIM,
        nameFirstName: 'Tim',
        nameLastName: 'Apple',
        locale: SOURCE_LOCALE,
        colorScheme: 'Light',
        userEmail: 'tim@apple.dev',
        userId: DEMO_SEED_USER_IDS.TIM,
      },
    ])
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code seeds company demo data into a database using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { COMPANIES_DEMO } from 'src/engine/workspace-manager/demo-objects-prefill-data/companies-demo.json';

export const seedCompanyWithDemoData = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.company`, [
      'name',
      'domainNamePrimaryLinkUrl',
      'addressAddressCity',
      'employees',
      'linkedinLinkPrimaryLinkUrl',
      'createdBySource',
      'createdByWorkspaceMemberId',
      'createdByName',
      'position'
    ])
    .orIgnore()
    .values(
      COMPANIES_DEMO.map((company, index) => ({ ...company, position: index })),
    )
    .returning('*')
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code seeds standard objects and demo data into a workspace using TypeORM transactions.
Code Snippet:
import { DataSource, EntityManager } from 'typeorm';

import { seedWorkspaceFavorites } from 'src/database/typeorm-seeds/workspace/favorites';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { shouldSeedWorkspaceFavorite } from 'src/engine/utils/should-seed-workspace-favorite';
import { companyPrefillData } from 'src/engine/workspace-manager/standard-objects-prefill-data/company';
import { personPrefillData } from 'src/engine/workspace-manager/standard-objects-prefill-data/person';
import { seedViewWithDemoData } from 'src/engine/workspace-manager/standard-objects-prefill-data/seed-view-with-demo-data';

export const standardObjectsPrefillData = async (
  workspaceDataSource: DataSource,
  schemaName: string,
  objectMetadata: ObjectMetadataEntity[],
) => {
  const objectMetadataMap = objectMetadata.reduce((acc, object) => {
    if (!object.standardId) {
      throw new Error('Standard Id is not set for object: ${object.name}');
    }

    acc[object.standardId] = {
      id: object.id,
      fields: object.fields.reduce((acc, field) => {
        if (!field.standardId) {
          throw new Error('Standard Id is not set for field: ${field.name}');
        }

        acc[field.standardId] = field.id;

        return acc;
      }, {}),
    };

    return acc;
  }, {});

  workspaceDataSource.transaction(async (entityManager: EntityManager) => {
    await companyPrefillData(entityManager, schemaName);
    await personPrefillData(entityManager, schemaName);
    const viewDefinitionsWithId = await seedViewWithDemoData(
      entityManager,
      schemaName,
      objectMetadataMap,
    );

    await seedWorkspaceFavorites(
      viewDefinitionsWithId
        .filter(
          (view) =>
            view.key === 'INDEX' &&
            shouldSeedWorkspaceFavorite(
              view.objectMetadataId,
              objectMetadataMap,
            ),
        )
        .map((view) => view.id),
      entityManager,
      schemaName,
    );
  });
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code inserts predefined company data into a database table named 'company' within a specified schema using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { FieldActorSource } from 'src/engine/metadata-modules/field-metadata/composite-types/actor.composite-type';

export const AIRBNB_ID = 'c776ee49-f608-4a77-8cc8-6fe96ae1e43f';
export const QONTO_ID = 'f45ee421-8a3e-4aa5-a1cf-7207cc6754e1';
export const STRIPE_ID = '1f70157c-4ea5-4d81-bc49-e1401abfbb94';
export const FIGMA_ID = '9d5bcf43-7d38-4e88-82cb-d6d4ce638bf0';
export const NOTION_ID = '06290608-8bf0-4806-99ae-a715a6a93fad';

export const companyPrefillData = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.company`, [
      'id',
      'name',
      'domainNamePrimaryLinkUrl',
      'addressAddressStreet1',
      'addressAddressStreet2',
      'addressAddressCity',
      'addressAddressState',
      'addressAddressPostcode',
      'addressAddressCountry',
      'employees',
      'position',
      'createdBySource',
      'createdByWorkspaceMemberId',
      'createdByName',
    ])
    .orIgnore()
    .values([
      {
        id: AIRBNB_ID,
        name: 'Airbnb',
        domainNamePrimaryLinkUrl: 'https://airbnb.com',
        addressAddressStreet1: '888 Brannan St',
        addressAddressStreet2: null,
        addressAddressCity: 'San Francisco',
        addressAddressState: 'CA',
        addressAddressPostcode: '94103',
        addressAddressCountry: 'United States',
        employees: 5000,
        position: 1,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
      },
      {
        id: QONTO_ID,
        name: 'Qonto',
        domainNamePrimaryLinkUrl: 'https://qonto.com',
        addressAddressStreet1: '18 rue de navarrin',
        addressAddressStreet2: null,
        addressAddressCity: 'Paris',
        addressAddressState: null,
        addressAddressPostcode: '75009',
        addressAddressCountry: 'France',
        employees: 800,
        position: 2,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
      },
      {
        id: STRIPE_ID,
        name: 'Stripe',
        domainNamePrimaryLinkUrl: 'https://stripe.com',
        addressAddressStreet1: 'Eutaw Street',
        addressAddressStreet2: null,
        addressAddressCity: 'Dublin',
        addressAddressState: null,
        addressAddressPostcode: null,
        addressAddressCountry: 'Ireland',
        employees: 8000,
        position: 3,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
      },
      {
        id: FIGMA_ID,
        name: 'Figma',
        domainNamePrimaryLinkUrl: 'https://figma.com',
        addressAddressStreet1: '760 Market St',
        addressAddressStreet2: 'Floor 10',
        addressAddressCity: 'San Francisco',
        addressAddressState: null,
        addressAddressPostcode: '94102',
        addressAddressCountry: 'United States',
        employees: 800,
        position: 4,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
      },
      {
        id: NOTION_ID,
        name: 'Notion',
        domainNamePrimaryLinkUrl: 'https://notion.com',
        addressAddressStreet1: '2300 Harrison St',
        addressAddressStreet2: null,
        addressAddressCity: 'San Francisco',
        addressAddressState: 'CA',
        addressAddressPostcode: '94110',
        addressAddressCountry: 'United States',
        employees: 400,
        position: 5,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
      },
    ])
    .returning('*')
    .execute();
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code inserts prefill data for persons into a database table using TypeORM.
Code Snippet:
import { EntityManager } from 'typeorm';

import { FieldActorSource } from 'src/engine/metadata-modules/field-metadata/composite-types/actor.composite-type';
import {
  AIRBNB_ID,
  FIGMA_ID,
  NOTION_ID,
  QONTO_ID,
  STRIPE_ID,
} from 'src/engine/workspace-manager/standard-objects-prefill-data/company';

// FixMe: Is this file a duplicate of src/database/typeorm-seeds/workspace/people.ts
export const personPrefillData = async (
  entityManager: EntityManager,
  schemaName: string,
) => {
  await entityManager
    .createQueryBuilder()
    .insert()
    .into(`${schemaName}.person`, [
      'nameFirstName',
      'nameLastName',
      'city',
      'emailsPrimaryEmail',
      'avatarUrl',
      'position',
      'createdBySource',
      'createdByWorkspaceMemberId',
      'createdByName',
      'phonesPrimaryPhoneNumber',
      'phonesPrimaryPhoneCountryCode',
      'companyId',
    ])
    .orIgnore()
    .values([
      {
        nameFirstName: 'Brian',
        nameLastName: 'Chesky',
        city: 'San Francisco',
        emailsPrimaryEmail: 'chesky@airbnb.com',
        avatarUrl:
          'https://twentyhq.github.io/placeholder-images/people/image-3.png',
        position: 1,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
        phonesPrimaryPhoneNumber: '1234567890',
        phonesPrimaryPhoneCountryCode: '+1',
        companyId: AIRBNB_ID,
      },
      {
        nameFirstName: 'Alexandre',
        nameLastName: 'Prot',
        city: 'Paris',
        emailsPrimaryEmail: 'prot@qonto.com',
        avatarUrl:
          'https://twentyhq.github.io/placeholder-images/people/image-89.png',
        position: 2,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
        phonesPrimaryPhoneNumber: '677118822',
        phonesPrimaryPhoneCountryCode: '+33',
        companyId: QONTO_ID,
      },
      {
        nameFirstName: 'Patrick',
        nameLastName: 'Collison',
        city: 'San Francisco',
        emailsPrimaryEmail: 'collison@stripe.com',
        avatarUrl:
          'https://twentyhq.github.io/placeholder-images/people/image-47.png',
        position: 3,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
        phonesPrimaryPhoneNumber: '987625341',
        phonesPrimaryPhoneCountryCode: '+1',
        companyId: STRIPE_ID,
      },
      {
        nameFirstName: 'Dylan',
        nameLastName: 'Field',
        city: 'San Francisco',
        emailsPrimaryEmail: 'field@figma.com',
        avatarUrl:
          'https://twentyhq.github.io/placeholder-images/people/image-40.png',
        position: 4,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
        phonesPrimaryPhoneNumber: '09882261',
        phonesPrimaryPhoneCountryCode: '+1',
        companyId: FIGMA_ID,
      },
      {
        nameFirstName: 'Ivan',
        nameLastName: 'Zhao',
        city: 'San Francisco',
        emailsPrimaryEmail: 'zhao@notion.com',
        avatarUrl:
          'https://twentyhq.github.io/placeholder-images/people/image-68.png',
        position: 5,
        createdBySource: FieldActorSource.SYSTEM,
        createdByWorkspaceMemberId: null,
        createdByName: 'System',
        phonesPrimaryPhoneNumber: '88226173',
        phonesPrimaryPhoneCountryCode: '+1',
        companyId: NOTION_ID,
      },
    ])
    .returning('*')
    .execute();
};

============================================ CODE SNIPPET END ============================================


</CLUSTER_2>



=== New Entry ===

<CLUSTER_3>
Number of Code Snippets part of this cluster: 26
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code sets up a test suite for the EmailAliasManagerService, focusing on testing the refreshHandleAliases method for Microsoft accounts.
Code Snippet:
import { Test, TestingModule } from '@nestjs/testing';

import { ConnectedAccountProvider } from 'twenty-shared';
import { Repository } from 'typeorm';

import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { GoogleEmailAliasManagerService } from 'src/modules/connected-account/email-alias-manager/drivers/google/google-email-alias-manager.service';
import { MicrosoftEmailAliasManagerService } from 'src/modules/connected-account/email-alias-manager/drivers/microsoft/microsoft-email-alias-manager.service';
import { microsoftGraphMeResponseWithProxyAddresses } from 'src/modules/connected-account/email-alias-manager/drivers/microsoft/mocks/microsoft-api-examples';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { MicrosoftClientProvider } from 'src/modules/messaging/message-import-manager/drivers/microsoft/providers/microsoft-client.provider';

import { EmailAliasManagerService } from './email-alias-manager.service';

describe('Email Alias Manager Service', () => {
  let emailAliasManagerService: EmailAliasManagerService;
  let microsoftEmailAliasManagerService: MicrosoftEmailAliasManagerService;
  let connectedAccountRepository: Partial<
    Repository<ConnectedAccountWorkspaceEntity>
  >;

  beforeEach(async () => {
    connectedAccountRepository = {
      update: jest.fn().mockResolvedValue((arg) => arg),
    };

    const module: TestingModule = await Test.createTestingModule({
      providers: [
        {
          provide: TwentyORMManager,
          useValue: {
            getRepository: jest
              .fn()
              .mockResolvedValue(connectedAccountRepository),
          },
        },
        EmailAliasManagerService,
        {
          provide: GoogleEmailAliasManagerService,
          useValue: {},
        },
        MicrosoftEmailAliasManagerService,
        {
          provide: MicrosoftClientProvider,
          useValue: {
            getMicrosoftClient: jest.fn().mockResolvedValue({
              api: jest.fn().mockReturnValue({
                get: jest
                  .fn()
                  .mockResolvedValue(
                    microsoftGraphMeResponseWithProxyAddresses,
                  ),
              }),
            }),
          },
        },
      ],
    }).compile();

    emailAliasManagerService = module.get<EmailAliasManagerService>(
      EmailAliasManagerService,
    );
    microsoftEmailAliasManagerService =
      module.get<MicrosoftEmailAliasManagerService>(
        MicrosoftEmailAliasManagerService,
      );
  });

  it('Service should be defined', () => {
    expect(emailAliasManagerService).toBeDefined();
  });

  describe('Refresh handle aliases for Microsoft', () => {
    it('Should refresh Microsoft handle aliases successfully', async () => {
      const mockConnectedAccount: Partial<ConnectedAccountWorkspaceEntity> = {
        id: 'test-id',
        provider: ConnectedAccountProvider.MICROSOFT,
        refreshToken: 'test-refresh-token',
      };

      const expectedAliases =
        'bertrand2@domain.onmicrosoft.com,bertrand3@otherdomain.com';

      jest.spyOn(microsoftEmailAliasManagerService, 'getHandleAliases');

      await emailAliasManagerService.refreshHandleAliases(
        mockConnectedAccount as ConnectedAccountWorkspaceEntity,
      );

      expect(
        microsoftEmailAliasManagerService.getHandleAliases,
      ).toHaveBeenCalledWith(mockConnectedAccount);

      expect(connectedAccountRepository.update).toHaveBeenCalledWith(
        { id: mockConnectedAccount.id },
        {
          handleAliases: expectedAliases,
        },
      );
    });
  });
});

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines an EmailAliasManagerService that refreshes email aliases for connected accounts from Google or Microsoft and updates the connected account entity in a database.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { assertUnreachable, ConnectedAccountProvider } from 'twenty-shared';

import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { GoogleEmailAliasManagerService } from 'src/modules/connected-account/email-alias-manager/drivers/google/google-email-alias-manager.service';
import { MicrosoftEmailAliasManagerService } from 'src/modules/connected-account/email-alias-manager/drivers/microsoft/microsoft-email-alias-manager.service';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';

@Injectable()
export class EmailAliasManagerService {
  constructor(
    private readonly googleEmailAliasManagerService: GoogleEmailAliasManagerService,
    private readonly microsoftEmailAliasManagerService: MicrosoftEmailAliasManagerService,
    private readonly twentyORMManager: TwentyORMManager,
  ) {}

  public async refreshHandleAliases(
    connectedAccount: ConnectedAccountWorkspaceEntity,
  ) {
    let handleAliases: string[];

    switch (connectedAccount.provider) {
      case ConnectedAccountProvider.MICROSOFT:
        handleAliases =
          await this.microsoftEmailAliasManagerService.getHandleAliases(
            connectedAccount,
          );
        break;
      case ConnectedAccountProvider.GOOGLE:
        handleAliases =
          await this.googleEmailAliasManagerService.getHandleAliases(
            connectedAccount,
          );
        break;
      default:
        assertUnreachable(
          connectedAccount.provider,
          `Email alias manager for provider ${connectedAccount.provider} is not implemented`,
        );
    }

    const connectedAccountRepository =
      await this.twentyORMManager.getRepository<ConnectedAccountWorkspaceEntity>(
        'connectedAccount',
      );

    await connectedAccountRepository.update(
      { id: connectedAccount.id },
      {
        handleAliases: handleAliases.join(','), // TODO: modify handleAliases to be of fieldmetadatatype array
      },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to refresh access tokens for connected accounts with Google and Microsoft, and save the new tokens to a database.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { assertUnreachable, ConnectedAccountProvider } from 'twenty-shared';

import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import {
  GoogleAPIRefreshAccessTokenService,
  GoogleTokens,
} from 'src/modules/connected-account/refresh-tokens-manager/drivers/google/services/google-api-refresh-access-token.service';
import {
  MicrosoftAPIRefreshAccessTokenService,
  MicrosoftTokens,
} from 'src/modules/connected-account/refresh-tokens-manager/drivers/microsoft/services/microsoft-api-refresh-tokens.service';
import {
  ConnectedAccountRefreshAccessTokenException,
  ConnectedAccountRefreshAccessTokenExceptionCode,
} from 'src/modules/connected-account/refresh-tokens-manager/exceptions/connected-account-refresh-tokens.exception';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';

export type ConnectedAccountTokens = GoogleTokens | MicrosoftTokens;

@Injectable()
export class ConnectedAccountRefreshTokensService {
  constructor(
    private readonly googleAPIRefreshAccessTokenService: GoogleAPIRefreshAccessTokenService,
    private readonly microsoftAPIRefreshAccessTokenService: MicrosoftAPIRefreshAccessTokenService,
    private readonly twentyORMManager: TwentyORMManager,
  ) {}

  async refreshAndSaveTokens(
    connectedAccount: ConnectedAccountWorkspaceEntity,
    workspaceId: string,
  ): Promise<string> {
    const refreshToken = connectedAccount.refreshToken;

    if (!refreshToken) {
      throw new ConnectedAccountRefreshAccessTokenException(
        `No refresh token found for connected account ${connectedAccount.id} in workspace ${workspaceId}`,
        ConnectedAccountRefreshAccessTokenExceptionCode.REFRESH_TOKEN_NOT_FOUND,
      );
    }

    const connectedAccountTokens = await this.refreshTokens(
      connectedAccount,
      refreshToken,
      workspaceId,
    );

    try {
      const connectedAccountRepository =
        await this.twentyORMManager.getRepository<ConnectedAccountWorkspaceEntity>(
          'connectedAccount',
        );

      await connectedAccountRepository.update(
        { id: connectedAccount.id },
        connectedAccountTokens,
      );
    } catch (error) {
      throw new Error(
        `Error saving the new tokens for connected account ${connectedAccount.id} in workspace ${workspaceId}: ${error.message} `,
      );
    }

    return connectedAccountTokens.accessToken;
  }

  async refreshTokens(
    connectedAccount: ConnectedAccountWorkspaceEntity,
    refreshToken: string,
    workspaceId: string,
  ): Promise<ConnectedAccountTokens> {
    try {
      switch (connectedAccount.provider) {
        case ConnectedAccountProvider.GOOGLE:
          return this.googleAPIRefreshAccessTokenService.refreshAccessToken(
            refreshToken,
          );
        case ConnectedAccountProvider.MICROSOFT:
          return this.microsoftAPIRefreshAccessTokenService.refreshTokens(
            refreshToken,
          );
        default:
          return assertUnreachable(
            connectedAccount.provider,
            `Provider ${connectedAccount.provider} not supported`,
          );
      }
    } catch (error) {
      throw new ConnectedAccountRefreshAccessTokenException(
        `Error refreshing tokens for connected account ${connectedAccount.id} in workspace ${workspaceId}: ${error.message} ${error?.response?.data?.error_description}`,
        ConnectedAccountRefreshAccessTokenExceptionCode.REFRESH_ACCESS_TOKEN_FAILED,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for sending and resending email verification links to users.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { i18n } from '@lingui/core';
import { t } from '@lingui/core/macro';
import { render } from '@react-email/render';
import { addMilliseconds, differenceInMilliseconds } from 'date-fns';
import ms from 'ms';
import { SendEmailVerificationLinkEmail } from 'twenty-emails';
import { APP_LOCALES } from 'twenty-shared';
import { Repository } from 'typeorm';

import {
  AppToken,
  AppTokenType,
} from 'src/engine/core-modules/app-token/app-token.entity';
import { EmailVerificationTokenService } from 'src/engine/core-modules/auth/token/services/email-verification-token.service';
import { WorkspaceSubdomainCustomDomainAndIsCustomDomainEnabledType } from 'src/engine/core-modules/domain-manager/domain-manager.type';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';
import {
  EmailVerificationException,
  EmailVerificationExceptionCode,
} from 'src/engine/core-modules/email-verification/email-verification.exception';
import { EmailService } from 'src/engine/core-modules/email/email.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { UserService } from 'src/engine/core-modules/user/services/user.service';

@Injectable()
// eslint-disable-next-line @nx/workspace-inject-workspace-repository
export class EmailVerificationService {
  constructor(
    @InjectRepository(AppToken, 'core')
    private readonly appTokenRepository: Repository<AppToken>,
    private readonly domainManagerService: DomainManagerService,
    private readonly emailService: EmailService,
    private readonly environmentService: EnvironmentService,
    private readonly userService: UserService,
    private readonly emailVerificationTokenService: EmailVerificationTokenService,
  ) {}

  async sendVerificationEmail(
    userId: string,
    email: string,
    workspace: WorkspaceSubdomainCustomDomainAndIsCustomDomainEnabledType,
    locale: keyof typeof APP_LOCALES,
  ) {
    if (!this.environmentService.get('IS_EMAIL_VERIFICATION_REQUIRED')) {
      return { success: false };
    }

    const { token: emailVerificationToken } =
      await this.emailVerificationTokenService.generateToken(userId, email);

    const verificationLink =
      this.domainManagerService.buildEmailVerificationURL({
        emailVerificationToken,
        email,
        workspace,
      });

    const emailData = {
      link: verificationLink.toString(),
      locale,
    };

    const emailTemplate = SendEmailVerificationLinkEmail(emailData);

    const html = render(emailTemplate);

    const text = render(emailTemplate, {
      plainText: true,
    });

    i18n.activate(locale);

    await this.emailService.send({
      from: `${this.environmentService.get(
        'EMAIL_FROM_NAME',
      )} <${this.environmentService.get('EMAIL_FROM_ADDRESS')}>`,
      to: email,
      subject: t`Welcome to Twenty: Please Confirm Your Email`,
      text,
      html,
    });

    return { success: true };
  }

  async resendEmailVerificationToken(
    email: string,
    workspace: WorkspaceSubdomainCustomDomainAndIsCustomDomainEnabledType,
    locale: keyof typeof APP_LOCALES,
  ) {
    if (!this.environmentService.get('IS_EMAIL_VERIFICATION_REQUIRED')) {
      throw new EmailVerificationException(
        'Email verification token cannot be sent because email verification is not required',
        EmailVerificationExceptionCode.EMAIL_VERIFICATION_NOT_REQUIRED,
      );
    }

    const user = await this.userService.getUserByEmail(email);

    if (user.isEmailVerified) {
      throw new EmailVerificationException(
        'Email already verified',
        EmailVerificationExceptionCode.EMAIL_ALREADY_VERIFIED,
      );
    }

    const existingToken = await this.appTokenRepository.findOne({
      where: {
        userId: user.id,
        type: AppTokenType.EmailVerificationToken,
      },
    });

    if (existingToken) {
      const cooldownDuration = ms('1m');
      const timeToWaitMs = differenceInMilliseconds(
        addMilliseconds(existingToken.createdAt, cooldownDuration),
        new Date(),
      );

      if (timeToWaitMs > 0) {
        throw new EmailVerificationException(
          `Please wait ${ms(timeToWaitMs, { long: true })} before requesting another verification email`,
          EmailVerificationExceptionCode.RATE_LIMIT_EXCEEDED,
        );
      }

      await this.appTokenRepository.delete(existingToken.id);
    }

    await this.sendVerificationEmail(user.id, email, workspace, locale);

    return { success: true };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code tests the AdminPanelService, mocking dependencies and testing methods for updating feature flags, impersonating users, and grouping environment variables.
Code Snippet:
import { Test, TestingModule } from '@nestjs/testing';
import { getRepositoryToken } from '@nestjs/typeorm';

import { AdminPanelService } from 'src/engine/core-modules/admin-panel/admin-panel.service';
import {
  AuthException,
  AuthExceptionCode,
} from 'src/engine/core-modules/auth/auth.exception';
import { LoginTokenService } from 'src/engine/core-modules/auth/token/services/login-token.service';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { FeatureFlag } from 'src/engine/core-modules/feature-flag/feature-flag.entity';
import { User } from 'src/engine/core-modules/user/user.entity';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';

const UserFindOneMock = jest.fn();
const WorkspaceFindOneMock = jest.fn();
const FeatureFlagUpdateMock = jest.fn();
const FeatureFlagSaveMock = jest.fn();
const LoginTokenServiceGenerateLoginTokenMock = jest.fn();
const EnvironmentServiceGetAllMock = jest.fn();

jest.mock(
  'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum',
  () => {
    return {
      FeatureFlagKey: {
        IsFlagEnabled: 'IS_FLAG_ENABLED',
      },
    };
  },
);

jest.mock(
  '../../environment/constants/environment-variables-group-metadata',
  () => ({
    ENVIRONMENT_VARIABLES_GROUP_METADATA: {
      SERVER_CONFIG: {
        position: 100,
        description: 'Server config description',
        isHiddenOnLoad: false,
      },
      RATE_LIMITING: {
        position: 200,
        description: 'Rate limiting description',
        isHiddenOnLoad: false,
      },
      OTHER: {
        position: 300,
        description: 'Other description',
        isHiddenOnLoad: true,
      },
    },
  }),
);

describe('AdminPanelService', () => {
  let service: AdminPanelService;

  beforeEach(async () => {
    const module: TestingModule = await Test.createTestingModule({
      providers: [
        AdminPanelService,
        {
          provide: getRepositoryToken(Workspace, 'core'),
          useValue: {
            findOne: WorkspaceFindOneMock,
          },
        },
        {
          provide: getRepositoryToken(User, 'core'),
          useValue: {
            findOne: UserFindOneMock,
          },
        },
        {
          provide: getRepositoryToken(FeatureFlag, 'core'),
          useValue: {
            update: FeatureFlagUpdateMock,
            save: FeatureFlagSaveMock,
          },
        },
        {
          provide: LoginTokenService,
          useValue: {
            generateLoginToken: LoginTokenServiceGenerateLoginTokenMock,
          },
        },
        {
          provide: DomainManagerService,
          useValue: {
            getWorkspaceUrls: jest.fn().mockReturnValue({
              customUrl: undefined,
              subdomainUrl: 'https://twenty.twenty.com',
            }),
          },
        },
        {
          provide: EnvironmentService,
          useValue: {
            getAll: EnvironmentServiceGetAllMock,
          },
        },
      ],
    }).compile();

    service = module.get<AdminPanelService>(AdminPanelService);
  });

  it('should be defined', async () => {
    expect(service).toBeDefined();
  });

  it('should update an existing feature flag if it exists', async () => {
    const workspaceId = 'workspace-id';
    const featureFlag = 'IsFlagEnabled' as FeatureFlagKey;
    const value = true;
    const existingFlag = {
      id: 'flag-id',
      key: 'IS_FLAG_ENABLED',
      value: false,
    };

    WorkspaceFindOneMock.mockReturnValueOnce({
      id: workspaceId,
      featureFlags: [existingFlag],
    });

    await service.updateWorkspaceFeatureFlags(workspaceId, featureFlag, value);

    expect(FeatureFlagUpdateMock).toHaveBeenCalledWith(existingFlag.id, {
      value,
    });
    expect(FeatureFlagSaveMock).not.toHaveBeenCalled();
  });

  it('should create a new feature flag if it does not exist', async () => {
    const workspaceId = 'workspace-id';
    const featureFlag = 'IsFlagEnabled' as FeatureFlagKey;
    const value = true;

    WorkspaceFindOneMock.mockReturnValueOnce({
      id: workspaceId,
      featureFlags: [],
    });

    await service.updateWorkspaceFeatureFlags(workspaceId, featureFlag, value);

    expect(FeatureFlagSaveMock).toHaveBeenCalledWith({
      key: 'IS_FLAG_ENABLED',
      value,
      workspaceId,
    });
    expect(FeatureFlagUpdateMock).not.toHaveBeenCalled();
  });

  it('should throw an exception if the workspace is not found', async () => {
    const workspaceId = 'non-existent-workspace';
    const featureFlag = 'IsFlagEnabled' as FeatureFlagKey;
    const value = true;

    WorkspaceFindOneMock.mockReturnValueOnce(null);

    await expect(
      service.updateWorkspaceFeatureFlags(workspaceId, featureFlag, value),
    ).rejects.toThrowError(
      new AuthException('Workspace not found', AuthExceptionCode.INVALID_INPUT),
    );
  });

  it('should throw an exception if the flag is not found', async () => {
    const workspaceId = 'non-existent-workspace';
    const featureFlag = 'IsUnknownFlagEnabled' as FeatureFlagKey;
    const value = true;

    WorkspaceFindOneMock.mockReturnValueOnce(null);

    await expect(
      service.updateWorkspaceFeatureFlags(workspaceId, featureFlag, value),
    ).rejects.toThrowError(
      new AuthException(
        'Invalid feature flag key',
        AuthExceptionCode.INVALID_INPUT,
      ),
    );
  });

  it('should impersonate a user and return workspace and loginToken on success', async () => {
    const mockUser = {
      id: 'user-id',
      email: 'user@example.com',
      workspaces: [
        {
          workspace: {
            id: 'workspace-id',
            allowImpersonation: true,
            subdomain: 'example-subdomain',
          },
        },
      ],
    };

    UserFindOneMock.mockReturnValueOnce(mockUser);
    LoginTokenServiceGenerateLoginTokenMock.mockReturnValueOnce({
      token: 'mock-login-token',
      expiresAt: new Date(),
    });

    const result = await service.impersonate('user-id', 'workspace-id');

    expect(UserFindOneMock).toHaveBeenCalledWith(
      expect.objectContaining({
        where: expect.objectContaining({
          id: 'user-id',
          workspaces: {
            workspaceId: 'workspace-id',
            workspace: { allowImpersonation: true },
          },
        }),
        relations: ['workspaces', 'workspaces.workspace'],
      }),
    );

    expect(LoginTokenServiceGenerateLoginTokenMock).toHaveBeenCalledWith(
      'user@example.com',
      'workspace-id',
    );

    expect(result).toEqual(
      expect.objectContaining({
        workspace: {
          id: 'workspace-id',
          workspaceUrls: {
            customUrl: undefined,
            subdomainUrl: 'https://twenty.twenty.com',
          },
        },
        loginToken: expect.objectContaining({
          token: 'mock-login-token',
          expiresAt: expect.any(Date),
        }),
      }),
    );
  });

  it('should throw an error when user is not found', async () => {
    UserFindOneMock.mockReturnValueOnce(null);

    await expect(
      service.impersonate('invalid-user-id', 'workspace-id'),
    ).rejects.toThrow(
      new AuthException(
        'User not found or impersonation not enable on workspace',
        AuthExceptionCode.INVALID_INPUT,
      ),
    );

    expect(UserFindOneMock).toHaveBeenCalled();
  });

  describe('getEnvironmentVariablesGrouped', () => {
    it('should correctly group and sort environment variables', () => {
      EnvironmentServiceGetAllMock.mockReturnValue({
        SERVER_URL: {
          value: 'http://localhost',
          metadata: {
            group: 'SERVER_CONFIG',
            description: 'Server URL',
          },
        },
        RATE_LIMIT_TTL: {
          value: '60',
          metadata: {
            group: 'RATE_LIMITING',
            description: 'Rate limit TTL',
          },
        },
        API_KEY: {
          value: 'secret-key',
          metadata: {
            group: 'SERVER_CONFIG',
            description: 'API Key',
            sensitive: true,
          },
        },
        OTHER_VAR: {
          value: 'other',
          metadata: {
            group: 'OTHER',
            description: 'Other var',
          },
        },
      });

      const result = service.getEnvironmentVariablesGrouped();

      expect(result).toEqual({
        groups: [
          {
            name: 'SERVER_CONFIG',
            description: 'Server config description',
            isHiddenOnLoad: false,
            variables: [
              {
                name: 'API_KEY',
                value: 'secret-key',
                description: 'API Key',
                sensitive: true,
              },
              {
                name: 'SERVER_URL',
                value: 'http://localhost',
                description: 'Server URL',
                sensitive: false,
              },
            ],
          },
          {
            name: 'RATE_LIMITING',
            description: 'Rate limiting description',
            isHiddenOnLoad: false,
            variables: [
              {
                name: 'RATE_LIMIT_TTL',
                value: '60',
                description: 'Rate limit TTL',
                sensitive: false,
              },
            ],
          },
          {
            name: 'OTHER',
            description: 'Other description',
            isHiddenOnLoad: true,
            variables: [
              {
                name: 'OTHER_VAR',
                value: 'other',
                description: 'Other var',
                sensitive: false,
              },
            ],
          },
        ],
      });

      expect(result.groups[0].name).toBe('SERVER_CONFIG');
      expect(result.groups[1].name).toBe('RATE_LIMITING');
      expect(result.groups[2].name).toBe('OTHER');
    });

    it('should handle empty environment variables', () => {
      EnvironmentServiceGetAllMock.mockReturnValue({});

      const result = service.getEnvironmentVariablesGrouped();

      expect(result).toEqual({
        groups: [],
      });
    });

    it('should handle variables with undefined metadata fields', () => {
      EnvironmentServiceGetAllMock.mockReturnValue({
        TEST_VAR: {
          value: 'test',
          metadata: {
            group: 'SERVER_CONFIG',
          },
        },
      });

      const result = service.getEnvironmentVariablesGrouped();

      expect(result.groups[0].variables[0]).toEqual({
        name: 'TEST_VAR',
        value: 'test',
        description: undefined,
        sensitive: false,
      });
    });
  });
});

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a service for managing approved access domains, including creating, validating, deleting, and retrieving domains, and sending validation emails.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import crypto from 'crypto';

import { render } from '@react-email/render';
import { Repository } from 'typeorm';
import { APP_LOCALES } from 'twenty-shared';
import { SendApprovedAccessDomainValidation } from 'twenty-emails';

import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { User } from 'src/engine/core-modules/user/user.entity';
import { EmailService } from 'src/engine/core-modules/email/email.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';
import { ApprovedAccessDomain as ApprovedAccessDomainEntity } from 'src/engine/core-modules/approved-access-domain/approved-access-domain.entity';
import { approvedAccessDomainValidator } from 'src/engine/core-modules/approved-access-domain/approved-access-domain.validate';
import {
  ApprovedAccessDomainException,
  ApprovedAccessDomainExceptionCode,
} from 'src/engine/core-modules/approved-access-domain/approved-access-domain.exception';
import { isWorkDomain } from 'src/utils/is-work-email';

@Injectable()
// eslint-disable-next-line @nx/workspace-inject-workspace-repository
export class ApprovedAccessDomainService {
  constructor(
    @InjectRepository(ApprovedAccessDomainEntity, 'core')
    private readonly approvedAccessDomainRepository: Repository<ApprovedAccessDomainEntity>,
    private readonly emailService: EmailService,
    private readonly environmentService: EnvironmentService,
    private readonly domainManagerService: DomainManagerService,
  ) {}

  async sendApprovedAccessDomainValidationEmail(
    sender: User,
    to: string,
    workspace: Workspace,
    approvedAccessDomain: ApprovedAccessDomainEntity,
  ) {
    if (approvedAccessDomain.isValidated) {
      throw new ApprovedAccessDomainException(
        'Approved access domain has already been validated',
        ApprovedAccessDomainExceptionCode.APPROVED_ACCESS_DOMAIN_ALREADY_VERIFIED,
      );
    }

    if (to.split('@')[1] !== approvedAccessDomain.domain) {
      throw new ApprovedAccessDomainException(
        'Approved access domain does not match email domain',
        ApprovedAccessDomainExceptionCode.APPROVED_ACCESS_DOMAIN_DOES_NOT_MATCH_DOMAIN_EMAIL,
      );
    }

    const link = this.domainManagerService.buildWorkspaceURL({
      workspace,
      pathname: `settings/security`,
      searchParams: {
        wtdId: approvedAccessDomain.id,
        validationToken: this.generateUniqueHash(approvedAccessDomain),
      },
    });

    const emailTemplate = SendApprovedAccessDomainValidation({
      link: link.toString(),
      workspace: { name: workspace.displayName, logo: workspace.logo },
      domain: approvedAccessDomain.domain,
      sender: {
        email: sender.email,
        firstName: sender.firstName,
        lastName: sender.lastName,
      },
      serverUrl: this.environmentService.get('SERVER_URL'),
      locale: 'en' as keyof typeof APP_LOCALES,
    });
    const html = render(emailTemplate);
    const text = render(emailTemplate, {
      plainText: true,
    });

    await this.emailService.send({
      from: `${sender.firstName} ${sender.lastName} (via Twenty) <${this.environmentService.get('EMAIL_FROM_ADDRESS')}>`,
      to,
      subject: 'Approve your access domain',
      text,
      html,
    });
  }

  private generateUniqueHash(approvedAccessDomain: ApprovedAccessDomainEntity) {
    return crypto
      .createHash('sha256')
      .update(
        JSON.stringify({
          id: approvedAccessDomain.id,
          domain: approvedAccessDomain.domain,
          key: this.environmentService.get('APP_SECRET'),
        }),
      )
      .digest('hex');
  }

  async validateApprovedAccessDomain({
    validationToken,
    approvedAccessDomainId,
  }: {
    validationToken: string;
    approvedAccessDomainId: string;
  }) {
    const approvedAccessDomain =
      await this.approvedAccessDomainRepository.findOneBy({
        id: approvedAccessDomainId,
      });

    approvedAccessDomainValidator.assertIsDefinedOrThrow(approvedAccessDomain);

    if (approvedAccessDomain.isValidated) {
      throw new ApprovedAccessDomainException(
        'Approved access domain has already been validated',
        ApprovedAccessDomainExceptionCode.APPROVED_ACCESS_DOMAIN_ALREADY_VALIDATED,
      );
    }

    const isHashValid =
      this.generateUniqueHash(approvedAccessDomain) === validationToken;

    if (!isHashValid) {
      throw new ApprovedAccessDomainException(
        'Invalid approved access domain validation token',
        ApprovedAccessDomainExceptionCode.APPROVED_ACCESS_DOMAIN_VALIDATION_TOKEN_INVALID,
      );
    }

    return await this.approvedAccessDomainRepository.save({
      ...approvedAccessDomain,
      isValidated: true,
    });
  }

  async createApprovedAccessDomain(
    domain: string,
    inWorkspace: Workspace,
    fromUser: User,
    emailToValidateDomain: string,
  ): Promise<ApprovedAccessDomainEntity> {
    if (!isWorkDomain(domain)) {
      throw new ApprovedAccessDomainException(
        'Approved access domain must be a company domain',
        ApprovedAccessDomainExceptionCode.APPROVED_ACCESS_DOMAIN_MUST_BE_A_COMPANY_DOMAIN,
      );
    }

    if (
      await this.approvedAccessDomainRepository.findOneBy({
        domain,
        workspaceId: inWorkspace.id,
      })
    ) {
      throw new ApprovedAccessDomainException(
        'Approved access domain already registered.',
        ApprovedAccessDomainExceptionCode.APPROVED_ACCESS_DOMAIN_ALREADY_REGISTERED,
      );
    }

    const approvedAccessDomain = await this.approvedAccessDomainRepository.save(
      {
        workspaceId: inWorkspace.id,
        domain,
      },
    );

    await this.sendApprovedAccessDomainValidationEmail(
      fromUser,
      emailToValidateDomain,
      inWorkspace,
      approvedAccessDomain,
    );

    return approvedAccessDomain;
  }

  async deleteApprovedAccessDomain(
    workspace: Workspace,
    approvedAccessDomainId: string,
  ) {
    const approvedAccessDomain =
      await this.approvedAccessDomainRepository.findOneBy({
        id: approvedAccessDomainId,
        workspaceId: workspace.id,
      });

    approvedAccessDomainValidator.assertIsDefinedOrThrow(approvedAccessDomain);

    await this.approvedAccessDomainRepository.delete({
      id: approvedAccessDomain.id,
    });
  }

  async getApprovedAccessDomains(workspace: Workspace) {
    return await this.approvedAccessDomainRepository.find({
      where: {
        workspaceId: workspace.id,
      },
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for handling refresh tokens, including verifying and generating refresh tokens, and managing token revocation.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { addMilliseconds } from 'date-fns';
import ms from 'ms';
import { Repository } from 'typeorm';

import {
  AppToken,
  AppTokenType,
} from 'src/engine/core-modules/app-token/app-token.entity';
import {
  AuthException,
  AuthExceptionCode,
} from 'src/engine/core-modules/auth/auth.exception';
import { AuthToken } from 'src/engine/core-modules/auth/dto/token.entity';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { JwtWrapperService } from 'src/engine/core-modules/jwt/services/jwt-wrapper.service';
import { User } from 'src/engine/core-modules/user/user.entity';

@Injectable()
export class RefreshTokenService {
  constructor(
    private readonly jwtWrapperService: JwtWrapperService,
    private readonly environmentService: EnvironmentService,
    @InjectRepository(AppToken, 'core')
    private readonly appTokenRepository: Repository<AppToken>,
    @InjectRepository(User, 'core')
    private readonly userRepository: Repository<User>,
  ) {}

  async verifyRefreshToken(refreshToken: string) {
    const coolDown = this.environmentService.get('REFRESH_TOKEN_COOL_DOWN');

    await this.jwtWrapperService.verifyWorkspaceToken(refreshToken, 'REFRESH');
    const jwtPayload = await this.jwtWrapperService.decode(refreshToken);

    if (!(jwtPayload.jti && jwtPayload.sub)) {
      throw new AuthException(
        'This refresh token is malformed',
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    const token = await this.appTokenRepository.findOneBy({
      id: jwtPayload.jti,
    });

    if (!token) {
      throw new AuthException(
        "This refresh token doesn't exist",
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    const user = await this.userRepository.findOne({
      where: { id: jwtPayload.sub },
      relations: ['appTokens'],
    });

    if (!user) {
      throw new AuthException(
        'User not found',
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    // Check if revokedAt is less than coolDown
    if (
      token.revokedAt &&
      token.revokedAt.getTime() <= Date.now() - ms(coolDown)
    ) {
      // Revoke all user refresh tokens
      await Promise.all(
        user.appTokens.map(async ({ id, type }) => {
          if (type === AppTokenType.RefreshToken) {
            await this.appTokenRepository.update(
              { id },
              {
                revokedAt: new Date(),
              },
            );
          }
        }),
      );

      throw new AuthException(
        'Suspicious activity detected, this refresh token has been revoked. All tokens have been revoked.',
        AuthExceptionCode.FORBIDDEN_EXCEPTION,
      );
    }

    // TODO: Delete this useless condition and error after March 31st 2025
    if (!token.workspaceId) {
      throw new AuthException(
        'This refresh token is malformed',
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    return { user, token };
  }

  async generateRefreshToken(
    userId: string,
    workspaceId: string,
  ): Promise<AuthToken> {
    const secret = this.jwtWrapperService.generateAppSecret(
      'REFRESH',
      workspaceId,
    );
    const expiresIn = this.environmentService.get('REFRESH_TOKEN_EXPIRES_IN');

    if (!expiresIn) {
      throw new AuthException(
        'Expiration time for access token is not set',
        AuthExceptionCode.INTERNAL_SERVER_ERROR,
      );
    }

    const expiresAt = addMilliseconds(new Date().getTime(), ms(expiresIn));

    const refreshTokenPayload = {
      userId,
      expiresAt,
      workspaceId,
      type: AppTokenType.RefreshToken,
    };
    const jwtPayload = {
      sub: userId,
      workspaceId,
    };

    const refreshToken = this.appTokenRepository.create(refreshTokenPayload);

    await this.appTokenRepository.save(refreshToken);

    return {
      token: this.jwtWrapperService.sign(jwtPayload, {
        secret,
        expiresIn,
        // Jwtid will be used to link RefreshToken entity to this token
        jwtid: refreshToken.id,
      }),
      expiresAt,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for generating and validating email verification tokens using a TypeORM repository.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import crypto from 'crypto';

import { addMilliseconds } from 'date-fns';
import ms from 'ms';
import { Repository } from 'typeorm';

import {
  AppToken,
  AppTokenType,
} from 'src/engine/core-modules/app-token/app-token.entity';
import { AuthToken } from 'src/engine/core-modules/auth/dto/token.entity';
import {
  EmailVerificationException,
  EmailVerificationExceptionCode,
} from 'src/engine/core-modules/email-verification/email-verification.exception';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';

@Injectable()
export class EmailVerificationTokenService {
  constructor(
    @InjectRepository(AppToken, 'core')
    private readonly appTokenRepository: Repository<AppToken>,
    private readonly environmentService: EnvironmentService,
  ) {}

  async generateToken(userId: string, email: string): Promise<AuthToken> {
    const expiresIn = this.environmentService.get(
      'EMAIL_VERIFICATION_TOKEN_EXPIRES_IN',
    );
    const expiresAt = addMilliseconds(new Date().getTime(), ms(expiresIn));

    const plainToken = crypto.randomBytes(32).toString('hex');
    const hashedToken = crypto
      .createHash('sha256')
      .update(plainToken)
      .digest('hex');

    const verificationToken = this.appTokenRepository.create({
      userId,
      expiresAt,
      type: AppTokenType.EmailVerificationToken,
      value: hashedToken,
      context: { email },
    });

    await this.appTokenRepository.save(verificationToken);

    return {
      token: plainToken,
      expiresAt,
    };
  }

  async validateEmailVerificationTokenOrThrow(emailVerificationToken: string) {
    const hashedToken = crypto
      .createHash('sha256')
      .update(emailVerificationToken)
      .digest('hex');

    const appToken = await this.appTokenRepository.findOne({
      where: {
        value: hashedToken,
        type: AppTokenType.EmailVerificationToken,
      },
      relations: ['user'],
    });

    if (!appToken) {
      throw new EmailVerificationException(
        'Invalid email verification token',
        EmailVerificationExceptionCode.INVALID_TOKEN,
      );
    }

    if (appToken.type !== AppTokenType.EmailVerificationToken) {
      throw new EmailVerificationException(
        'Invalid email verification token type',
        EmailVerificationExceptionCode.INVALID_APP_TOKEN_TYPE,
      );
    }

    if (new Date() > appToken.expiresAt) {
      throw new EmailVerificationException(
        'Email verification token expired',
        EmailVerificationExceptionCode.TOKEN_EXPIRED,
      );
    }

    if (!appToken.context?.email) {
      throw new EmailVerificationException(
        'Email missing in email verification token context',
        EmailVerificationExceptionCode.EMAIL_MISSING,
      );
    }

    await this.appTokenRepository.remove(appToken);

    return appToken.user;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to renew access and refresh tokens using a provided refresh token.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { AppToken } from 'src/engine/core-modules/app-token/app-token.entity';
import {
  AuthException,
  AuthExceptionCode,
} from 'src/engine/core-modules/auth/auth.exception';
import { AuthToken } from 'src/engine/core-modules/auth/dto/token.entity';
import { AccessTokenService } from 'src/engine/core-modules/auth/token/services/access-token.service';
import { RefreshTokenService } from 'src/engine/core-modules/auth/token/services/refresh-token.service';

@Injectable()
export class RenewTokenService {
  constructor(
    @InjectRepository(AppToken, 'core')
    private readonly appTokenRepository: Repository<AppToken>,
    private readonly accessTokenService: AccessTokenService,
    private readonly refreshTokenService: RefreshTokenService,
  ) {}

  async generateTokensFromRefreshToken(token: string): Promise<{
    accessToken: AuthToken;
    refreshToken: AuthToken;
  }> {
    if (!token) {
      throw new AuthException(
        'Refresh token not found',
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    const {
      user,
      token: { id, workspaceId },
    } = await this.refreshTokenService.verifyRefreshToken(token);

    // Revoke old refresh token
    await this.appTokenRepository.update(
      {
        id,
      },
      {
        revokedAt: new Date(),
      },
    );

    const accessToken = await this.accessTokenService.generateAccessToken(
      user.id,
      workspaceId,
    );
    const refreshToken = await this.refreshTokenService.generateRefreshToken(
      user.id,
      workspaceId,
    );

    return {
      accessToken,
      refreshToken,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a Google authentication controller with endpoints to initiate and handle Google SSO redirects, including user data handling and login token generation.
Code Snippet:
import {
  Controller,
  Get,
  Req,
  Res,
  UseFilters,
  UseGuards,
} from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Response } from 'express';
import { Repository } from 'typeorm';

import { AuthOAuthExceptionFilter } from 'src/engine/core-modules/auth/filters/auth-oauth-exception.filter';
import { AuthRestApiExceptionFilter } from 'src/engine/core-modules/auth/filters/auth-rest-api-exception.filter';
import { GoogleOauthGuard } from 'src/engine/core-modules/auth/guards/google-oauth.guard';
import { GoogleProviderEnabledGuard } from 'src/engine/core-modules/auth/guards/google-provider-enabled.guard';
import { AuthService } from 'src/engine/core-modules/auth/services/auth.service';
import { GoogleRequest } from 'src/engine/core-modules/auth/strategies/google.auth.strategy';
import { LoginTokenService } from 'src/engine/core-modules/auth/token/services/login-token.service';
import { GuardRedirectService } from 'src/engine/core-modules/guard-redirect/services/guard-redirect.service';
import { User } from 'src/engine/core-modules/user/user.entity';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';

@Controller('auth/google')
@UseFilters(AuthRestApiExceptionFilter)
export class GoogleAuthController {
  constructor(
    private readonly loginTokenService: LoginTokenService,
    private readonly authService: AuthService,
    private readonly guardRedirectService: GuardRedirectService,
    private readonly domainManagerService: DomainManagerService,
    @InjectRepository(User, 'core')
    private readonly userRepository: Repository<User>,
  ) {}

  @Get()
  @UseGuards(GoogleProviderEnabledGuard, GoogleOauthGuard)
  async googleAuth() {
    // As this method is protected by Google Auth guard, it will trigger Google SSO flow
    return;
  }

  @Get('redirect')
  @UseGuards(GoogleProviderEnabledGuard, GoogleOauthGuard)
  @UseFilters(AuthOAuthExceptionFilter)
  async googleAuthRedirect(@Req() req: GoogleRequest, @Res() res: Response) {
    const {
      firstName,
      lastName,
      email,
      picture,
      workspaceInviteHash,
      workspaceId,
      billingCheckoutSessionState,
      locale,
    } = req.user;

    const currentWorkspace = await this.authService.findWorkspaceForSignInUp({
      workspaceId,
      workspaceInviteHash,
      email,
      authProvider: 'google',
    });

    try {
      const invitation =
        currentWorkspace && email
          ? await this.authService.findInvitationForSignInUp({
              currentWorkspace,
              email,
            })
          : undefined;

      const existingUser = await this.userRepository.findOne({
        where: { email },
      });

      const { userData } = this.authService.formatUserDataPayload(
        {
          firstName,
          lastName,
          email,
          picture,
          locale,
        },
        existingUser,
      );

      await this.authService.checkAccessForSignIn({
        userData,
        invitation,
        workspaceInviteHash,
        workspace: currentWorkspace,
      });

      const { user, workspace } = await this.authService.signInUp({
        invitation,
        workspace: currentWorkspace,
        userData,
        authParams: {
          provider: 'google',
        },
        billingCheckoutSessionState,
      });

      const loginToken = await this.loginTokenService.generateLoginToken(
        user.email,
        workspace.id,
      );

      return res.redirect(
        this.authService.computeRedirectURI({
          loginToken: loginToken.token,
          workspace,
          billingCheckoutSessionState,
        }),
      );
    } catch (err) {
      return res.redirect(
        this.guardRedirectService.getRedirectErrorUrlAndCaptureExceptions(
          err,
          this.domainManagerService.getSubdomainAndCustomDomainFromWorkspaceFallbackOnDefaultSubdomain(
            currentWorkspace,
          ),
        ),
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS controller for handling Microsoft OAuth authentication, including the SSO flow and user redirection after authentication.
Code Snippet:
import {
  Controller,
  Get,
  Req,
  Res,
  UseFilters,
  UseGuards,
} from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Response } from 'express';
import { Repository } from 'typeorm';

import { AuthRestApiExceptionFilter } from 'src/engine/core-modules/auth/filters/auth-rest-api-exception.filter';
import { MicrosoftOAuthGuard } from 'src/engine/core-modules/auth/guards/microsoft-oauth.guard';
import { MicrosoftProviderEnabledGuard } from 'src/engine/core-modules/auth/guards/microsoft-provider-enabled.guard';
import { AuthService } from 'src/engine/core-modules/auth/services/auth.service';
import { MicrosoftRequest } from 'src/engine/core-modules/auth/strategies/microsoft.auth.strategy';
import { LoginTokenService } from 'src/engine/core-modules/auth/token/services/login-token.service';
import { GuardRedirectService } from 'src/engine/core-modules/guard-redirect/services/guard-redirect.service';
import { User } from 'src/engine/core-modules/user/user.entity';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';

@Controller('auth/microsoft')
@UseFilters(AuthRestApiExceptionFilter)
export class MicrosoftAuthController {
  constructor(
    private readonly loginTokenService: LoginTokenService,
    private readonly authService: AuthService,
    private readonly guardRedirectService: GuardRedirectService,
    @InjectRepository(User, 'core')
    private readonly userRepository: Repository<User>,
    private readonly domainManagerService: DomainManagerService,
  ) {}

  @Get()
  @UseGuards(MicrosoftProviderEnabledGuard, MicrosoftOAuthGuard)
  async microsoftAuth() {
    // As this method is protected by Microsoft Auth guard, it will trigger Microsoft SSO flow
    return;
  }

  @Get('redirect')
  @UseGuards(MicrosoftProviderEnabledGuard, MicrosoftOAuthGuard)
  async microsoftAuthRedirect(
    @Req() req: MicrosoftRequest,
    @Res() res: Response,
  ) {
    const {
      firstName,
      lastName,
      email,
      picture,
      workspaceInviteHash,
      workspaceId,
      billingCheckoutSessionState,
      locale,
    } = req.user;

    const currentWorkspace = await this.authService.findWorkspaceForSignInUp({
      workspaceId,
      workspaceInviteHash,
      email,
      authProvider: 'microsoft',
    });

    try {
      const invitation =
        currentWorkspace && email
          ? await this.authService.findInvitationForSignInUp({
              currentWorkspace,
              email,
            })
          : undefined;

      const existingUser = await this.userRepository.findOne({
        where: { email },
      });

      const { userData } = this.authService.formatUserDataPayload(
        {
          firstName,
          lastName,
          email,
          picture,
          locale,
        },
        existingUser,
      );

      await this.authService.checkAccessForSignIn({
        userData,
        invitation,
        workspaceInviteHash,
        workspace: currentWorkspace,
      });

      const { user, workspace } = await this.authService.signInUp({
        invitation,
        workspace: currentWorkspace,
        userData,
        authParams: {
          provider: 'microsoft',
        },
        billingCheckoutSessionState,
      });

      const loginToken = await this.loginTokenService.generateLoginToken(
        user.email,
        workspace.id,
      );

      return res.redirect(
        this.authService.computeRedirectURI({
          loginToken: loginToken.token,
          workspace,
          billingCheckoutSessionState,
        }),
      );
    } catch (err) {
      return res.redirect(
        this.guardRedirectService.getRedirectErrorUrlAndCaptureExceptions(
          err,
          this.domainManagerService.getSubdomainAndCustomDomainFromWorkspaceFallbackOnDefaultSubdomain(
            currentWorkspace,
          ),
        ),
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code tests the ResetPasswordService to ensure it correctly generates, sends, validates, and invalidates password reset tokens.
Code Snippet:
import { Test, TestingModule } from '@nestjs/testing';
import { getRepositoryToken } from '@nestjs/typeorm';

import { addMilliseconds } from 'date-fns';
import { Repository } from 'typeorm';

import {
  AppToken,
  AppTokenType,
} from 'src/engine/core-modules/app-token/app-token.entity';
import { AuthException } from 'src/engine/core-modules/auth/auth.exception';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';
import { EmailService } from 'src/engine/core-modules/email/email.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { User } from 'src/engine/core-modules/user/user.entity';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';

import { ResetPasswordService } from './reset-password.service';

describe('ResetPasswordService', () => {
  let service: ResetPasswordService;
  let userRepository: Repository<User>;
  let workspaceRepository: Repository<Workspace>;
  let appTokenRepository: Repository<AppToken>;
  let emailService: EmailService;
  let environmentService: EnvironmentService;
  let domainManagerService: DomainManagerService;

  beforeEach(async () => {
    const module: TestingModule = await Test.createTestingModule({
      providers: [
        ResetPasswordService,
        {
          provide: getRepositoryToken(User, 'core'),
          useClass: Repository,
        },
        {
          provide: getRepositoryToken(Workspace, 'core'),
          useClass: Repository,
        },
        {
          provide: getRepositoryToken(AppToken, 'core'),
          useClass: Repository,
        },
        {
          provide: getRepositoryToken(Workspace, 'core'),
          useClass: Repository,
        },
        {
          provide: EmailService,
          useValue: {
            send: jest.fn().mockResolvedValue({ success: true }),
          },
        },
        {
          provide: DomainManagerService,
          useValue: {
            getBaseUrl: jest
              .fn()
              .mockResolvedValue(new URL('http://localhost:3001')),
            buildWorkspaceURL: jest.fn(),
          },
        },
        {
          provide: EnvironmentService,
          useValue: {
            get: jest.fn(),
          },
        },
      ],
    }).compile();

    service = module.get<ResetPasswordService>(ResetPasswordService);
    userRepository = module.get<Repository<User>>(
      getRepositoryToken(User, 'core'),
    );
    workspaceRepository = module.get<Repository<Workspace>>(
      getRepositoryToken(Workspace, 'core'),
    );
    appTokenRepository = module.get<Repository<AppToken>>(
      getRepositoryToken(AppToken, 'core'),
    );
    emailService = module.get<EmailService>(EmailService);
    environmentService = module.get<EnvironmentService>(EnvironmentService);
    domainManagerService =
      module.get<DomainManagerService>(DomainManagerService);
  });

  it('should be defined', () => {
    expect(service).toBeDefined();
  });

  describe('generatePasswordResetToken', () => {
    it('should generate a password reset token for a valid user', async () => {
      const mockUser = { id: '1', email: 'test@example.com' };

      jest
        .spyOn(userRepository, 'findOneBy')
        .mockResolvedValue(mockUser as User);
      jest.spyOn(appTokenRepository, 'findOne').mockResolvedValue(null);
      jest.spyOn(appTokenRepository, 'save').mockResolvedValue({} as AppToken);
      jest.spyOn(environmentService, 'get').mockReturnValue('1h');

      const result = await service.generatePasswordResetToken(
        'test@example.com',
        'workspace-id',
      );

      expect(result.passwordResetToken).toBeDefined();
      expect(result.passwordResetTokenExpiresAt).toBeDefined();
      expect(appTokenRepository.save).toHaveBeenCalledWith(
        expect.objectContaining({
          userId: '1',
          type: AppTokenType.PasswordResetToken,
        }),
      );
    });

    it('should throw an error if user is not found', async () => {
      jest.spyOn(userRepository, 'findOneBy').mockResolvedValue(null);

      await expect(
        service.generatePasswordResetToken(
          'nonexistent@example.com',
          'workspace-id',
        ),
      ).rejects.toThrow(AuthException);
    });

    it('should throw an error if a token already exists', async () => {
      const mockUser = { id: '1', email: 'test@example.com' };
      const mockExistingToken = {
        userId: '1',
        type: AppTokenType.PasswordResetToken,
        workspaceId: 'workspace-id',
        expiresAt: addMilliseconds(new Date(), 3600000),
      };

      jest
        .spyOn(userRepository, 'findOneBy')
        .mockResolvedValue(mockUser as User);
      jest
        .spyOn(appTokenRepository, 'findOne')
        .mockResolvedValue(mockExistingToken as AppToken);

      await expect(
        service.generatePasswordResetToken('test@example.com', 'workspace-id'),
      ).rejects.toThrow(AuthException);
    });
  });

  describe('sendEmailPasswordResetLink', () => {
    it('should send a password reset email', async () => {
      const mockUser = { id: '1', email: 'test@example.com' };
      const mockToken = {
        workspaceId: 'workspace-id',
        passwordResetToken: 'token123',
        passwordResetTokenExpiresAt: new Date(),
      };

      jest
        .spyOn(userRepository, 'findOneBy')
        .mockResolvedValue(mockUser as User);
      jest
        .spyOn(workspaceRepository, 'findOneBy')
        .mockResolvedValue({ id: 'workspace-id' } as Workspace);
      jest
        .spyOn(environmentService, 'get')
        .mockReturnValue('http://localhost:3000');
      jest
        .spyOn(domainManagerService, 'buildWorkspaceURL')
        .mockReturnValue(
          new URL(
            'https://subdomain.localhost.com:3000/reset-password/passwordResetToken',
          ),
        );

      const result = await service.sendEmailPasswordResetLink(
        mockToken,
        'test@example.com',
        'en',
      );

      expect(result.success).toBe(true);
      expect(emailService.send).toHaveBeenCalled();
    });

    it('should throw an error if user is not found', async () => {
      jest.spyOn(userRepository, 'findOneBy').mockResolvedValue(null);

      await expect(
        service.sendEmailPasswordResetLink(
          {} as any,
          'nonexistent@example.com',
          'en',
        ),
      ).rejects.toThrow(AuthException);
    });
  });

  describe('validatePasswordResetToken', () => {
    it('should validate a correct password reset token', async () => {
      const mockToken = {
        userId: '1',
        type: AppTokenType.PasswordResetToken,
        expiresAt: addMilliseconds(new Date(), 3600000),
      };
      const mockUser = { id: '1', email: 'test@example.com' };

      jest
        .spyOn(appTokenRepository, 'findOne')
        .mockResolvedValue(mockToken as AppToken);
      jest
        .spyOn(userRepository, 'findOneBy')
        .mockResolvedValue(mockUser as User);

      const result = await service.validatePasswordResetToken('validToken');

      expect(result).toEqual({ id: '1', email: 'test@example.com' });
    });

    it('should throw an error for an invalid token', async () => {
      jest.spyOn(appTokenRepository, 'findOne').mockResolvedValue(null);

      await expect(
        service.validatePasswordResetToken('invalidToken'),
      ).rejects.toThrow(AuthException);
    });
  });

  describe('invalidatePasswordResetToken', () => {
    it('should invalidate an existing password reset token', async () => {
      const mockUser = { id: '1', email: 'test@example.com' };

      jest
        .spyOn(userRepository, 'findOneBy')
        .mockResolvedValue(mockUser as User);
      jest.spyOn(appTokenRepository, 'update').mockResolvedValue({} as any);

      const result = await service.invalidatePasswordResetToken('1');

      expect(result.success).toBe(true);
      expect(appTokenRepository.update).toHaveBeenCalledWith(
        { userId: '1', type: AppTokenType.PasswordResetToken },
        { revokedAt: expect.any(Date) },
      );
    });

    it('should throw an error if user is not found', async () => {
      jest.spyOn(userRepository, 'findOneBy').mockResolvedValue(null);

      await expect(
        service.invalidatePasswordResetToken('nonexistent'),
      ).rejects.toThrow(AuthException);
    });
  });
});

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines an OAuthService class that verifies an authorization code and generates access, refresh, and login tokens for a user.
Code Snippet:
// import { Injectable } from '@nestjs/common';
// import { InjectRepository } from '@nestjs/typeorm';
//
// import crypto from 'crypto';
//
// import { Repository } from 'typeorm';
//
// import { AppToken } from 'src/engine/core-modules/app-token/app-token.entity';
// import {
//   AuthException,
//   AuthExceptionCode,
// } from 'src/engine/core-modules/auth/auth.exception';
// import { ExchangeAuthCode } from 'src/engine/core-modules/auth/dto/exchange-auth-code.entity';
// import { ExchangeAuthCodeInput } from 'src/engine/core-modules/auth/dto/exchange-auth-code.input';
// import { AccessTokenService } from 'src/engine/core-modules/auth/token/services/access-token.service';
// import { LoginTokenService } from 'src/engine/core-modules/auth/token/services/login-token.service';
// import { RefreshTokenService } from 'src/engine/core-modules/auth/token/services/refresh-token.service';
// import { User } from 'src/engine/core-modules/user/user.entity';
// import { userValidator } from 'src/engine/core-modules/user/user.validate';
//
// @Injectable()
// export class OAuthService {
//   constructor(
//     @InjectRepository(User, 'core')
//     private readonly userRepository: Repository<User>,
//     @InjectRepository(AppToken, 'core')
//     private readonly appTokenRepository: Repository<AppToken>,
//     private readonly accessTokenService: AccessTokenService,
//     private readonly refreshTokenService: RefreshTokenService,
//     private readonly loginTokenService: LoginTokenService,
//   ) {}
//
//   async verifyAuthorizationCode(
//     exchangeAuthCodeInput: ExchangeAuthCodeInput,
//   ): Promise<ExchangeAuthCode> {
//     const { authorizationCode, codeVerifier } = exchangeAuthCodeInput;
//
//     if (!authorizationCode) {
//       throw new AuthException(
//         'Authorization code not found',
//         AuthExceptionCode.INVALID_INPUT,
//       );
//     }
//
//     let userId = '';
//
//     if (codeVerifier) {
//       const authorizationCodeAppToken = await this.appTokenRepository.findOne({
//         where: {
//           value: authorizationCode,
//         },
//       });
//
//       if (!authorizationCodeAppToken) {
//         throw new AuthException(
//           'Authorization code does not exist',
//           AuthExceptionCode.INVALID_INPUT,
//         );
//       }
//
//       if (!(authorizationCodeAppToken.expiresAt.getTime() >= Date.now())) {
//         throw new AuthException(
//           'Authorization code expired.',
//           AuthExceptionCode.FORBIDDEN_EXCEPTION,
//         );
//       }
//
//       const codeChallenge = crypto
//         .createHash('sha256')
//         .update(codeVerifier)
//         .digest()
//         .toString('base64')
//         .replace(/\+/g, '-')
//         .replace(/\//g, '_')
//         .replace(/=/g, '');
//
//       const codeChallengeAppToken = await this.appTokenRepository.findOne({
//         where: {
//           value: codeChallenge,
//         },
//       });
//
//       if (!codeChallengeAppToken || !codeChallengeAppToken.userId) {
//         throw new AuthException(
//           'code verifier doesnt match the challenge',
//           AuthExceptionCode.FORBIDDEN_EXCEPTION,
//         );
//       }
//
//       if (!(codeChallengeAppToken.expiresAt.getTime() >= Date.now())) {
//         throw new AuthException(
//           'code challenge expired.',
//           AuthExceptionCode.FORBIDDEN_EXCEPTION,
//         );
//       }
//
//       if (codeChallengeAppToken.userId !== authorizationCodeAppToken.userId) {
//         throw new AuthException(
//           'authorization code / code verifier was not created by same client',
//           AuthExceptionCode.FORBIDDEN_EXCEPTION,
//         );
//       }
//
//       if (codeChallengeAppToken.revokedAt) {
//         throw new AuthException(
//           'Token has been revoked.',
//           AuthExceptionCode.FORBIDDEN_EXCEPTION,
//         );
//       }
//
//       await this.appTokenRepository.save({
//         id: codeChallengeAppToken.id,
//         revokedAt: new Date(),
//       });
//
//       userId = codeChallengeAppToken.userId;
//     }
//
//     const user = await this.userRepository.findOne({
//       where: { id: userId },
//       relations: ['defaultWorkspace'],
//     });
//
//     userValidator.assertIsDefinedOrThrow(
//       user,
//       new AuthException(
//         'User who generated the token does not exist',
//         AuthExceptionCode.INVALID_INPUT,
//       ),
//     );
//
//     if (!user.defaultWorkspace) {
//       throw new AuthException(
//         'User does not have a default workspace',
//         AuthExceptionCode.INVALID_DATA,
//       );
//     }
//
//     const accessToken = await this.accessTokenService.generateAccessToken(
//       user.id,
//       user.defaultWorkspaceId,
//     );
//     const refreshToken = await this.refreshTokenService.generateRefreshToken(
//       user.id,
//       user.defaultWorkspaceId,
//     );
//     const loginToken = await this.loginTokenService.generateLoginToken(
//       user.email,
//     );
//
//     return {
//       accessToken,
//       refreshToken,
//       loginToken,
//     };
//   }
// }

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code implements a service for generating, sending, validating, and invalidating password reset tokens for users in a NestJS application.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import crypto from 'crypto';

import { i18n } from '@lingui/core';
import { t } from '@lingui/core/macro';
import { render } from '@react-email/render';
import { addMilliseconds, differenceInMilliseconds } from 'date-fns';
import ms from 'ms';
import { PasswordResetLinkEmail } from 'twenty-emails';
import { APP_LOCALES } from 'twenty-shared';
import { IsNull, MoreThan, Repository } from 'typeorm';

import {
  AppToken,
  AppTokenType,
} from 'src/engine/core-modules/app-token/app-token.entity';
import {
  AuthException,
  AuthExceptionCode,
} from 'src/engine/core-modules/auth/auth.exception';
import { EmailPasswordResetLink } from 'src/engine/core-modules/auth/dto/email-password-reset-link.entity';
import { InvalidatePassword } from 'src/engine/core-modules/auth/dto/invalidate-password.entity';
import { PasswordResetToken } from 'src/engine/core-modules/auth/dto/token.entity';
import { ValidatePasswordResetToken } from 'src/engine/core-modules/auth/dto/validate-password-reset-token.entity';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';
import { EmailService } from 'src/engine/core-modules/email/email.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { User } from 'src/engine/core-modules/user/user.entity';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { workspaceValidator } from 'src/engine/core-modules/workspace/workspace.validate';

@Injectable()
export class ResetPasswordService {
  constructor(
    private readonly environmentService: EnvironmentService,
    private readonly domainManagerService: DomainManagerService,
    @InjectRepository(User, 'core')
    private readonly userRepository: Repository<User>,
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    @InjectRepository(AppToken, 'core')
    private readonly appTokenRepository: Repository<AppToken>,
    private readonly emailService: EmailService,
  ) {}

  async generatePasswordResetToken(
    email: string,
    workspaceId: string,
  ): Promise<PasswordResetToken> {
    const user = await this.userRepository.findOneBy({
      email,
    });

    if (!user) {
      throw new AuthException(
        'User not found',
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    const expiresIn = this.environmentService.get(
      'PASSWORD_RESET_TOKEN_EXPIRES_IN',
    );

    if (!expiresIn) {
      throw new AuthException(
        'PASSWORD_RESET_TOKEN_EXPIRES_IN constant value not found',
        AuthExceptionCode.INTERNAL_SERVER_ERROR,
      );
    }

    const existingToken = await this.appTokenRepository.findOne({
      where: {
        userId: user.id,
        type: AppTokenType.PasswordResetToken,
        expiresAt: MoreThan(new Date()),
        revokedAt: IsNull(),
      },
    });

    if (existingToken) {
      const timeToWait = ms(
        differenceInMilliseconds(existingToken.expiresAt, new Date()),
        { long: true },
      );

      throw new AuthException(
        `Token has already been generated. Please wait for ${timeToWait} to generate again.`,
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    const plainResetToken = crypto.randomBytes(32).toString('hex');
    const hashedResetToken = crypto
      .createHash('sha256')
      .update(plainResetToken)
      .digest('hex');

    const expiresAt = addMilliseconds(new Date().getTime(), ms(expiresIn));

    await this.appTokenRepository.save({
      userId: user.id,
      workspaceId: workspaceId,
      value: hashedResetToken,
      expiresAt,
      type: AppTokenType.PasswordResetToken,
    });

    return {
      workspaceId,
      passwordResetToken: plainResetToken,
      passwordResetTokenExpiresAt: expiresAt,
    };
  }

  async sendEmailPasswordResetLink(
    resetToken: PasswordResetToken,
    email: string,
    locale: keyof typeof APP_LOCALES,
  ): Promise<EmailPasswordResetLink> {
    const user = await this.userRepository.findOneBy({
      email,
    });

    if (!user) {
      throw new AuthException(
        'User not found',
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    const workspace = await this.workspaceRepository.findOneBy({
      id: resetToken.workspaceId,
    });

    workspaceValidator.assertIsDefinedOrThrow(workspace);

    const link = this.domainManagerService.buildWorkspaceURL({
      workspace,
      pathname: `/reset-password/${resetToken.passwordResetToken}`,
    });

    const emailData = {
      link: link.toString(),
      duration: ms(
        differenceInMilliseconds(
          resetToken.passwordResetTokenExpiresAt,
          new Date(),
        ),
        {
          long: true,
        },
      ),
      locale,
    };

    const emailTemplate = PasswordResetLinkEmail(emailData);

    const html = render(emailTemplate, { pretty: true });
    const text = render(emailTemplate, { plainText: true });

    i18n.activate(locale);

    this.emailService.send({
      from: `${this.environmentService.get(
        'EMAIL_FROM_NAME',
      )} <${this.environmentService.get('EMAIL_FROM_ADDRESS')}>`,
      to: email,
      subject: t`Action Needed to Reset Password`,
      text,
      html,
    });

    return { success: true };
  }

  async validatePasswordResetToken(
    resetToken: string,
  ): Promise<ValidatePasswordResetToken> {
    const hashedResetToken = crypto
      .createHash('sha256')
      .update(resetToken)
      .digest('hex');

    const token = await this.appTokenRepository.findOne({
      where: {
        value: hashedResetToken,
        type: AppTokenType.PasswordResetToken,
        expiresAt: MoreThan(new Date()),
        revokedAt: IsNull(),
      },
    });

    if (!token || !token.userId) {
      throw new AuthException(
        'Token is invalid',
        AuthExceptionCode.FORBIDDEN_EXCEPTION,
      );
    }

    const user = await this.userRepository.findOneBy({
      id: token.userId,
    });

    if (!user) {
      throw new AuthException(
        'User not found',
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    return {
      id: user.id,
      email: user.email,
    };
  }

  async invalidatePasswordResetToken(
    userId: string,
  ): Promise<InvalidatePassword> {
    const user = await this.userRepository.findOneBy({
      id: userId,
    });

    if (!user) {
      throw new AuthException(
        'User not found',
        AuthExceptionCode.INVALID_INPUT,
      );
    }

    await this.appTokenRepository.update(
      {
        userId,
        type: AppTokenType.PasswordResetToken,
      },
      {
        revokedAt: new Date(),
      },
    );

    return { success: true };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines an OIDC authentication guard for a NestJS application, handling authentication using OpenID Connect and redirecting on errors.
Code Snippet:
/* @license Enterprise */

import { ExecutionContext, Injectable } from '@nestjs/common';
import { AuthGuard } from '@nestjs/passport';

import { Issuer } from 'openid-client';

import {
  AuthException,
  AuthExceptionCode,
} from 'src/engine/core-modules/auth/auth.exception';
import { OIDCAuthStrategy } from 'src/engine/core-modules/auth/strategies/oidc.auth.strategy';
import { SSOService } from 'src/engine/core-modules/sso/services/sso.service';
import { GuardRedirectService } from 'src/engine/core-modules/guard-redirect/services/guard-redirect.service';
import { SSOConfiguration } from 'src/engine/core-modules/sso/types/SSOConfigurations.type';
import { WorkspaceSSOIdentityProvider } from 'src/engine/core-modules/sso/workspace-sso-identity-provider.entity';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';

@Injectable()
export class OIDCAuthGuard extends AuthGuard('openidconnect') {
  constructor(
    private readonly sSOService: SSOService,
    private readonly guardRedirectService: GuardRedirectService,
    private readonly domainManagerService: DomainManagerService,
  ) {
    super();
  }

  private getStateByRequest(request: any): {
    identityProviderId: string;
  } {
    if (request.params.identityProviderId) {
      return {
        identityProviderId: request.params.identityProviderId,
      };
    }

    if (
      request.query.state &&
      typeof request.query.state === 'string' &&
      request.query.state.startsWith('{') &&
      request.query.state.endsWith('}')
    ) {
      const state = JSON.parse(request.query.state);

      return {
        identityProviderId: state.identityProviderId,
      };
    }

    throw new Error('Invalid OIDC identity provider params');
  }

  async canActivate(context: ExecutionContext): Promise<boolean> {
    const request = context.switchToHttp().getRequest<Request>();

    let identityProvider:
      | (SSOConfiguration & WorkspaceSSOIdentityProvider)
      | null = null;

    try {
      const state = this.getStateByRequest(request);

      if (!state.identityProviderId) {
        throw new AuthException(
          'identityProviderId missing',
          AuthExceptionCode.INVALID_DATA,
        );
      }

      identityProvider = await this.sSOService.findSSOIdentityProviderById(
        state.identityProviderId,
      );

      if (!identityProvider) {
        throw new AuthException(
          'Identity provider not found',
          AuthExceptionCode.INVALID_DATA,
        );
      }
      const issuer = await Issuer.discover(identityProvider.issuer);

      new OIDCAuthStrategy(
        this.sSOService.getOIDCClient(identityProvider, issuer),
        identityProvider.id,
      );

      return (await super.canActivate(context)) as boolean;
    } catch (err) {
      this.guardRedirectService.dispatchErrorFromGuard(
        context,
        err,
        this.domainManagerService.getSubdomainAndCustomDomainFromWorkspaceFallbackOnDefaultSubdomain(
          identityProvider?.workspace,
        ),
      );

      return false;
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS guard that checks if an enterprise key is present in the environment variables and throws an exception if it is missing.
Code Snippet:
/* @license Enterprise */

import { CanActivate, ExecutionContext, Injectable } from '@nestjs/common';

import {
  AuthException,
  AuthExceptionCode,
} from 'src/engine/core-modules/auth/auth.exception';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { GuardRedirectService } from 'src/engine/core-modules/guard-redirect/services/guard-redirect.service';

@Injectable()
export class EnterpriseFeaturesEnabledGuard implements CanActivate {
  constructor(
    private readonly guardRedirectService: GuardRedirectService,
    private readonly environmentService: EnvironmentService,
  ) {}

  canActivate(context: ExecutionContext): boolean {
    try {
      if (!this.environmentService.get('ENTERPRISE_KEY')) {
        throw new AuthException(
          'Enterprise key missing',
          AuthExceptionCode.MISSING_ENVIRONMENT_VARIABLE,
        );
      }

      return true;
    } catch (err) {
      this.guardRedirectService.dispatchErrorFromGuard(
        context,
        err,
        this.guardRedirectService.getSubdomainAndCustomDomainFromContext(
          context,
        ),
      );

      return false;
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for updating public feature flags in a lab, interacting with repositories for FeatureFlag and Workspace entities.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import {
  AuthException,
  AuthExceptionCode,
} from 'src/engine/core-modules/auth/auth.exception';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { FeatureFlag } from 'src/engine/core-modules/feature-flag/feature-flag.entity';
import {
  FeatureFlagException,
  FeatureFlagExceptionCode,
} from 'src/engine/core-modules/feature-flag/feature-flag.exception';
import { featureFlagValidator } from 'src/engine/core-modules/feature-flag/validates/feature-flag.validate';
import { publicFeatureFlagValidator } from 'src/engine/core-modules/feature-flag/validates/is-public-feature-flag.validate';
import { UpdateLabPublicFeatureFlagInput } from 'src/engine/core-modules/lab/dtos/update-lab-public-feature-flag.input';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { workspaceValidator } from 'src/engine/core-modules/workspace/workspace.validate';

@Injectable()
export class LabService {
  constructor(
    @InjectRepository(FeatureFlag, 'core')
    private readonly featureFlagRepository: Repository<FeatureFlag>,
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
  ) {}

  async updateLabPublicFeatureFlag(
    workspaceId: string,
    payload: UpdateLabPublicFeatureFlagInput,
  ): Promise<FeatureFlag> {
    featureFlagValidator.assertIsFeatureFlagKey(
      payload.publicFeatureFlag,
      new FeatureFlagException(
        'Invalid feature flag key',
        FeatureFlagExceptionCode.INVALID_FEATURE_FLAG_KEY,
      ),
    );

    publicFeatureFlagValidator.assertIsPublicFeatureFlag(
      FeatureFlagKey[payload.publicFeatureFlag],
      new FeatureFlagException(
        'Feature flag is not public',
        FeatureFlagExceptionCode.FEATURE_FLAG_IS_NOT_PUBLIC,
      ),
    );

    const workspace = await this.workspaceRepository.findOne({
      where: { id: workspaceId },
    });

    workspaceValidator.assertIsDefinedOrThrow(
      workspace,
      new AuthException('Workspace not found', AuthExceptionCode.INVALID_INPUT),
    );

    const existingFlag = await this.featureFlagRepository.findOne({
      where: {
        workspaceId,
        key: FeatureFlagKey[payload.publicFeatureFlag],
      },
    });

    if (existingFlag) {
      await this.featureFlagRepository.update(existingFlag.id, {
        value: payload.value,
      });

      return { ...existingFlag, value: payload.value };
    }

    return this.featureFlagRepository.save({
      key: FeatureFlagKey[payload.publicFeatureFlag],
      value: payload.value,
      workspaceId,
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing PostgreSQL credentials, including enabling, disabling, and retrieving credentials for a workspace.
Code Snippet:
import { BadRequestException } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { randomBytes } from 'crypto';

import { Repository } from 'typeorm';

import {
  decryptText,
  encryptText,
} from 'src/engine/core-modules/auth/auth.util';
import { NotFoundError } from 'src/engine/core-modules/graphql/utils/graphql-errors.util';
import { JwtWrapperService } from 'src/engine/core-modules/jwt/services/jwt-wrapper.service';
import { PostgresCredentialsDTO } from 'src/engine/core-modules/postgres-credentials/dtos/postgres-credentials.dto';
import { PostgresCredentials } from 'src/engine/core-modules/postgres-credentials/postgres-credentials.entity';

export class PostgresCredentialsService {
  constructor(
    @InjectRepository(PostgresCredentials, 'core')
    private readonly postgresCredentialsRepository: Repository<PostgresCredentials>,
    private readonly jwtWrapperService: JwtWrapperService,
  ) {}

  async enablePostgresProxy(
    workspaceId: string,
  ): Promise<PostgresCredentialsDTO> {
    const user = `user_${randomBytes(4).toString('hex')}`;
    const password = randomBytes(16).toString('hex');

    const key = this.jwtWrapperService.generateAppSecret(
      'POSTGRES_PROXY',
      workspaceId,
    );
    const passwordHash = encryptText(password, key);

    const existingCredentials =
      await this.postgresCredentialsRepository.findOne({
        where: {
          workspaceId,
        },
      });

    if (existingCredentials) {
      throw new BadRequestException(
        'Postgres credentials already exist for this workspace',
      );
    }

    const postgresCredentials = await this.postgresCredentialsRepository.create(
      {
        user,
        passwordHash,
        workspaceId,
      },
    );

    await this.postgresCredentialsRepository.save(postgresCredentials);

    return {
      id: postgresCredentials.id,
      user,
      password,
      workspaceId,
    };
  }

  async disablePostgresProxy(
    workspaceId: string,
  ): Promise<PostgresCredentialsDTO> {
    const postgresCredentials =
      await this.postgresCredentialsRepository.findOne({
        where: {
          workspaceId,
        },
      });

    if (!postgresCredentials?.id) {
      throw new NotFoundError(
        'No valid Postgres credentials not found for this workspace',
      );
    }

    await this.postgresCredentialsRepository.delete({
      id: postgresCredentials.id,
    });

    const key = this.jwtWrapperService.generateAppSecret(
      'POSTGRES_PROXY',
      workspaceId,
    );

    return {
      id: postgresCredentials.id,
      user: postgresCredentials.user,
      password: decryptText(postgresCredentials.passwordHash, key),
      workspaceId: postgresCredentials.workspaceId,
    };
  }

  async getPostgresCredentials(
    workspaceId: string,
  ): Promise<PostgresCredentialsDTO | null> {
    const postgresCredentials =
      await this.postgresCredentialsRepository.findOne({
        where: {
          workspaceId,
        },
      });

    if (!postgresCredentials) {
      return null;
    }

    const key = this.jwtWrapperService.generateAppSecret(
      'POSTGRES_PROXY',
      workspaceId,
    );

    return {
      id: postgresCredentials.id,
      user: postgresCredentials.user,
      password: decryptText(postgresCredentials.passwordHash, key),
      workspaceId: postgresCredentials.workspaceId,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS guard for validating captcha tokens and updating a cache if the captcha is invalid.
Code Snippet:
import {
  BadRequestException,
  CanActivate,
  ExecutionContext,
  Injectable,
} from '@nestjs/common';
import { GqlExecutionContext } from '@nestjs/graphql';

import { CaptchaService } from 'src/engine/core-modules/captcha/captcha.service';
import { HealthCacheService } from 'src/engine/core-modules/health/health-cache.service';

@Injectable()
export class CaptchaGuard implements CanActivate {
  constructor(
    private captchaService: CaptchaService,
    private healthCacheService: HealthCacheService,
  ) {}

  async canActivate(context: ExecutionContext): Promise<boolean> {
    const ctx = GqlExecutionContext.create(context);

    const { captchaToken: token } = ctx.getArgs();

    const result = await this.captchaService.validate(token || '');

    if (result.success) {
      return true;
    } else {
      await this.healthCacheService.updateInvalidCaptchaCache(token);

      throw new BadRequestException(
        'Invalid Captcha, please try another device',
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a service for managing workspace invitations, including creating, validating, and sending invitations via email.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import crypto from 'crypto';

import { i18n } from '@lingui/core';
import { t } from '@lingui/core/macro';
import { render } from '@react-email/render';
import { addMilliseconds } from 'date-fns';
import ms from 'ms';
import { SendInviteLinkEmail } from 'twenty-emails';
import { APP_LOCALES } from 'twenty-shared';
import { IsNull, Repository } from 'typeorm';

import {
  AppToken,
  AppTokenType,
} from 'src/engine/core-modules/app-token/app-token.entity';
import {
  AuthException,
  AuthExceptionCode,
} from 'src/engine/core-modules/auth/auth.exception';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';
import { EmailService } from 'src/engine/core-modules/email/email.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { OnboardingService } from 'src/engine/core-modules/onboarding/onboarding.service';
import { UserWorkspace } from 'src/engine/core-modules/user-workspace/user-workspace.entity';
import { User } from 'src/engine/core-modules/user/user.entity';
import { SendInvitationsOutput } from 'src/engine/core-modules/workspace-invitation/dtos/send-invitations.output';
import { castAppTokenToWorkspaceInvitationUtil } from 'src/engine/core-modules/workspace-invitation/utils/cast-app-token-to-workspace-invitation.util';
import {
  WorkspaceInvitationException,
  WorkspaceInvitationExceptionCode,
} from 'src/engine/core-modules/workspace-invitation/workspace-invitation.exception';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';

@Injectable()
// eslint-disable-next-line @nx/workspace-inject-workspace-repository
export class WorkspaceInvitationService {
  constructor(
    @InjectRepository(AppToken, 'core')
    private readonly appTokenRepository: Repository<AppToken>,
    @InjectRepository(UserWorkspace, 'core')
    private readonly userWorkspaceRepository: Repository<UserWorkspace>,
    private readonly environmentService: EnvironmentService,
    private readonly emailService: EmailService,
    private readonly onboardingService: OnboardingService,
    private readonly domainManagerService: DomainManagerService,
  ) {}

  async validatePersonalInvitation({
    workspacePersonalInviteToken,
    email,
  }: {
    workspacePersonalInviteToken?: string;
    email: string;
  }) {
    try {
      const appToken = await this.appTokenRepository.findOne({
        where: {
          value: workspacePersonalInviteToken,
          type: AppTokenType.InvitationToken,
        },
        relations: ['workspace'],
      });

      if (!appToken) {
        throw new Error('Invalid invitation token');
      }

      if (!appToken.context?.email || appToken.context?.email !== email) {
        throw new Error('Email does not match the invitation');
      }

      if (new Date(appToken.expiresAt) < new Date()) {
        throw new Error('Invitation expired');
      }

      return { isValid: true, workspace: appToken.workspace };
    } catch (err) {
      throw new AuthException(
        err.message,
        AuthExceptionCode.FORBIDDEN_EXCEPTION,
      );
    }
  }

  async findInvitationByWorkspaceSubdomainAndUserEmail({
    subdomain,
    email,
  }: {
    subdomain: string;
    email: string;
  }) {
    const workspace =
      await this.domainManagerService.getWorkspaceBySubdomainOrDefaultWorkspace(
        subdomain,
      );

    if (!workspace) return;

    return await this.getOneWorkspaceInvitation(workspace.id, email);
  }

  async getOneWorkspaceInvitation(workspaceId: string, email: string) {
    return await this.appTokenRepository
      .createQueryBuilder('appToken')
      .where('"appToken"."workspaceId" = :workspaceId', {
        workspaceId,
      })
      .andWhere('"appToken".type = :type', {
        type: AppTokenType.InvitationToken,
      })
      .andWhere('"appToken".context->>\'email\' = :email', { email })
      .getOne();
  }

  async getAppTokenByInvitationToken(invitationToken: string) {
    const appToken = await this.appTokenRepository.findOne({
      where: {
        value: invitationToken,
        type: AppTokenType.InvitationToken,
      },
      relations: ['workspace'],
    });

    if (!appToken) {
      throw new WorkspaceInvitationException(
        'Invalid invitation token',
        WorkspaceInvitationExceptionCode.INVALID_INVITATION,
      );
    }

    return appToken;
  }

  async loadWorkspaceInvitations(workspace: Workspace) {
    const appTokens = await this.appTokenRepository.find({
      where: {
        workspaceId: workspace.id,
        type: AppTokenType.InvitationToken,
        deletedAt: IsNull(),
      },
      select: {
        value: false,
      },
    });

    return appTokens.map(castAppTokenToWorkspaceInvitationUtil);
  }

  async createWorkspaceInvitation(email: string, workspace: Workspace) {
    const maybeWorkspaceInvitation = await this.getOneWorkspaceInvitation(
      workspace.id,
      email.toLowerCase(),
    );

    if (maybeWorkspaceInvitation) {
      throw new WorkspaceInvitationException(
        `${email} already invited`,
        WorkspaceInvitationExceptionCode.INVITATION_ALREADY_EXIST,
      );
    }

    const isUserAlreadyInWorkspace = await this.userWorkspaceRepository.exists({
      where: {
        workspaceId: workspace.id,
        user: {
          email,
        },
      },
      relations: {
        user: true,
      },
    });

    if (isUserAlreadyInWorkspace) {
      throw new WorkspaceInvitationException(
        `${email} is already in the workspace`,
        WorkspaceInvitationExceptionCode.USER_ALREADY_EXIST,
      );
    }

    return this.generateInvitationToken(workspace.id, email);
  }

  async deleteWorkspaceInvitation(appTokenId: string, workspaceId: string) {
    const appToken = await this.appTokenRepository.findOne({
      where: {
        id: appTokenId,
        workspaceId,
        type: AppTokenType.InvitationToken,
      },
    });

    if (!appToken) {
      return 'error';
    }

    await this.appTokenRepository.delete(appToken.id);

    return 'success';
  }

  async invalidateWorkspaceInvitation(workspaceId: string, email: string) {
    const appToken = await this.getOneWorkspaceInvitation(workspaceId, email);

    if (appToken) {
      await this.appTokenRepository.delete(appToken.id);
    }
  }

  async resendWorkspaceInvitation(
    appTokenId: string,
    workspace: Workspace,
    sender: User,
  ) {
    const appToken = await this.appTokenRepository.findOne({
      where: {
        id: appTokenId,
        workspaceId: workspace.id,
        type: AppTokenType.InvitationToken,
      },
    });

    if (!appToken || !appToken.context?.email) {
      throw new WorkspaceInvitationException(
        'Invalid appToken',
        WorkspaceInvitationExceptionCode.INVALID_INVITATION,
      );
    }

    await this.appTokenRepository.delete(appToken.id);

    return this.sendInvitations([appToken.context.email], workspace, sender);
  }

  async sendInvitations(
    emails: string[],
    workspace: Workspace,
    sender: User,
    usePersonalInvitation = true,
  ): Promise<SendInvitationsOutput> {
    if (!workspace?.inviteHash) {
      return {
        success: false,
        errors: ['Workspace invite hash not found'],
        result: [],
      };
    }

    const invitationsPr = await Promise.allSettled(
      emails.map(async (email) => {
        if (usePersonalInvitation) {
          const appToken = await this.createWorkspaceInvitation(
            email,
            workspace,
          );

          if (!appToken.context?.email) {
            throw new WorkspaceInvitationException(
              'Invalid email',
              WorkspaceInvitationExceptionCode.EMAIL_MISSING,
            );
          }

          return {
            isPersonalInvitation: true as const,
            appToken,
            email: appToken.context.email,
          };
        }

        return {
          isPersonalInvitation: false as const,
          email,
        };
      }),
    );

    for (const invitation of invitationsPr) {
      if (invitation.status === 'fulfilled') {
        const link = this.domainManagerService.buildWorkspaceURL({
          workspace,
          pathname: `invite/${workspace?.inviteHash}`,
          searchParams: invitation.value.isPersonalInvitation
            ? {
                inviteToken: invitation.value.appToken.value,
                email: invitation.value.email,
              }
            : {},
        });

        // Todo: sender name and locale should come from workspace member not user!
        const emailData = {
          link: link.toString(),
          workspace: { name: workspace.displayName, logo: workspace.logo },
          sender: {
            email: sender.email,
            firstName: sender.firstName,
            lastName: sender.lastName,
          },
          serverUrl: this.environmentService.get('SERVER_URL'),
          locale: sender.locale as keyof typeof APP_LOCALES,
        };

        const emailTemplate = SendInviteLinkEmail(emailData);
        const html = render(emailTemplate);
        const text = render(emailTemplate, {
          plainText: true,
        });

        i18n.activate(sender.locale);

        await this.emailService.send({
          from: `${sender.firstName} ${sender.lastName} (via Twenty) <${this.environmentService.get('EMAIL_FROM_ADDRESS')}>`,
          to: invitation.value.email,
          subject: t`Join your team on Twenty`,
          text,
          html,
        });
      }
    }

    await this.onboardingService.setOnboardingInviteTeamPending({
      workspaceId: workspace.id,
      value: false,
    });

    const result = invitationsPr.reduce<{
      errors: string[];
      result: ReturnType<
        typeof this.workspaceInvitationService.createWorkspaceInvitation
      >['status'] extends 'rejected'
        ? never
        : ReturnType<
            typeof this.workspaceInvitationService.appTokenToWorkspaceInvitation
          >;
    }>(
      (acc, invitation) => {
        if (invitation.status === 'rejected') {
          acc.errors.push(invitation.reason?.message ?? 'Unknown error');
        } else {
          acc.result.push(
            invitation.value.isPersonalInvitation
              ? castAppTokenToWorkspaceInvitationUtil(invitation.value.appToken)
              : { email: invitation.value.email },
          );
        }

        return acc;
      },
      { errors: [], result: [] },
    );

    return {
      success: result.errors.length === 0,
      ...result,
    };
  }

  async generateInvitationToken(workspaceId: string, email: string) {
    const expiresIn = this.environmentService.get(
      'INVITATION_TOKEN_EXPIRES_IN',
    );

    if (!expiresIn) {
      throw new AuthException(
        'Expiration time for invitation token is not set',
        AuthExceptionCode.INTERNAL_SERVER_ERROR,
      );
    }

    const expiresAt = addMilliseconds(new Date().getTime(), ms(expiresIn));

    const invitationToken = this.appTokenRepository.create({
      workspaceId,
      expiresAt,
      type: AppTokenType.InvitationToken,
      value: crypto.randomBytes(32).toString('hex'),
      context: {
        email,
      },
    });

    return this.appTokenRepository.save(invitationToken);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS controller for handling Cloudflare custom hostname webhooks, updating workspace custom domain details based on webhook data.
Code Snippet:
/* @license Enterprise */

import {
  Controller,
  Post,
  Req,
  Res,
  UseFilters,
  UseGuards,
} from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Response, Request } from 'express';
import { Repository } from 'typeorm';

import { AuthRestApiExceptionFilter } from 'src/engine/core-modules/auth/filters/auth-rest-api-exception.filter';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import {
  DomainManagerException,
  DomainManagerExceptionCode,
} from 'src/engine/core-modules/domain-manager/domain-manager.exception';
import { handleException } from 'src/engine/core-modules/exception-handler/http-exception-handler.service';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { CloudflareSecretMatchGuard } from 'src/engine/core-modules/domain-manager/guards/cloudflare-secret.guard';
import { CustomDomainService } from 'src/engine/core-modules/domain-manager/services/custom-domain.service';

@Controller('cloudflare')
@UseFilters(AuthRestApiExceptionFilter)
export class CloudflareController {
  constructor(
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    private readonly domainManagerService: DomainManagerService,
    private readonly customDomainService: CustomDomainService,
    private readonly exceptionHandlerService: ExceptionHandlerService,
  ) {}

  @Post('custom-hostname-webhooks')
  @UseGuards(CloudflareSecretMatchGuard)
  async customHostnameWebhooks(@Req() req: Request, @Res() res: Response) {
    if (!req.body?.data?.data?.hostname) {
      handleException(
        new DomainManagerException(
          'Hostname missing',
          DomainManagerExceptionCode.INVALID_INPUT_DATA,
        ),
        this.exceptionHandlerService,
      );

      return res.status(200).send();
    }

    const workspace = await this.workspaceRepository.findOneBy({
      customDomain: req.body.data.data.hostname,
    });

    if (!workspace) return;

    const customDomainDetails =
      await this.customDomainService.getCustomDomainDetails(
        req.body.data.data.hostname,
      );

    const workspaceUpdated: Partial<Workspace> = {
      customDomain: workspace.customDomain,
    };

    if (!customDomainDetails && workspace) {
      workspaceUpdated.customDomain = null;
    }

    workspaceUpdated.isCustomDomainEnabled = customDomainDetails
      ? this.domainManagerService.isCustomDomainWorking(customDomainDetails)
      : false;

    if (
      workspaceUpdated.isCustomDomainEnabled !==
        workspace.isCustomDomainEnabled ||
      workspaceUpdated.customDomain !== workspace.customDomain
    ) {
      await this.workspaceRepository.save({
        ...workspace,
        ...workspaceUpdated,
      });
    }

    return res.status(200).send();
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code tests the customHostnameWebhooks method in the CloudflareController to handle webhooks from Cloudflare, updating the workspace entity based on the custom domain details.
Code Snippet:
import { Test, TestingModule } from '@nestjs/testing';
import { getRepositoryToken } from '@nestjs/typeorm';

import { Repository } from 'typeorm';
import { Request, Response } from 'express';

import { CloudflareController } from 'src/engine/core-modules/domain-manager/controllers/cloudflare.controller';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { HttpExceptionHandlerService } from 'src/engine/core-modules/exception-handler/http-exception-handler.service';
import { CustomDomainValidRecords } from 'src/engine/core-modules/domain-manager/dtos/custom-domain-valid-records';
import { CustomDomainService } from 'src/engine/core-modules/domain-manager/services/custom-domain.service';

describe('CloudflareController - customHostnameWebhooks', () => {
  let controller: CloudflareController;
  let WorkspaceRepository: Repository<Workspace>;
  let environmentService: EnvironmentService;
  let domainManagerService: DomainManagerService;
  let customDomainService: CustomDomainService;

  beforeEach(async () => {
    const module: TestingModule = await Test.createTestingModule({
      controllers: [CloudflareController],
      providers: [
        {
          provide: getRepositoryToken(Workspace, 'core'),
          useValue: {
            findOneBy: jest.fn(),
            save: jest.fn(),
          },
        },
        {
          provide: DomainManagerService,
          useValue: {
            isCustomDomainWorking: jest.fn(),
          },
        },
        {
          provide: CustomDomainService,
          useValue: {
            getCustomDomainDetails: jest.fn(),
          },
        },
        {
          provide: HttpExceptionHandlerService,
          useValue: {
            handleError: jest.fn(),
          },
        },
        {
          provide: ExceptionHandlerService,
          useValue: {
            captureExceptions: jest.fn(),
          },
        },
        {
          provide: EnvironmentService,
          useValue: {
            get: jest.fn(),
          },
        },
      ],
    }).compile();

    controller = module.get<CloudflareController>(CloudflareController);
    WorkspaceRepository = module.get(getRepositoryToken(Workspace, 'core'));
    environmentService = module.get<EnvironmentService>(EnvironmentService);
    domainManagerService =
      module.get<DomainManagerService>(DomainManagerService);
    customDomainService = module.get<CustomDomainService>(CustomDomainService);
  });

  it('should handle exception and return status 200 if hostname is missing', async () => {
    const req = {
      headers: { 'cf-webhook-auth': 'correct-secret' },
      body: { data: { data: {} } },
    } as unknown as Request;
    const sendMock = jest.fn();
    const res = {
      status: jest.fn().mockReturnThis(),
      send: sendMock,
    } as unknown as Response;

    jest.spyOn(environmentService, 'get').mockReturnValue('correct-secret');

    await controller.customHostnameWebhooks(req, res);

    expect(res.status).toHaveBeenCalledWith(200);
    expect(sendMock).toHaveBeenCalled();
  });

  it('should update workspace for a valid hostname and save changes', async () => {
    const req = {
      headers: { 'cf-webhook-auth': 'correct-secret' },
      body: { data: { data: { hostname: 'example.com' } } },
    } as unknown as Request;
    const sendMock = jest.fn();
    const res = {
      status: jest.fn().mockReturnThis(),
      send: sendMock,
    } as unknown as Response;

    jest.spyOn(environmentService, 'get').mockReturnValue('correct-secret');
    jest
      .spyOn(customDomainService, 'getCustomDomainDetails')
      .mockResolvedValue({
        records: [
          {
            success: true,
          },
        ],
      } as unknown as CustomDomainValidRecords);
    jest
      .spyOn(domainManagerService, 'isCustomDomainWorking')
      .mockReturnValue(true);
    jest.spyOn(WorkspaceRepository, 'findOneBy').mockResolvedValue({
      customDomain: 'example.com',
      isCustomDomainEnabled: false,
    } as Workspace);

    await controller.customHostnameWebhooks(req, res);

    expect(WorkspaceRepository.findOneBy).toHaveBeenCalledWith({
      customDomain: 'example.com',
    });
    expect(customDomainService.getCustomDomainDetails).toHaveBeenCalledWith(
      'example.com',
    );
    expect(WorkspaceRepository.save).toHaveBeenCalledWith({
      customDomain: 'example.com',
      isCustomDomainEnabled: true,
    });
    expect(res.status).toHaveBeenCalledWith(200);
    expect(sendMock).toHaveBeenCalled();
  });

  it('should remove customDomain if no hostname found', async () => {
    const req = {
      headers: { 'cf-webhook-auth': 'correct-secret' },
      body: { data: { data: { hostname: 'notfound.com' } } },
    } as unknown as Request;
    const sendMock = jest.fn();
    const res = {
      status: jest.fn().mockReturnThis(),
      send: sendMock,
    } as unknown as Response;

    jest.spyOn(environmentService, 'get').mockReturnValue('correct-secret');
    jest.spyOn(WorkspaceRepository, 'findOneBy').mockResolvedValue({
      customDomain: 'notfound.com',
      isCustomDomainEnabled: true,
    } as Workspace);

    jest
      .spyOn(customDomainService, 'getCustomDomainDetails')
      .mockResolvedValue(undefined);

    await controller.customHostnameWebhooks(req, res);

    expect(WorkspaceRepository.findOneBy).toHaveBeenCalledWith({
      customDomain: 'notfound.com',
    });
    expect(WorkspaceRepository.save).toHaveBeenCalledWith({
      customDomain: null,
      isCustomDomainEnabled: false,
    });
    expect(res.status).toHaveBeenCalledWith(200);
    expect(sendMock).toHaveBeenCalled();
  });
  it('should do nothing if nothing changes', async () => {
    const req = {
      headers: { 'cf-webhook-auth': 'correct-secret' },
      body: { data: { data: { hostname: 'nothing-change.com' } } },
    } as unknown as Request;
    const sendMock = jest.fn();
    const res = {
      status: jest.fn().mockReturnThis(),
      send: sendMock,
    } as unknown as Response;

    jest.spyOn(environmentService, 'get').mockReturnValue('correct-secret');
    jest.spyOn(WorkspaceRepository, 'findOneBy').mockResolvedValue({
      customDomain: 'nothing-change.com',
      isCustomDomainEnabled: true,
    } as Workspace);
    jest
      .spyOn(customDomainService, 'getCustomDomainDetails')
      .mockResolvedValue({
        records: [
          {
            success: true,
          },
        ],
      } as unknown as CustomDomainValidRecords);
    jest
      .spyOn(domainManagerService, 'isCustomDomainWorking')
      .mockReturnValue(true);

    await controller.customHostnameWebhooks(req, res);

    expect(WorkspaceRepository.findOneBy).toHaveBeenCalledWith({
      customDomain: 'nothing-change.com',
    });
    expect(WorkspaceRepository.save).not.toHaveBeenCalled();
    expect(res.status).toHaveBeenCalledWith(200);
    expect(sendMock).toHaveBeenCalled();
  });
});

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing custom domains using Cloudflare's API, including registering, retrieving, updating, and deleting custom domains.
Code Snippet:
/* @license Enterprise */
import { Injectable } from '@nestjs/common';

import Cloudflare from 'cloudflare';
import { isDefined } from 'twenty-shared';

import {
  DomainManagerException,
  DomainManagerExceptionCode,
} from 'src/engine/core-modules/domain-manager/domain-manager.exception';
import { CustomDomainValidRecords } from 'src/engine/core-modules/domain-manager/dtos/custom-domain-valid-records';
import { domainManagerValidator } from 'src/engine/core-modules/domain-manager/validator/cloudflare.validate';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';

@Injectable()
export class CustomDomainService {
  cloudflareClient?: Cloudflare;

  constructor(
    private readonly environmentService: EnvironmentService,
    private readonly domainManagerService: DomainManagerService,
  ) {
    if (this.environmentService.get('CLOUDFLARE_API_KEY')) {
      this.cloudflareClient = new Cloudflare({
        apiToken: this.environmentService.get('CLOUDFLARE_API_KEY'),
      });
    }
  }

  async registerCustomDomain(customDomain: string) {
    domainManagerValidator.isCloudflareInstanceDefined(this.cloudflareClient);

    if (isDefined(await this.getCustomDomainDetails(customDomain))) {
      throw new DomainManagerException(
        'Hostname already registered',
        DomainManagerExceptionCode.HOSTNAME_ALREADY_REGISTERED,
      );
    }

    return await this.cloudflareClient.customHostnames.create({
      zone_id: this.environmentService.get('CLOUDFLARE_ZONE_ID'),
      hostname: customDomain,
      ssl: {
        method: 'txt',
        type: 'dv',
        settings: {
          http2: 'on',
          min_tls_version: '1.2',
          tls_1_3: 'on',
          ciphers: ['ECDHE-RSA-AES128-GCM-SHA256', 'AES128-SHA'],
          early_hints: 'on',
        },
        bundle_method: 'ubiquitous',
        wildcard: false,
      },
    });
  }

  async getCustomDomainDetails(
    customDomain: string,
  ): Promise<CustomDomainValidRecords | undefined> {
    domainManagerValidator.isCloudflareInstanceDefined(this.cloudflareClient);

    const response = await this.cloudflareClient.customHostnames.list({
      zone_id: this.environmentService.get('CLOUDFLARE_ZONE_ID'),
      hostname: customDomain,
    });

    if (response.result.length === 0) {
      return undefined;
    }

    if (response.result.length === 1) {
      return {
        id: response.result[0].id,
        customDomain: response.result[0].hostname,
        records: [
          response.result[0].ownership_verification,
          ...(response.result[0].ssl?.validation_records ?? []),
        ]
          .map<CustomDomainValidRecords['records'][0] | undefined>((record) => {
            if (!record) return;

            if (
              'txt_name' in record &&
              'txt_value' in record &&
              record.txt_name &&
              record.txt_value
            ) {
              return {
                validationType: 'ssl' as const,
                type: 'txt' as const,
                status:
                  !response.result[0].ssl.status ||
                  response.result[0].ssl.status.startsWith('pending')
                    ? 'pending'
                    : response.result[0].ssl.status,
                key: record.txt_name,
                value: record.txt_value,
              };
            }

            if (
              'type' in record &&
              record.type === 'txt' &&
              record.value &&
              record.name
            ) {
              return {
                validationType: 'ownership' as const,
                type: 'txt' as const,
                status: response.result[0].status ?? 'pending',
                key: record.name,
                value: record.value,
              };
            }
          })
          .filter(isDefined)
          .concat([
            {
              validationType: 'redirection' as const,
              type: 'cname' as const,
              status:
                // wait 10s before starting the real check
                response.result[0].created_at &&
                new Date().getTime() -
                  new Date(response.result[0].created_at).getTime() <
                  1000 * 10
                  ? 'pending'
                  : response.result[0].verification_errors?.[0] ===
                      'custom hostname does not CNAME to this zone.'
                    ? 'error'
                    : 'success',
              key: response.result[0].hostname,
              value: this.domainManagerService.getFrontUrl().hostname,
            },
          ]),
      };
    }

    // should never append. error 5xx
    throw new Error('More than one custom hostname found in cloudflare');
  }

  async updateCustomDomain(fromHostname: string, toHostname: string) {
    domainManagerValidator.isCloudflareInstanceDefined(this.cloudflareClient);

    const fromCustomHostname = await this.getCustomDomainDetails(fromHostname);

    if (fromCustomHostname) {
      await this.deleteCustomHostname(fromCustomHostname.id);
    }

    return this.registerCustomDomain(toHostname);
  }

  async deleteCustomHostnameByHostnameSilently(customDomain: string) {
    domainManagerValidator.isCloudflareInstanceDefined(this.cloudflareClient);

    try {
      const customHostname = await this.getCustomDomainDetails(customDomain);

      if (customHostname) {
        await this.cloudflareClient.customHostnames.delete(customHostname.id, {
          zone_id: this.environmentService.get('CLOUDFLARE_ZONE_ID'),
        });
      }
    } catch (err) {
      return;
    }
  }

  async deleteCustomHostname(customHostnameId: string) {
    domainManagerValidator.isCloudflareInstanceDefined(this.cloudflareClient);

    await this.cloudflareClient.customHostnames.delete(customHostnameId, {
      zone_id: this.environmentService.get('CLOUDFLARE_ZONE_ID'),
    });
  }

  isCustomDomainWorking(customDomainDetails: CustomDomainValidRecords) {
    return customDomainDetails.records.every(
      ({ status }) => status === 'success',
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS controller with two endpoints to generate OpenAPI schemas for core and metadata.
Code Snippet:
import { Controller, Get, Req, Res } from '@nestjs/common';

import { Request, Response } from 'express';

import { OpenApiService } from 'src/engine/core-modules/open-api/open-api.service';

@Controller('open-api')
export class OpenApiController {
  constructor(private readonly openApiService: OpenApiService) {}

  @Get('core')
  async generateOpenApiSchemaCore(
    @Req() request: Request,
    @Res() res: Response,
  ) {
    const data = await this.openApiService.generateCoreSchema(request);

    res.send(data);
  }

  @Get('metadata')
  async generateOpenApiSchemaMetaData(
    @Req() request: Request,
    @Res() res: Response,
  ) {
    const data = await this.openApiService.generateMetaDataSchema(request);

    res.send(data);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to clean up suspended workspaces by warning members and then soft-deleting or deleting them based on inactivity.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { i18n } from '@lingui/core';
import { t } from '@lingui/core/macro';
import { render } from '@react-email/render';
import { differenceInDays } from 'date-fns';
import {
  CleanSuspendedWorkspaceEmail,
  WarnSuspendedWorkspaceEmail,
} from 'twenty-emails';
import { isDefined, WorkspaceActivationStatus } from 'twenty-shared';
import { In, Repository } from 'typeorm';

import { BillingSubscription } from 'src/engine/core-modules/billing/entities/billing-subscription.entity';
import { EmailService } from 'src/engine/core-modules/email/email.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { UserService } from 'src/engine/core-modules/user/services/user.service';
import { UserVarsService } from 'src/engine/core-modules/user/user-vars/services/user-vars.service';
import { WorkspaceService } from 'src/engine/core-modules/workspace/services/workspace.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { USER_WORKSPACE_DELETION_WARNING_SENT_KEY } from 'src/engine/workspace-manager/workspace-cleaner/constants/user-workspace-deletion-warning-sent-key.constant';
import {
  WorkspaceCleanerException,
  WorkspaceCleanerExceptionCode,
} from 'src/engine/workspace-manager/workspace-cleaner/exceptions/workspace-cleaner.exception';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';

@Injectable()
export class CleanerWorkspaceService {
  private readonly logger = new Logger(CleanerWorkspaceService.name);
  private readonly inactiveDaysBeforeSoftDelete: number;
  private readonly inactiveDaysBeforeDelete: number;
  private readonly inactiveDaysBeforeWarn: number;
  private readonly maxNumberOfWorkspacesDeletedPerExecution: number;

  constructor(
    private readonly workspaceService: WorkspaceService,
    private readonly environmentService: EnvironmentService,
    private readonly userVarsService: UserVarsService,
    private readonly userService: UserService,
    private readonly emailService: EmailService,
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    @InjectRepository(BillingSubscription, 'core')
    private readonly billingSubscriptionRepository: Repository<BillingSubscription>,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {
    this.inactiveDaysBeforeSoftDelete = this.environmentService.get(
      'WORKSPACE_INACTIVE_DAYS_BEFORE_SOFT_DELETION',
    );
    this.inactiveDaysBeforeDelete = this.environmentService.get(
      'WORKSPACE_INACTIVE_DAYS_BEFORE_DELETION',
    );
    this.inactiveDaysBeforeWarn = this.environmentService.get(
      'WORKSPACE_INACTIVE_DAYS_BEFORE_NOTIFICATION',
    );
    this.maxNumberOfWorkspacesDeletedPerExecution = this.environmentService.get(
      'MAX_NUMBER_OF_WORKSPACES_DELETED_PER_EXECUTION',
    );
  }

  async computeWorkspaceBillingInactivity(
    workspace: Workspace,
  ): Promise<number> {
    try {
      const lastSubscription =
        await this.billingSubscriptionRepository.findOneOrFail({
          where: { workspaceId: workspace.id },
          order: { updatedAt: 'DESC' },
        });

      const daysSinceBillingInactivity = differenceInDays(
        new Date(),
        lastSubscription.updatedAt,
      );

      return daysSinceBillingInactivity;
    } catch {
      throw new WorkspaceCleanerException(
        `No billing subscription found for workspace ${workspace.id} ${workspace.displayName}`,
        WorkspaceCleanerExceptionCode.BILLING_SUBSCRIPTION_NOT_FOUND,
      );
    }
  }

  async checkIfAtLeastOneWorkspaceMemberWarned(
    workspaceMembers: WorkspaceMemberWorkspaceEntity[],
    workspaceId: string,
  ) {
    for (const workspaceMember of workspaceMembers) {
      const workspaceMemberWarned = await this.userVarsService.get({
        userId: workspaceMember.userId,
        workspaceId: workspaceId,
        key: USER_WORKSPACE_DELETION_WARNING_SENT_KEY,
      });

      if (workspaceMemberWarned) {
        return true;
      }
    }

    return false;
  }

  async sendWarningEmail(
    workspaceMember: WorkspaceMemberWorkspaceEntity,
    workspaceDisplayName: string | undefined,
    daysSinceInactive: number,
  ) {
    const emailData = {
      daysSinceInactive,
      inactiveDaysBeforeDelete: this.inactiveDaysBeforeSoftDelete,
      userName: `${workspaceMember.name.firstName} ${workspaceMember.name.lastName}`,
      workspaceDisplayName: `${workspaceDisplayName}`,
      locale: workspaceMember.locale,
    };
    const emailTemplate = WarnSuspendedWorkspaceEmail(emailData);
    const html = render(emailTemplate, { pretty: true });
    const text = render(emailTemplate, { plainText: true });

    i18n.activate(workspaceMember.locale);

    this.emailService.send({
      to: workspaceMember.userEmail,
      bcc: this.environmentService.get('EMAIL_SYSTEM_ADDRESS'),
      from: `${this.environmentService.get(
        'EMAIL_FROM_NAME',
      )} <${this.environmentService.get('EMAIL_FROM_ADDRESS')}>`,
      subject: t`Action needed to prevent workspace deletion`,
      html,
      text,
    });
  }

  async warnWorkspaceMembers(
    workspace: Workspace,
    daysSinceInactive: number,
    dryRun: boolean,
  ) {
    const workspaceMembers =
      await this.userService.loadWorkspaceMembers(workspace);

    const workspaceMembersWarned =
      await this.checkIfAtLeastOneWorkspaceMemberWarned(
        workspaceMembers,
        workspace.id,
      );

    if (workspaceMembersWarned) {
      this.logger.log(
        `${dryRun ? 'DRY RUN - ' : ''}Workspace ${workspace.id} ${workspace.displayName} already warned`,
      );

      return;
    }

    this.logger.log(
      `${dryRun ? 'DRY RUN - ' : ''}Sending ${workspace.id} ${
        workspace.displayName
      } suspended since ${daysSinceInactive} days emails to users ['${workspaceMembers
        .map((workspaceUser) => workspaceUser.userId)
        .join(', ')}']`,
    );

    if (!dryRun) {
      for (const workspaceMember of workspaceMembers) {
        await this.userVarsService.set({
          userId: workspaceMember.userId,
          workspaceId: workspace.id,
          key: USER_WORKSPACE_DELETION_WARNING_SENT_KEY,
          value: true,
        });

        await this.sendWarningEmail(
          workspaceMember,
          workspace.displayName,
          daysSinceInactive,
        );
      }
    }
  }

  async sendCleaningEmail(
    workspaceMember: WorkspaceMemberWorkspaceEntity,
    workspaceDisplayName: string,
    daysSinceInactive: number,
  ) {
    const emailData = {
      daysSinceInactive: daysSinceInactive,
      userName: `${workspaceMember.name.firstName} ${workspaceMember.name.lastName}`,
      workspaceDisplayName,
      locale: workspaceMember.locale,
    };
    const emailTemplate = CleanSuspendedWorkspaceEmail(emailData);
    const html = render(emailTemplate, { pretty: true });
    const text = render(emailTemplate, { plainText: true });

    this.emailService.send({
      to: workspaceMember.userEmail,
      bcc: this.environmentService.get('EMAIL_SYSTEM_ADDRESS'),
      from: `${this.environmentService.get(
        'EMAIL_FROM_NAME',
      )} <${this.environmentService.get('EMAIL_FROM_ADDRESS')}>`,
      subject: 'Your workspace has been deleted',
      html,
      text,
    });
  }

  async informWorkspaceMembersAndSoftDeleteWorkspace(
    workspace: Workspace,
    daysSinceInactive: number,
    dryRun: boolean,
  ) {
    if (isDefined(workspace.deletedAt)) {
      this.logger.log(
        `${dryRun ? 'DRY RUN - ' : ''}Workspace ${workspace.id} ${
          workspace.displayName
        } already soft deleted`,
      );

      return;
    }

    const workspaceMembers =
      await this.userService.loadWorkspaceMembers(workspace);

    this.logger.log(
      `${dryRun ? 'DRY RUN - ' : ''}Sending workspace ${workspace.id} ${
        workspace.displayName
      } deletion emails to users ['${workspaceMembers
        .map((workspaceUser) => workspaceUser.userId)
        .join(', ')}']`,
    );

    if (!dryRun) {
      for (const workspaceMember of workspaceMembers) {
        await this.userVarsService.delete({
          userId: workspaceMember.userId,
          workspaceId: workspace.id,
          key: USER_WORKSPACE_DELETION_WARNING_SENT_KEY,
        });

        await this.sendCleaningEmail(
          workspaceMember,
          workspace.displayName || '',
          daysSinceInactive,
        );
      }

      await this.workspaceService.deleteWorkspace(workspace.id, true);
    }
    this.logger.log(
      `${dryRun ? 'DRY RUN - ' : ''}Soft deleting Workspace ${workspace.id} ${workspace.displayName}`,
    );
  }

  async batchWarnOrCleanSuspendedWorkspaces(
    workspaceIds: string[],
    dryRun = false,
  ): Promise<void> {
    this.logger.log(
      `${dryRun ? 'DRY RUN - ' : ''}batchWarnOrCleanSuspendedWorkspaces running...`,
    );

    const workspaces = await this.workspaceRepository.find({
      where: {
        id: In(workspaceIds),
        activationStatus: WorkspaceActivationStatus.SUSPENDED,
      },
      withDeleted: true,
    });

    let deletedWorkspacesCount = 0;

    for (const workspace of workspaces) {
      try {
        const workspaceInactivity =
          await this.computeWorkspaceBillingInactivity(workspace);

        const daysSinceSoftDeleted = workspace.deletedAt
          ? differenceInDays(new Date(), workspace.deletedAt)
          : 0;

        if (
          daysSinceSoftDeleted >
            this.inactiveDaysBeforeDelete - this.inactiveDaysBeforeSoftDelete &&
          deletedWorkspacesCount < this.maxNumberOfWorkspacesDeletedPerExecution
        ) {
          this.logger.log(
            `${dryRun ? 'DRY RUN - ' : ''}Destroying workspace ${workspace.id} ${workspace.displayName}`,
          );
          if (!dryRun) {
            await this.workspaceService.deleteWorkspace(workspace.id);
          }
          deletedWorkspacesCount++;

          continue;
        }
        if (
          workspaceInactivity > this.inactiveDaysBeforeSoftDelete &&
          !isDefined(workspace.deletedAt)
        ) {
          await this.informWorkspaceMembersAndSoftDeleteWorkspace(
            workspace,
            workspaceInactivity,
            dryRun,
          );

          continue;
        }
        if (
          workspaceInactivity > this.inactiveDaysBeforeWarn &&
          workspaceInactivity <= this.inactiveDaysBeforeSoftDelete
        ) {
          await this.warnWorkspaceMembers(
            workspace,
            workspaceInactivity,
            dryRun,
          );
        }
      } catch (error) {
        this.logger.error(
          `Error while processing workspace ${workspace.id} ${workspace.displayName}: ${error}`,
        );
      }

      await this.twentyORMGlobalManager.destroyDataSourceForWorkspace(
        workspace.id,
      );
    }
    this.logger.log(
      `${dryRun ? 'DRY RUN - ' : ''}batchWarnOrCleanSuspendedWorkspaces done!`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a JWT authentication guard in a NestJS application that validates access tokens and enriches the request object with user and workspace information.
Code Snippet:
import { CanActivate, ExecutionContext, Injectable } from '@nestjs/common';

import { AccessTokenService } from 'src/engine/core-modules/auth/token/services/access-token.service';
import { WorkspaceCacheStorageService } from 'src/engine/workspace-cache-storage/workspace-cache-storage.service';

@Injectable()
export class JwtAuthGuard implements CanActivate {
  constructor(
    private readonly accessTokenService: AccessTokenService,
    private readonly workspaceStorageCacheService: WorkspaceCacheStorageService,
  ) {}

  async canActivate(context: ExecutionContext): Promise<boolean> {
    const request = context.switchToHttp().getRequest();

    try {
      const data =
        await this.accessTokenService.validateTokenByRequest(request);
      const metadataVersion =
        await this.workspaceStorageCacheService.getMetadataVersion(
          data.workspace.id,
        );

      request.user = data.user;
      request.apiKey = data.apiKey;
      request.workspace = data.workspace;
      request.workspaceId = data.workspace.id;
      request.workspaceMetadataVersion = metadataVersion;
      request.workspaceMemberId = data.workspaceMemberId;
      request.userWorkspaceId = data.userWorkspaceId;

      return true;
    } catch (error) {
      return false;
    }
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_3>



=== New Entry ===

<CLUSTER_4>
Number of Code Snippets part of this cluster: 16
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code defines a cron job that processes active workspaces, identifies calendar channels needing event import, and queues jobs for fetching calendar events.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { WorkspaceActivationStatus } from 'twenty-shared';
import { Equal, Repository } from 'typeorm';

import { SentryCronMonitor } from 'src/engine/core-modules/cron/sentry-cron-monitor.decorator';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { CalendarEventListFetchJobData } from 'src/modules/calendar/calendar-event-import-manager/jobs/calendar-event-list-fetch.job';
import { CalendarEventsImportJob } from 'src/modules/calendar/calendar-event-import-manager/jobs/calendar-events-import.job';
import { CalendarChannelSyncStage } from 'src/modules/calendar/common/standard-objects/calendar-channel.workspace-entity';
export const CALENDAR_EVENTS_IMPORT_CRON_PATTERN = '*/1 * * * *';

@Processor({
  queueName: MessageQueue.cronQueue,
})
export class CalendarEventsImportCronJob {
  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    @InjectMessageQueue(MessageQueue.calendarQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    private readonly exceptionHandlerService: ExceptionHandlerService,
  ) {}

  @Process(CalendarEventsImportCronJob.name)
  @SentryCronMonitor(
    CalendarEventsImportCronJob.name,
    CALENDAR_EVENTS_IMPORT_CRON_PATTERN,
  )
  async handle(): Promise<void> {
    const activeWorkspaces = await this.workspaceRepository.find({
      where: {
        activationStatus: WorkspaceActivationStatus.ACTIVE,
      },
    });

    for (const activeWorkspace of activeWorkspaces) {
      try {
        const calendarChannelRepository =
          await this.twentyORMGlobalManager.getRepositoryForWorkspace(
            activeWorkspace.id,
            'calendarChannel',
          );

        const calendarChannels = await calendarChannelRepository.find({
          where: {
            isSyncEnabled: true,
            syncStage: Equal(
              CalendarChannelSyncStage.CALENDAR_EVENTS_IMPORT_PENDING,
            ),
          },
        });

        for (const calendarChannel of calendarChannels) {
          await this.messageQueueService.add<CalendarEventListFetchJobData>(
            CalendarEventsImportJob.name,
            {
              calendarChannelId: calendarChannel.id,
              workspaceId: activeWorkspace.id,
            },
          );
        }
      } catch (error) {
        this.exceptionHandlerService.captureExceptions([error], {
          workspace: {
            id: activeWorkspace.id,
          },
        });
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a cron job that fetches calendar events for active workspaces with pending syncs and adds jobs to a message queue for processing.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { WorkspaceActivationStatus } from 'twenty-shared';
import { Any, Repository } from 'typeorm';

import { SentryCronMonitor } from 'src/engine/core-modules/cron/sentry-cron-monitor.decorator';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import {
  CalendarEventListFetchJob,
  CalendarEventListFetchJobData,
} from 'src/modules/calendar/calendar-event-import-manager/jobs/calendar-event-list-fetch.job';
import { CalendarChannelSyncStage } from 'src/modules/calendar/common/standard-objects/calendar-channel.workspace-entity';

export const CALENDAR_EVENT_LIST_FETCH_CRON_PATTERN = '*/5 * * * *';

@Processor({
  queueName: MessageQueue.cronQueue,
})
export class CalendarEventListFetchCronJob {
  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    @InjectMessageQueue(MessageQueue.calendarQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    private readonly exceptionHandlerService: ExceptionHandlerService,
  ) {}

  @Process(CalendarEventListFetchCronJob.name)
  @SentryCronMonitor(
    CalendarEventListFetchCronJob.name,
    CALENDAR_EVENT_LIST_FETCH_CRON_PATTERN,
  )
  async handle(): Promise<void> {
    const activeWorkspaces = await this.workspaceRepository.find({
      where: {
        activationStatus: WorkspaceActivationStatus.ACTIVE,
      },
    });

    for (const activeWorkspace of activeWorkspaces) {
      try {
        const calendarChannelRepository =
          await this.twentyORMGlobalManager.getRepositoryForWorkspace(
            activeWorkspace.id,
            'calendarChannel',
          );

        const calendarChannels = await calendarChannelRepository.find({
          where: {
            isSyncEnabled: true,
            syncStage: Any([
              CalendarChannelSyncStage.FULL_CALENDAR_EVENT_LIST_FETCH_PENDING,
              CalendarChannelSyncStage.PARTIAL_CALENDAR_EVENT_LIST_FETCH_PENDING,
            ]),
          },
        });

        for (const calendarChannel of calendarChannels) {
          await this.messageQueueService.add<CalendarEventListFetchJobData>(
            CalendarEventListFetchJob.name,
            {
              calendarChannelId: calendarChannel.id,
              workspaceId: activeWorkspace.id,
            },
          );
        }
      } catch (error) {
        this.exceptionHandlerService.captureExceptions([error], {
          workspace: {
            id: activeWorkspace.id,
          },
        });
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a cron job that identifies active workspaces and enqueues a job to process stale calendar events for each active workspace.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { WorkspaceActivationStatus } from 'twenty-shared';
import { Repository } from 'typeorm';

import { SentryCronMonitor } from 'src/engine/core-modules/cron/sentry-cron-monitor.decorator';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import {
  CalendarOngoingStaleJob,
  CalendarOngoingStaleJobData,
} from 'src/modules/calendar/calendar-event-import-manager/jobs/calendar-ongoing-stale.job';
export const CALENDAR_ONGOING_STALE_CRON_PATTERN = '0 * * * *';

@Processor(MessageQueue.cronQueue)
export class CalendarOngoingStaleCronJob {
  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    @InjectMessageQueue(MessageQueue.calendarQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly exceptionHandlerService: ExceptionHandlerService,
  ) {}

  @Process(CalendarOngoingStaleCronJob.name)
  @SentryCronMonitor(
    CalendarOngoingStaleCronJob.name,
    CALENDAR_ONGOING_STALE_CRON_PATTERN,
  )
  async handle(): Promise<void> {
    const activeWorkspaces = await this.workspaceRepository.find({
      where: {
        activationStatus: WorkspaceActivationStatus.ACTIVE,
      },
    });

    for (const activeWorkspace of activeWorkspaces) {
      try {
        await this.messageQueueService.add<CalendarOngoingStaleJobData>(
          CalendarOngoingStaleJob.name,
          {
            workspaceId: activeWorkspace.id,
          },
        );
      } catch (error) {
        this.exceptionHandlerService.captureExceptions([error], {
          workspace: {
            id: activeWorkspace.id,
          },
        });
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to start a cron job that fetches messages from connected accounts and stores them in cache.
Code Snippet:
import { Command, CommandRunner } from 'nest-commander';

import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import {
  MESSAGING_MESSAGE_LIST_FETCH_CRON_PATTERN,
  MessagingMessageListFetchCronJob,
} from 'src/modules/messaging/message-import-manager/crons/jobs/messaging-message-list-fetch.cron.job';

@Command({
  name: 'cron:messaging:message-list-fetch',
  description:
    'Starts a cron job to sync existing connected account messages and store them in the cache',
})
export class MessagingMessageListFetchCronCommand extends CommandRunner {
  constructor(
    @InjectMessageQueue(MessageQueue.cronQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {
    super();
  }

  async run(): Promise<void> {
    await this.messageQueueService.addCron<undefined>({
      jobName: MessagingMessageListFetchCronJob.name,
      data: undefined,
      options: {
        repeat: { pattern: MESSAGING_MESSAGE_LIST_FETCH_CRON_PATTERN },
      },
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a cron job that periodically checks for active workspaces and message channels with pending message imports, then enqueues a job to import messages for each such channel.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { WorkspaceActivationStatus } from 'twenty-shared';
import { Repository } from 'typeorm';

import { SentryCronMonitor } from 'src/engine/core-modules/cron/sentry-cron-monitor.decorator';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import {
  MessageChannelSyncStage,
  MessageChannelWorkspaceEntity,
} from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import {
  MessagingMessagesImportJob,
  MessagingMessagesImportJobData,
} from 'src/modules/messaging/message-import-manager/jobs/messaging-messages-import.job';

export const MESSAGING_MESSAGES_IMPORT_CRON_PATTERN = '*/1 * * * *';

@Processor(MessageQueue.cronQueue)
export class MessagingMessagesImportCronJob {
  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    @InjectMessageQueue(MessageQueue.messagingQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    private readonly exceptionHandlerService: ExceptionHandlerService,
  ) {}

  @Process(MessagingMessagesImportCronJob.name)
  @SentryCronMonitor(
    MessagingMessagesImportCronJob.name,
    MESSAGING_MESSAGES_IMPORT_CRON_PATTERN,
  )
  async handle(): Promise<void> {
    const activeWorkspaces = await this.workspaceRepository.find({
      where: {
        activationStatus: WorkspaceActivationStatus.ACTIVE,
      },
    });

    for (const activeWorkspace of activeWorkspaces) {
      try {
        const messageChannelRepository =
          await this.twentyORMGlobalManager.getRepositoryForWorkspace<MessageChannelWorkspaceEntity>(
            activeWorkspace.id,
            'messageChannel',
          );

        const messageChannels = await messageChannelRepository.find({
          where: {
            isSyncEnabled: true,
            syncStage: MessageChannelSyncStage.MESSAGES_IMPORT_PENDING,
          },
        });

        for (const messageChannel of messageChannels) {
          await this.messageQueueService.add<MessagingMessagesImportJobData>(
            MessagingMessagesImportJob.name,
            {
              workspaceId: activeWorkspace.id,
              messageChannelId: messageChannel.id,
            },
          );
        }
      } catch (error) {
        this.exceptionHandlerService.captureExceptions([error], {
          workspace: {
            id: activeWorkspace.id,
          },
        });
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a cron job that fetches message lists for active workspaces with pending syncs and enqueues these jobs for processing.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { WorkspaceActivationStatus } from 'twenty-shared';
import { In, Repository } from 'typeorm';

import { SentryCronMonitor } from 'src/engine/core-modules/cron/sentry-cron-monitor.decorator';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import {
  MessageChannelSyncStage,
  MessageChannelWorkspaceEntity,
} from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import {
  MessagingMessageListFetchJob,
  MessagingMessageListFetchJobData,
} from 'src/modules/messaging/message-import-manager/jobs/messaging-message-list-fetch.job';
export const MESSAGING_MESSAGE_LIST_FETCH_CRON_PATTERN = '*/5 * * * *';

@Processor(MessageQueue.cronQueue)
export class MessagingMessageListFetchCronJob {
  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    @InjectMessageQueue(MessageQueue.messagingQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    private readonly exceptionHandlerService: ExceptionHandlerService,
  ) {}

  @Process(MessagingMessageListFetchCronJob.name)
  @SentryCronMonitor(
    MessagingMessageListFetchCronJob.name,
    MESSAGING_MESSAGE_LIST_FETCH_CRON_PATTERN,
  )
  async handle(): Promise<void> {
    const activeWorkspaces = await this.workspaceRepository.find({
      where: {
        activationStatus: WorkspaceActivationStatus.ACTIVE,
      },
    });

    for (const activeWorkspace of activeWorkspaces) {
      try {
        const messageChannelRepository =
          await this.twentyORMGlobalManager.getRepositoryForWorkspace<MessageChannelWorkspaceEntity>(
            activeWorkspace.id,
            'messageChannel',
          );

        const messageChannels = await messageChannelRepository.find({
          where: {
            isSyncEnabled: true,
            syncStage: In([
              MessageChannelSyncStage.PARTIAL_MESSAGE_LIST_FETCH_PENDING,
              MessageChannelSyncStage.FULL_MESSAGE_LIST_FETCH_PENDING,
            ]),
          },
        });

        for (const messageChannel of messageChannels) {
          await this.messageQueueService.add<MessagingMessageListFetchJobData>(
            MessagingMessageListFetchJob.name,
            {
              workspaceId: activeWorkspace.id,
              messageChannelId: messageChannel.id,
            },
          );
        }
      } catch (error) {
        this.exceptionHandlerService.captureExceptions([error], {
          workspace: {
            id: activeWorkspace.id,
          },
        });
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a cron job that identifies active workspaces and adds a job to the message queue for each active workspace.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { WorkspaceActivationStatus } from 'twenty-shared';
import { Repository } from 'typeorm';

import { SentryCronMonitor } from 'src/engine/core-modules/cron/sentry-cron-monitor.decorator';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import {
  MessagingOngoingStaleJob,
  MessagingOngoingStaleJobData,
} from 'src/modules/messaging/message-import-manager/jobs/messaging-ongoing-stale.job';
export const MESSAGING_ONGOING_STALE_CRON_PATTERN = '0 * * * *';

@Processor(MessageQueue.cronQueue)
export class MessagingOngoingStaleCronJob {
  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    @InjectMessageQueue(MessageQueue.messagingQueue)
    private readonly messageQueueService: MessageQueueService,
    private readonly exceptionHandlerService: ExceptionHandlerService,
  ) {}

  @Process(MessagingOngoingStaleCronJob.name)
  @SentryCronMonitor(
    MessagingOngoingStaleCronJob.name,
    MESSAGING_ONGOING_STALE_CRON_PATTERN,
  )
  async handle(): Promise<void> {
    const activeWorkspaces = await this.workspaceRepository.find({
      where: {
        activationStatus: WorkspaceActivationStatus.ACTIVE,
      },
    });

    for (const activeWorkspace of activeWorkspaces) {
      try {
        await this.messageQueueService.add<MessagingOngoingStaleJobData>(
          MessagingOngoingStaleJob.name,
          {
            workspaceId: activeWorkspace.id,
          },
        );
      } catch (error) {
        this.exceptionHandlerService.captureExceptions([error], {
          workspace: {
            id: activeWorkspace.id,
          },
        });
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a cron job to monitor the sync status of message channels for active workspaces and logs the status using telemetry.
Code Snippet:
import { Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import snakeCase from 'lodash.snakecase';
import { WorkspaceActivationStatus } from 'twenty-shared';
import { Repository } from 'typeorm';

import { SentryCronMonitor } from 'src/engine/core-modules/cron/sentry-cron-monitor.decorator';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { MessageChannelWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import { MessagingTelemetryService } from 'src/modules/messaging/monitoring/services/messaging-telemetry.service';

export const MESSAGING_MESSAGE_CHANNEL_SYNC_STATUS_MONITORING_CRON_PATTERN =
  '2/10 * * * *'; //Every 10 minutes, starting at 2 minutes past the hour

@Processor(MessageQueue.cronQueue)
export class MessagingMessageChannelSyncStatusMonitoringCronJob {
  private readonly logger = new Logger(
    MessagingMessageChannelSyncStatusMonitoringCronJob.name,
  );

  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    private readonly messagingTelemetryService: MessagingTelemetryService,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    private readonly exceptionHandlerService: ExceptionHandlerService,
  ) {}

  @Process(MessagingMessageChannelSyncStatusMonitoringCronJob.name)
  @SentryCronMonitor(
    MessagingMessageChannelSyncStatusMonitoringCronJob.name,
    MESSAGING_MESSAGE_CHANNEL_SYNC_STATUS_MONITORING_CRON_PATTERN,
  )
  async handle(): Promise<void> {
    this.logger.log('Starting message channel sync status monitoring...');

    await this.messagingTelemetryService.track({
      eventName: 'message_channel.monitoring.sync_status.start',
      message: 'Starting message channel sync status monitoring',
    });

    const activeWorkspaces = await this.workspaceRepository.find({
      where: {
        activationStatus: WorkspaceActivationStatus.ACTIVE,
      },
    });

    for (const activeWorkspace of activeWorkspaces) {
      try {
        const messageChannelRepository =
          await this.twentyORMGlobalManager.getRepositoryForWorkspace<MessageChannelWorkspaceEntity>(
            activeWorkspace.id,
            'messageChannel',
          );
        const messageChannels = await messageChannelRepository.find({
          select: ['id', 'syncStatus', 'connectedAccountId'],
        });

        for (const messageChannel of messageChannels) {
          if (!messageChannel.syncStatus) {
            continue;
          }
          await this.messagingTelemetryService.track({
            eventName: `message_channel.monitoring.sync_status.${snakeCase(
              messageChannel.syncStatus,
            )}`,
            workspaceId: activeWorkspace.id,
            connectedAccountId: messageChannel.connectedAccountId,
            messageChannelId: messageChannel.id,
            message: messageChannel.syncStatus,
          });
        }
      } catch (error) {
        this.exceptionHandlerService.captureExceptions([error], {
          workspace: {
            id: activeWorkspace.id,
          },
        });
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a class for handling exceptions using Sentry, capturing exceptions with additional context and returning event IDs.
Code Snippet:
import * as Sentry from '@sentry/node';

import { ExceptionHandlerOptions } from 'src/engine/core-modules/exception-handler/interfaces/exception-handler-options.interface';

import { ExceptionHandlerDriverInterface } from 'src/engine/core-modules/exception-handler/interfaces';

export class ExceptionHandlerSentryDriver
  implements ExceptionHandlerDriverInterface
{
  captureExceptions(
    exceptions: ReadonlyArray<any>,
    options?: ExceptionHandlerOptions,
  ) {
    const eventIds: string[] = [];

    Sentry.withScope((scope) => {
      if (options?.operation) {
        scope.setTag('operation', options.operation.name);
        scope.setTag('operationName', options.operation.name);
      }

      if (options?.document) {
        scope.setExtra('document', options.document);
      }

      if (options?.workspace) {
        scope.setExtra('workspace', options.workspace);
      }

      if (options?.user) {
        scope.setUser({
          id: options.user.id,
          email: options.user.email,
          firstName: options.user.firstName,
          lastName: options.user.lastName,
        });
      }

      for (const exception of exceptions) {
        const errorPath = (exception.path ?? [])
          .map((v: string | number) => (typeof v === 'number' ? '$index' : v))
          .join(' > ');

        if (errorPath) {
          scope.addBreadcrumb({
            category: 'execution-path',
            message: errorPath,
            level: 'debug',
          });
        }

        const eventId = Sentry.captureException(exception, {
          fingerprint: [
            'graphql',
            errorPath,
            options?.operation?.name,
            options?.operation?.type,
          ],
          contexts: {
            GraphQL: {
              operationName: options?.operation?.name,
              operationType: options?.operation?.type,
            },
          },
        });

        eventIds.push(eventId);
      }
    });

    return eventIds;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service class for sending emails using an injected email driver.
Code Snippet:
import { Inject, Injectable } from '@nestjs/common';

import { SendMailOptions } from 'nodemailer';

import { EmailDriver } from 'src/engine/core-modules/email/drivers/interfaces/email-driver.interface';

import { EMAIL_DRIVER } from 'src/engine/core-modules/email/email.constants';

@Injectable()
export class EmailSenderService implements EmailDriver {
  constructor(@Inject(EMAIL_DRIVER) private driver: EmailDriver) {}

  async send(sendMailOptions: SendMailOptions): Promise<void> {
    await this.driver.send(sendMailOptions);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a job to send emails using a message queue system. It listens for email sending requests and processes them using the EmailSenderService.
Code Snippet:
import { SendMailOptions } from 'nodemailer';

import { EmailSenderService } from 'src/engine/core-modules/email/email-sender.service';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';

@Processor(MessageQueue.emailQueue)
export class EmailSenderJob {
  constructor(private readonly emailSenderService: EmailSenderService) {}

  @Process(EmailSenderJob.name)
  async handle(data: SendMailOptions): Promise<void> {
    await this.emailSenderService.send(data);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines an EmailService in a NestJS application that sends emails by adding tasks to a message queue.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { SendMailOptions } from 'nodemailer';

import { EmailSenderJob } from 'src/engine/core-modules/email/email-sender.job';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';

@Injectable()
export class EmailService {
  constructor(
    @InjectMessageQueue(MessageQueue.emailQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  async send(sendMailOptions: SendMailOptions): Promise<void> {
    await this.messageQueueService.add<SendMailOptions>(
      EmailSenderJob.name,
      sendMailOptions,
      { retryLimit: 3 },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines an SMTP email driver using nodemailer to send emails and logs the success or failure of the email sending process.
Code Snippet:
import { Logger } from '@nestjs/common';

import { createTransport, Transporter, SendMailOptions } from 'nodemailer';
import SMTPConnection from 'nodemailer/lib/smtp-connection';

import { EmailDriver } from 'src/engine/core-modules/email/drivers/interfaces/email-driver.interface';

export class SmtpDriver implements EmailDriver {
  private readonly logger = new Logger(SmtpDriver.name);
  private transport: Transporter;

  constructor(options: SMTPConnection.Options) {
    this.transport = createTransport(options);
  }

  async send(sendMailOptions: SendMailOptions): Promise<void> {
    this.transport
      .sendMail(sendMailOptions)
      .then(() =>
        this.logger.log(`Email to '${sendMailOptions.to}' successfully sent`),
      )
      .catch((err) =>
        this.logger.error(`sending email to '${sendMailOptions.to}': ${err}`),
      );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a LoggerDriver class that logs email sending details instead of actually sending an email.
Code Snippet:
import { Logger } from '@nestjs/common';

import { SendMailOptions } from 'nodemailer';

import { EmailDriver } from 'src/engine/core-modules/email/drivers/interfaces/email-driver.interface';

export class LoggerDriver implements EmailDriver {
  private readonly logger = new Logger(LoggerDriver.name);

  async send(sendMailOptions: SendMailOptions): Promise<void> {
    const info =
      `Sent email to: ${sendMailOptions.to}\n` +
      `From: ${sendMailOptions.from}\n` +
      `Subject: ${sendMailOptions.subject}\n` +
      `Content Text: ${sendMailOptions.text}\n` +
      `Content HTML: ${sendMailOptions.html}`;

    this.logger.log(info);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: Defines an interface for an email driver with a method to send emails.
Code Snippet:
import { SendMailOptions } from 'nodemailer';

export interface EmailDriver {
  send(sendMailOptions: SendMailOptions): Promise<void>;
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a decorator function SentryCronMonitor to wrap methods with monitoring capabilities using Sentry's check-in feature.
Code Snippet:
import * as Sentry from '@sentry/node';

export function SentryCronMonitor(monitorSlug: string, schedule: string) {
  return function (
    target: any,
    propertyKey: string,
    descriptor: PropertyDescriptor,
  ) {
    const originalMethod = descriptor.value;

    descriptor.value = async function (...args: any[]) {
      if (!Sentry.isInitialized()) {
        return await originalMethod.apply(this, args);
      }

      let checkInId: string | undefined;

      try {
        checkInId = Sentry.captureCheckIn(
          {
            monitorSlug,
            status: 'in_progress',
          },
          {
            schedule: {
              type: 'crontab',
              value: schedule,
            },
            checkinMargin: 1,
            maxRuntime: 5,
            timezone: 'UTC',
          },
        );
        const result = await originalMethod.apply(this, args);

        Sentry.captureCheckIn({
          checkInId,
          monitorSlug,
          status: 'ok',
        });

        return result;
      } catch (error) {
        Sentry.captureCheckIn({
          checkInId,
          monitorSlug,
          status: 'error',
        });
        throw error;
      }
    };

    return descriptor;
  };
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_4>



=== New Entry ===

<CLUSTER_5>
Number of Code Snippets part of this cluster: 16
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for seeding demo workspaces, including initializing the database, flushing cache, and managing workspace entities.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import {
  deleteCoreSchema,
  seedCoreSchema,
} from 'src/database/typeorm-seeds/core/demo';
import { rawDataSource } from 'src/database/typeorm/raw/raw.datasource';
import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { WorkspaceManagerService } from 'src/engine/workspace-manager/workspace-manager.service';

@Injectable()
export class DataSeedDemoWorkspaceService {
  constructor(
    private readonly environmentService: EnvironmentService,
    private readonly workspaceManagerService: WorkspaceManagerService,
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    @InjectCacheStorage(CacheStorageNamespace.EngineWorkspace)
    private readonly workspaceSchemaCache: CacheStorageService,
  ) {}

  async seedDemo(): Promise<void> {
    try {
      await rawDataSource.initialize();

      // TODO: migrate demo seeds to dev seeds
      const demoWorkspaceIds = ['', ''];

      await this.workspaceSchemaCache.flush();

      for (const workspaceId of demoWorkspaceIds) {
        const existingWorkspaces = await this.workspaceRepository.findBy({
          id: workspaceId,
        });

        if (existingWorkspaces.length > 0) {
          await this.workspaceManagerService.delete(workspaceId);
          await deleteCoreSchema(rawDataSource, workspaceId);
        }

        await seedCoreSchema(rawDataSource, workspaceId);
        await this.workspaceManagerService.initDemo(workspaceId);
      }
    } catch (error) {
      // eslint-disable-next-line no-console
      console.error(error);

      return;
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This service manages the synchronization status of calendar channels, updating their sync stages and statuses, and handling failures by flushing cache and reconnecting accounts as needed.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { Any } from 'typeorm';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { HealthCacheService } from 'src/engine/core-modules/health/health-cache.service';
import { HealthCounterCacheKeys } from 'src/engine/core-modules/health/types/health-counter-cache-keys.type';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import {
  CalendarChannelSyncStage,
  CalendarChannelSyncStatus,
  CalendarChannelWorkspaceEntity,
} from 'src/modules/calendar/common/standard-objects/calendar-channel.workspace-entity';
import { AccountsToReconnectService } from 'src/modules/connected-account/services/accounts-to-reconnect.service';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { AccountsToReconnectKeys } from 'src/modules/connected-account/types/accounts-to-reconnect-key-value.type';

@Injectable()
export class CalendarChannelSyncStatusService {
  constructor(
    private readonly twentyORMManager: TwentyORMManager,
    @InjectCacheStorage(CacheStorageNamespace.ModuleCalendar)
    private readonly cacheStorage: CacheStorageService,
    private readonly accountsToReconnectService: AccountsToReconnectService,
    private readonly healthCacheService: HealthCacheService,
  ) {}

  public async scheduleFullCalendarEventListFetch(
    calendarChannelIds: string[],
  ) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    await calendarChannelRepository.update(calendarChannelIds, {
      syncStage:
        CalendarChannelSyncStage.FULL_CALENDAR_EVENT_LIST_FETCH_PENDING,
    });
  }

  public async schedulePartialCalendarEventListFetch(
    calendarChannelIds: string[],
  ) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    await calendarChannelRepository.update(calendarChannelIds, {
      syncStage:
        CalendarChannelSyncStage.PARTIAL_CALENDAR_EVENT_LIST_FETCH_PENDING,
    });
  }

  public async markAsCalendarEventListFetchOngoing(
    calendarChannelIds: string[],
  ) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    await calendarChannelRepository.update(calendarChannelIds, {
      syncStage: CalendarChannelSyncStage.CALENDAR_EVENT_LIST_FETCH_ONGOING,
      syncStatus: CalendarChannelSyncStatus.ONGOING,
      syncStageStartedAt: new Date().toISOString(),
    });
  }

  public async resetAndScheduleFullCalendarEventListFetch(
    calendarChannelIds: string[],
    workspaceId: string,
  ) {
    if (!calendarChannelIds.length) {
      return;
    }

    for (const calendarChannelId of calendarChannelIds) {
      await this.cacheStorage.del(
        `calendar-events-to-import:${workspaceId}:${calendarChannelId}`,
      );
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    await calendarChannelRepository.update(calendarChannelIds, {
      syncCursor: '',
      syncStageStartedAt: null,
      throttleFailureCount: 0,
    });

    await this.scheduleFullCalendarEventListFetch(calendarChannelIds);
  }

  public async resetSyncStageStartedAt(calendarChannelIds: string[]) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    await calendarChannelRepository.update(calendarChannelIds, {
      syncStageStartedAt: null,
    });
  }

  public async scheduleCalendarEventsImport(calendarChannelIds: string[]) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    await calendarChannelRepository.update(calendarChannelIds, {
      syncStage: CalendarChannelSyncStage.CALENDAR_EVENTS_IMPORT_PENDING,
    });
  }

  public async markAsCalendarEventsImportOngoing(calendarChannelIds: string[]) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    await calendarChannelRepository.update(calendarChannelIds, {
      syncStage: CalendarChannelSyncStage.CALENDAR_EVENTS_IMPORT_ONGOING,
      syncStatus: CalendarChannelSyncStatus.ONGOING,
    });
  }

  public async markAsCompletedAndSchedulePartialCalendarEventListFetch(
    calendarChannelIds: string[],
  ) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    await calendarChannelRepository.update(calendarChannelIds, {
      syncStage:
        CalendarChannelSyncStage.PARTIAL_CALENDAR_EVENT_LIST_FETCH_PENDING,
      syncStatus: CalendarChannelSyncStatus.ACTIVE,
      throttleFailureCount: 0,
      syncStageStartedAt: null,
      syncedAt: new Date().toISOString(),
    });

    await this.schedulePartialCalendarEventListFetch(calendarChannelIds);

    await this.healthCacheService.updateMessageOrCalendarChannelSyncJobByStatusCache(
      HealthCounterCacheKeys.CalendarEventSyncJobByStatus,
      CalendarChannelSyncStatus.ACTIVE,
      calendarChannelIds,
    );
  }

  public async markAsFailedUnknownAndFlushCalendarEventsToImport(
    calendarChannelIds: string[],
    workspaceId: string,
  ) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    for (const calendarChannelId of calendarChannelIds) {
      await this.cacheStorage.del(
        `calendar-events-to-import:${workspaceId}:${calendarChannelId}`,
      );
    }

    await calendarChannelRepository.update(calendarChannelIds, {
      syncStatus: CalendarChannelSyncStatus.FAILED_UNKNOWN,
      syncStage: CalendarChannelSyncStage.FAILED,
    });

    await this.healthCacheService.updateMessageOrCalendarChannelSyncJobByStatusCache(
      HealthCounterCacheKeys.CalendarEventSyncJobByStatus,
      CalendarChannelSyncStatus.FAILED_UNKNOWN,
      calendarChannelIds,
    );
  }

  public async markAsFailedInsufficientPermissionsAndFlushCalendarEventsToImport(
    calendarChannelIds: string[],
    workspaceId: string,
  ) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    for (const calendarChannelId of calendarChannelIds) {
      await this.cacheStorage.del(
        `calendar-events-to-import:${workspaceId}:${calendarChannelId}`,
      );
    }
    await calendarChannelRepository.update(calendarChannelIds, {
      syncStatus: CalendarChannelSyncStatus.FAILED_INSUFFICIENT_PERMISSIONS,
      syncStage: CalendarChannelSyncStage.FAILED,
    });

    const connectedAccountRepository =
      await this.twentyORMManager.getRepository<ConnectedAccountWorkspaceEntity>(
        'connectedAccount',
      );

    const calendarChannels = await calendarChannelRepository.find({
      select: ['id', 'connectedAccountId'],
      where: { id: Any(calendarChannelIds) },
    });

    const connectedAccountIds = calendarChannels.map(
      (calendarChannel) => calendarChannel.connectedAccountId,
    );

    await connectedAccountRepository.update(
      { id: Any(connectedAccountIds) },
      {
        authFailedAt: new Date(),
      },
    );

    await this.addToAccountsToReconnect(
      calendarChannels.map((calendarChannel) => calendarChannel.id),
      workspaceId,
    );

    await this.healthCacheService.updateMessageOrCalendarChannelSyncJobByStatusCache(
      HealthCounterCacheKeys.CalendarEventSyncJobByStatus,
      CalendarChannelSyncStatus.FAILED_INSUFFICIENT_PERMISSIONS,
      calendarChannelIds,
    );
  }

  private async addToAccountsToReconnect(
    calendarChannelIds: string[],
    workspaceId: string,
  ) {
    if (!calendarChannelIds.length) {
      return;
    }

    const calendarChannelRepository =
      await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
        'calendarChannel',
      );

    const calendarChannels = await calendarChannelRepository.find({
      where: {
        id: Any(calendarChannelIds),
      },
      relations: {
        connectedAccount: {
          accountOwner: true,
        },
      },
    });

    for (const calendarChannel of calendarChannels) {
      const userId = calendarChannel.connectedAccount.accountOwner.userId;
      const connectedAccountId = calendarChannel.connectedAccount.id;

      await this.accountsToReconnectService.addAccountToReconnectByKey(
        AccountsToReconnectKeys.ACCOUNTS_TO_RECONNECT_INSUFFICIENT_PERMISSIONS,
        userId,
        workspaceId,
        connectedAccountId,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to fetch calendar events, update sync status, and manage event imports based on the response from a calendar API.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import {
  CalendarEventImportDriverException,
  CalendarEventImportDriverExceptionCode,
} from 'src/modules/calendar/calendar-event-import-manager/drivers/exceptions/calendar-event-import-driver.exception';
import {
  CalendarEventImportErrorHandlerService,
  CalendarEventImportSyncStep,
} from 'src/modules/calendar/calendar-event-import-manager/services/calendar-event-import-exception-handler.service';
import { CalendarEventsImportService } from 'src/modules/calendar/calendar-event-import-manager/services/calendar-events-import.service';
import { CalendarGetCalendarEventsService } from 'src/modules/calendar/calendar-event-import-manager/services/calendar-get-events.service';
import { CalendarChannelSyncStatusService } from 'src/modules/calendar/common/services/calendar-channel-sync-status.service';
import {
  CalendarChannelSyncStage,
  CalendarChannelWorkspaceEntity,
} from 'src/modules/calendar/common/standard-objects/calendar-channel.workspace-entity';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';

@Injectable()
export class CalendarFetchEventsService {
  constructor(
    @InjectCacheStorage(CacheStorageNamespace.ModuleCalendar)
    private readonly cacheStorage: CacheStorageService,
    private readonly twentyORMManager: TwentyORMManager,
    private readonly calendarChannelSyncStatusService: CalendarChannelSyncStatusService,
    private readonly getCalendarEventsService: CalendarGetCalendarEventsService,
    private readonly calendarEventImportErrorHandlerService: CalendarEventImportErrorHandlerService,
    private readonly calendarEventsImportService: CalendarEventsImportService,
  ) {}

  public async fetchCalendarEvents(
    calendarChannel: CalendarChannelWorkspaceEntity,
    connectedAccount: ConnectedAccountWorkspaceEntity,
    workspaceId: string,
  ): Promise<void> {
    const syncStep =
      calendarChannel.syncStage ===
      CalendarChannelSyncStage.FULL_CALENDAR_EVENT_LIST_FETCH_PENDING
        ? CalendarEventImportSyncStep.FULL_CALENDAR_EVENT_LIST_FETCH
        : CalendarEventImportSyncStep.PARTIAL_CALENDAR_EVENT_LIST_FETCH;

    await this.calendarChannelSyncStatusService.markAsCalendarEventListFetchOngoing(
      [calendarChannel.id],
    );

    try {
      const getCalendarEventsResponse =
        await this.getCalendarEventsService.getCalendarEvents(
          connectedAccount,
          calendarChannel.syncCursor,
        );

      const hasFullEvents = getCalendarEventsResponse.fullEvents;

      const calendarEvents = hasFullEvents
        ? getCalendarEventsResponse.calendarEvents
        : null;
      const calendarEventIds = getCalendarEventsResponse.calendarEventIds;
      const nextSyncCursor = getCalendarEventsResponse.nextSyncCursor;

      const calendarChannelRepository =
        await this.twentyORMManager.getRepository<CalendarChannelWorkspaceEntity>(
          'calendarChannel',
        );

      if (!calendarEvents || calendarEvents?.length === 0) {
        await calendarChannelRepository.update(
          {
            id: calendarChannel.id,
          },
          {
            syncCursor: nextSyncCursor,
          },
        );

        await this.calendarChannelSyncStatusService.schedulePartialCalendarEventListFetch(
          [calendarChannel.id],
        );
      }

      await calendarChannelRepository.update(
        {
          id: calendarChannel.id,
        },
        {
          syncCursor: nextSyncCursor,
        },
      );

      if (hasFullEvents && calendarEvents) {
        // Event Import already done
        await this.calendarEventsImportService.processCalendarEventsImport(
          calendarChannel,
          connectedAccount,
          workspaceId,
          calendarEvents,
        );
      } else if (!hasFullEvents && calendarEventIds) {
        // Event Import still needed

        await this.cacheStorage.setAdd(
          `calendar-events-to-import:${workspaceId}:${calendarChannel.id}`,
          calendarEventIds,
        );

        await this.calendarChannelSyncStatusService.scheduleCalendarEventsImport(
          [calendarChannel.id],
        );
      } else {
        throw new CalendarEventImportDriverException(
          "Expected 'calendarEvents' or 'calendarEventIds' to be present",
          CalendarEventImportDriverExceptionCode.UNKNOWN,
        );
      }
    } catch (error) {
      await this.calendarEventImportErrorHandlerService.handleDriverException(
        error,
        syncStep,
        calendarChannel,
        workspaceId,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a processor that adds a single message to a cache for import jobs using data from a message queue.
Code Snippet:
import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';

export type MessagingAddSingleMessageToCacheForImportJobData = {
  messageExternalId: string;
  messageChannelId: string;
  workspaceId: string;
};

@Processor(MessageQueue.messagingQueue)
export class MessagingAddSingleMessageToCacheForImportJob {
  constructor(
    @InjectCacheStorage(CacheStorageNamespace.ModuleMessaging)
    private readonly cacheStorage: CacheStorageService,
  ) {}

  @Process(MessagingAddSingleMessageToCacheForImportJob.name)
  async handle(
    data: MessagingAddSingleMessageToCacheForImportJobData,
  ): Promise<void> {
    const { messageExternalId, messageChannelId, workspaceId } = data;

    await this.cacheStorage.setAdd(
      `messages-to-import:${workspaceId}:${messageChannelId}`,
      [messageExternalId],
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a job processor that cleans cache for a specific message channel in a workspace by deleting the associated cache entry.
Code Snippet:
import { Logger } from '@nestjs/common';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';

export type MessagingCleanCacheJobData = {
  workspaceId: string;
  messageChannelId: string;
};

@Processor(MessageQueue.messagingQueue)
export class MessagingCleanCacheJob {
  private readonly logger = new Logger(MessagingCleanCacheJob.name);

  constructor(
    @InjectCacheStorage(CacheStorageNamespace.ModuleMessaging)
    private readonly cacheStorage: CacheStorageService,
  ) {}

  @Process(MessagingCleanCacheJob.name)
  async handle(data: MessagingCleanCacheJobData): Promise<void> {
    this.logger.log(
      `Deleting message channel ${data.messageChannelId} associated cache in workspace ${data.workspaceId}`,
    );

    await this.cacheStorage.del(
      `messages-to-import:${data.workspaceId}:${data.messageChannelId}`,
    );

    this.logger.log(
      `Deleted message channel ${data.messageChannelId} associated cache in workspace ${data.workspaceId}`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for fetching and processing a full list of messages for a given message channel and connected account, updating associations, and scheduling further imports.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { In } from 'typeorm';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { MessageChannelSyncStatusService } from 'src/modules/messaging/common/services/message-channel-sync-status.service';
import { MessageChannelMessageAssociationWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel-message-association.workspace-entity';
import { MessageChannelWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import { MessagingMessageCleanerService } from 'src/modules/messaging/message-cleaner/services/messaging-message-cleaner.service';
import { MessagingCursorService } from 'src/modules/messaging/message-import-manager/services/messaging-cursor.service';
import { MessagingGetMessageListService } from 'src/modules/messaging/message-import-manager/services/messaging-get-message-list.service';
import {
  MessageImportExceptionHandlerService,
  MessageImportSyncStep,
} from 'src/modules/messaging/message-import-manager/services/messaging-import-exception-handler.service';
@Injectable()
export class MessagingFullMessageListFetchService {
  constructor(
    @InjectCacheStorage(CacheStorageNamespace.ModuleMessaging)
    private readonly cacheStorage: CacheStorageService,
    private readonly messageChannelSyncStatusService: MessageChannelSyncStatusService,
    private readonly twentyORMManager: TwentyORMManager,
    private readonly messagingGetMessageListService: MessagingGetMessageListService,
    private readonly messageImportErrorHandlerService: MessageImportExceptionHandlerService,
    private readonly messagingMessageCleanerService: MessagingMessageCleanerService,
    private readonly messagingCursorService: MessagingCursorService,
  ) {}

  public async processMessageListFetch(
    messageChannel: MessageChannelWorkspaceEntity,
    connectedAccount: ConnectedAccountWorkspaceEntity,
    workspaceId: string,
  ) {
    try {
      await this.messageChannelSyncStatusService.markAsMessagesListFetchOngoing(
        [messageChannel.id],
      );

      const fullMessageLists =
        await this.messagingGetMessageListService.getFullMessageLists(
          messageChannel,
        );

      for (const fullMessageList of fullMessageLists) {
        const { messageExternalIds, nextSyncCursor, folderId } =
          fullMessageList;

        const messageChannelMessageAssociationRepository =
          await this.twentyORMManager.getRepository<MessageChannelMessageAssociationWorkspaceEntity>(
            'messageChannelMessageAssociation',
          );

        const existingMessageChannelMessageAssociations =
          await messageChannelMessageAssociationRepository.find({
            where: {
              messageChannelId: messageChannel.id,
            },
          });

        const existingMessageChannelMessageAssociationsExternalIds =
          existingMessageChannelMessageAssociations.map(
            (messageChannelMessageAssociation) =>
              messageChannelMessageAssociation.messageExternalId,
          );

        const messageExternalIdsToImport = messageExternalIds.filter(
          (messageExternalId) =>
            !existingMessageChannelMessageAssociationsExternalIds.includes(
              messageExternalId,
            ),
        );

        const messageExternalIdsToDelete =
          existingMessageChannelMessageAssociationsExternalIds.filter(
            (existingMessageCMAExternalId) =>
              existingMessageCMAExternalId &&
              !messageExternalIds.includes(existingMessageCMAExternalId),
          );

        if (messageExternalIdsToDelete.length) {
          await messageChannelMessageAssociationRepository.delete({
            messageChannelId: messageChannel.id,
            messageExternalId: In(messageExternalIdsToDelete),
          });

          await this.messagingMessageCleanerService.cleanWorkspaceThreads(
            workspaceId,
          );
        }

        if (messageExternalIdsToImport.length) {
          await this.cacheStorage.setAdd(
            `messages-to-import:${workspaceId}:${messageChannel.id}`,
            messageExternalIdsToImport,
          );
        }

        await this.messagingCursorService.updateCursor(
          messageChannel,
          nextSyncCursor,
          folderId,
        );
      }

      await this.messageChannelSyncStatusService.scheduleMessagesImport([
        messageChannel.id,
      ]);
    } catch (error) {
      await this.messageImportErrorHandlerService.handleDriverException(
        error,
        MessageImportSyncStep.FULL_MESSAGE_LIST_FETCH,
        messageChannel,
        workspaceId,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to fetch and process partial message lists for a messaging channel, updating cache, databases, and handling errors.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { In } from 'typeorm';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { MessageChannelSyncStatusService } from 'src/modules/messaging/common/services/message-channel-sync-status.service';
import { MessageChannelMessageAssociationWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel-message-association.workspace-entity';
import { MessageChannelWorkspaceEntity } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import { MessagingMessageCleanerService } from 'src/modules/messaging/message-cleaner/services/messaging-message-cleaner.service';
import { MessagingCursorService } from 'src/modules/messaging/message-import-manager/services/messaging-cursor.service';
import { MessagingGetMessageListService } from 'src/modules/messaging/message-import-manager/services/messaging-get-message-list.service';
import {
  MessageImportExceptionHandlerService,
  MessageImportSyncStep,
} from 'src/modules/messaging/message-import-manager/services/messaging-import-exception-handler.service';

@Injectable()
export class MessagingPartialMessageListFetchService {
  private readonly logger = new Logger(
    MessagingPartialMessageListFetchService.name,
  );

  constructor(
    @InjectCacheStorage(CacheStorageNamespace.ModuleMessaging)
    private readonly cacheStorage: CacheStorageService,
    private readonly messagingGetMessageListService: MessagingGetMessageListService,
    private readonly messageChannelSyncStatusService: MessageChannelSyncStatusService,
    private readonly twentyORMManager: TwentyORMManager,
    private readonly messageImportErrorHandlerService: MessageImportExceptionHandlerService,
    private readonly messagingMessageCleanerService: MessagingMessageCleanerService,
    private readonly messagingCursorService: MessagingCursorService,
  ) {}

  public async processMessageListFetch(
    messageChannel: MessageChannelWorkspaceEntity,
    connectedAccount: ConnectedAccountWorkspaceEntity,
    workspaceId: string,
  ): Promise<void> {
    try {
      await this.messageChannelSyncStatusService.markAsMessagesListFetchOngoing(
        [messageChannel.id],
      );

      const messageChannelRepository =
        await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
          'messageChannel',
        );

      await messageChannelRepository.update(
        {
          id: messageChannel.id,
        },
        {
          throttleFailureCount: 0,
        },
      );

      const partialMessageLists =
        await this.messagingGetMessageListService.getPartialMessageLists(
          messageChannel,
        );

      for (const partialMessageList of partialMessageLists) {
        const {
          messageExternalIds,
          messageExternalIdsToDelete,
          previousSyncCursor,
          nextSyncCursor,
          folderId,
        } = partialMessageList;

        const isPartialImportFinished = this.isPartialImportFinished(
          previousSyncCursor,
          nextSyncCursor,
        );

        if (isPartialImportFinished) {
          this.logger.log(
            `Partial message list import done on message channel ${messageChannel.id} in folder ${folderId} for workspace ${workspaceId} and account ${connectedAccount.id}`,
          );
          continue;
        }

        await this.cacheStorage.setAdd(
          `messages-to-import:${workspaceId}:${messageChannel.id}`,
          messageExternalIds,
        );

        this.logger.log(
          `Added ${messageExternalIds.length} messages to import for workspace ${workspaceId} and account ${connectedAccount.id}`,
        );

        const messageChannelMessageAssociationRepository =
          await this.twentyORMManager.getRepository<MessageChannelMessageAssociationWorkspaceEntity>(
            'messageChannelMessageAssociation',
          );

        if (messageExternalIdsToDelete.length) {
          await messageChannelMessageAssociationRepository.delete({
            messageChannelId: messageChannel.id,
            messageExternalId: In(messageExternalIdsToDelete),
          });

          await this.messagingMessageCleanerService.cleanWorkspaceThreads(
            workspaceId,
          );
        }

        this.logger.log(
          `Deleted ${messageExternalIdsToDelete.length} messages for workspace ${workspaceId} and account ${connectedAccount.id}`,
        );

        await this.messagingCursorService.updateCursor(
          messageChannel,
          nextSyncCursor,
          folderId,
        );
      }

      const isPartialImportFinishedForAllFolders = partialMessageLists.every(
        (partialMessageList) =>
          this.isPartialImportFinished(
            partialMessageList.previousSyncCursor,
            partialMessageList.nextSyncCursor,
          ),
      );

      if (isPartialImportFinishedForAllFolders) {
        this.logger.log(
          `Partial message list import done on message channel ${messageChannel.id} entirely for workspace ${workspaceId} and account ${connectedAccount.id}`,
        );

        await this.messageChannelSyncStatusService.markAsCompletedAndSchedulePartialMessageListFetch(
          [messageChannel.id],
        );

        return;
      }

      await this.messageChannelSyncStatusService.scheduleMessagesImport([
        messageChannel.id,
      ]);
    } catch (error) {
      await this.messageImportErrorHandlerService.handleDriverException(
        error,
        MessageImportSyncStep.PARTIAL_MESSAGE_LIST_FETCH,
        messageChannel,
        workspaceId,
      );
    }
  }

  private isPartialImportFinished(
    previousSyncCursor: string,
    nextSyncCursor: string,
  ): boolean {
    return previousSyncCursor === nextSyncCursor;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for importing messages, handling caching, refreshing access tokens, and saving messages while managing exceptions and telemetry.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { InjectObjectMetadataRepository } from 'src/engine/object-metadata-repository/object-metadata-repository.decorator';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { BlocklistRepository } from 'src/modules/blocklist/repositories/blocklist.repository';
import { BlocklistWorkspaceEntity } from 'src/modules/blocklist/standard-objects/blocklist.workspace-entity';
import { EmailAliasManagerService } from 'src/modules/connected-account/email-alias-manager/services/email-alias-manager.service';
import { ConnectedAccountRefreshAccessTokenExceptionCode } from 'src/modules/connected-account/refresh-tokens-manager/exceptions/connected-account-refresh-tokens.exception';
import { ConnectedAccountRefreshTokensService } from 'src/modules/connected-account/refresh-tokens-manager/services/connected-account-refresh-tokens.service';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { MessageChannelSyncStatusService } from 'src/modules/messaging/common/services/message-channel-sync-status.service';
import {
  MessageChannelSyncStage,
  MessageChannelWorkspaceEntity,
} from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';
import { MessageImportDriverExceptionCode } from 'src/modules/messaging/message-import-manager/drivers/exceptions/message-import-driver.exception';
import { MESSAGING_GMAIL_USERS_MESSAGES_GET_BATCH_SIZE } from 'src/modules/messaging/message-import-manager/drivers/gmail/constants/messaging-gmail-users-messages-get-batch-size.constant';
import { MessageImportExceptionCode } from 'src/modules/messaging/message-import-manager/exceptions/message-import.exception';
import { MessagingGetMessagesService } from 'src/modules/messaging/message-import-manager/services/messaging-get-messages.service';
import {
  MessageImportExceptionHandlerService,
  MessageImportSyncStep,
} from 'src/modules/messaging/message-import-manager/services/messaging-import-exception-handler.service';
import { MessagingSaveMessagesAndEnqueueContactCreationService } from 'src/modules/messaging/message-import-manager/services/messaging-save-messages-and-enqueue-contact-creation.service';
import { filterEmails } from 'src/modules/messaging/message-import-manager/utils/filter-emails.util';
import { MessagingTelemetryService } from 'src/modules/messaging/monitoring/services/messaging-telemetry.service';

@Injectable()
export class MessagingMessagesImportService {
  private readonly logger = new Logger(MessagingMessagesImportService.name);

  constructor(
    @InjectCacheStorage(CacheStorageNamespace.ModuleMessaging)
    private readonly cacheStorage: CacheStorageService,
    private readonly messageChannelSyncStatusService: MessageChannelSyncStatusService,
    private readonly saveMessagesAndEnqueueContactCreationService: MessagingSaveMessagesAndEnqueueContactCreationService,
    private readonly connectedAccountRefreshTokensService: ConnectedAccountRefreshTokensService,
    private readonly messagingTelemetryService: MessagingTelemetryService,
    @InjectObjectMetadataRepository(BlocklistWorkspaceEntity)
    private readonly blocklistRepository: BlocklistRepository,
    private readonly emailAliasManagerService: EmailAliasManagerService,
    private readonly twentyORMManager: TwentyORMManager,
    private readonly messagingGetMessagesService: MessagingGetMessagesService,
    private readonly messageImportErrorHandlerService: MessageImportExceptionHandlerService,
  ) {}

  async processMessageBatchImport(
    messageChannel: MessageChannelWorkspaceEntity,
    connectedAccount: ConnectedAccountWorkspaceEntity,
    workspaceId: string,
  ) {
    let messageIdsToFetch: string[] = [];

    try {
      if (
        messageChannel.syncStage !==
        MessageChannelSyncStage.MESSAGES_IMPORT_PENDING
      ) {
        return;
      }

      await this.messagingTelemetryService.track({
        eventName: 'messages_import.started',
        workspaceId,
        connectedAccountId: messageChannel.connectedAccountId,
        messageChannelId: messageChannel.id,
      });

      this.logger.log(
        `Messaging import for workspace ${workspaceId} and account ${connectedAccount.id} starting...`,
      );

      await this.messageChannelSyncStatusService.markAsMessagesImportOngoing([
        messageChannel.id,
      ]);

      try {
        connectedAccount.accessToken =
          await this.connectedAccountRefreshTokensService.refreshAndSaveTokens(
            connectedAccount,
            workspaceId,
          );
      } catch (error) {
        switch (error.code) {
          case ConnectedAccountRefreshAccessTokenExceptionCode.REFRESH_ACCESS_TOKEN_FAILED:
          case ConnectedAccountRefreshAccessTokenExceptionCode.REFRESH_TOKEN_NOT_FOUND:
            await this.messagingTelemetryService.track({
              eventName: `refresh_token.error.insufficient_permissions`,
              workspaceId,
              connectedAccountId: messageChannel.connectedAccountId,
              messageChannelId: messageChannel.id,
              message: `${error.code}: ${error.reason}`,
            });
            throw {
              code: MessageImportDriverExceptionCode.INSUFFICIENT_PERMISSIONS,
              message: error.message,
            };
          case ConnectedAccountRefreshAccessTokenExceptionCode.PROVIDER_NOT_SUPPORTED:
            throw {
              code: MessageImportExceptionCode.PROVIDER_NOT_SUPPORTED,
              message: error.message,
            };
          default:
            throw error;
        }
      }

      await this.emailAliasManagerService.refreshHandleAliases(
        connectedAccount,
      );

      messageIdsToFetch = await this.cacheStorage.setPop(
        `messages-to-import:${workspaceId}:${messageChannel.id}`,
        MESSAGING_GMAIL_USERS_MESSAGES_GET_BATCH_SIZE,
      );

      if (!messageIdsToFetch?.length) {
        await this.messageChannelSyncStatusService.markAsCompletedAndSchedulePartialMessageListFetch(
          [messageChannel.id],
        );

        return await this.trackMessageImportCompleted(
          messageChannel,
          workspaceId,
        );
      }

      const allMessages = await this.messagingGetMessagesService.getMessages(
        messageIdsToFetch,
        connectedAccount,
        workspaceId,
      );

      const blocklist = await this.blocklistRepository.getByWorkspaceMemberId(
        connectedAccount.accountOwnerId,
        workspaceId,
      );

      const messagesToSave = filterEmails(
        messageChannel.handle,
        [...connectedAccount.handleAliases.split(',')],
        allMessages,
        blocklist.map((blocklistItem) => blocklistItem.handle),
      );

      await this.saveMessagesAndEnqueueContactCreationService.saveMessagesAndEnqueueContactCreationJob(
        messagesToSave,
        messageChannel,
        connectedAccount,
        workspaceId,
      );

      if (
        messageIdsToFetch.length < MESSAGING_GMAIL_USERS_MESSAGES_GET_BATCH_SIZE
      ) {
        await this.messageChannelSyncStatusService.markAsCompletedAndSchedulePartialMessageListFetch(
          [messageChannel.id],
        );
      } else {
        await this.messageChannelSyncStatusService.scheduleMessagesImport([
          messageChannel.id,
        ]);
      }

      const messageChannelRepository =
        await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
          'messageChannel',
        );

      await messageChannelRepository.update(
        {
          id: messageChannel.id,
        },
        {
          throttleFailureCount: 0,
          syncStageStartedAt: null,
        },
      );

      return await this.trackMessageImportCompleted(
        messageChannel,
        workspaceId,
      );
    } catch (error) {
      await this.cacheStorage.setAdd(
        `messages-to-import:${workspaceId}:${messageChannel.id}`,
        messageIdsToFetch,
      );

      await this.messageImportErrorHandlerService.handleDriverException(
        error,
        MessageImportSyncStep.MESSAGES_IMPORT,
        messageChannel,
        workspaceId,
      );

      return await this.trackMessageImportCompleted(
        messageChannel,
        workspaceId,
      );
    }
  }

  private async trackMessageImportCompleted(
    messageChannel: MessageChannelWorkspaceEntity,
    workspaceId: string,
  ) {
    await this.messagingTelemetryService.track({
      eventName: 'messages_import.completed',
      workspaceId,
      connectedAccountId: messageChannel.connectedAccountId,
      messageChannelId: messageChannel.id,
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This service manages the synchronization status and stages of message channels, updating their states in a database and cache.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { Any } from 'typeorm';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { HealthCacheService } from 'src/engine/core-modules/health/health-cache.service';
import { HealthCounterCacheKeys } from 'src/engine/core-modules/health/types/health-counter-cache-keys.type';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { AccountsToReconnectService } from 'src/modules/connected-account/services/accounts-to-reconnect.service';
import { ConnectedAccountWorkspaceEntity } from 'src/modules/connected-account/standard-objects/connected-account.workspace-entity';
import { AccountsToReconnectKeys } from 'src/modules/connected-account/types/accounts-to-reconnect-key-value.type';
import {
  MessageChannelSyncStage,
  MessageChannelSyncStatus,
  MessageChannelWorkspaceEntity,
} from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';

@Injectable()
export class MessageChannelSyncStatusService {
  constructor(
    @InjectCacheStorage(CacheStorageNamespace.ModuleMessaging)
    private readonly cacheStorage: CacheStorageService,
    private readonly twentyORMManager: TwentyORMManager,
    private readonly accountsToReconnectService: AccountsToReconnectService,
    private readonly healthCacheService: HealthCacheService,
  ) {}

  public async scheduleFullMessageListFetch(messageChannelIds: string[]) {
    if (!messageChannelIds.length) {
      return;
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncStage: MessageChannelSyncStage.FULL_MESSAGE_LIST_FETCH_PENDING,
    });
  }

  public async schedulePartialMessageListFetch(messageChannelIds: string[]) {
    if (!messageChannelIds.length) {
      return;
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncStage: MessageChannelSyncStage.PARTIAL_MESSAGE_LIST_FETCH_PENDING,
    });
  }

  public async scheduleMessagesImport(messageChannelIds: string[]) {
    if (!messageChannelIds.length) {
      return;
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncStage: MessageChannelSyncStage.MESSAGES_IMPORT_PENDING,
    });
  }

  public async resetAndScheduleFullMessageListFetch(
    messageChannelIds: string[],
    workspaceId: string,
  ) {
    if (!messageChannelIds.length) {
      return;
    }

    for (const messageChannelId of messageChannelIds) {
      await this.cacheStorage.del(
        `messages-to-import:${workspaceId}:${messageChannelId}`,
      );
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncCursor: '',
      syncStageStartedAt: null,
      throttleFailureCount: 0,
    });

    await this.scheduleFullMessageListFetch(messageChannelIds);
  }

  public async resetSyncStageStartedAt(messageChannelIds: string[]) {
    if (!messageChannelIds.length) {
      return;
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncStageStartedAt: null,
    });
  }

  public async markAsMessagesListFetchOngoing(messageChannelIds: string[]) {
    if (!messageChannelIds.length) {
      return;
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncStage: MessageChannelSyncStage.MESSAGE_LIST_FETCH_ONGOING,
      syncStatus: MessageChannelSyncStatus.ONGOING,
      syncStageStartedAt: new Date().toISOString(),
    });
  }

  public async markAsCompletedAndSchedulePartialMessageListFetch(
    messageChannelIds: string[],
  ) {
    if (!messageChannelIds.length) {
      return;
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncStatus: MessageChannelSyncStatus.ACTIVE,
      syncStage: MessageChannelSyncStage.PARTIAL_MESSAGE_LIST_FETCH_PENDING,
      throttleFailureCount: 0,
      syncStageStartedAt: null,
      syncedAt: new Date().toISOString(),
    });

    await this.healthCacheService.updateMessageOrCalendarChannelSyncJobByStatusCache(
      HealthCounterCacheKeys.MessageChannelSyncJobByStatus,
      MessageChannelSyncStatus.ACTIVE,
      messageChannelIds,
    );
  }

  public async markAsMessagesImportOngoing(messageChannelIds: string[]) {
    if (!messageChannelIds.length) {
      return;
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncStage: MessageChannelSyncStage.MESSAGES_IMPORT_ONGOING,
      syncStageStartedAt: new Date().toISOString(),
    });
  }

  public async markAsFailedUnknownAndFlushMessagesToImport(
    messageChannelIds: string[],
    workspaceId: string,
  ) {
    if (!messageChannelIds.length) {
      return;
    }

    for (const messageChannelId of messageChannelIds) {
      await this.cacheStorage.del(
        `messages-to-import:${workspaceId}:${messageChannelId}`,
      );
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncStage: MessageChannelSyncStage.FAILED,
      syncStatus: MessageChannelSyncStatus.FAILED_UNKNOWN,
    });

    await this.healthCacheService.updateMessageOrCalendarChannelSyncJobByStatusCache(
      HealthCounterCacheKeys.MessageChannelSyncJobByStatus,
      MessageChannelSyncStatus.FAILED_UNKNOWN,
      messageChannelIds,
    );
  }

  public async markAsFailedInsufficientPermissionsAndFlushMessagesToImport(
    messageChannelIds: string[],
    workspaceId: string,
  ) {
    if (!messageChannelIds.length) {
      return;
    }

    for (const messageChannelId of messageChannelIds) {
      await this.cacheStorage.del(
        `messages-to-import:${workspaceId}:${messageChannelId}`,
      );
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    await messageChannelRepository.update(messageChannelIds, {
      syncStage: MessageChannelSyncStage.FAILED,
      syncStatus: MessageChannelSyncStatus.FAILED_INSUFFICIENT_PERMISSIONS,
    });

    await this.healthCacheService.updateMessageOrCalendarChannelSyncJobByStatusCache(
      HealthCounterCacheKeys.MessageChannelSyncJobByStatus,
      MessageChannelSyncStatus.FAILED_INSUFFICIENT_PERMISSIONS,
      messageChannelIds,
    );

    const connectedAccountRepository =
      await this.twentyORMManager.getRepository<ConnectedAccountWorkspaceEntity>(
        'connectedAccount',
      );

    const messageChannels = await messageChannelRepository.find({
      select: ['id', 'connectedAccountId'],
      where: { id: Any(messageChannelIds) },
    });

    const connectedAccountIds = messageChannels.map(
      (messageChannel) => messageChannel.connectedAccountId,
    );

    await connectedAccountRepository.update(
      { id: Any(connectedAccountIds) },
      {
        authFailedAt: new Date(),
      },
    );

    await this.addToAccountsToReconnect(
      messageChannels.map((messageChannel) => messageChannel.id),
      workspaceId,
    );
  }

  private async addToAccountsToReconnect(
    messageChannelIds: string[],
    workspaceId: string,
  ) {
    if (!messageChannelIds.length) {
      return;
    }

    const messageChannelRepository =
      await this.twentyORMManager.getRepository<MessageChannelWorkspaceEntity>(
        'messageChannel',
      );

    const messageChannels = await messageChannelRepository.find({
      where: { id: Any(messageChannelIds) },
      relations: {
        connectedAccount: {
          accountOwner: true,
        },
      },
    });

    for (const messageChannel of messageChannels) {
      const userId = messageChannel.connectedAccount.accountOwner.userId;
      const connectedAccountId = messageChannel.connectedAccount.id;

      await this.accountsToReconnectService.addAccountToReconnectByKey(
        AccountsToReconnectKeys.ACCOUNTS_TO_RECONNECT_INSUFFICIENT_PERMISSIONS,
        userId,
        workspaceId,
        connectedAccountId,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a ThrottlerService that uses cache storage to limit the number of requests for a given key within a specified time frame.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import {
  ThrottlerException,
  ThrottlerExceptionCode,
} from 'src/engine/core-modules/throttler/throttler.exception';

@Injectable()
export class ThrottlerService {
  constructor(
    @InjectCacheStorage(CacheStorageNamespace.EngineWorkspace)
    private readonly cacheStorage: CacheStorageService,
  ) {}

  async throttle(key: string, limit: number, ttl: number): Promise<void> {
    const currentCount = (await this.cacheStorage.get<number>(key)) ?? 0;

    if (currentCount >= limit) {
      throw new ThrottlerException(
        'Too many requests',
        ThrottlerExceptionCode.TOO_MANY_REQUESTS,
      );
    }

    await this.cacheStorage.set(key, currentCount + 1, ttl);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing health metrics cache using a cache storage system. It handles caching and counting operations for different sync statuses and invalid captchas.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { AccountSyncJobByStatusCounter } from 'src/engine/core-modules/health/types/account-sync-metrics.types';
import { HealthCounterCacheKeys } from 'src/engine/core-modules/health/types/health-counter-cache-keys.type';
import { CalendarChannelSyncStatus } from 'src/modules/calendar/common/standard-objects/calendar-channel.workspace-entity';
import { MessageChannelSyncStatus } from 'src/modules/messaging/common/standard-objects/message-channel.workspace-entity';

const CACHE_BUCKET_DURATION_MS = 15000; // 15 seconds window for each cache bucket

@Injectable()
export class HealthCacheService {
  private readonly healthMetricsTimeWindowInMinutes: number;
  private readonly healthCacheTtl: number;

  constructor(
    @InjectCacheStorage(CacheStorageNamespace.EngineHealth)
    private readonly cacheStorage: CacheStorageService,
    private readonly environmentService: EnvironmentService,
  ) {
    this.healthMetricsTimeWindowInMinutes = this.environmentService.get(
      'HEALTH_METRICS_TIME_WINDOW_IN_MINUTES',
    );
    this.healthCacheTtl = this.healthMetricsTimeWindowInMinutes * 60000 * 2;
  }

  private getCacheBucketStartTimestamp(timestamp: number): number {
    return (
      Math.floor(timestamp / CACHE_BUCKET_DURATION_MS) *
      CACHE_BUCKET_DURATION_MS
    );
  }

  private getCacheKeyWithTimestamp(key: string, timestamp?: number): string {
    const currentIntervalTimestamp =
      timestamp ?? this.getCacheBucketStartTimestamp(Date.now());

    return `${key}:${currentIntervalTimestamp}`;
  }

  private getLastCacheBucketStartTimestampsFromDate(
    cacheBucketsCount: number,
    date: number = Date.now(),
  ): number[] {
    const currentIntervalTimestamp = this.getCacheBucketStartTimestamp(date);

    return Array.from(
      { length: cacheBucketsCount },
      (_, i) => currentIntervalTimestamp - i * CACHE_BUCKET_DURATION_MS,
    );
  }

  async updateMessageOrCalendarChannelSyncJobByStatusCache(
    key: HealthCounterCacheKeys,
    status: MessageChannelSyncStatus | CalendarChannelSyncStatus,
    messageChannelIds: string[],
  ) {
    return await this.cacheStorage.setAdd(
      this.getCacheKeyWithTimestamp(`${key}:${status}`),
      messageChannelIds,
      this.healthCacheTtl,
    );
  }

  async countChannelSyncJobByStatus(
    key:
      | HealthCounterCacheKeys.MessageChannelSyncJobByStatus
      | HealthCounterCacheKeys.CalendarEventSyncJobByStatus,
    timeWindowInSeconds: number = this.healthMetricsTimeWindowInMinutes * 60,
  ): Promise<AccountSyncJobByStatusCounter> {
    if ((timeWindowInSeconds * 1000) % CACHE_BUCKET_DURATION_MS !== 0) {
      throw new Error(
        `Time window must be divisible by ${CACHE_BUCKET_DURATION_MS}`,
      );
    }

    const now = Date.now();
    const countByStatus = {} as AccountSyncJobByStatusCounter;
    const statuses =
      key === HealthCounterCacheKeys.MessageChannelSyncJobByStatus
        ? Object.values(MessageChannelSyncStatus).filter(
            (status) => status !== MessageChannelSyncStatus.ONGOING,
          )
        : Object.values(CalendarChannelSyncStatus).filter(
            (status) => status !== CalendarChannelSyncStatus.ONGOING,
          );

    const cacheBuckets =
      timeWindowInSeconds / (CACHE_BUCKET_DURATION_MS / 1000);

    for (const status of statuses) {
      const cacheKeys = this.computeTimeStampedCacheKeys(
        `${key}:${status}`,
        cacheBuckets,
        now,
      );

      const channelIdsCount =
        await this.cacheStorage.countAllSetMembers(cacheKeys);

      countByStatus[status] = channelIdsCount;
    }

    return countByStatus;
  }

  computeTimeStampedCacheKeys(
    key: string,
    cacheBucketsCount: number,
    date: number = Date.now(),
  ) {
    return this.getLastCacheBucketStartTimestampsFromDate(
      cacheBucketsCount,
      date,
    ).map((timestamp) => this.getCacheKeyWithTimestamp(key, timestamp));
  }

  async updateInvalidCaptchaCache(captchaToken: string) {
    return await this.cacheStorage.setAdd(
      this.getCacheKeyWithTimestamp(HealthCounterCacheKeys.InvalidCaptcha),
      [captchaToken],
      this.healthCacheTtl,
    );
  }

  async getInvalidCaptchaCounter(
    timeWindowInSeconds: number = this.healthMetricsTimeWindowInMinutes * 60,
  ) {
    return await this.cacheStorage.countAllSetMembers(
      this.computeTimeStampedCacheKeys(
        HealthCounterCacheKeys.InvalidCaptcha,
        timeWindowInSeconds / (CACHE_BUCKET_DURATION_MS / 1000),
      ),
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code configures a cache module using Redis as the storage backend based on environment settings.
Code Snippet:
import { CacheModuleOptions } from '@nestjs/common';

import { redisStore } from 'cache-manager-redis-yet';

import { CacheStorageType } from 'src/engine/core-modules/cache-storage/types/cache-storage-type.enum';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';

export const cacheStorageModuleFactory = (
  environmentService: EnvironmentService,
): CacheModuleOptions => {
  const cacheStorageType = CacheStorageType.Redis;
  const cacheStorageTtl = environmentService.get('CACHE_STORAGE_TTL');
  const cacheModuleOptions: CacheModuleOptions = {
    isGlobal: true,
    ttl: cacheStorageTtl * 1000,
  };

  switch (cacheStorageType) {
    /* case CacheStorageType.Memory: {
      return cacheModuleOptions;
    }*/
    case CacheStorageType.Redis: {
      const redisUrl = environmentService.get('REDIS_URL');

      if (!redisUrl) {
        throw new Error(
          `${cacheStorageType} cache storage requires REDIS_URL to be defined, check your .env file`,
        );
      }

      return {
        ...cacheModuleOptions,
        store: redisStore,
        url: redisUrl,
      };
    }
    default:
      throw new Error(
        `Invalid cache-storage (${cacheStorageType}), check your .env file`,
      );
  }
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to flush cache entries based on a specified pattern.
Code Snippet:
import { Logger } from '@nestjs/common';

import { Command, CommandRunner, Option } from 'nest-commander';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';

@Command({
  name: 'cache:flush',
  description: 'Flush cache for specific keys matching the pattern',
})
export class FlushCacheCommand extends CommandRunner {
  private readonly logger = new Logger(FlushCacheCommand.name);

  constructor(
    @InjectCacheStorage(CacheStorageNamespace.EngineWorkspace)
    private readonly cacheStorage: CacheStorageService,
  ) {
    super();
  }

  async run(
    passedParams: string[],
    options?: Record<string, any>,
  ): Promise<void> {
    const pattern = options?.pattern || '*';

    this.logger.log(`Flushing cache for pattern: ${pattern}...`);

    if (pattern === '*') {
      await this.cacheStorage.flush();
    } else {
      await this.cacheStorage.flushByPattern(pattern);
    }

    this.logger.log('Cache flushed');
  }

  @Option({
    flags: '-p, --pattern <pattern>',
    description: 'Pattern to flush specific cache keys (e.g., engine:*)',
  })
  parsePattern(val: string): string {
    return val;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing cache operations using Redis or an in-memory cache, with methods to get, set, delete, add to sets, pop from sets, count set members, and flush cache.
Code Snippet:
import { CACHE_MANAGER, Cache } from '@nestjs/cache-manager';
import { Inject, Injectable } from '@nestjs/common';

import { RedisCache } from 'cache-manager-redis-yet';

import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';

@Injectable()
export class CacheStorageService {
  constructor(
    @Inject(CACHE_MANAGER)
    private readonly cache: Cache,
    private readonly namespace: CacheStorageNamespace,
  ) {}

  async get<T>(key: string): Promise<T | undefined> {
    return this.cache.get(`${this.namespace}:${key}`);
  }

  async set<T>(key: string, value: T, ttl?: number) {
    return this.cache.set(`${this.namespace}:${key}`, value, ttl);
  }

  async del(key: string) {
    return this.cache.del(`${this.namespace}:${key}`);
  }

  async setAdd(key: string, value: string[], ttl?: number) {
    if (value.length === 0) {
      return;
    }

    if (this.isRedisCache()) {
      await (this.cache as RedisCache).store.client.sAdd(
        `${this.namespace}:${key}`,
        value,
      );

      if (ttl) {
        await (this.cache as RedisCache).store.client.expire(
          `${this.namespace}:${key}`,
          ttl / 1000,
        );
      }

      return;
    }

    this.get(key).then((res: string[]) => {
      if (res) {
        this.set(key, [...res, ...value], ttl);
      } else {
        this.set(key, value, ttl);
      }
    });
  }

  async countAllSetMembers(cacheKeys: string[]) {
    return (
      await Promise.all(cacheKeys.map((key) => this.getSetLength(key) || 0))
    ).reduce((acc, setLength) => acc + setLength, 0);
  }

  async setPop(key: string, size = 1) {
    if (this.isRedisCache()) {
      return (this.cache as RedisCache).store.client.sPop(
        `${this.namespace}:${key}`,
        size,
      );
    }

    return this.get(key).then((res: string[]) => {
      if (res) {
        this.set(key, res.slice(0, -size));

        return res.slice(-size);
      }

      return [];
    });
  }

  async getSetLength(key: string) {
    if (this.isRedisCache()) {
      return await (this.cache as RedisCache).store.client.sCard(
        `${this.namespace}:${key}`,
      );
    }

    return this.get(key).then((res: string[]) => {
      return res.length;
    });
  }

  async flush() {
    return this.cache.reset();
  }

  async flushByPattern(scanPattern: string): Promise<void> {
    if (!this.isRedisCache()) {
      throw new Error('flushByPattern is only supported with Redis cache');
    }

    const redisClient = (this.cache as RedisCache).store.client;
    let cursor = 0;

    do {
      const result = await redisClient.scan(cursor, {
        MATCH: scanPattern,
        COUNT: 100,
      });

      const nextCursor = result.cursor;
      const keys = result.keys;

      if (keys.length > 0) {
        await redisClient.del(keys);
      }

      cursor = nextCursor;
    } while (cursor !== 0);
  }

  private isRedisCache() {
    return (this.cache.store as any)?.name === 'redis';
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code configures session storage options using Redis as the cache storage type, ensuring secure session management with environment-based settings.
Code Snippet:
import { createHash } from 'crypto';

import RedisStore from 'connect-redis';
import session from 'express-session';
import { createClient } from 'redis';

import { CacheStorageType } from 'src/engine/core-modules/cache-storage/types/cache-storage-type.enum';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';

export const getSessionStorageOptions = (
  environmentService: EnvironmentService,
): session.SessionOptions => {
  const cacheStorageType = CacheStorageType.Redis;

  const SERVER_URL = environmentService.get('SERVER_URL');

  const appSecret = environmentService.get('APP_SECRET');

  if (!appSecret) {
    throw new Error('APP_SECRET is not set');
  }

  const sessionSecret = createHash('sha256')
    .update(`${appSecret}SESSION_STORE_SECRET`)
    .digest('hex');

  const sessionStorage: session.SessionOptions = {
    secret: sessionSecret,
    resave: false,
    saveUninitialized: false,
    proxy: true,
    cookie: {
      secure: !!(SERVER_URL && SERVER_URL.startsWith('https')),
      maxAge: 1000 * 60 * 30, // 30 minutes
    },
  };

  switch (cacheStorageType) {
    /* case CacheStorageType.Memory: {
      Logger.warn(
        'Memory session storage is not recommended for production. Prefer Redis.',
      );

      return sessionStorage;
    }*/
    case CacheStorageType.Redis: {
      const connectionString = environmentService.get('REDIS_URL');

      if (!connectionString) {
        throw new Error(
          `${CacheStorageType.Redis} session storage requires REDIS_URL to be defined, check your .env file`,
        );
      }

      const redisClient = createClient({
        url: connectionString,
      });

      redisClient.connect().catch((err) => {
        throw new Error(`Redis connection failed: ${err}`);
      });

      return {
        ...sessionStorage,
        store: new RedisStore({
          client: redisClient,
          prefix: 'engine:session:',
        }),
      };
    }
    default:
      throw new Error(
        `Invalid session-storage (${cacheStorageType}), check your .env file`,
      );
  }
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing workspace-specific data in a cache storage, including GraphQL type definitions, scalar names, operations, ORM entity schemas, metadata version, and feature flags. It provides methods for setting, getting, and deleting these data items.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { EntitySchemaOptions } from 'typeorm';

import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { ObjectMetadataMaps } from 'src/engine/metadata-modules/types/object-metadata-maps';

export enum WorkspaceCacheKeys {
  GraphQLTypeDefs = 'graphql:type-defs',
  GraphQLUsedScalarNames = 'graphql:used-scalar-names',
  GraphQLOperations = 'graphql:operations',
  ORMEntitySchemas = 'orm:entity-schemas',
  GraphQLFeatureFlag = 'graphql:feature-flag',
  MetadataObjectMetadataMaps = 'metadata:object-metadata-maps',
  MetadataObjectMetadataOngoingCachingLock = 'metadata:object-metadata-ongoing-caching-lock',
  MetadataVersion = 'metadata:workspace-metadata-version',
}

const TTL_INFINITE = 0;

@Injectable()
export class WorkspaceCacheStorageService {
  constructor(
    @InjectCacheStorage(CacheStorageNamespace.EngineWorkspace)
    private readonly cacheStorageService: CacheStorageService,
  ) {}

  setORMEntitySchema(
    workspaceId: string,
    metadataVersion: number,
    entitySchemas: EntitySchemaOptions<any>[],
  ) {
    return this.cacheStorageService.set<EntitySchemaOptions<any>[]>(
      `${WorkspaceCacheKeys.ORMEntitySchemas}:${workspaceId}:${metadataVersion}`,
      entitySchemas,
      TTL_INFINITE,
    );
  }

  getORMEntitySchema(
    workspaceId: string,
    metadataVersion: number,
  ): Promise<EntitySchemaOptions<any>[] | undefined> {
    return this.cacheStorageService.get<EntitySchemaOptions<any>[]>(
      `${WorkspaceCacheKeys.ORMEntitySchemas}:${workspaceId}:${metadataVersion}`,
    );
  }

  setMetadataVersion(
    workspaceId: string,
    metadataVersion: number,
  ): Promise<void> {
    return this.cacheStorageService.set<number>(
      `${WorkspaceCacheKeys.MetadataVersion}:${workspaceId}`,
      metadataVersion,
      TTL_INFINITE,
    );
  }

  getMetadataVersion(workspaceId: string): Promise<number | undefined> {
    return this.cacheStorageService.get<number>(
      `${WorkspaceCacheKeys.MetadataVersion}:${workspaceId}`,
    );
  }

  addObjectMetadataCollectionOngoingCachingLock(
    workspaceId: string,
    metadataVersion: number,
  ) {
    return this.cacheStorageService.set<boolean>(
      `${WorkspaceCacheKeys.MetadataObjectMetadataOngoingCachingLock}:${workspaceId}:${metadataVersion}`,
      true,
      TTL_INFINITE,
    );
  }

  removeObjectMetadataOngoingCachingLock(
    workspaceId: string,
    metadataVersion: number,
  ) {
    return this.cacheStorageService.del(
      `${WorkspaceCacheKeys.MetadataObjectMetadataOngoingCachingLock}:${workspaceId}:${metadataVersion}`,
    );
  }

  getObjectMetadataOngoingCachingLock(
    workspaceId: string,
    metadataVersion: number,
  ): Promise<boolean | undefined> {
    return this.cacheStorageService.get<boolean>(
      `${WorkspaceCacheKeys.MetadataObjectMetadataOngoingCachingLock}:${workspaceId}:${metadataVersion}`,
    );
  }

  setObjectMetadataMaps(
    workspaceId: string,
    metadataVersion: number,
    objectMetadataMaps: ObjectMetadataMaps,
  ) {
    return this.cacheStorageService.set<ObjectMetadataMaps>(
      `${WorkspaceCacheKeys.MetadataObjectMetadataMaps}:${workspaceId}:${metadataVersion}`,
      objectMetadataMaps,
      TTL_INFINITE,
    );
  }

  getObjectMetadataMaps(
    workspaceId: string,
    metadataVersion: number,
  ): Promise<ObjectMetadataMaps | undefined> {
    return this.cacheStorageService.get<ObjectMetadataMaps>(
      `${WorkspaceCacheKeys.MetadataObjectMetadataMaps}:${workspaceId}:${metadataVersion}`,
    );
  }

  setGraphQLTypeDefs(
    workspaceId: string,
    metadataVersion: number,
    typeDefs: string,
  ): Promise<void> {
    return this.cacheStorageService.set<string>(
      `${WorkspaceCacheKeys.GraphQLTypeDefs}:${workspaceId}:${metadataVersion}`,
      typeDefs,
      TTL_INFINITE,
    );
  }

  getGraphQLTypeDefs(
    workspaceId: string,
    metadataVersion: number,
  ): Promise<string | undefined> {
    return this.cacheStorageService.get<string>(
      `${WorkspaceCacheKeys.GraphQLTypeDefs}:${workspaceId}:${metadataVersion}`,
    );
  }

  setGraphQLUsedScalarNames(
    workspaceId: string,
    metadataVersion: number,
    usedScalarNames: string[],
  ): Promise<void> {
    return this.cacheStorageService.set<string[]>(
      `${WorkspaceCacheKeys.GraphQLUsedScalarNames}:${workspaceId}:${metadataVersion}`,
      usedScalarNames,
      TTL_INFINITE,
    );
  }

  getGraphQLUsedScalarNames(
    workspaceId: string,
    metadataVersion: number,
  ): Promise<string[] | undefined> {
    return this.cacheStorageService.get<string[]>(
      `${WorkspaceCacheKeys.GraphQLUsedScalarNames}:${workspaceId}:${metadataVersion}`,
    );
  }

  // TODO: remove this after the feature flag is droped
  setIsNewRelationEnabled(workspaceId: string, isNewRelationEnabled: boolean) {
    return this.cacheStorageService.set<boolean>(
      `${WorkspaceCacheKeys.GraphQLFeatureFlag}:${workspaceId}:${FeatureFlagKey.IsNewRelationEnabled}`,
      isNewRelationEnabled,
      TTL_INFINITE,
    );
  }

  // TODO: remove this after the feature flag is droped
  getIsNewRelationEnabled(workspaceId: string): Promise<boolean | undefined> {
    return this.cacheStorageService.get<boolean>(
      `${WorkspaceCacheKeys.GraphQLFeatureFlag}:${workspaceId}:${FeatureFlagKey.IsNewRelationEnabled}`,
    );
  }

  async flush(workspaceId: string, metadataVersion: number): Promise<void> {
    await this.cacheStorageService.del(
      `${WorkspaceCacheKeys.MetadataObjectMetadataMaps}:${workspaceId}:${metadataVersion}`,
    );
    await this.cacheStorageService.del(
      `${WorkspaceCacheKeys.MetadataVersion}:${workspaceId}:${metadataVersion}`,
    );
    await this.cacheStorageService.del(
      `${WorkspaceCacheKeys.GraphQLTypeDefs}:${workspaceId}:${metadataVersion}`,
    );
    await this.cacheStorageService.del(
      `${WorkspaceCacheKeys.GraphQLUsedScalarNames}:${workspaceId}:${metadataVersion}`,
    );
    await this.cacheStorageService.del(
      `${WorkspaceCacheKeys.ORMEntitySchemas}:${workspaceId}:${metadataVersion}`,
    );
    await this.cacheStorageService.del(
      `${WorkspaceCacheKeys.MetadataObjectMetadataOngoingCachingLock}:${workspaceId}:${metadataVersion}`,
    );

    // TODO: remove this after the feature flag is droped
    await this.cacheStorageService.del(
      `${FeatureFlagKey.IsNewRelationEnabled}:${workspaceId}`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_5>



=== New Entry ===

<CLUSTER_6>
Number of Code Snippets part of this cluster: 14
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: This code defines a NestJS module for handling CRUD operations on records within a workspace context, utilizing TypeORM for data management and feature flags for conditional logic.
Code Snippet:
import { Module } from '@nestjs/common';

import { NestjsQueryTypeOrmModule } from '@ptc-org/nestjs-query-typeorm';

import { FeatureFlagModule } from 'src/engine/core-modules/feature-flag/feature-flag.module';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { ScopedWorkspaceContextFactory } from 'src/engine/twenty-orm/factories/scoped-workspace-context.factory';
import { WorkspaceCacheStorageModule } from 'src/engine/workspace-cache-storage/workspace-cache-storage.module';
import { CreateRecordWorkflowAction } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/create-record.workflow-action';
import { DeleteRecordWorkflowAction } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/delete-record.workflow-action';
import { FindRecordsWorkflowAction } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/find-records.workflow-action';
import { UpdateRecordWorkflowAction } from 'src/modules/workflow/workflow-executor/workflow-actions/record-crud/update-record.workflow-action';

@Module({
  imports: [
    WorkspaceCacheStorageModule,
    NestjsQueryTypeOrmModule.forFeature([ObjectMetadataEntity], 'metadata'),
    FeatureFlagModule,
  ],
  providers: [
    ScopedWorkspaceContextFactory,
    CreateRecordWorkflowAction,
    UpdateRecordWorkflowAction,
    DeleteRecordWorkflowAction,
    FindRecordsWorkflowAction,
  ],
  exports: [
    CreateRecordWorkflowAction,
    UpdateRecordWorkflowAction,
    DeleteRecordWorkflowAction,
    FindRecordsWorkflowAction,
  ],
})
export class RecordCRUDActionModule {}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines an AuditLogRepository class in a NestJS application that inserts audit log entries into a database.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';

@Injectable()
export class AuditLogRepository {
  constructor(
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
  ) {}

  public async insert(
    name: string,
    properties: object | null,
    workspaceMemberId: string | null,
    objectName: string,
    objectMetadataId: string,
    recordId: string,
    workspaceId: string,
  ): Promise<void> {
    const dataSourceSchema =
      this.workspaceDataSourceService.getSchemaName(workspaceId);

    await this.workspaceDataSourceService.executeRawQuery(
      `INSERT INTO ${dataSourceSchema}."auditLog"
      ("name", "properties", "workspaceMemberId", "objectName", "objectMetadataId", "recordId")
      VALUES ($1, $2, $3, $4, $5, $6)`,
      [
        name,
        properties,
        workspaceMemberId,
        objectName,
        objectMetadataId,
        recordId,
      ],
      workspaceId,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a factory for creating and managing WorkspaceDataSource instances, handling metadata caching and schema creation.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { EntitySchema } from 'typeorm';

import { NodeEnvironment } from 'src/engine/core-modules/environment/interfaces/node-environment.interface';

import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { DataSourceService } from 'src/engine/metadata-modules/data-source/data-source.service';
import { WorkspaceMetadataCacheService } from 'src/engine/metadata-modules/workspace-metadata-cache/services/workspace-metadata-cache.service';
import { WorkspaceDataSource } from 'src/engine/twenty-orm/datasource/workspace.datasource';
import {
  TwentyORMException,
  TwentyORMExceptionCode,
} from 'src/engine/twenty-orm/exceptions/twenty-orm.exception';
import { EntitySchemaFactory } from 'src/engine/twenty-orm/factories/entity-schema.factory';
import { CacheManager } from 'src/engine/twenty-orm/storage/cache-manager.storage';
import { CacheKey } from 'src/engine/twenty-orm/storage/types/cache-key.type';
import { WorkspaceCacheStorageService } from 'src/engine/workspace-cache-storage/workspace-cache-storage.service';

@Injectable()
export class WorkspaceDatasourceFactory {
  private readonly logger = new Logger(WorkspaceDatasourceFactory.name);
  private cacheManager = new CacheManager<WorkspaceDataSource>();
  private cachedDataSourcePromise: Record<
    CacheKey,
    Promise<WorkspaceDataSource>
  >;

  constructor(
    private readonly dataSourceService: DataSourceService,
    private readonly environmentService: EnvironmentService,
    private readonly workspaceCacheStorageService: WorkspaceCacheStorageService,
    private readonly workspaceMetadataCacheService: WorkspaceMetadataCacheService,
    private readonly entitySchemaFactory: EntitySchemaFactory,
  ) {
    this.cachedDataSourcePromise = {};
  }

  public async create(
    workspaceId: string,
    workspaceMetadataVersion: number | null,
    failOnMetadataCacheMiss = true,
  ): Promise<WorkspaceDataSource> {
    const cachedWorkspaceMetadataVersion =
      await this.getWorkspaceMetadataVersionFromCache(
        workspaceId,
        failOnMetadataCacheMiss,
      );

    if (
      workspaceMetadataVersion !== null &&
      cachedWorkspaceMetadataVersion !== workspaceMetadataVersion
    ) {
      throw new TwentyORMException(
        `Workspace metadata version mismatch detected for workspace ${workspaceId}. Current version: ${cachedWorkspaceMetadataVersion}. Desired version: ${workspaceMetadataVersion}`,
        TwentyORMExceptionCode.METADATA_VERSION_MISMATCH,
      );
    }

    const cacheKey: CacheKey = `${workspaceId}-${cachedWorkspaceMetadataVersion}`;

    if (cacheKey in this.cachedDataSourcePromise) {
      return this.cachedDataSourcePromise[cacheKey];
    }

    const creationPromise = (async (): Promise<WorkspaceDataSource> => {
      try {
        const result = await this.cacheManager.execute(
          cacheKey,
          async () => {
            const dataSourceMetadata =
              await this.dataSourceService.getLastDataSourceMetadataFromWorkspaceId(
                workspaceId,
              );

            if (!dataSourceMetadata) {
              throw new TwentyORMException(
                `Workspace Schema not found for workspace ${workspaceId}`,
                TwentyORMExceptionCode.WORKSPACE_SCHEMA_NOT_FOUND,
              );
            }

            const cachedEntitySchemaOptions =
              await this.workspaceCacheStorageService.getORMEntitySchema(
                workspaceId,
                cachedWorkspaceMetadataVersion,
              );

            let cachedEntitySchemas: EntitySchema[];

            const cachedObjectMetadataMaps =
              await this.workspaceCacheStorageService.getObjectMetadataMaps(
                workspaceId,
                cachedWorkspaceMetadataVersion,
              );

            if (!cachedObjectMetadataMaps) {
              throw new TwentyORMException(
                `Workspace Schema not found for workspace ${workspaceId}`,
                TwentyORMExceptionCode.METADATA_COLLECTION_NOT_FOUND,
              );
            }

            if (cachedEntitySchemaOptions) {
              cachedEntitySchemas = cachedEntitySchemaOptions.map(
                (option) => new EntitySchema(option),
              );
            } else {
              const entitySchemas = await Promise.all(
                Object.values(cachedObjectMetadataMaps.byId).map(
                  (objectMetadata) =>
                    this.entitySchemaFactory.create(
                      workspaceId,
                      cachedWorkspaceMetadataVersion,
                      objectMetadata,
                      cachedObjectMetadataMaps,
                    ),
                ),
              );

              await this.workspaceCacheStorageService.setORMEntitySchema(
                workspaceId,
                cachedWorkspaceMetadataVersion,
                entitySchemas.map((entitySchema) => entitySchema.options),
              );

              cachedEntitySchemas = entitySchemas;
            }

            const workspaceDataSource = new WorkspaceDataSource(
              {
                workspaceId,
                objectMetadataMaps: cachedObjectMetadataMaps,
              },
              {
                url:
                  dataSourceMetadata.url ??
                  this.environmentService.get('PG_DATABASE_URL'),
                type: 'postgres',
                logging:
                  this.environmentService.get('NODE_ENV') ===
                  NodeEnvironment.development
                    ? ['query', 'error']
                    : ['error'],
                schema: dataSourceMetadata.schema,
                entities: cachedEntitySchemas,
                ssl: this.environmentService.get('PG_SSL_ALLOW_SELF_SIGNED')
                  ? {
                      rejectUnauthorized: false,
                    }
                  : undefined,
              },
            );

            await workspaceDataSource.initialize();

            return workspaceDataSource;
          },
          async (dataSource) => {
            try {
              await dataSource.destroy();
            } catch (error) {
              // Ignore error if pool has already been destroyed which is a common race condition case
              if (error.message === 'Called end on pool more than once') {
                return;
              }

              throw error;
            }
          },
        );

        if (result === null) {
          throw new Error(
            `Failed to create WorkspaceDataSource for ${cacheKey}`,
          );
        }

        return result;
      } finally {
        delete this.cachedDataSourcePromise[cacheKey];
      }
    })();

    this.cachedDataSourcePromise[cacheKey] = creationPromise;

    return creationPromise;
  }

  public async destroy(workspaceId: string): Promise<void> {
    const cacheKeys = (
      Object.keys(this.cachedDataSourcePromise) as CacheKey[]
    ).filter((key) => key.startsWith(`${workspaceId}`));

    for (const cacheKey of cacheKeys) {
      await this.cacheManager.clearKey(cacheKey);
    }
  }

  private async getWorkspaceMetadataVersionFromCache(
    workspaceId: string,
    failOnMetadataCacheMiss = true,
  ): Promise<number> {
    let latestWorkspaceMetadataVersion =
      await this.workspaceCacheStorageService.getMetadataVersion(workspaceId);

    if (latestWorkspaceMetadataVersion === undefined) {
      await this.workspaceMetadataCacheService.recomputeMetadataCache({
        workspaceId,
        ignoreLock: !failOnMetadataCacheMiss,
      });

      if (failOnMetadataCacheMiss) {
        throw new TwentyORMException(
          `Metadata version not found for workspace ${workspaceId}`,
          TwentyORMExceptionCode.METADATA_VERSION_NOT_FOUND,
        );
      } else {
        latestWorkspaceMetadataVersion =
          await this.workspaceCacheStorageService.getMetadataVersion(
            workspaceId,
          );
      }
    }

    if (!latestWorkspaceMetadataVersion) {
      throw new TwentyORMException(
        `Metadata version not found after recompute for workspace ${workspaceId}`,
        TwentyORMExceptionCode.METADATA_VERSION_NOT_FOUND,
      );
    }

    return latestWorkspaceMetadataVersion;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing workspace data sources, including connecting to data sources, checking schema existence, creating and deleting DB schemas, and executing raw queries.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { DataSource, EntityManager } from 'typeorm';

import { DataSourceService } from 'src/engine/metadata-modules/data-source/data-source.service';
import { TypeORMService } from 'src/database/typeorm/typeorm.service';
import { DataSourceEntity } from 'src/engine/metadata-modules/data-source/data-source.entity';

@Injectable()
export class WorkspaceDataSourceService {
  constructor(
    private readonly dataSourceService: DataSourceService,
    private readonly typeormService: TypeORMService,
  ) {}

  /**
   *
   * Connect to the workspace data source
   *
   * @param workspaceId
   * @returns
   */
  public async connectToWorkspaceDataSource(
    workspaceId: string,
  ): Promise<DataSource> {
    const { dataSource } =
      await this.connectedToWorkspaceDataSourceAndReturnMetadata(workspaceId);

    return dataSource;
  }

  public async checkSchemaExists(workspaceId: string) {
    const dataSource =
      await this.dataSourceService.getDataSourcesMetadataFromWorkspaceId(
        workspaceId,
      );

    return dataSource.length > 0;
  }

  public async connectedToWorkspaceDataSourceAndReturnMetadata(
    workspaceId: string,
  ): Promise<{ dataSource: DataSource; dataSourceMetadata: DataSourceEntity }> {
    const dataSourceMetadata =
      await this.dataSourceService.getLastDataSourceMetadataFromWorkspaceIdOrFail(
        workspaceId,
      );

    const dataSource =
      await this.typeormService.connectToDataSource(dataSourceMetadata);

    if (!dataSource) {
      throw new Error(
        `Could not connect to workspace data source for workspace ${workspaceId}`,
      );
    }

    return { dataSource, dataSourceMetadata };
  }

  /**
   *
   * Create a new DB schema for a workspace
   *
   * @param workspaceId
   * @returns
   */
  public async createWorkspaceDBSchema(workspaceId: string): Promise<string> {
    const schemaName = this.getSchemaName(workspaceId);

    return await this.typeormService.createSchema(schemaName);
  }

  /**
   *
   * Delete a DB schema for a workspace
   *
   * @param workspaceId
   * @returns
   */
  public async deleteWorkspaceDBSchema(workspaceId: string): Promise<void> {
    const schemaName = this.getSchemaName(workspaceId);

    return await this.typeormService.deleteSchema(schemaName);
  }

  /**
   *
   * Get the schema name for a workspace
   * Note: This is assuming that the workspace only has one schema but we should prefer querying the metadata table instead.
   *
   * @param workspaceId
   * @returns string
   */
  public getSchemaName(workspaceId: string): string {
    return `workspace_${this.uuidToBase36(workspaceId)}`;
  }

  /**
   *
   * Convert a uuid to base36
   *
   * @param uuid
   * @returns string
   */
  private uuidToBase36(uuid: string): string {
    let devId = false;

    if (uuid.startsWith('twenty-')) {
      devId = true;
      // Clean dev uuids (twenty-)
      uuid = uuid.replace('twenty-', '');
    }
    const hexString = uuid.replace(/-/g, '');
    const base10Number = BigInt('0x' + hexString);
    const base36String = base10Number.toString(36);

    return `${devId ? 'twenty_' : ''}${base36String}`;
  }

  public async executeRawQuery(
    query: string,
    parameters: any[] = [],
    workspaceId: string,
    transactionManager?: EntityManager,
  ): Promise<any> {
    try {
      if (transactionManager) {
        return await transactionManager.query(query, parameters);
      }
      const workspaceDataSource =
        await this.connectToWorkspaceDataSource(workspaceId);

      return await workspaceDataSource.query(query, parameters);
    } catch (error) {
      throw new Error(
        `Error executing raw query for workspace ${workspaceId}: ${error.message}`,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a RoleService class that interacts with a RoleEntity repository to manage roles within workspaces, including retrieving and creating roles with specific permissions.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { ADMIN_ROLE_LABEL } from 'src/engine/metadata-modules/permissions/constants/admin-role-label.constants';
import { MEMBER_ROLE_LABEL } from 'src/engine/metadata-modules/permissions/constants/member-role-label.constants';
import { RoleEntity } from 'src/engine/metadata-modules/role/role.entity';

export class RoleService {
  constructor(
    @InjectRepository(RoleEntity, 'metadata')
    private readonly roleRepository: Repository<RoleEntity>,
  ) {}

  public async getWorkspaceRoles(workspaceId: string): Promise<RoleEntity[]> {
    return this.roleRepository.find({
      where: {
        workspaceId,
      },
      relations: ['userWorkspaceRoles'],
    });
  }

  public async getRoleById(
    id: string,
    workspaceId: string,
  ): Promise<RoleEntity | null> {
    return this.roleRepository.findOne({
      where: {
        id,
        workspaceId,
      },
      relations: ['userWorkspaceRoles'],
    });
  }

  public async createAdminRole({
    workspaceId,
  }: {
    workspaceId: string;
  }): Promise<RoleEntity> {
    return this.roleRepository.save({
      label: ADMIN_ROLE_LABEL,
      description: 'Admin role',
      canUpdateAllSettings: true,
      canReadAllObjectRecords: true,
      canUpdateAllObjectRecords: true,
      canSoftDeleteAllObjectRecords: true,
      canDestroyAllObjectRecords: true,
      isEditable: false,
      workspaceId,
    });
  }

  public async createMemberRole({
    workspaceId,
  }: {
    workspaceId: string;
  }): Promise<RoleEntity> {
    return this.roleRepository.save({
      label: MEMBER_ROLE_LABEL,
      description: 'Member role',
      canUpdateAllSettings: false,
      canReadAllObjectRecords: true,
      canUpdateAllObjectRecords: true,
      canSoftDeleteAllObjectRecords: true,
      canDestroyAllObjectRecords: true,
      isEditable: false,
      workspaceId,
    });
  }

  // Only used for dev seeding and testing
  public async createGuestRole({
    workspaceId,
  }: {
    workspaceId: string;
  }): Promise<RoleEntity> {
    return this.roleRepository.save({
      label: 'Guest',
      description: 'Guest role',
      canUpdateAllSettings: false,
      canReadAllObjectRecords: true,
      canUpdateAllObjectRecords: false,
      canSoftDeleteAllObjectRecords: false,
      canDestroyAllObjectRecords: false,
      isEditable: false,
      workspaceId,
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: Defines a NestJS module for caching workspace metadata using TypeORM and a custom storage module.
Code Snippet:
import { Module } from '@nestjs/common';
import { TypeOrmModule } from '@nestjs/typeorm';

import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { WorkspaceMetadataCacheService } from 'src/engine/metadata-modules/workspace-metadata-cache/services/workspace-metadata-cache.service';
import { WorkspaceCacheStorageModule } from 'src/engine/workspace-cache-storage/workspace-cache-storage.module';

@Module({
  imports: [
    TypeOrmModule.forFeature([Workspace], 'core'),
    TypeOrmModule.forFeature([ObjectMetadataEntity], 'metadata'),
    WorkspaceCacheStorageModule,
  ],
  exports: [WorkspaceMetadataCacheService],
  providers: [WorkspaceMetadataCacheService],
})
export class WorkspaceMetadataCacheModule {}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to recompute and cache metadata for a workspace, ensuring that the cache is updated only when necessary and handling concurrency with locks.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { generateObjectMetadataMaps } from 'src/engine/metadata-modules/utils/generate-object-metadata-maps.util';
import {
  WorkspaceMetadataCacheException,
  WorkspaceMetadataCacheExceptionCode,
} from 'src/engine/metadata-modules/workspace-metadata-cache/exceptions/workspace-metadata-cache.exception';
import { WorkspaceCacheStorageService } from 'src/engine/workspace-cache-storage/workspace-cache-storage.service';

@Injectable()
export class WorkspaceMetadataCacheService {
  logger = new Logger(WorkspaceMetadataCacheService.name);

  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    private readonly workspaceCacheStorageService: WorkspaceCacheStorageService,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
  ) {}

  async recomputeMetadataCache({
    workspaceId,
    ignoreLock = false,
  }: {
    workspaceId: string;
    ignoreLock?: boolean;
  }): Promise<void> {
    const currentCacheVersion =
      await this.getMetadataVersionFromCache(workspaceId);

    const currentDatabaseVersion =
      await this.getMetadataVersionFromDatabase(workspaceId);

    if (currentDatabaseVersion === undefined) {
      throw new WorkspaceMetadataCacheException(
        'Metadata version not found in the database',
        WorkspaceMetadataCacheExceptionCode.METADATA_VERSION_NOT_FOUND,
      );
    }

    const isAlreadyCaching =
      await this.workspaceCacheStorageService.getObjectMetadataOngoingCachingLock(
        workspaceId,
        currentDatabaseVersion,
      );

    if (!ignoreLock && isAlreadyCaching) {
      return;
    }

    if (currentCacheVersion !== undefined) {
      this.workspaceCacheStorageService.flush(workspaceId, currentCacheVersion);
    }

    await this.workspaceCacheStorageService.addObjectMetadataCollectionOngoingCachingLock(
      workspaceId,
      currentDatabaseVersion,
    );

    await this.workspaceCacheStorageService.setMetadataVersion(
      workspaceId,
      currentDatabaseVersion,
    );

    const objectMetadataItems = await this.objectMetadataRepository.find({
      where: { workspaceId },
      relations: [
        'fields',
        'fields.fromRelationMetadata',
        'fields.toRelationMetadata',
        'indexMetadatas',
        'indexMetadatas.indexFieldMetadatas',
      ],
    });

    const freshObjectMetadataMaps =
      generateObjectMetadataMaps(objectMetadataItems);

    await this.workspaceCacheStorageService.setObjectMetadataMaps(
      workspaceId,
      currentDatabaseVersion,
      freshObjectMetadataMaps,
    );

    await this.workspaceCacheStorageService.removeObjectMetadataOngoingCachingLock(
      workspaceId,
      currentDatabaseVersion,
    );
  }

  private async getMetadataVersionFromDatabase(
    workspaceId: string,
  ): Promise<number | undefined> {
    const workspace = await this.workspaceRepository.findOne({
      where: { id: workspaceId },
    });

    return workspace?.metadataVersion;
  }

  private async getMetadataVersionFromCache(
    workspaceId: string,
  ): Promise<number | undefined> {
    return await this.workspaceCacheStorageService.getMetadataVersion(
      workspaceId,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service for managing data source metadata, including creating, retrieving, and deleting metadata entities associated with workspaces.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { FindManyOptions, Repository } from 'typeorm';

import {
  DataSourceException,
  DataSourceExceptionCode,
} from 'src/engine/metadata-modules/data-source/data-source.exception';

import { DataSourceEntity } from './data-source.entity';

@Injectable()
export class DataSourceService {
  constructor(
    @InjectRepository(DataSourceEntity, 'metadata')
    private readonly dataSourceMetadataRepository: Repository<DataSourceEntity>,
  ) {}

  async createDataSourceMetadata(
    workspaceId: string,
    workspaceSchema: string,
  ): Promise<DataSourceEntity> {
    // TODO: Double check if this is the correct way to do this
    const dataSource = await this.dataSourceMetadataRepository.findOne({
      where: { workspaceId },
    });

    if (dataSource) {
      return dataSource;
    }

    return this.dataSourceMetadataRepository.save({
      workspaceId,
      schema: workspaceSchema,
    });
  }

  async getManyDataSourceMetadata(
    options: FindManyOptions<DataSourceEntity> = {},
  ): Promise<DataSourceEntity[]> {
    return this.dataSourceMetadataRepository.find(options);
  }

  async getDataSourcesMetadataFromWorkspaceId(
    workspaceId: string,
  ): Promise<DataSourceEntity[]> {
    return this.dataSourceMetadataRepository.find({
      where: { workspaceId },
      order: { createdAt: 'DESC' },
    });
  }

  async getLastDataSourceMetadataFromWorkspaceId(
    workspaceId: string,
  ): Promise<DataSourceEntity | null> {
    return this.dataSourceMetadataRepository.findOne({
      where: { workspaceId },
      order: { createdAt: 'DESC' },
    });
  }

  async getLastDataSourceMetadataFromWorkspaceIdOrFail(
    workspaceId: string,
  ): Promise<DataSourceEntity> {
    try {
      return this.dataSourceMetadataRepository.findOneOrFail({
        where: { workspaceId },
        order: { createdAt: 'DESC' },
      });
    } catch (error) {
      throw new DataSourceException(
        `Data source not found for workspace ${workspaceId}: ${error}`,
        DataSourceExceptionCode.DATA_SOURCE_NOT_FOUND,
      );
    }
  }

  async delete(workspaceId: string): Promise<void> {
    await this.dataSourceMetadataRepository.delete({ workspaceId });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a service for managing workspace migrations, including retrieving, updating, creating, and deleting migrations.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { IsNull, Repository } from 'typeorm';

import {
  WorkspaceMigrationEntity,
  WorkspaceMigrationTableAction,
} from './workspace-migration.entity';

@Injectable()
export class WorkspaceMigrationService {
  constructor(
    @InjectRepository(WorkspaceMigrationEntity, 'metadata')
    private readonly workspaceMigrationRepository: Repository<WorkspaceMigrationEntity>,
  ) {}

  /**
   * Get all pending migrations for a given workspaceId
   *
   * @returns Promise<WorkspaceMigration[]>
   * @param workspaceId
   */
  public async getPendingMigrations(
    workspaceId: string,
  ): Promise<WorkspaceMigrationEntity[]> {
    const pendingMigrations = await this.workspaceMigrationRepository.find({
      order: { createdAt: 'ASC', name: 'ASC' },
      where: {
        appliedAt: IsNull(),
        workspaceId,
      },
    });

    const typeOrder = { delete: 1, update: 2, create: 3 };

    const getType = (name: string) =>
      name.split('-')[1] as keyof typeof typeOrder;

    return pendingMigrations.sort((a, b) => {
      if (a.createdAt.getTime() !== b.createdAt.getTime()) {
        return a.createdAt.getTime() - b.createdAt.getTime();
      }

      return (
        (typeOrder[getType(a.name)] || 4) - (typeOrder[getType(b.name)] || 4) ||
        a.name.localeCompare(b.name)
      );
    });
  }

  /**
   * Set appliedAt as current date for a given migration.
   * Should be called once the migration has been applied
   *
   * @param workspaceId
   * @param migration
   */
  public async setAppliedAtForMigration(
    workspaceId: string,
    migration: WorkspaceMigrationEntity,
  ) {
    await this.workspaceMigrationRepository.update(
      { id: migration.id, workspaceId },
      { appliedAt: new Date() },
    );
  }

  /**
   * Create a new pending migration for a given workspaceId and expected changes
   *
   * @param name
   * @param workspaceId
   * @param migrations
   */
  public async createCustomMigration(
    name: string,
    workspaceId: string,
    migrations: WorkspaceMigrationTableAction[],
  ) {
    return this.workspaceMigrationRepository.save({
      name,
      migrations,
      workspaceId,
      isCustom: true,
    });
  }

  public async deleteAllWithinWorkspace(workspaceId: string) {
    await this.workspaceMigrationRepository.delete({ workspaceId });
  }

  public async deleteById(id: string) {
    await this.workspaceMigrationRepository.delete({ id });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service that increments the metadata version of a workspace and updates the cache.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { WorkspaceMetadataCacheService } from 'src/engine/metadata-modules/workspace-metadata-cache/services/workspace-metadata-cache.service';
import {
  WorkspaceMetadataVersionException,
  WorkspaceMetadataVersionExceptionCode,
} from 'src/engine/metadata-modules/workspace-metadata-version/exceptions/workspace-metadata-version.exception';

@Injectable()
export class WorkspaceMetadataVersionService {
  logger = new Logger(WorkspaceMetadataCacheService.name);

  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    private readonly workspaceMetadataCacheService: WorkspaceMetadataCacheService,
  ) {}

  async incrementMetadataVersion(workspaceId: string): Promise<void> {
    const workspace = await this.workspaceRepository.findOne({
      where: { id: workspaceId },
    });

    const metadataVersion = workspace?.metadataVersion;

    if (metadataVersion === undefined) {
      throw new WorkspaceMetadataVersionException(
        'Metadata version not found',
        WorkspaceMetadataVersionExceptionCode.METADATA_VERSION_NOT_FOUND,
      );
    }

    const newMetadataVersion = metadataVersion + 1;

    await this.workspaceRepository.update(
      { id: workspaceId },
      { metadataVersion: newMetadataVersion },
    );

    await this.workspaceMetadataCacheService.recomputeMetadataCache({
      workspaceId,
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing feature flags, including checking if a feature is enabled, retrieving workspace feature flags, and enabling feature flags.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import { FeatureFlagMap } from 'src/engine/core-modules/feature-flag/interfaces/feature-flag-map.interface';

import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { FeatureFlag } from 'src/engine/core-modules/feature-flag/feature-flag.entity';

@Injectable()
export class FeatureFlagService {
  constructor(
    @InjectRepository(FeatureFlag, 'core')
    private readonly featureFlagRepository: Repository<FeatureFlag>,
  ) {}

  public async isFeatureEnabled(
    key: FeatureFlagKey,
    workspaceId: string,
  ): Promise<boolean> {
    const featureFlag = await this.featureFlagRepository.findOneBy({
      workspaceId,
      key,
      value: true,
    });

    return !!featureFlag?.value;
  }

  public async getWorkspaceFeatureFlags(
    workspaceId: string,
  ): Promise<FeatureFlag[]> {
    return this.featureFlagRepository.find({ where: { workspaceId } });
  }

  public async getWorkspaceFeatureFlagsMap(
    workspaceId: string,
  ): Promise<FeatureFlagMap> {
    const workspaceFeatureFlags =
      await this.getWorkspaceFeatureFlags(workspaceId);

    const workspaceFeatureFlagsMap = workspaceFeatureFlags.reduce(
      (result, currentFeatureFlag) => {
        result[currentFeatureFlag.key] = currentFeatureFlag.value;

        return result;
      },
      {} as FeatureFlagMap,
    );

    return workspaceFeatureFlagsMap;
  }

  public async enableFeatureFlags(
    keys: FeatureFlagKey[],
    workspaceId: string,
  ): Promise<void> {
    await this.featureFlagRepository.upsert(
      keys.map((key) => ({ workspaceId, key, value: true })),
      {
        conflictPaths: ['workspaceId', 'key'],
        skipUpdateIfNoValuesChanged: true,
      },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service class for managing key-value pairs with associated user and workspace IDs, supporting get, set, and delete operations.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { IsNull, Repository } from 'typeorm';

import {
  KeyValuePair,
  KeyValuePairType,
} from 'src/engine/core-modules/key-value-pair/key-value-pair.entity';

export class KeyValuePairService<
  KeyValueTypesMap extends Record<string, any> = Record<string, any>,
> {
  constructor(
    @InjectRepository(KeyValuePair, 'core')
    private readonly keyValuePairRepository: Repository<KeyValuePair>,
  ) {}

  async get<K extends keyof KeyValueTypesMap>({
    userId,
    workspaceId,
    type,
    key,
  }: {
    userId?: string | null;
    workspaceId?: string | null;
    type: KeyValuePairType;
    key?: Extract<K, string>;
  }): Promise<Array<KeyValueTypesMap[K]>> {
    const keyValuePairs = (await this.keyValuePairRepository.find({
      where: {
        ...(userId === undefined
          ? {}
          : userId === null
            ? { userId: IsNull() }
            : { userId }),
        ...(workspaceId === undefined
          ? {}
          : workspaceId === null
            ? { workspaceId: IsNull() }
            : { workspaceId }),
        ...(key === undefined ? {} : { key }),
        type,
      },
    })) as Array<KeyValueTypesMap[K]>;

    return keyValuePairs.map((keyValuePair) => ({
      ...keyValuePair,
      value: keyValuePair.value ?? keyValuePair.textValueDeprecated,
    }));
  }

  async set<K extends keyof KeyValueTypesMap>({
    userId,
    workspaceId,
    key,
    value,
    type,
  }: {
    userId?: string | null;
    workspaceId?: string | null;
    key: Extract<K, string>;
    value: KeyValueTypesMap[K];
    type: KeyValuePairType;
  }) {
    const upsertData = {
      userId,
      workspaceId,
      key,
      value,
      type,
    };

    const conflictPaths = Object.keys(upsertData).filter(
      (key) =>
        ['userId', 'workspaceId', 'key'].includes(key) &&
        upsertData[key] !== undefined,
    );

    const indexPredicate = !userId
      ? '"userId" is NULL'
      : !workspaceId
        ? '"workspaceId" is NULL'
        : undefined;

    await this.keyValuePairRepository.upsert(upsertData, {
      conflictPaths,
      indexPredicate,
    });
  }

  async delete({
    userId,
    workspaceId,
    type,
    key,
  }: {
    userId?: string | null;
    workspaceId?: string | null;
    type: KeyValuePairType;
    key: Extract<keyof KeyValueTypesMap, string>;
  }) {
    await this.keyValuePairRepository.delete({
      ...(userId === undefined
        ? {}
        : userId === null
          ? { userId: IsNull() }
          : { userId }),
      ...(workspaceId === undefined
        ? {}
        : workspaceId === null
          ? { workspaceId: IsNull() }
          : { workspaceId }),
      type,
      key,
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for checking and fixing health issues in a workspace's metadata and database schema.
Code Snippet:
import { Injectable, Logger, NotFoundException } from '@nestjs/common';
import { InjectDataSource } from '@nestjs/typeorm';

import { DataSource } from 'typeorm';

import { WorkspaceHealthFixKind } from 'src/engine/workspace-manager/workspace-health/interfaces/workspace-health-fix-kind.interface';
import { WorkspaceHealthIssue } from 'src/engine/workspace-manager/workspace-health/interfaces/workspace-health-issue.interface';
import {
  WorkspaceHealthMode,
  WorkspaceHealthOptions,
} from 'src/engine/workspace-manager/workspace-health/interfaces/workspace-health-options.interface';

import { TypeORMService } from 'src/database/typeorm/typeorm.service';
import { DataSourceService } from 'src/engine/metadata-modules/data-source/data-source.service';
import { ObjectMetadataService } from 'src/engine/metadata-modules/object-metadata/object-metadata.service';
import { WorkspaceMigrationEntity } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { computeObjectTargetTable } from 'src/engine/utils/compute-object-target-table.util';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';
import { DatabaseStructureService } from 'src/engine/workspace-manager/workspace-health/services/database-structure.service';
import { FieldMetadataHealthService } from 'src/engine/workspace-manager/workspace-health/services/field-metadata-health.service';
import { ObjectMetadataHealthService } from 'src/engine/workspace-manager/workspace-health/services/object-metadata-health.service';
import { RelationMetadataHealthService } from 'src/engine/workspace-manager/workspace-health/services/relation-metadata.health.service';
import { WorkspaceFixService } from 'src/engine/workspace-manager/workspace-health/services/workspace-fix.service';
import { WorkspaceMigrationRunnerService } from 'src/engine/workspace-manager/workspace-migration-runner/workspace-migration-runner.service';

@Injectable()
export class WorkspaceHealthService {
  private readonly logger = new Logger(WorkspaceHealthService.name);

  constructor(
    @InjectDataSource('metadata')
    private readonly metadataDataSource: DataSource,
    private readonly dataSourceService: DataSourceService,
    private readonly typeORMService: TypeORMService,
    private readonly objectMetadataService: ObjectMetadataService,
    private readonly databaseStructureService: DatabaseStructureService,
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
    private readonly objectMetadataHealthService: ObjectMetadataHealthService,
    private readonly fieldMetadataHealthService: FieldMetadataHealthService,
    private readonly relationMetadataHealthService: RelationMetadataHealthService,
    private readonly workspaceMigrationRunnerService: WorkspaceMigrationRunnerService,
    private readonly workspaceFixService: WorkspaceFixService,
  ) {}

  async healthCheck(
    workspaceId: string,
    options: WorkspaceHealthOptions = { mode: WorkspaceHealthMode.All },
  ): Promise<WorkspaceHealthIssue[]> {
    const schemaName =
      this.workspaceDataSourceService.getSchemaName(workspaceId);
    const issues: WorkspaceHealthIssue[] = [];

    const dataSourceMetadata =
      await this.dataSourceService.getLastDataSourceMetadataFromWorkspaceIdOrFail(
        workspaceId,
      );

    // Check if a data source exists for this workspace
    if (!dataSourceMetadata) {
      throw new NotFoundException(
        `DataSource for workspace id ${workspaceId} not found`,
      );
    }

    // Try to connect to the data source
    await this.typeORMService.connectToDataSource(dataSourceMetadata);

    const objectMetadataCollection =
      await this.objectMetadataService.findManyWithinWorkspace(workspaceId);

    // Check if object metadata exists for this workspace
    if (!objectMetadataCollection || objectMetadataCollection.length === 0) {
      throw new NotFoundException(`Workspace with id ${workspaceId} not found`);
    }

    for (const objectMetadata of objectMetadataCollection) {
      const tableName = computeObjectTargetTable(objectMetadata);
      const workspaceTableColumns =
        await this.databaseStructureService.getWorkspaceTableColumns(
          schemaName,
          tableName,
        );

      if (!workspaceTableColumns || workspaceTableColumns.length === 0) {
        throw new NotFoundException(
          `Table ${tableName} not found in schema ${schemaName}`,
        );
      }

      // Check object metadata health
      const objectIssues = await this.objectMetadataHealthService.healthCheck(
        schemaName,
        objectMetadata,
        options,
      );

      issues.push(...objectIssues);

      // Check fields metadata health
      const fieldIssues = await this.fieldMetadataHealthService.healthCheck(
        computeObjectTargetTable(objectMetadata),
        workspaceTableColumns,
        objectMetadata.fields,
        options,
      );

      issues.push(...fieldIssues);

      // Check relation metadata health
      const relationIssues = this.relationMetadataHealthService.healthCheck(
        workspaceTableColumns,
        objectMetadataCollection,
        objectMetadata,
        options,
      );

      issues.push(...relationIssues);
    }

    return issues;
  }

  async fixIssues(
    workspaceId: string,
    issues: WorkspaceHealthIssue[],
    options: {
      type: WorkspaceHealthFixKind;
      applyChanges?: boolean;
    },
  ): Promise<{
    workspaceMigrations: Partial<WorkspaceMigrationEntity>[];
    metadataEntities: unknown[];
  }> {
    let workspaceMigrations: Partial<WorkspaceMigrationEntity>[] = [];
    let metadataEntities: unknown[] = [];

    // Set default options
    options.applyChanges ??= true;

    const queryRunner = this.metadataDataSource.createQueryRunner();

    await queryRunner.connect();
    await queryRunner.startTransaction();

    const manager = queryRunner.manager;

    try {
      const workspaceMigrationRepository = manager.getRepository(
        WorkspaceMigrationEntity,
      );
      const objectMetadataCollection =
        await this.objectMetadataService.findManyWithinWorkspace(workspaceId);

      workspaceMigrations =
        await this.workspaceFixService.createWorkspaceMigrations(
          manager,
          objectMetadataCollection,
          options.type,
          issues,
        );

      metadataEntities = await this.workspaceFixService.createMetadataUpdates(
        manager,
        objectMetadataCollection,
        options.type,
        issues,
      );

      // Save workspace migrations into the database
      await workspaceMigrationRepository.save(workspaceMigrations);

      if (!options.applyChanges) {
        // Rollback transactions
        await queryRunner.rollbackTransaction();

        await queryRunner.release();

        return {
          workspaceMigrations,
          metadataEntities,
        };
      }

      // Commit the transaction
      await queryRunner.commitTransaction();

      // Apply pending migrations
      await this.workspaceMigrationRunnerService.executeMigrationFromPendingMigrations(
        workspaceId,
      );
    } catch (error) {
      await queryRunner.rollbackTransaction();
      this.logger.error('Fix of issues failed with:', error);
    } finally {
      await queryRunner.release();
    }

    return {
      workspaceMigrations,
      metadataEntities,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for synchronizing workspace metadata, including objects, fields, relations, and indexes, and applying migrations based on the differences detected.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';
import { InjectDataSource } from '@nestjs/typeorm';

import { DataSource, QueryFailedError } from 'typeorm';

import { WorkspaceSyncContext } from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/workspace-sync-context.interface';

import { FeatureFlagService } from 'src/engine/core-modules/feature-flag/services/feature-flag.service';
import { WorkspaceMetadataVersionService } from 'src/engine/metadata-modules/workspace-metadata-version/services/workspace-metadata-version.service';
import {
  WorkspaceMigrationEntity,
  WorkspaceMigrationTableActionType,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceMigrationRunnerService } from 'src/engine/workspace-manager/workspace-migration-runner/workspace-migration-runner.service';
import { WorkspaceSyncFieldMetadataService } from 'src/engine/workspace-manager/workspace-sync-metadata/services/workspace-sync-field-metadata.service';
import { WorkspaceSyncIndexMetadataService } from 'src/engine/workspace-manager/workspace-sync-metadata/services/workspace-sync-index-metadata.service';
import { WorkspaceSyncObjectMetadataIdentifiersService } from 'src/engine/workspace-manager/workspace-sync-metadata/services/workspace-sync-object-metadata-identifiers.service';
import { WorkspaceSyncObjectMetadataService } from 'src/engine/workspace-manager/workspace-sync-metadata/services/workspace-sync-object-metadata.service';
import { WorkspaceSyncRelationMetadataService } from 'src/engine/workspace-manager/workspace-sync-metadata/services/workspace-sync-relation-metadata.service';
import { WorkspaceSyncStorage } from 'src/engine/workspace-manager/workspace-sync-metadata/storage/workspace-sync.storage';

interface SynchronizeOptions {
  applyChanges?: boolean;
}

@Injectable()
export class WorkspaceSyncMetadataService {
  private readonly logger = new Logger(WorkspaceSyncMetadataService.name);

  constructor(
    @InjectDataSource('metadata')
    private readonly metadataDataSource: DataSource,
    private readonly featureFlagService: FeatureFlagService,
    private readonly workspaceMigrationRunnerService: WorkspaceMigrationRunnerService,
    private readonly workspaceSyncObjectMetadataService: WorkspaceSyncObjectMetadataService,
    private readonly workspaceSyncRelationMetadataService: WorkspaceSyncRelationMetadataService,
    private readonly workspaceSyncFieldMetadataService: WorkspaceSyncFieldMetadataService,
    private readonly workspaceSyncIndexMetadataService: WorkspaceSyncIndexMetadataService,
    private readonly workspaceSyncObjectMetadataIdentifiersService: WorkspaceSyncObjectMetadataIdentifiersService,
    private readonly workspaceMetadataVersionService: WorkspaceMetadataVersionService,
  ) {}

  /**
   *
   * Sync all standard objects and fields metadata for a given workspace and data source
   * This will update the metadata if it has changed and generate migrations based on the diff.
   *
   * @param context
   * @param options
   */
  public async synchronize(
    context: WorkspaceSyncContext,
    options: SynchronizeOptions = { applyChanges: true },
  ): Promise<{
    workspaceMigrations: WorkspaceMigrationEntity[];
    storage: WorkspaceSyncStorage;
  }> {
    let workspaceMigrations: WorkspaceMigrationEntity[] = [];
    const storage = new WorkspaceSyncStorage();
    const queryRunner = this.metadataDataSource.createQueryRunner();

    this.logger.log('Syncing standard objects and fields metadata');

    await queryRunner.connect();
    await queryRunner.startTransaction();

    const manager = queryRunner.manager;

    try {
      const workspaceMigrationRepository = manager.getRepository(
        WorkspaceMigrationEntity,
      );

      // Retrieve feature flags
      const workspaceFeatureFlagsMap =
        await this.featureFlagService.getWorkspaceFeatureFlagsMap(
          context.workspaceId,
        );

      this.logger.log('Syncing standard objects and fields metadata');

      // 1 - Sync standard objects

      const workspaceObjectMigrationsStart = performance.now();
      const workspaceObjectMigrations =
        await this.workspaceSyncObjectMetadataService.synchronize(
          context,
          manager,
          storage,
          workspaceFeatureFlagsMap,
        );

      const workspaceObjectMigrationsEnd = performance.now();

      this.logger.log(
        `Workspace object migrations took ${workspaceObjectMigrationsEnd - workspaceObjectMigrationsStart}ms`,
      );

      // 2 - Sync standard fields on standard and custom objects
      const workspaceFieldMigrationsStart = performance.now();
      const workspaceFieldMigrations =
        await this.workspaceSyncFieldMetadataService.synchronize(
          context,
          manager,
          storage,
          workspaceFeatureFlagsMap,
        );

      const workspaceFieldMigrationsEnd = performance.now();

      this.logger.log(
        `Workspace field migrations took ${workspaceFieldMigrationsEnd - workspaceFieldMigrationsStart}ms`,
      );

      // Merge object and field migrations during table creation
      const {
        objectMigrations: mergedObjectMigrations,
        fieldMigrations: mergedFieldMigrations,
      } = this.mergeMigrations({
        objectMigrations: workspaceObjectMigrations,
        fieldMigrations: workspaceFieldMigrations,
      });

      // 3 - Sync standard relations on standard and custom objects
      const workspaceRelationMigrationsStart = performance.now();
      const workspaceRelationMigrations =
        await this.workspaceSyncRelationMetadataService.synchronize(
          context,
          manager,
          storage,
          workspaceFeatureFlagsMap,
        );

      const workspaceRelationMigrationsEnd = performance.now();

      this.logger.log(
        `Workspace relation migrations took ${workspaceRelationMigrationsEnd - workspaceRelationMigrationsStart}ms`,
      );

      // 4 - Sync standard indexes on standard objects
      const workspaceIndexMigrationsStart = performance.now();
      const workspaceIndexMigrations =
        await this.workspaceSyncIndexMetadataService.synchronize(
          context,
          manager,
          storage,
          workspaceFeatureFlagsMap,
        );

      const workspaceIndexMigrationsEnd = performance.now();

      this.logger.log(
        `Workspace index migrations took ${workspaceIndexMigrationsEnd - workspaceIndexMigrationsStart}ms`,
      );

      // 5 - Sync standard object metadata identifiers, does not need to return nor apply migrations
      const workspaceObjectMetadataIdentifiersStart = performance.now();

      await this.workspaceSyncObjectMetadataIdentifiersService.synchronize(
        context,
        manager,
        storage,
        workspaceFeatureFlagsMap,
      );

      const workspaceObjectMetadataIdentifiersEnd = performance.now();

      this.logger.log(
        `Workspace object metadata identifiers took ${workspaceObjectMetadataIdentifiersEnd - workspaceObjectMetadataIdentifiersStart}ms`,
      );

      const workspaceMigrationsSaveStart = performance.now();

      // Save workspace migrations into the database
      workspaceMigrations = await workspaceMigrationRepository.save([
        ...mergedObjectMigrations,
        ...mergedFieldMigrations,
        ...workspaceRelationMigrations,
        ...workspaceIndexMigrations,
      ]);

      const workspaceMigrationsSaveEnd = performance.now();

      this.logger.log(
        `Workspace migrations save took ${workspaceMigrationsSaveEnd - workspaceMigrationsSaveStart}ms`,
      );

      // If we're running a dry run, rollback the transaction and do not execute migrations
      if (!options.applyChanges) {
        this.logger.log('Running in dry run mode, rolling back transaction');

        await queryRunner.rollbackTransaction();

        await queryRunner.release();

        return {
          workspaceMigrations,
          storage,
        };
      }

      await queryRunner.commitTransaction();

      // Execute migrations
      this.logger.log('Executing pending migrations');
      const executeMigrationsStart = performance.now();

      await this.workspaceMigrationRunnerService.executeMigrationFromPendingMigrations(
        context.workspaceId,
      );
      const executeMigrationsEnd = performance.now();

      this.logger.log(
        `Execute migrations took ${executeMigrationsEnd - executeMigrationsStart}ms`,
      );
    } catch (error) {
      this.logger.error('Sync of standard objects failed with:', error);

      if (error instanceof QueryFailedError && (error as any).detail) {
        this.logger.error((error as any).detail);
      }
      await queryRunner.rollbackTransaction();
    } finally {
      await queryRunner.release();
      await this.workspaceMetadataVersionService.incrementMetadataVersion(
        context.workspaceId,
      );
    }

    return {
      workspaceMigrations,
      storage,
    };
  }

  private mergeMigrations({
    objectMigrations,
    fieldMigrations,
  }: {
    objectMigrations: Partial<WorkspaceMigrationEntity>[];
    fieldMigrations: Partial<WorkspaceMigrationEntity>[];
  }): {
    objectMigrations: Partial<WorkspaceMigrationEntity>[];
    fieldMigrations: Partial<WorkspaceMigrationEntity>[];
  } {
    const createMigrationsByTable = new Map<string, any>();

    for (const objectMigration of objectMigrations) {
      if (
        !objectMigration.migrations ||
        objectMigration.migrations.length === 0
      )
        continue;

      const tableMigration = objectMigration.migrations[0];

      if (tableMigration.action === WorkspaceMigrationTableActionType.CREATE) {
        createMigrationsByTable.set(tableMigration.name, tableMigration);
      }
    }

    const fieldMigrationsWithoutTableCreation = fieldMigrations.filter(
      (fieldMigration) => {
        if (
          !fieldMigration.migrations ||
          fieldMigration.migrations.length === 0
        )
          return true;

        const tableMigration = fieldMigration.migrations[0];
        const tableName = tableMigration.name;

        if (createMigrationsByTable.has(tableName)) {
          const createMigration = createMigrationsByTable.get(tableName);

          if (tableMigration.columns?.length) {
            createMigration.columns = createMigration.columns || [];
            createMigration.columns.push(...tableMigration.columns);
          }

          return false;
        }

        return true;
      },
    );

    return {
      objectMigrations,
      fieldMigrations: fieldMigrationsWithoutTableCreation,
    };
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_6>



=== New Entry ===

<CLUSTER_7>
Number of Code Snippets part of this cluster: 13
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code seeds a workspace with initial data for development purposes using TypeORM and a variety of seed functions.
Code Snippet:
import { Logger } from '@nestjs/common';

import { Command, CommandRunner } from 'nest-commander';
import { DataSource, EntityManager } from 'typeorm';

import { seedCoreSchema } from 'src/database/typeorm-seeds/core';
import {
  SEED_ACME_WORKSPACE_ID,
  SEED_APPLE_WORKSPACE_ID,
} from 'src/database/typeorm-seeds/core/workspaces';
import {
  getDevSeedCompanyCustomFields,
  getDevSeedPeopleCustomFields,
} from 'src/database/typeorm-seeds/metadata/fieldsMetadata';
import { seedCalendarChannels } from 'src/database/typeorm-seeds/workspace/calendar-channel';
import { seedCalendarChannelEventAssociations } from 'src/database/typeorm-seeds/workspace/calendar-channel-event-association';
import { seedCalendarEventParticipants } from 'src/database/typeorm-seeds/workspace/calendar-event-participants';
import { seedCalendarEvents } from 'src/database/typeorm-seeds/workspace/calendar-events';
import { seedCompanies } from 'src/database/typeorm-seeds/workspace/companies';
import { seedConnectedAccount } from 'src/database/typeorm-seeds/workspace/connected-account';
import { seedWorkspaceFavorites } from 'src/database/typeorm-seeds/workspace/favorites';
import { seedMessageChannelMessageAssociation } from 'src/database/typeorm-seeds/workspace/message-channel-message-associations';
import { seedMessageChannel } from 'src/database/typeorm-seeds/workspace/message-channels';
import { seedMessageParticipant } from 'src/database/typeorm-seeds/workspace/message-participants';
import { seedMessageThread } from 'src/database/typeorm-seeds/workspace/message-threads';
import { seedMessage } from 'src/database/typeorm-seeds/workspace/messages';
import { seedOpportunity } from 'src/database/typeorm-seeds/workspace/opportunities';
import { seedPeople } from 'src/database/typeorm-seeds/workspace/seedPeople';
import { seedWorkspaceMember } from 'src/database/typeorm-seeds/workspace/workspace-members';
import { rawDataSource } from 'src/database/typeorm/raw/raw.datasource';
import { TypeORMService } from 'src/database/typeorm/typeorm.service';
import { InjectCacheStorage } from 'src/engine/core-modules/cache-storage/decorators/cache-storage.decorator';
import { CacheStorageService } from 'src/engine/core-modules/cache-storage/services/cache-storage.service';
import { CacheStorageNamespace } from 'src/engine/core-modules/cache-storage/types/cache-storage-namespace.enum';
import { DataSourceEntity } from 'src/engine/metadata-modules/data-source/data-source.entity';
import { DataSourceService } from 'src/engine/metadata-modules/data-source/data-source.service';
import { FieldMetadataService } from 'src/engine/metadata-modules/field-metadata/field-metadata.service';
import { ObjectMetadataService } from 'src/engine/metadata-modules/object-metadata/object-metadata.service';
import { PETS_DATA_SEEDS } from 'src/engine/seeder/data-seeds/pets-data-seeds';
import { SURVEY_RESULTS_DATA_SEEDS } from 'src/engine/seeder/data-seeds/survey-results-data-seeds';
import { PETS_METADATA_SEEDS } from 'src/engine/seeder/metadata-seeds/pets-metadata-seeds';
import { SURVEY_RESULTS_METADATA_SEEDS } from 'src/engine/seeder/metadata-seeds/survey-results-metadata-seeds';
import { SeederService } from 'src/engine/seeder/seeder.service';
import { shouldSeedWorkspaceFavorite } from 'src/engine/utils/should-seed-workspace-favorite';
import { createWorkspaceViews } from 'src/engine/workspace-manager/standard-objects-prefill-data/create-workspace-views';
import { seedViewWithDemoData } from 'src/engine/workspace-manager/standard-objects-prefill-data/seed-view-with-demo-data';
import { opportunitiesTableByStageView } from 'src/engine/workspace-manager/standard-objects-prefill-data/views/opportunity-table-by-stage.view';
import { WorkspaceManagerService } from 'src/engine/workspace-manager/workspace-manager.service';
import { STANDARD_OBJECT_IDS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-object-ids';

// TODO: implement dry-run
@Command({
  name: 'workspace:seed:dev',
  description:
    'Seed workspace with initial data. This command is intended for development only.',
})
export class DataSeedWorkspaceCommand extends CommandRunner {
  workspaceIds = [SEED_APPLE_WORKSPACE_ID, SEED_ACME_WORKSPACE_ID];
  private readonly logger = new Logger(DataSeedWorkspaceCommand.name);

  constructor(
    private readonly dataSourceService: DataSourceService,
    private readonly typeORMService: TypeORMService,
    private readonly fieldMetadataService: FieldMetadataService,
    private readonly objectMetadataService: ObjectMetadataService,
    @InjectCacheStorage(CacheStorageNamespace.EngineWorkspace)
    private readonly workspaceSchemaCache: CacheStorageService,
    private readonly seederService: SeederService,
    private readonly workspaceManagerService: WorkspaceManagerService,
  ) {
    super();
  }

  async run(): Promise<void> {
    try {
      for (const workspaceId of this.workspaceIds) {
        await this.createWorkspaceSchema(workspaceId);
      }
    } catch (error) {
      this.logger.error(error);

      return;
    }

    for (const workspaceId of this.workspaceIds) {
      await this.seedWorkspace(workspaceId);
    }
  }

  async createWorkspaceSchema(workspaceId: string) {
    await this.workspaceSchemaCache.flush();

    await rawDataSource.initialize();

    await seedCoreSchema(rawDataSource, workspaceId);

    await rawDataSource.destroy();

    await this.workspaceManagerService.initDev(workspaceId);
  }

  async seedWorkspace(workspaceId: string) {
    const dataSourceMetadata =
      await this.dataSourceService.getLastDataSourceMetadataFromWorkspaceIdOrFail(
        workspaceId,
      );

    const workspaceDataSource =
      await this.typeORMService.connectToDataSource(dataSourceMetadata);

    if (!workspaceDataSource) {
      throw new Error('Could not connect to workspace data source');
    }

    try {
      const { objectMetadataStandardIdToIdMap } =
        await this.objectMetadataService.getObjectMetadataStandardIdToIdMap(
          workspaceId,
        );

      await this.seedCompanyCustomFields(
        objectMetadataStandardIdToIdMap[STANDARD_OBJECT_IDS.company].id,
        workspaceId,
      );

      await this.seedPeopleCustomFields(
        objectMetadataStandardIdToIdMap[STANDARD_OBJECT_IDS.person].id,
        workspaceId,
      );

      await this.seedStandardObjectRecords(
        workspaceDataSource,
        dataSourceMetadata,
      );

      await this.seederService.seedCustomObjects(
        dataSourceMetadata.id,
        workspaceId,
        PETS_METADATA_SEEDS,
        PETS_DATA_SEEDS,
      );

      await this.seederService.seedCustomObjects(
        dataSourceMetadata.id,
        workspaceId,
        SURVEY_RESULTS_METADATA_SEEDS,
        SURVEY_RESULTS_DATA_SEEDS,
      );
    } catch (error) {
      this.logger.error(error);
    }

    await this.typeORMService.disconnectFromDataSource(dataSourceMetadata.id);
  }

  async seedStandardObjectRecords(
    workspaceDataSource: DataSource,
    dataSourceMetadata: DataSourceEntity,
  ) {
    await workspaceDataSource.transaction(
      async (entityManager: EntityManager) => {
        const { objectMetadataStandardIdToIdMap } =
          await this.objectMetadataService.getObjectMetadataStandardIdToIdMap(
            dataSourceMetadata.workspaceId,
          );

        await seedCompanies(entityManager, dataSourceMetadata.schema);
        await seedPeople(entityManager, dataSourceMetadata.schema);
        await seedOpportunity(entityManager, dataSourceMetadata.schema);
        await seedWorkspaceMember(
          entityManager,
          dataSourceMetadata.schema,
          dataSourceMetadata.workspaceId,
        );

        if (dataSourceMetadata.workspaceId === SEED_APPLE_WORKSPACE_ID) {
          await seedMessageThread(entityManager, dataSourceMetadata.schema);
          await seedConnectedAccount(entityManager, dataSourceMetadata.schema);

          await seedMessage(entityManager, dataSourceMetadata.schema);
          await seedMessageChannel(entityManager, dataSourceMetadata.schema);
          await seedMessageChannelMessageAssociation(
            entityManager,
            dataSourceMetadata.schema,
          );
          await seedMessageParticipant(
            entityManager,
            dataSourceMetadata.schema,
          );

          await seedCalendarEvents(entityManager, dataSourceMetadata.schema);
          await seedCalendarChannels(entityManager, dataSourceMetadata.schema);
          await seedCalendarChannelEventAssociations(
            entityManager,
            dataSourceMetadata.schema,
          );
          await seedCalendarEventParticipants(
            entityManager,
            dataSourceMetadata.schema,
          );
        }

        const viewDefinitionsWithId = await seedViewWithDemoData(
          entityManager,
          dataSourceMetadata.schema,
          objectMetadataStandardIdToIdMap,
        );

        const devViewDefinitionsWithId = await createWorkspaceViews(
          entityManager,
          dataSourceMetadata.schema,
          [opportunitiesTableByStageView(objectMetadataStandardIdToIdMap)],
        );

        viewDefinitionsWithId.push(...devViewDefinitionsWithId);

        await seedWorkspaceFavorites(
          viewDefinitionsWithId
            .filter(
              (view) =>
                view.key === 'INDEX' &&
                shouldSeedWorkspaceFavorite(
                  view.objectMetadataId,
                  objectMetadataStandardIdToIdMap,
                ),
            )
            .map((view) => view.id),
          entityManager,
          dataSourceMetadata.schema,
        );
      },
    );
  }

  async seedCompanyCustomFields(
    companyObjectMetadataId: string,
    workspaceId: string,
  ) {
    if (!companyObjectMetadataId) {
      throw new Error(
        `Company object metadata not found for workspace ${workspaceId}, can't seed custom fields`,
      );
    }

    const DEV_SEED_COMPANY_CUSTOM_FIELDS = getDevSeedCompanyCustomFields(
      companyObjectMetadataId,
      workspaceId,
    );

    await this.fieldMetadataService.createMany(
      DEV_SEED_COMPANY_CUSTOM_FIELDS.map((customField) => ({
        ...customField,
        isCustom: true,
      })),
    );
  }

  async seedPeopleCustomFields(
    personObjectMetadataId: string,
    workspaceId: string,
  ) {
    if (!personObjectMetadataId) {
      throw new Error(
        `Person object metadata not found for workspace ${workspaceId}, can't seed custom fields`,
      );
    }

    const DEV_SEED_PERSON_CUSTOM_FIELDS = getDevSeedPeopleCustomFields(
      personObjectMetadataId,
      workspaceId,
    );

    await this.fieldMetadataService.createMany(
      DEV_SEED_PERSON_CUSTOM_FIELDS.map((customField) => ({
        ...customField,
        isCustom: true,
      })),
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to add a 'Tasks Assigned to Me' view in workspaces, interacting with various metadata and view entities.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import chalk from 'chalk';
import { Command } from 'nest-commander';
import { Repository } from 'typeorm';
import { v4 } from 'uuid';

import {
  ActiveOrSuspendedWorkspacesMigrationCommandRunner,
  RunOnWorkspaceArgs,
} from 'src/database/commands/command-runners/active-or-suspended-workspaces-migration.command-runner';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { FieldMetadataDefaultOption } from 'src/engine/metadata-modules/field-metadata/dtos/options.input';
import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { WorkspaceMetadataVersionService } from 'src/engine/metadata-modules/workspace-metadata-version/services/workspace-metadata-version.service';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { tasksAssignedToMeView } from 'src/engine/workspace-manager/standard-objects-prefill-data/views/tasks-assigned-to-me';
import { TASK_STANDARD_FIELD_IDS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-field-ids';
import { STANDARD_OBJECT_IDS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-object-ids';
import { ViewFieldWorkspaceEntity } from 'src/modules/view/standard-objects/view-field.workspace-entity';
import { ViewFilterWorkspaceEntity } from 'src/modules/view/standard-objects/view-filter.workspace-entity';
import { ViewGroupWorkspaceEntity } from 'src/modules/view/standard-objects/view-group.workspace-entity';
import { ViewWorkspaceEntity } from 'src/modules/view/standard-objects/view.workspace-entity';

@Command({
  name: 'upgrade:0-43:add-tasks-assigned-to-me-view',
  description: 'Add tasks assigned to me view',
})
export class AddTasksAssignedToMeViewCommand extends ActiveOrSuspendedWorkspacesMigrationCommandRunner {
  constructor(
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    @InjectRepository(FieldMetadataEntity, 'metadata')
    private readonly fieldMetadataRepository: Repository<FieldMetadataEntity>,
    protected readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    private readonly workspaceMetadataVersionService: WorkspaceMetadataVersionService,
  ) {
    super(workspaceRepository, twentyORMGlobalManager);
  }

  override async runOnWorkspace({
    index,
    total,
    workspaceId,
  }: RunOnWorkspaceArgs): Promise<void> {
    this.logger.log(
      `Running command for workspace ${workspaceId} ${index + 1}/${total}`,
    );

    await this.createTasksAssignedToMeView(workspaceId);

    this.logger.log(
      chalk.green(`Command completed for workspace ${workspaceId}.`),
    );
  }

  private async createTasksAssignedToMeView(
    workspaceId: string,
  ): Promise<void> {
    const objectMetadata = await this.objectMetadataRepository.find({
      where: { workspaceId },
      relations: ['fields'],
    });

    const objectMetadataMap = objectMetadata.reduce((acc, object) => {
      acc[object.standardId ?? ''] = {
        id: object.id,
        fields: object.fields.reduce((acc, field) => {
          acc[field.standardId ?? ''] = field.id;

          return acc;
        }, {}),
      };

      return acc;
    }, {});

    const taskObjectMetadata = objectMetadata.find(
      (object) => object.standardId === STANDARD_OBJECT_IDS.task,
    );

    if (!taskObjectMetadata) {
      throw new Error(`Task object not found for workspace ${workspaceId}`);
    }

    const viewRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace<ViewWorkspaceEntity>(
        workspaceId,
        'view',
        false,
      );

    const existingView = await viewRepository.findOne({
      where: {
        name: 'Assigned to Me',
        objectMetadataId: taskObjectMetadata.id,
      },
    });

    if (existingView) {
      this.logger.log(
        chalk.yellow(
          `"Assigned to Me" view already exists for workspace ${workspaceId}`,
        ),
      );

      return;
    }

    const viewDefinition = tasksAssignedToMeView(objectMetadataMap);
    const viewId = v4();

    const insertedView = await viewRepository.save({
      id: viewId,
      name: viewDefinition.name,
      objectMetadataId: viewDefinition.objectMetadataId,
      type: viewDefinition.type,
      position: viewDefinition.position,
      icon: viewDefinition.icon,
      kanbanFieldMetadataId: viewDefinition.kanbanFieldMetadataId,
    });

    if (viewDefinition.fields && viewDefinition.fields.length > 0) {
      const viewFieldRepository =
        await this.twentyORMGlobalManager.getRepositoryForWorkspace<ViewFieldWorkspaceEntity>(
          workspaceId,
          'viewField',
          false,
        );

      const viewFields = viewDefinition.fields.map((field) => ({
        fieldMetadataId: field.fieldMetadataId,
        position: field.position,
        isVisible: field.isVisible,
        size: field.size,
        viewId: insertedView.id,
      }));

      await viewFieldRepository.save(viewFields);
    }

    if (viewDefinition.filters && viewDefinition.filters.length > 0) {
      const viewFilterRepository =
        await this.twentyORMGlobalManager.getRepositoryForWorkspace<ViewFilterWorkspaceEntity>(
          workspaceId,
          'viewFilter',
          false,
        );

      const viewFilters = viewDefinition.filters.map((filter) => ({
        fieldMetadataId: filter.fieldMetadataId,
        displayValue: filter.displayValue,
        operand: filter.operand,
        value: filter.value,
        viewId: insertedView.id,
      }));

      await viewFilterRepository.save(viewFilters);
    }

    await this.createTasksAssignedToMeViewGroups(workspaceId, insertedView.id);
  }

  private async createTasksAssignedToMeViewGroups(
    workspaceId: string,
    viewId: string,
  ) {
    const taskStatusFieldMetadata = await this.fieldMetadataRepository.findOne({
      where: {
        workspaceId,
        standardId: TASK_STANDARD_FIELD_IDS.status,
      },
    });

    if (!taskStatusFieldMetadata) {
      throw new Error(
        `Task status field metadata not found for workspace ${workspaceId}`,
      );
    }

    const optionValueViewGroups = taskStatusFieldMetadata.options.map(
      (taskStatusOption: FieldMetadataDefaultOption, index) =>
        ({
          fieldMetadataId: taskStatusFieldMetadata.id,
          viewId,
          fieldValue: taskStatusOption.value,
          position: index,
        }) satisfies Partial<ViewGroupWorkspaceEntity>,
    );

    const noValueViewGroup: Partial<ViewGroupWorkspaceEntity> = {
      fieldMetadataId: taskStatusFieldMetadata.id,
      viewId,
      fieldValue: '',
      position: optionValueViewGroups.length,
    };

    const viewGroups = [...optionValueViewGroups, noValueViewGroup];

    const viewGroupRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace<ViewGroupWorkspaceEntity>(
        workspaceId,
        'viewGroup',
        false,
      );

    await viewGroupRepository.insert(viewGroups);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to migrate RICH_TEXT content from version 1 to version 2 in workspaces, updating the content to new columns for Blocknote and Markdown.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { ServerBlockNoteEditor } from '@blocknote/server-util';
import chalk from 'chalk';
import { Command } from 'nest-commander';
import { FieldMetadataType } from 'twenty-shared';
import { Repository } from 'typeorm';

import {
  ActiveOrSuspendedWorkspacesMigrationCommandOptions,
  ActiveOrSuspendedWorkspacesMigrationCommandRunner,
  RunOnWorkspaceArgs,
} from 'src/database/commands/command-runners/active-or-suspended-workspaces-migration.command-runner';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { FeatureFlag } from 'src/engine/core-modules/feature-flag/feature-flag.entity';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { computeTableName } from 'src/engine/utils/compute-table-name.util';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';

type MigrateRichTextContentArgs = {
  richTextFieldsWithObjectMetadata: RichTextFieldsWithObjectMetadata[];
  workspaceId: string;
  options: ActiveOrSuspendedWorkspacesMigrationCommandOptions;
};

type RichTextFieldsWithObjectMetadata = {
  richTextField: FieldMetadataEntity;
  objectMetadata: ObjectMetadataEntity | null;
};

type ProcessRichTextFieldsArgs = {
  richTextFields: FieldMetadataEntity[];
  workspaceId: string;
};

@Command({
  name: 'upgrade:0-43:migrate-rich-text-content-patch',
  description: 'Migrate RICH_TEXT content from v1 to v2',
})
export class MigrateRichTextContentPatchCommand extends ActiveOrSuspendedWorkspacesMigrationCommandRunner {
  constructor(
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    protected readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    @InjectRepository(FieldMetadataEntity, 'metadata')
    private readonly fieldMetadataRepository: Repository<FieldMetadataEntity>,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    @InjectRepository(FeatureFlag, 'core')
    protected readonly featureFlagRepository: Repository<FeatureFlag>,
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
  ) {
    super(workspaceRepository, twentyORMGlobalManager);
  }

  override async runOnWorkspace({
    index,
    total,
    options,
    workspaceId,
  }: RunOnWorkspaceArgs): Promise<void> {
    this.logger.log(
      `Running MigrateRichTextContentPatchCommand for workspace ${workspaceId} ${index + 1}/${total}`,
    );

    if (await this.hasRichTextV2FeatureFlag(workspaceId)) {
      this.logger.log(
        chalk.yellow(
          'Rich text v2 feature flag is enabled, skipping migration',
        ),
      );

      return;
    }

    const richTextFields = await this.fieldMetadataRepository.find({
      where: {
        workspaceId,
        type: FieldMetadataType.RICH_TEXT,
      },
    });

    if (!richTextFields.length) {
      this.logger.log(
        chalk.yellow('No RICH_TEXT fields found in this workspace'),
      );

      return;
    }

    this.logger.log(`Found ${richTextFields.length} RICH_TEXT fields`);

    const richTextFieldsWithObjectMetadata =
      await this.getRichTextFieldsWithObjectMetadata({
        richTextFields,
        workspaceId,
      });

    await this.migrateToNewRichTextFieldsColumn({
      richTextFieldsWithObjectMetadata,
      workspaceId,
      options,
    });

    this.logger.log(
      chalk.green(`Command completed for workspace ${workspaceId}`),
    );
  }

  private async hasRichTextV2FeatureFlag(
    workspaceId: string,
  ): Promise<boolean> {
    return await this.featureFlagRepository.exists({
      where: {
        workspaceId,
        key: 'IS_RICH_TEXT_V2_ENABLED' as FeatureFlagKey,
        value: true,
      },
    });
  }

  private async getRichTextFieldsWithObjectMetadata({
    richTextFields,
    workspaceId,
  }: ProcessRichTextFieldsArgs): Promise<RichTextFieldsWithObjectMetadata[]> {
    const richTextFieldsWithObjectMetadata: RichTextFieldsWithObjectMetadata[] =
      [];

    for (const richTextField of richTextFields) {
      const objectMetadata = await this.objectMetadataRepository.findOne({
        where: { id: richTextField.objectMetadataId },
        relations: {
          fields: true,
        },
      });

      if (objectMetadata === null) {
        this.logger.log(
          `Object metadata not found for rich text field ${richTextField.name} in workspace ${workspaceId}`,
        );
      }

      richTextFieldsWithObjectMetadata.push({
        richTextField,
        objectMetadata,
      });
    }

    return richTextFieldsWithObjectMetadata;
  }

  private jsonParseOrSilentlyFail(input: string): null | unknown {
    try {
      return JSON.parse(input);
    } catch (e) {
      return null;
    }
  }

  private async getMarkdownFieldValue({
    blocknoteFieldValue,
    serverBlockNoteEditor,
  }: {
    blocknoteFieldValue: string | null;
    serverBlockNoteEditor: ServerBlockNoteEditor;
  }): Promise<string | null> {
    const blocknoteFieldValueIsDefined =
      blocknoteFieldValue !== null &&
      blocknoteFieldValue !== undefined &&
      blocknoteFieldValue !== '{}';

    if (!blocknoteFieldValueIsDefined) {
      return null;
    }

    const jsonParsedblocknoteFieldValue =
      this.jsonParseOrSilentlyFail(blocknoteFieldValue);

    if (jsonParsedblocknoteFieldValue === null) {
      return null;
    }

    if (!Array.isArray(jsonParsedblocknoteFieldValue)) {
      this.logger.log(
        `blocknoteFieldValue is defined and is not an array got ${blocknoteFieldValue}`,
      );

      return null;
    }

    let markdown: string | null = null;

    try {
      markdown = await serverBlockNoteEditor.blocksToMarkdownLossy(
        jsonParsedblocknoteFieldValue,
      );
    } catch (error) {
      this.logger.log(
        `Error converting blocknote to markdown for ${blocknoteFieldValue}`,
      );
    }

    return markdown;
  }

  private async migrateToNewRichTextFieldsColumn({
    richTextFieldsWithObjectMetadata,
    workspaceId,
    options,
  }: MigrateRichTextContentArgs) {
    const serverBlockNoteEditor = ServerBlockNoteEditor.create();

    for (const {
      richTextField,
      objectMetadata,
    } of richTextFieldsWithObjectMetadata) {
      if (objectMetadata === null) {
        this.logger.log(
          `Object metadata not found for rich text field ${richTextField.name} in workspace ${workspaceId}`,
        );
        continue;
      }

      const schemaName =
        this.workspaceDataSourceService.getSchemaName(workspaceId);

      const failOnMetadataCacheMiss = false;
      const workspaceDataSource =
        await this.twentyORMGlobalManager.getDataSourceForWorkspace(
          workspaceId,
          failOnMetadataCacheMiss,
        );

      const rows = await workspaceDataSource.query(
        `SELECT id, "${richTextField.name}" FROM "${schemaName}"."${computeTableName(objectMetadata.nameSingular, objectMetadata.isCustom)}" WHERE "${richTextField.name}" IS NOT NULL`,
      );

      this.logger.log(`Generating markdown for ${rows.length} records`);

      for (const row of rows) {
        const blocknoteFieldValue = row[richTextField.name];
        const markdownFieldValue = await this.getMarkdownFieldValue({
          blocknoteFieldValue,
          serverBlockNoteEditor,
        });

        if (!options.dryRun) {
          try {
            await workspaceDataSource.query(
              `UPDATE "${schemaName}"."${computeTableName(objectMetadata.nameSingular, objectMetadata.isCustom)}" SET "${richTextField.name}V2Blocknote" = $1, "${richTextField.name}V2Markdown" = $2 WHERE id = $3`,
              [blocknoteFieldValue, markdownFieldValue, row.id],
            );
          } catch (error) {
            this.logger.log(
              chalk.red(
                `Error updating rich text field ${richTextField.name} for record ${row.id} in workspace ${workspaceId}`,
              ),
            );
          }
        }
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a NestJS command to migrate search vectors on note and task entities for workspaces.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { Command } from 'nest-commander';
import { Repository } from 'typeorm';

import {
  ActiveOrSuspendedWorkspacesMigrationCommandRunner,
  RunOnWorkspaceArgs,
} from 'src/database/commands/command-runners/active-or-suspended-workspaces-migration.command-runner';
import { FeatureFlag } from 'src/engine/core-modules/feature-flag/feature-flag.entity';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { SearchService } from 'src/engine/metadata-modules/search/search.service';
import { WorkspaceMetadataVersionService } from 'src/engine/metadata-modules/workspace-metadata-version/services/workspace-metadata-version.service';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { WorkspaceMigrationRunnerService } from 'src/engine/workspace-manager/workspace-migration-runner/workspace-migration-runner.service';
import { SEARCH_FIELDS_FOR_NOTES } from 'src/modules/note/standard-objects/note.workspace-entity';
import { SEARCH_FIELDS_FOR_TASKS } from 'src/modules/task/standard-objects/task.workspace-entity';

@Command({
  name: 'upgrade:0-43:migrate-search-vector-on-note-and-task-entities',
  description: 'Migrate search vector on note and task entities',
})
export class MigrateSearchVectorOnNoteAndTaskEntitiesCommand extends ActiveOrSuspendedWorkspacesMigrationCommandRunner {
  constructor(
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    protected readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    @InjectRepository(FeatureFlag, 'core')
    protected readonly featureFlagRepository: Repository<FeatureFlag>,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    protected readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    private readonly searchService: SearchService,
    private readonly workspaceMigrationRunnerService: WorkspaceMigrationRunnerService,
    private readonly workspaceMetadataVersionService: WorkspaceMetadataVersionService,
  ) {
    super(workspaceRepository, twentyORMGlobalManager);
  }

  override async runOnWorkspace({
    index,
    total,
    workspaceId,
    options,
  }: RunOnWorkspaceArgs): Promise<void> {
    this.logger.log(
      `Running command for workspace ${workspaceId} ${index + 1}/${total}`,
    );

    const noteObjectMetadata =
      await this.objectMetadataRepository.findOneOrFail({
        select: ['id'],
        where: {
          workspaceId,
          nameSingular: 'note',
        },
      });

    if (!options.dryRun) {
      await this.searchService.updateSearchVector(
        noteObjectMetadata.id,
        SEARCH_FIELDS_FOR_NOTES,
        workspaceId,
      );
    }

    const taskObjectMetadata =
      await this.objectMetadataRepository.findOneOrFail({
        select: ['id'],
        where: {
          workspaceId,
          nameSingular: 'task',
        },
      });

    if (!options.dryRun) {
      await this.searchService.updateSearchVector(
        taskObjectMetadata.id,
        SEARCH_FIELDS_FOR_TASKS,
        workspaceId,
      );
    }

    await this.workspaceMigrationRunnerService.executeMigrationFromPendingMigrations(
      workspaceId,
    );

    await this.workspaceMetadataVersionService.incrementMetadataVersion(
      workspaceId,
    );

    this.logger.log(
      `Migrated search vector on note and task entities for workspace ${workspaceId}`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to update default view record opening for workflow objects in workspaces.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import chalk from 'chalk';
import { Command } from 'nest-commander';
import { In, Repository } from 'typeorm';

import {
  ActiveOrSuspendedWorkspacesMigrationCommandRunner,
  RunOnWorkspaceArgs,
} from 'src/database/commands/command-runners/active-or-suspended-workspaces-migration.command-runner';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { STANDARD_OBJECT_IDS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-object-ids';
import { ViewOpenRecordInType } from 'src/modules/view/standard-objects/view.workspace-entity';

@Command({
  name: 'upgrade:0-43:update-default-view-record-opening-on-workflow-objects',
  description:
    'Update default view record opening on workflow objects to record page',
})
export class UpdateDefaultViewRecordOpeningOnWorkflowObjectsCommand extends ActiveOrSuspendedWorkspacesMigrationCommandRunner {
  constructor(
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    protected readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    protected readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {
    super(workspaceRepository, twentyORMGlobalManager);
  }

  override async runOnWorkspace({
    index,
    total,
    workspaceId,
    options,
  }: RunOnWorkspaceArgs): Promise<void> {
    this.logger.log(
      `Running command for workspace ${workspaceId} ${index + 1}/${total}`,
    );

    const workflowObjectsMetadata = await this.objectMetadataRepository.find({
      select: ['id'],
      where: {
        workspaceId,
        standardId: In([
          STANDARD_OBJECT_IDS.workflow,
          STANDARD_OBJECT_IDS.workflowVersion,
          STANDARD_OBJECT_IDS.workflowRun,
        ]),
      },
    });

    if (workflowObjectsMetadata.length === 0) {
      this.logger.log(
        chalk.yellow(`No workflow objects found for workspace ${workspaceId}`),
      );

      return;
    }

    if (!options.dryRun) {
      await this.updateDefaultViewsRecordOpening(
        workflowObjectsMetadata.map((metadata) => metadata.id),
        workspaceId,
      );
    }

    this.logger.log(
      chalk.green(`Command completed for workspace ${workspaceId}.`),
    );
  }

  private async updateDefaultViewsRecordOpening(
    workflowObjectMetadataIds: string[],
    workspaceId: string,
  ): Promise<void> {
    const failOnMetadataCacheMiss = false;
    const viewRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace(
        workspaceId,
        'view',
        failOnMetadataCacheMiss,
      );

    await viewRepository.update(
      {
        objectMetadataId: In(workflowObjectMetadataIds),
        key: 'INDEX',
      },
      {
        openRecordIn: ViewOpenRecordInType.RECORD_PAGE,
      },
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to initialize permissions for workspaces, including creating admin and member roles, setting the admin role as default, and assigning admin roles to workspace members.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import chalk from 'chalk';
import { Command } from 'nest-commander';
import { isDefined } from 'twenty-shared';
import { Repository } from 'typeorm';

import {
  ActiveOrSuspendedWorkspacesMigrationCommandOptions,
  ActiveOrSuspendedWorkspacesMigrationCommandRunner,
  RunOnWorkspaceArgs,
} from 'src/database/commands/command-runners/active-or-suspended-workspaces-migration.command-runner';
import { UserWorkspace } from 'src/engine/core-modules/user-workspace/user-workspace.entity';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { ADMIN_ROLE_LABEL } from 'src/engine/metadata-modules/permissions/constants/admin-role-label.constants';
import { MEMBER_ROLE_LABEL } from 'src/engine/metadata-modules/permissions/constants/member-role-label.constants';
import { RoleService } from 'src/engine/metadata-modules/role/role.service';
import { UserRoleService } from 'src/engine/metadata-modules/user-role/user-role.service';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';

@Command({
  name: 'upgrade:0-44:initialize-permissions',
  description: 'Initialize permissions',
})
export class InitializePermissionsCommand extends ActiveOrSuspendedWorkspacesMigrationCommandRunner {
  constructor(
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    @InjectRepository(UserWorkspace, 'core')
    protected readonly userWorkspaceRepository: Repository<UserWorkspace>,
    protected readonly twentyORMGlobalManager: TwentyORMGlobalManager,
    private readonly roleService: RoleService,
    private readonly userRoleService: UserRoleService,
  ) {
    super(workspaceRepository, twentyORMGlobalManager);
  }

  override async runOnWorkspace({
    index,
    total,
    workspaceId,
    options,
  }: RunOnWorkspaceArgs): Promise<void> {
    try {
      this.logger.log(
        `Running command for workspace ${workspaceId} ${index + 1}/${total}`,
      );

      let adminRoleId: string | undefined;

      const workspaceRoles =
        await this.roleService.getWorkspaceRoles(workspaceId);

      adminRoleId = workspaceRoles.find(
        (role) => role.label === ADMIN_ROLE_LABEL,
      )?.id;

      if (!isDefined(adminRoleId)) {
        adminRoleId = await this.createAdminRole({
          workspaceId,
          options,
        });
      }

      await this.assignAdminRoleToMembers({
        workspaceId,
        adminRoleId,
        options,
      });

      await this.setAdminRoleAsDefaultRole({
        workspaceId,
        adminRoleId,
        options,
      });

      const memberRole = workspaceRoles.find(
        (role) => role.label === MEMBER_ROLE_LABEL,
      );

      if (!isDefined(memberRole)) {
        await this.createMemberRole({
          workspaceId,
          options,
        });
      }
    } catch (error) {
      this.logger.log(
        chalk.red(`Error in workspace ${workspaceId} - ${error.message}`),
      );
    }
  }

  private async createAdminRole({
    workspaceId,
    options,
  }: {
    workspaceId: string;
    options: ActiveOrSuspendedWorkspacesMigrationCommandOptions;
  }) {
    this.logger.log(
      chalk.green(`Creating admin role ${options.dryRun ? '(dry run)' : ''}`),
    );

    if (options.dryRun) {
      return '';
    }

    const adminRole = await this.roleService.createAdminRole({
      workspaceId,
    });

    return adminRole.id;
  }

  private async createMemberRole({
    workspaceId,
    options,
  }: {
    workspaceId: string;
    options: ActiveOrSuspendedWorkspacesMigrationCommandOptions;
  }) {
    this.logger.log(
      chalk.green(`Creating member role ${options.dryRun ? '(dry run)' : ''}`),
    );

    if (options.dryRun) {
      return '';
    }

    const memberRole = await this.roleService.createMemberRole({
      workspaceId,
    });

    return memberRole.id;
  }

  private async setAdminRoleAsDefaultRole({
    workspaceId,
    adminRoleId,
    options,
  }: {
    workspaceId: string;
    adminRoleId: string;
    options: ActiveOrSuspendedWorkspacesMigrationCommandOptions;
  }) {
    const workspaceDefaultRole = await this.workspaceRepository.findOne({
      where: {
        id: workspaceId,
      },
    });

    if (isDefined(workspaceDefaultRole?.defaultRoleId)) {
      this.logger.log(
        chalk.green(
          'Workspace already has a default role. Skipping setting admin role as default role',
        ),
      );

      return;
    }

    this.logger.log(
      chalk.green(
        `Setting admin role as default role ${options.dryRun ? '(dry run)' : ''}`,
      ),
    );

    if (options.dryRun) {
      return;
    }

    await this.workspaceRepository.update(workspaceId, {
      defaultRoleId: adminRoleId,
    });
  }

  private async assignAdminRoleToMembers({
    workspaceId,
    adminRoleId,
    options,
  }: {
    workspaceId: string;
    adminRoleId: string;
    options: ActiveOrSuspendedWorkspacesMigrationCommandOptions;
  }) {
    const userWorkspaces = await this.userWorkspaceRepository.find({
      where: {
        workspaceId,
      },
    });

    const rolesByUserWorkspace =
      await this.userRoleService.getRolesByUserWorkspaces({
        userWorkspaceIds: userWorkspaces.map(
          (userWorkspace) => userWorkspace.id,
        ),
        workspaceId,
      });

    for (const userWorkspace of userWorkspaces) {
      if (
        rolesByUserWorkspace
          .get(userWorkspace.id)
          ?.some((role) => isDefined(role))
      ) {
        this.logger.log(
          chalk.green(
            `User workspace ${userWorkspace.id} already has a role. Skipping role assignation`,
          ),
        );
        continue;
      }

      this.logger.log(
        chalk.green(
          `Assigning admin role to workspace member ${userWorkspace.id} ${options.dryRun ? '(dry run)' : ''}`,
        ),
      );

      if (options.dryRun) {
        continue;
      }

      await this.userRoleService.assignRoleToUserWorkspace({
        roleId: adminRoleId,
        userWorkspaceId: userWorkspace.id,
        workspaceId,
      });
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a NestJS command to migrate relations to field metadata for workspaces.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import chalk from 'chalk';
import { Command } from 'nest-commander';
import { FieldMetadataType } from 'twenty-shared';
import { In, Repository } from 'typeorm';

import { RelationType } from 'src/engine/metadata-modules/field-metadata/interfaces/relation-type.interface';

import {
  ActiveOrSuspendedWorkspacesMigrationCommandRunner,
  RunOnWorkspaceArgs,
} from 'src/database/commands/command-runners/active-or-suspended-workspaces-migration.command-runner';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import {
  RelationDirection,
  deduceRelationDirection,
} from 'src/engine/utils/deduce-relation-direction.util';
import { isFieldMetadataOfType } from 'src/engine/utils/is-field-metadata-of-type.util';

@Command({
  name: 'upgrade:0-44:migrate-relations-to-field-metadata',
  description: 'Migrate relations to field metadata',
})
export class MigrateRelationsToFieldMetadataCommand extends ActiveOrSuspendedWorkspacesMigrationCommandRunner {
  constructor(
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    @InjectRepository(FieldMetadataEntity, 'metadata')
    private readonly fieldMetadataRepository: Repository<FieldMetadataEntity>,
    protected readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {
    super(workspaceRepository, twentyORMGlobalManager);
  }

  override async runOnWorkspace({
    index,
    total,
    workspaceId,
  }: RunOnWorkspaceArgs): Promise<void> {
    this.logger.log(
      `Running command for workspace ${workspaceId} ${index + 1}/${total}`,
    );

    const fieldMetadataCollection = await this.fieldMetadataRepository.find({
      where: {
        workspaceId,
        type: In([FieldMetadataType.RELATION, FieldMetadataType.UUID]),
      },
      relations: ['fromRelationMetadata', 'toRelationMetadata'],
    });

    if (!fieldMetadataCollection.length) {
      this.logger.log(
        chalk.yellow(
          `No relation field metadata found for workspace ${workspaceId}.`,
        ),
      );

      return;
    }

    const joinColumnFieldMetadataCollection = fieldMetadataCollection.filter(
      (fieldMetadata) =>
        isFieldMetadataOfType(fieldMetadata, FieldMetadataType.UUID),
      // TODO: Fix this, it's working in other places but not here
    ) as FieldMetadataEntity<FieldMetadataType.UUID>[];

    const fieldMetadataToUpdateCollection = fieldMetadataCollection
      .filter((fieldMetadata) =>
        isFieldMetadataOfType(fieldMetadata, FieldMetadataType.RELATION),
      )
      .map((fieldMetadata) =>
        this.updateRelationFieldMetadata(
          joinColumnFieldMetadataCollection,
          // TODO: Fix this, it's working in other places but not here
          fieldMetadata as FieldMetadataEntity<FieldMetadataType.RELATION>,
        ),
      );

    if (fieldMetadataToUpdateCollection.length > 0) {
      await this.fieldMetadataRepository.save(fieldMetadataToUpdateCollection);
    }

    this.logger.log(
      chalk.green(`Command completed for workspace ${workspaceId}.`),
    );
  }

  private updateRelationFieldMetadata(
    joinColumnFieldMetadataCollection: FieldMetadataEntity<FieldMetadataType.UUID>[],
    fieldMetadata: FieldMetadataEntity<FieldMetadataType.RELATION>,
  ): FieldMetadataEntity<FieldMetadataType.RELATION> {
    const relationMetadata =
      fieldMetadata.fromRelationMetadata ?? fieldMetadata.toRelationMetadata;
    const joinColumnFieldMetadata = joinColumnFieldMetadataCollection.find(
      (joinColumnFieldMetadata) =>
        // We're deducing the field based on the name of the relation field
        // This is not the best way to do this but we don't have a better way
        joinColumnFieldMetadata.name === `${fieldMetadata.name}Id`,
    );

    const relationDirection = deduceRelationDirection(
      fieldMetadata,
      relationMetadata,
    );
    let relationType = relationMetadata.relationType as unknown as RelationType;

    if (
      relationDirection === RelationDirection.TO &&
      relationType === RelationType.ONE_TO_MANY
    ) {
      relationType = RelationType.MANY_TO_ONE;
    }

    const relationTargetFieldMetadataId =
      relationDirection === RelationDirection.FROM
        ? relationMetadata.toFieldMetadataId
        : relationMetadata.fromFieldMetadataId;

    const relationTargetObjectMetadataId =
      relationDirection === RelationDirection.FROM
        ? relationMetadata.toObjectMetadataId
        : relationMetadata.fromObjectMetadataId;

    return {
      ...fieldMetadata,
      settings: {
        relationType,
        onDelete: relationMetadata.onDeleteAction,
        joinColumnName: joinColumnFieldMetadata?.name,
      },
      relationTargetFieldMetadataId,
      relationTargetObjectMetadataId,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service for creating companies in a workspace, avoiding duplicates and fetching additional company information from an external API.
Code Snippet:
import { Injectable } from '@nestjs/common';

import axios, { AxiosInstance } from 'axios';
import uniqBy from 'lodash.uniqby';
import {
  ConnectedAccountProvider,
  TWENTY_COMPANIES_BASE_URL,
} from 'twenty-shared';
import { DeepPartial, EntityManager, ILike } from 'typeorm';

import { FieldActorSource } from 'src/engine/metadata-modules/field-metadata/composite-types/actor.composite-type';
import { WorkspaceRepository } from 'src/engine/twenty-orm/repository/workspace.repository';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { CompanyWorkspaceEntity } from 'src/modules/company/standard-objects/company.workspace-entity';
import { extractDomainFromLink } from 'src/modules/contact-creation-manager/utils/extract-domain-from-link.util';
import { getCompanyNameFromDomainName } from 'src/modules/contact-creation-manager/utils/get-company-name-from-domain-name.util';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';
import { computeDisplayName } from 'src/utils/compute-display-name';

type CompanyToCreate = {
  domainName: string | undefined;
  createdBySource: FieldActorSource;
  createdByWorkspaceMember?: WorkspaceMemberWorkspaceEntity | null;
  createdByContext: {
    provider: ConnectedAccountProvider;
  };
};

@Injectable()
export class CreateCompanyService {
  private readonly httpService: AxiosInstance;

  constructor(private readonly twentyORMGlobalManager: TwentyORMGlobalManager) {
    this.httpService = axios.create({
      baseURL: TWENTY_COMPANIES_BASE_URL,
    });
  }

  async createCompanies(
    companies: CompanyToCreate[],
    workspaceId: string,
    transactionManager?: EntityManager,
  ): Promise<{
    [domainName: string]: string;
  }> {
    if (companies.length === 0) {
      return {};
    }

    const companyRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace(
        workspaceId,
        CompanyWorkspaceEntity,
      );

    // Avoid creating duplicate companies
    const uniqueCompanies = uniqBy(companies, 'domainName');
    const conditions = uniqueCompanies.map((companyToCreate) => ({
      domainName: {
        primaryLinkUrl: ILike(`%${companyToCreate.domainName}%`),
      },
    }));

    // Find existing companies
    const existingCompanies = await companyRepository.find(
      {
        where: conditions,
      },
      transactionManager,
    );
    const existingCompanyIdsMap = this.createCompanyMap(existingCompanies);

    // Filter out companies that already exist
    const newCompaniesToCreate = uniqueCompanies.filter(
      (company) =>
        !existingCompanies.some(
          (existingCompany) =>
            existingCompany.domainName &&
            extractDomainFromLink(existingCompany.domainName.primaryLinkUrl) ===
              company.domainName,
        ),
    );

    if (newCompaniesToCreate.length === 0) {
      return existingCompanyIdsMap;
    }

    // Retrieve the last company position
    let lastCompanyPosition = await this.getLastCompanyPosition(
      companyRepository,
      transactionManager,
    );
    const newCompaniesData = await Promise.all(
      newCompaniesToCreate.map((company) =>
        this.prepareCompanyData(company, ++lastCompanyPosition),
      ),
    );

    // Create new companies
    const createdCompanies = await companyRepository.save(newCompaniesData);
    const createdCompanyIdsMap = this.createCompanyMap(createdCompanies);

    return {
      ...existingCompanyIdsMap,
      ...createdCompanyIdsMap,
    };
  }

  private async prepareCompanyData(
    company: CompanyToCreate,
    position: number,
  ): Promise<DeepPartial<CompanyWorkspaceEntity>> {
    const { name, city } = await this.getCompanyInfoFromDomainName(
      company.domainName,
    );
    const createdByName = computeDisplayName(
      company.createdByWorkspaceMember?.name,
    );

    return {
      domainName: {
        primaryLinkUrl: 'https://' + company.domainName,
      },
      name,
      createdBy: {
        source: company.createdBySource,
        workspaceMemberId: company.createdByWorkspaceMember?.id,
        name: createdByName,
        context: {
          provider: company.createdByContext.provider,
        },
      },
      address: {
        addressCity: city,
      },
      position,
    };
  }

  private createCompanyMap(companies: DeepPartial<CompanyWorkspaceEntity>[]) {
    return companies.reduce(
      (acc, company) => {
        if (!company.domainName?.primaryLinkUrl || !company.id) {
          return acc;
        }
        const key = extractDomainFromLink(company.domainName.primaryLinkUrl);

        acc[key] = company.id;

        return acc;
      },
      {} as { [domainName: string]: string },
    );
  }

  private async getLastCompanyPosition(
    companyRepository: WorkspaceRepository<CompanyWorkspaceEntity>,
    transactionManager?: EntityManager,
  ): Promise<number> {
    const lastCompanyPosition = await companyRepository.maximum(
      'position',
      undefined,
      transactionManager,
    );

    return lastCompanyPosition ?? 0;
  }

  private async getCompanyInfoFromDomainName(
    domainName: string | undefined,
  ): Promise<{
    name: string;
    city: string;
  }> {
    try {
      const response = await this.httpService.get(`/${domainName}`);

      const data = response.data;

      return {
        name: data.name ?? getCompanyNameFromDomainName(domainName ?? ''),
        city: data.city,
      };
    } catch (e) {
      return {
        name: getCompanyNameFromDomainName(domainName ?? ''),
        city: '',
      };
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service for creating contacts in a workspace, formatting contact data, and saving it to a repository.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { ConnectedAccountProvider } from 'twenty-shared';
import { DeepPartial, EntityManager } from 'typeorm';
import { v4 } from 'uuid';

import { FieldActorSource } from 'src/engine/metadata-modules/field-metadata/composite-types/actor.composite-type';
import { WorkspaceRepository } from 'src/engine/twenty-orm/repository/workspace.repository';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { getFirstNameAndLastNameFromHandleAndDisplayName } from 'src/modules/contact-creation-manager/utils/get-first-name-and-last-name-from-handle-and-display-name.util';
import { PersonWorkspaceEntity } from 'src/modules/person/standard-objects/person.workspace-entity';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';
import { computeDisplayName } from 'src/utils/compute-display-name';

type ContactToCreate = {
  handle: string;
  displayName: string;
  companyId?: string;
  createdBySource: FieldActorSource;
  createdByWorkspaceMember?: WorkspaceMemberWorkspaceEntity | null;
  createdByContext?: {
    provider?: ConnectedAccountProvider;
  };
};

@Injectable()
export class CreateContactService {
  constructor(
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {}

  private formatContacts(
    contactsToCreate: ContactToCreate[],
    lastPersonPosition: number,
  ): DeepPartial<PersonWorkspaceEntity>[] {
    return contactsToCreate.map((contact) => {
      const id = v4();

      const {
        handle,
        displayName,
        companyId,
        createdBySource,
        createdByWorkspaceMember,
        createdByContext,
      } = contact;

      const { firstName, lastName } =
        getFirstNameAndLastNameFromHandleAndDisplayName(handle, displayName);
      const createdByName = computeDisplayName(createdByWorkspaceMember?.name);

      return {
        id,
        emails: { primaryEmail: handle, additionalEmails: null },
        name: {
          firstName,
          lastName,
        },
        companyId,
        createdBy: {
          source: createdBySource,
          workspaceMemberId: contact.createdByWorkspaceMember?.id,
          name: createdByName,
          context: createdByContext,
        },
        position: ++lastPersonPosition,
      };
    });
  }

  public async createPeople(
    contactsToCreate: ContactToCreate[],
    workspaceId: string,
    transactionManager?: EntityManager,
  ): Promise<DeepPartial<PersonWorkspaceEntity>[]> {
    if (contactsToCreate.length === 0) return [];

    const personRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace(
        workspaceId,
        PersonWorkspaceEntity,
      );

    const lastPersonPosition = await this.getLastPersonPosition(
      personRepository,
      transactionManager,
    );

    const formattedContacts = this.formatContacts(
      contactsToCreate,
      lastPersonPosition,
    );

    return personRepository.save(
      formattedContacts,
      undefined,
      transactionManager,
    );
  }

  private async getLastPersonPosition(
    personRepository: WorkspaceRepository<PersonWorkspaceEntity>,
    transactionManager?: EntityManager,
  ): Promise<number> {
    const lastPersonPosition = await personRepository.maximum(
      'position',
      undefined,
      transactionManager,
    );

    return lastPersonPosition ?? 0;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service class for managing user roles within workspaces, including assigning roles, retrieving roles, and validating user workspace roles.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { isDefined } from 'twenty-shared';
import { In, Not, Repository } from 'typeorm';

import { UserWorkspace } from 'src/engine/core-modules/user-workspace/user-workspace.entity';
import { ADMIN_ROLE_LABEL } from 'src/engine/metadata-modules/permissions/constants/admin-role-label.constants';
import {
  PermissionsException,
  PermissionsExceptionCode,
  PermissionsExceptionMessage,
} from 'src/engine/metadata-modules/permissions/permissions.exception';
import { RoleEntity } from 'src/engine/metadata-modules/role/role.entity';
import { UserWorkspaceRoleEntity } from 'src/engine/metadata-modules/role/user-workspace-role.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';

export class UserRoleService {
  constructor(
    @InjectRepository(RoleEntity, 'metadata')
    private readonly roleRepository: Repository<RoleEntity>,
    @InjectRepository(UserWorkspaceRoleEntity, 'metadata')
    private readonly userWorkspaceRoleRepository: Repository<UserWorkspaceRoleEntity>,
    @InjectRepository(UserWorkspace, 'core')
    private readonly userWorkspaceRepository: Repository<UserWorkspace>,
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {}

  public async assignRoleToUserWorkspace({
    workspaceId,
    userWorkspaceId,
    roleId,
  }: {
    workspaceId: string;
    userWorkspaceId: string;
    roleId: string;
  }): Promise<void> {
    const validationResult = await this.validateAssignRoleInput({
      userWorkspaceId,
      workspaceId,
      roleId,
    });

    if (validationResult?.roleToAssignIsSameAsCurrentRole) {
      return;
    }

    const newUserWorkspaceRole = await this.userWorkspaceRoleRepository.save({
      roleId,
      userWorkspaceId,
      workspaceId,
    });

    await this.userWorkspaceRoleRepository.delete({
      userWorkspaceId,
      workspaceId,
      id: Not(newUserWorkspaceRole.id),
    });
  }

  public async getRolesByUserWorkspaces({
    userWorkspaceIds,
    workspaceId,
  }: {
    userWorkspaceIds: string[];
    workspaceId: string;
  }): Promise<Map<string, RoleEntity[]>> {
    if (!userWorkspaceIds.length) {
      return new Map();
    }

    const allUserWorkspaceRoles = await this.userWorkspaceRoleRepository.find({
      where: {
        userWorkspaceId: In(userWorkspaceIds),
        workspaceId,
      },
      relations: {
        role: true,
      },
    });

    if (!allUserWorkspaceRoles.length) {
      return new Map();
    }

    const rolesMap = new Map<string, RoleEntity[]>();

    for (const userWorkspaceId of userWorkspaceIds) {
      const userWorkspaceRolesOfUserWorkspace = allUserWorkspaceRoles.filter(
        (userWorkspaceRole) =>
          userWorkspaceRole.userWorkspaceId === userWorkspaceId,
      );

      const rolesOfUserWorkspace = userWorkspaceRolesOfUserWorkspace
        .map((userWorkspaceRole) => userWorkspaceRole.role)
        .filter(isDefined);

      rolesMap.set(userWorkspaceId, rolesOfUserWorkspace);
    }

    return rolesMap;
  }

  public async getWorkspaceMembersAssignedToRole(
    roleId: string,
    workspaceId: string,
  ): Promise<WorkspaceMemberWorkspaceEntity[]> {
    const userWorkspaceRoles = await this.userWorkspaceRoleRepository.find({
      where: {
        roleId,
        workspaceId,
      },
    });

    const userIds = await this.userWorkspaceRepository
      .find({
        where: {
          id: In(
            userWorkspaceRoles.map(
              (userWorkspaceRole) => userWorkspaceRole.userWorkspaceId,
            ),
          ),
        },
      })
      .then((userWorkspaces) =>
        userWorkspaces.map((userWorkspace) => userWorkspace.userId),
      );

    const workspaceMemberRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace<WorkspaceMemberWorkspaceEntity>(
        workspaceId,
        'workspaceMember',
      );

    const workspaceMembers = await workspaceMemberRepository.find({
      where: {
        userId: In(userIds),
      },
    });

    return workspaceMembers;
  }

  public async validateUserWorkspaceIsNotUniqueAdminOrThrow({
    userWorkspaceId,
    workspaceId,
  }: {
    userWorkspaceId: string;
    workspaceId: string;
  }) {
    const roleOfUserWorkspace = await this.getRolesByUserWorkspaces({
      userWorkspaceIds: [userWorkspaceId],
      workspaceId,
    }).then((roles) => roles.get(userWorkspaceId)?.[0]);

    if (!isDefined(roleOfUserWorkspace)) {
      throw new PermissionsException(
        PermissionsExceptionMessage.NO_ROLE_FOUND_FOR_USER_WORKSPACE,
        PermissionsExceptionCode.NO_ROLE_FOUND_FOR_USER_WORKSPACE,
      );
    }

    if (roleOfUserWorkspace.label === ADMIN_ROLE_LABEL) {
      const adminRole = roleOfUserWorkspace;

      await this.validateMoreThanOneWorkspaceMemberHasAdminRoleOrThrow({
        adminRoleId: adminRole.id,
        workspaceId,
      });
    }
  }

  private async validateAssignRoleInput({
    userWorkspaceId,
    workspaceId,
    roleId,
  }: {
    userWorkspaceId: string;
    workspaceId: string;
    roleId: string;
  }) {
    const userWorkspace = await this.userWorkspaceRepository.findOne({
      where: {
        id: userWorkspaceId,
      },
    });

    if (!isDefined(userWorkspace)) {
      throw new PermissionsException(
        'User workspace not found',
        PermissionsExceptionCode.USER_WORKSPACE_NOT_FOUND,
      );
    }

    const role = await this.roleRepository.findOne({
      where: {
        id: roleId,
      },
    });

    if (!isDefined(role)) {
      throw new PermissionsException(
        'Role not found',
        PermissionsExceptionCode.ROLE_NOT_FOUND,
      );
    }

    const roles = await this.getRolesByUserWorkspaces({
      userWorkspaceIds: [userWorkspace.id],
      workspaceId,
    });

    const currentRole = roles.get(userWorkspace.id)?.[0];

    if (currentRole?.id === roleId) {
      return {
        roleToAssignIsSameAsCurrentRole: true,
      };
    }

    if (!(currentRole?.label === ADMIN_ROLE_LABEL)) {
      return;
    }

    await this.validateMoreThanOneWorkspaceMemberHasAdminRoleOrThrow({
      workspaceId,
      adminRoleId: currentRole.id,
    });
  }

  private async validateMoreThanOneWorkspaceMemberHasAdminRoleOrThrow({
    adminRoleId,
    workspaceId,
  }: {
    adminRoleId: string;
    workspaceId: string;
  }) {
    const workspaceMembersWithAdminRole =
      await this.getWorkspaceMembersAssignedToRole(adminRoleId, workspaceId);

    if (workspaceMembersWithAdminRole.length === 1) {
      throw new PermissionsException(
        PermissionsExceptionMessage.CANNOT_UNASSIGN_LAST_ADMIN,
        PermissionsExceptionCode.CANNOT_UNASSIGN_LAST_ADMIN,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to check and optionally fix the health of a workspace, logging issues to a file.
Code Snippet:
import { Logger } from '@nestjs/common';

import chalk from 'chalk';
import { Command, CommandRunner, Option } from 'nest-commander';

import { WorkspaceHealthFixKind } from 'src/engine/workspace-manager/workspace-health/interfaces/workspace-health-fix-kind.interface';
import { WorkspaceHealthMode } from 'src/engine/workspace-manager/workspace-health/interfaces/workspace-health-options.interface';

import { CommandLogger } from 'src/command/command-logger';
import { WorkspaceHealthService } from 'src/engine/workspace-manager/workspace-health/workspace-health.service';

interface WorkspaceHealthCommandOptions {
  workspaceId: string;
  mode?: WorkspaceHealthMode;
  fix?: WorkspaceHealthFixKind;
  dryRun?: boolean;
}

@Command({
  name: 'workspace:health',
  description: 'Check health of the given workspace.',
})
export class WorkspaceHealthCommand extends CommandRunner {
  private readonly logger = new Logger(WorkspaceHealthCommand.name);
  private readonly commandLogger = new CommandLogger(
    WorkspaceHealthCommand.name,
  );

  constructor(private readonly workspaceHealthService: WorkspaceHealthService) {
    super();
  }

  async run(
    _passedParam: string[],
    options: WorkspaceHealthCommandOptions,
  ): Promise<void> {
    const issues = await this.workspaceHealthService.healthCheck(
      options.workspaceId,
      {
        mode: options.mode ?? WorkspaceHealthMode.All,
      },
    );

    if (issues.length === 0) {
      this.logger.log(chalk.green('Workspace is healthy'));
    } else {
      this.logger.log(
        chalk.red(`Workspace is not healthy, found ${issues.length} issues`),
      );

      for (let issueIndex = 0; issueIndex < issues.length; issueIndex++) {
        this.logger.log(
          chalk.red(`Issue #${issueIndex + 1} : ${issues[issueIndex].message}`),
        );
      }

      const logFilePath = await this.commandLogger.writeLog(
        `workspace-health-issues-${options.workspaceId}`,
        issues,
      );

      this.logger.log(
        chalk.yellow(`Issues written to log at : ${logFilePath}`),
      );
    }

    if (options.fix) {
      this.logger.log(chalk.yellow('Fixing issues'));

      const { workspaceMigrations, metadataEntities } =
        await this.workspaceHealthService.fixIssues(
          options.workspaceId,
          issues,
          {
            type: options.fix,
            applyChanges: !options.dryRun,
          },
        );
      const totalCount = workspaceMigrations.length + metadataEntities.length;

      if (options.dryRun) {
        await this.commandLogger.writeLog(
          `workspace-health-${options.fix}-migrations`,
          workspaceMigrations,
        );

        await this.commandLogger.writeLog(
          `workspace-health-${options.fix}-metadata-entities`,
          metadataEntities,
        );
      } else {
        this.logger.log(
          chalk.green(`Fixed ${totalCount}/${issues.length} issues`),
        );
      }
    }
  }

  @Option({
    flags: '-w, --workspace-id [workspace_id]',
    description: 'workspace id',
    required: true,
  })
  parseWorkspaceId(value: string): string {
    return value;
  }

  @Option({
    flags: '-f, --fix [kind]',
    description: 'fix issues',
    required: false,
  })
  fix(value: string): WorkspaceHealthFixKind {
    if (!Object.values(WorkspaceHealthFixKind).includes(value as any)) {
      throw new Error(`Invalid fix kind ${value}`);
    }

    return value as WorkspaceHealthFixKind;
  }

  @Option({
    flags: '-m, --mode [mode]',
    description: 'Mode of the health check [structure, metadata, all]',
    required: false,
    defaultValue: WorkspaceHealthMode.All,
  })
  parseMode(value: string): WorkspaceHealthMode {
    if (!Object.values(WorkspaceHealthMode).includes(value as any)) {
      throw new Error(`Invalid mode ${value}`);
    }

    return value as WorkspaceHealthMode;
  }

  @Option({
    flags: '-d, --dry-run',
    description: 'Dry run without applying changes',
    required: false,
  })
  dryRun(): boolean {
    return true;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to sync metadata for workspaces, using services for data source, workspace synchronization, and logging.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { Command } from 'nest-commander';
import { Repository } from 'typeorm';

import {
  ActiveOrSuspendedWorkspacesMigrationCommandRunner,
  RunOnWorkspaceArgs,
} from 'src/database/commands/command-runners/active-or-suspended-workspaces-migration.command-runner';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { DataSourceService } from 'src/engine/metadata-modules/data-source/data-source.service';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { WorkspaceSyncMetadataService } from 'src/engine/workspace-manager/workspace-sync-metadata/workspace-sync-metadata.service';

import { SyncWorkspaceLoggerService } from './services/sync-workspace-logger.service';

@Command({
  name: 'workspace:sync-metadata',
  description: 'Sync metadata',
})
export class SyncWorkspaceMetadataCommand extends ActiveOrSuspendedWorkspacesMigrationCommandRunner {
  constructor(
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    private readonly workspaceSyncMetadataService: WorkspaceSyncMetadataService,
    private readonly dataSourceService: DataSourceService,
    private readonly syncWorkspaceLoggerService: SyncWorkspaceLoggerService,
    protected readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {
    super(workspaceRepository, twentyORMGlobalManager);
  }

  override async runOnWorkspace({
    workspaceId,
    options,
    index,
    total,
  }: RunOnWorkspaceArgs): Promise<void> {
    this.logger.log(
      `Running workspace sync for workspace: ${workspaceId} (${index} out of ${total})`,
    );

    const dataSourceMetadata =
      await this.dataSourceService.getLastDataSourceMetadataFromWorkspaceIdOrFail(
        workspaceId,
      );

    const { storage, workspaceMigrations } =
      await this.workspaceSyncMetadataService.synchronize(
        {
          workspaceId,
          dataSourceId: dataSourceMetadata.id,
        },
        { applyChanges: !options.dryRun },
      );

    if (options.dryRun) {
      await this.syncWorkspaceLoggerService.saveLogs(
        workspaceId,
        storage,
        workspaceMigrations,
      );
    }

    this.logger.log(
      `Finished synchronizing all active workspaces (${total} workspaces).`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to clean suspended workspaces, either by a specified ID or all suspended workspaces if no ID is provided.
Code Snippet:
import { InjectRepository } from '@nestjs/typeorm';

import { Command, Option } from 'nest-commander';
import { WorkspaceActivationStatus } from 'twenty-shared';
import { In, Repository } from 'typeorm';

import {
  MigrationCommandOptions,
  MigrationCommandRunner,
} from 'src/database/commands/command-runners/migration.command-runner';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { CleanerWorkspaceService } from 'src/engine/workspace-manager/workspace-cleaner/services/cleaner.workspace-service';

@Command({
  name: 'workspace:clean',
  description: 'Clean suspended workspace',
})
export class CleanSuspendedWorkspacesCommand extends MigrationCommandRunner {
  private workspaceIds: string[] = [];

  constructor(
    private readonly cleanerWorkspaceService: CleanerWorkspaceService,
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
  ) {
    super();
  }

  @Option({
    flags: '-w, --workspace-id [workspace_id]',
    description:
      'workspace id. Command runs on all suspended workspaces if not provided',
    required: false,
  })
  parseWorkspaceId(val: string): string[] {
    this.workspaceIds.push(val);

    return this.workspaceIds;
  }

  async fetchSuspendedWorkspaceIds(): Promise<string[]> {
    const suspendedWorkspaces = await this.workspaceRepository.find({
      select: ['id'],
      where: {
        activationStatus: In([WorkspaceActivationStatus.SUSPENDED]),
      },
      withDeleted: true,
    });

    return suspendedWorkspaces.map((workspace) => workspace.id);
  }

  override async runMigrationCommand(
    _passedParams: string[],
    options: MigrationCommandOptions,
  ): Promise<void> {
    const { dryRun } = options;

    const suspendedWorkspaceIds =
      this.workspaceIds.length > 0
        ? this.workspaceIds
        : await this.fetchSuspendedWorkspaceIds();

    this.logger.log(
      `${dryRun ? 'DRY RUN - ' : ''}Cleaning ${suspendedWorkspaceIds.length} suspended workspaces`,
    );

    await this.cleanerWorkspaceService.batchWarnOrCleanSuspendedWorkspaces(
      suspendedWorkspaceIds,
      dryRun,
    );
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_7>



=== New Entry ===

<CLUSTER_8>
Number of Code Snippets part of this cluster: 11
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for executing workflows in a NestJS application. It handles workflow steps, retries, and error handling, and emits billing events upon successful step execution.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { WorkflowExecutor } from 'src/modules/workflow/workflow-executor/interfaces/workflow-executor.interface';

import { BILLING_FEATURE_USED } from 'src/engine/core-modules/billing/constants/billing-feature-used.constant';
import { BillingMeterEventName } from 'src/engine/core-modules/billing/enums/billing-meter-event-names';
import { BillingUsageEvent } from 'src/engine/core-modules/billing/types/billing-usage-event.type';
import { ScopedWorkspaceContextFactory } from 'src/engine/twenty-orm/factories/scoped-workspace-context.factory';
import { WorkspaceEventEmitter } from 'src/engine/workspace-event-emitter/workspace-event-emitter';
import {
  StepOutput,
  WorkflowRunOutput,
  WorkflowRunStatus,
} from 'src/modules/workflow/common/standard-objects/workflow-run.workspace-entity';
import { WorkflowExecutorFactory } from 'src/modules/workflow/workflow-executor/factories/workflow-executor.factory';
import { WorkflowExecutorInput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-input';
import { WorkflowExecutorOutput } from 'src/modules/workflow/workflow-executor/types/workflow-executor-output.type';
import { WorkflowRunWorkspaceService } from 'src/modules/workflow/workflow-runner/workflow-run/workflow-run.workspace-service';

const MAX_RETRIES_ON_FAILURE = 3;

export type WorkflowExecutorState = {
  stepsOutput: WorkflowRunOutput['stepsOutput'];
  status: WorkflowRunStatus;
};

@Injectable()
export class WorkflowExecutorWorkspaceService implements WorkflowExecutor {
  constructor(
    private readonly workflowExecutorFactory: WorkflowExecutorFactory,
    private readonly workspaceEventEmitter: WorkspaceEventEmitter,
    private readonly scopedWorkspaceContextFactory: ScopedWorkspaceContextFactory,
    private readonly workflowRunWorkspaceService: WorkflowRunWorkspaceService,
  ) {}

  async execute({
    currentStepIndex,
    steps,
    context,
    attemptCount = 1,
    workflowRunId,
  }: WorkflowExecutorInput): Promise<WorkflowExecutorOutput> {
    if (currentStepIndex >= steps.length) {
      return {
        result: {
          success: true,
        },
      };
    }

    const step = steps[currentStepIndex];

    const workflowExecutor = this.workflowExecutorFactory.get(step.type);

    let actionOutput: WorkflowExecutorOutput;

    try {
      actionOutput = await workflowExecutor.execute({
        currentStepIndex,
        steps,
        context,
        attemptCount,
        workflowRunId,
      });
    } catch (error) {
      actionOutput = {
        error: error.message ?? 'Execution result error, no data or error',
      };
    }

    if (!actionOutput.error) {
      this.sendWorkflowNodeRunEvent();
    }

    const stepOutput: StepOutput = {
      id: step.id,
      output: actionOutput,
    };

    if (actionOutput.pendingEvent) {
      await this.workflowRunWorkspaceService.saveWorkflowRunState({
        workflowRunId,
        stepOutput,
        context,
      });

      return actionOutput;
    }

    if (actionOutput.result) {
      const updatedContext = {
        ...context,
        [step.id]: actionOutput.result,
      };

      await this.workflowRunWorkspaceService.saveWorkflowRunState({
        workflowRunId,
        stepOutput,
        context: updatedContext,
      });

      return await this.execute({
        workflowRunId,
        currentStepIndex: currentStepIndex + 1,
        steps,
        context: updatedContext,
      });
    }

    if (step.settings.errorHandlingOptions.continueOnFailure.value) {
      await this.workflowRunWorkspaceService.saveWorkflowRunState({
        workflowRunId,
        stepOutput,
        context,
      });

      return await this.execute({
        workflowRunId,
        currentStepIndex: currentStepIndex + 1,
        steps,
        context,
      });
    }

    if (
      step.settings.errorHandlingOptions.retryOnFailure.value &&
      attemptCount < MAX_RETRIES_ON_FAILURE
    ) {
      return await this.execute({
        workflowRunId,
        currentStepIndex,
        steps,
        context,
        attemptCount: attemptCount + 1,
      });
    }

    await this.workflowRunWorkspaceService.saveWorkflowRunState({
      workflowRunId,
      stepOutput,
      context,
    });

    return actionOutput;
  }

  private sendWorkflowNodeRunEvent() {
    const workspaceId =
      this.scopedWorkspaceContextFactory.create().workspaceId ?? '';

    this.workspaceEventEmitter.emitCustomBatchEvent<BillingUsageEvent>(
      BILLING_FEATURE_USED,
      [
        {
          eventName: BillingMeterEventName.WORKFLOW_NODE_RUN,
          value: 1,
        },
      ],
      workspaceId,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a WorkspaceService class that handles various operations related to workspaces, including updating, activating, deleting, and managing workspace metadata and permissions.
Code Snippet:
import { BadRequestException, Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import assert from 'assert';

import { TypeOrmQueryService } from '@ptc-org/nestjs-query-typeorm';
import { isDefined, WorkspaceActivationStatus } from 'twenty-shared';
import { Repository } from 'typeorm';

import { BillingEntitlementKey } from 'src/engine/core-modules/billing/enums/billing-entitlement-key.enum';
import { BillingSubscriptionService } from 'src/engine/core-modules/billing/services/billing-subscription.service';
import { BillingService } from 'src/engine/core-modules/billing/services/billing.service';
import { CustomDomainService } from 'src/engine/core-modules/domain-manager/services/custom-domain.service';
import { DomainManagerService } from 'src/engine/core-modules/domain-manager/services/domain-manager.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';
import { FeatureFlagKey } from 'src/engine/core-modules/feature-flag/enums/feature-flag-key.enum';
import { FeatureFlagService } from 'src/engine/core-modules/feature-flag/services/feature-flag.service';
import {
  FileWorkspaceFolderDeletionJob,
  FileWorkspaceFolderDeletionJobData,
} from 'src/engine/core-modules/file/jobs/file-workspace-folder-deletion.job';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { UserWorkspace } from 'src/engine/core-modules/user-workspace/user-workspace.entity';
import { UserWorkspaceService } from 'src/engine/core-modules/user-workspace/user-workspace.service';
import { User } from 'src/engine/core-modules/user/user.entity';
import { ActivateWorkspaceInput } from 'src/engine/core-modules/workspace/dtos/activate-workspace-input';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import {
  WorkspaceException,
  WorkspaceExceptionCode,
} from 'src/engine/core-modules/workspace/workspace.exception';
import { workspaceValidator } from 'src/engine/core-modules/workspace/workspace.validate';
import { SettingsPermissions } from 'src/engine/metadata-modules/permissions/constants/settings-permissions.constants';
import {
  PermissionsException,
  PermissionsExceptionCode,
  PermissionsExceptionMessage,
} from 'src/engine/metadata-modules/permissions/permissions.exception';
import { PermissionsService } from 'src/engine/metadata-modules/permissions/permissions.service';
import { WorkspaceCacheStorageService } from 'src/engine/workspace-cache-storage/workspace-cache-storage.service';
import { WorkspaceManagerService } from 'src/engine/workspace-manager/workspace-manager.service';
import { DEFAULT_FEATURE_FLAGS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/default-feature-flags';

@Injectable()
// eslint-disable-next-line @nx/workspace-inject-workspace-repository
export class WorkspaceService extends TypeOrmQueryService<Workspace> {
  private readonly featureLookUpKey = BillingEntitlementKey.CUSTOM_DOMAIN;

  constructor(
    @InjectRepository(Workspace, 'core')
    private readonly workspaceRepository: Repository<Workspace>,
    @InjectRepository(User, 'core')
    private readonly userRepository: Repository<User>,
    @InjectRepository(UserWorkspace, 'core')
    private readonly userWorkspaceRepository: Repository<UserWorkspace>,
    private readonly workspaceManagerService: WorkspaceManagerService,
    private readonly featureFlagService: FeatureFlagService,
    private readonly billingSubscriptionService: BillingSubscriptionService,
    private readonly billingService: BillingService,
    private readonly userWorkspaceService: UserWorkspaceService,
    private readonly environmentService: EnvironmentService,
    private readonly domainManagerService: DomainManagerService,
    private readonly exceptionHandlerService: ExceptionHandlerService,
    private readonly permissionsService: PermissionsService,
    private readonly customDomainService: CustomDomainService,
    private readonly workspaceCacheStorageService: WorkspaceCacheStorageService,
    @InjectMessageQueue(MessageQueue.deleteCascadeQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {
    super(workspaceRepository);
  }

  private async isCustomDomainEnabled(workspaceId: string) {
    const isCustomDomainBillingEnabled =
      await this.billingService.hasEntitlement(
        workspaceId,
        this.featureLookUpKey,
      );

    if (!isCustomDomainBillingEnabled) {
      throw new WorkspaceException(
        `No entitlement found for this workspace`,
        WorkspaceExceptionCode.WORKSPACE_CUSTOM_DOMAIN_DISABLED,
      );
    }
  }

  private async validateSubdomainUpdate(newSubdomain: string) {
    const subdomainAvailable = await this.isSubdomainAvailable(newSubdomain);

    if (
      !subdomainAvailable ||
      this.environmentService.get('DEFAULT_SUBDOMAIN') === newSubdomain
    ) {
      throw new WorkspaceException(
        'Subdomain already taken',
        WorkspaceExceptionCode.SUBDOMAIN_ALREADY_TAKEN,
      );
    }
  }

  private async setCustomDomain(workspace: Workspace, customDomain: string) {
    await this.isCustomDomainEnabled(workspace.id);

    const existingWorkspace = await this.workspaceRepository.findOne({
      where: { customDomain },
    });

    if (existingWorkspace && existingWorkspace.id !== workspace.id) {
      throw new WorkspaceException(
        'Domain already taken',
        WorkspaceExceptionCode.DOMAIN_ALREADY_TAKEN,
      );
    }

    if (
      customDomain &&
      workspace.customDomain !== customDomain &&
      isDefined(workspace.customDomain)
    ) {
      await this.customDomainService.updateCustomDomain(
        workspace.customDomain,
        customDomain,
      );
    }

    if (
      customDomain &&
      workspace.customDomain !== customDomain &&
      !isDefined(workspace.customDomain)
    ) {
      await this.customDomainService.registerCustomDomain(customDomain);
    }
  }

  async updateWorkspaceById({
    payload,
    userWorkspaceId,
    apiKey,
  }: {
    payload: Partial<Workspace> & { id: string };
    userWorkspaceId?: string;
    apiKey?: string;
  }) {
    const workspace = await this.workspaceRepository.findOneBy({
      id: payload.id,
    });

    workspaceValidator.assertIsDefinedOrThrow(workspace);

    const permissionsEnabled = await this.featureFlagService.isFeatureEnabled(
      FeatureFlagKey.IsPermissionsEnabled,
      workspace.id,
    );

    if (permissionsEnabled) {
      await this.validateSecurityPermissions({
        payload,
        userWorkspaceId,
        workspaceId: workspace.id,
        apiKey,
      });

      await this.validateWorkspacePermissions({
        payload,
        userWorkspaceId,
        workspaceId: workspace.id,
        apiKey,
      });
    }

    if (payload.subdomain && workspace.subdomain !== payload.subdomain) {
      await this.validateSubdomainUpdate(payload.subdomain);
    }

    let customDomainRegistered = false;

    if (payload.customDomain === null && isDefined(workspace.customDomain)) {
      await this.customDomainService.deleteCustomHostnameByHostnameSilently(
        workspace.customDomain,
      );
    }

    if (
      payload.customDomain &&
      workspace.customDomain !== payload.customDomain
    ) {
      await this.setCustomDomain(workspace, payload.customDomain);
      customDomainRegistered = true;
    }

    const authProvidersBySystem = {
      google: this.environmentService.get('AUTH_GOOGLE_ENABLED'),
      password: this.environmentService.get('AUTH_PASSWORD_ENABLED'),
      microsoft: this.environmentService.get('AUTH_MICROSOFT_ENABLED'),
    };

    if (payload.isGoogleAuthEnabled && !authProvidersBySystem.google) {
      throw new WorkspaceException(
        'Google auth is not enabled in the system.',
        WorkspaceExceptionCode.ENVIRONMENT_VAR_NOT_ENABLED,
      );
    }
    if (payload.isMicrosoftAuthEnabled && !authProvidersBySystem.microsoft) {
      throw new WorkspaceException(
        'Microsoft auth is not enabled in the system.',
        WorkspaceExceptionCode.ENVIRONMENT_VAR_NOT_ENABLED,
      );
    }
    if (payload.isPasswordAuthEnabled && !authProvidersBySystem.password) {
      throw new WorkspaceException(
        'Password auth is not enabled in the system.',
        WorkspaceExceptionCode.ENVIRONMENT_VAR_NOT_ENABLED,
      );
    }

    try {
      return await this.workspaceRepository.save({
        ...workspace,
        ...payload,
      });
    } catch (error) {
      // revert custom domain registration on error
      if (payload.customDomain && customDomainRegistered) {
        this.customDomainService
          .deleteCustomHostnameByHostnameSilently(payload.customDomain)
          .catch((err) => {
            this.exceptionHandlerService.captureExceptions([err]);
          });
      }
      throw error;
    }
  }

  async activateWorkspace(
    user: User,
    workspace: Workspace,
    data: ActivateWorkspaceInput,
  ) {
    if (!data.displayName || !data.displayName.length) {
      throw new BadRequestException("'displayName' not provided");
    }

    if (
      workspace.activationStatus === WorkspaceActivationStatus.ONGOING_CREATION
    ) {
      throw new Error('Workspace is already being created');
    }

    if (
      workspace.activationStatus !== WorkspaceActivationStatus.PENDING_CREATION
    ) {
      throw new Error('Workspace is not pending creation');
    }

    await this.workspaceRepository.update(workspace.id, {
      activationStatus: WorkspaceActivationStatus.ONGOING_CREATION,
    });

    await this.featureFlagService.enableFeatureFlags(
      DEFAULT_FEATURE_FLAGS,
      workspace.id,
    );

    await this.workspaceManagerService.init({
      workspaceId: workspace.id,
      userId: user.id,
    });
    await this.userWorkspaceService.createWorkspaceMember(workspace.id, user);

    await this.workspaceRepository.update(workspace.id, {
      displayName: data.displayName,
      activationStatus: WorkspaceActivationStatus.ACTIVE,
    });

    return await this.workspaceRepository.findOneBy({
      id: workspace.id,
    });
  }

  async deleteMetadataSchemaCacheAndUserWorkspace(workspace: Workspace) {
    await this.userWorkspaceRepository.delete({ workspaceId: workspace.id });

    if (this.billingService.isBillingEnabled()) {
      await this.billingSubscriptionService.deleteSubscriptions(workspace.id);
    }

    await this.workspaceManagerService.delete(workspace.id);

    return workspace;
  }

  async deleteWorkspace(id: string, softDelete = false) {
    const workspace = await this.workspaceRepository.findOne({
      where: { id },
      withDeleted: true,
    });

    assert(workspace, 'Workspace not found');

    const userWorkspaces = await this.userWorkspaceRepository.find({
      where: {
        workspaceId: id,
      },
      withDeleted: true,
    });

    for (const userWorkspace of userWorkspaces) {
      await this.handleRemoveWorkspaceMember(
        id,
        userWorkspace.userId,
        softDelete,
      );
    }

    await this.workspaceCacheStorageService.flush(
      workspace.id,
      workspace.metadataVersion,
    );

    if (softDelete) {
      await this.workspaceRepository.softDelete({ id });

      return workspace;
    }

    await this.deleteMetadataSchemaCacheAndUserWorkspace(workspace);

    await this.messageQueueService.add<FileWorkspaceFolderDeletionJobData>(
      FileWorkspaceFolderDeletionJob.name,
      { workspaceId: id },
    );
    await this.workspaceRepository.delete(id);

    return workspace;
  }

  async handleRemoveWorkspaceMember(
    workspaceId: string,
    userId: string,
    softDelete = false,
  ) {
    if (softDelete) {
      await this.userWorkspaceRepository.softDelete({
        userId,
        workspaceId,
      });
    } else {
      await this.userWorkspaceRepository.delete({
        userId,
        workspaceId,
      });
    }

    const userWorkspaces = await this.userWorkspaceRepository.find({
      where: {
        userId,
      },
    });

    if (userWorkspaces.length === 0) {
      await this.userRepository.softDelete(userId);
    }
  }

  async isSubdomainAvailable(subdomain: string) {
    const existingWorkspace = await this.workspaceRepository.findOne({
      where: { subdomain: subdomain },
    });

    return !existingWorkspace;
  }

  async checkCustomDomainValidRecords(workspace: Workspace) {
    if (!workspace.customDomain) return;

    const customDomainDetails =
      await this.customDomainService.getCustomDomainDetails(
        workspace.customDomain,
      );

    if (!customDomainDetails) return;

    const isCustomDomainWorking =
      this.domainManagerService.isCustomDomainWorking(customDomainDetails);

    if (workspace.isCustomDomainEnabled !== isCustomDomainWorking) {
      workspace.isCustomDomainEnabled = isCustomDomainWorking;
      await this.workspaceRepository.save(workspace);
    }

    return customDomainDetails;
  }

  private async validateSecurityPermissions({
    payload,
    userWorkspaceId,
    workspaceId,
    apiKey,
  }: {
    payload: Partial<Workspace>;
    userWorkspaceId?: string;
    workspaceId: string;
    apiKey?: string;
  }) {
    if (
      'isGoogleAuthEnabled' in payload ||
      'isMicrosoftAuthEnabled' in payload ||
      'isPasswordAuthEnabled' in payload ||
      'isPublicInviteLinkEnabled' in payload
    ) {
      if (!userWorkspaceId) {
        throw new Error('Missing userWorkspaceId in authContext');
      }

      const userHasPermission =
        await this.permissionsService.userHasWorkspaceSettingPermission({
          userWorkspaceId,
          _setting: SettingsPermissions.SECURITY,
          workspaceId: workspaceId,
          isExecutedByApiKey: isDefined(apiKey),
        });

      if (!userHasPermission) {
        throw new PermissionsException(
          PermissionsExceptionMessage.PERMISSION_DENIED,
          PermissionsExceptionCode.PERMISSION_DENIED,
        );
      }
    }
  }

  private async validateWorkspacePermissions({
    payload,
    userWorkspaceId,
    workspaceId,
    apiKey,
  }: {
    payload: Partial<Workspace>;
    userWorkspaceId?: string;
    workspaceId: string;
    apiKey?: string;
  }) {
    if (
      'displayName' in payload ||
      'subdomain' in payload ||
      'customDomain' in payload ||
      'logo' in payload
    ) {
      if (!userWorkspaceId) {
        throw new Error('Missing userWorkspaceId in authContext');
      }

      const userHasPermission =
        await this.permissionsService.userHasWorkspaceSettingPermission({
          userWorkspaceId,
          workspaceId,
          _setting: SettingsPermissions.WORKSPACE,
          isExecutedByApiKey: isDefined(apiKey),
        });

      if (!userHasPermission) {
        throw new PermissionsException(
          PermissionsExceptionMessage.PERMISSION_DENIED,
          PermissionsExceptionCode.PERMISSION_DENIED,
        );
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines an SSOService for managing Single Sign-On identity providers, including creating, retrieving, updating, and deleting OIDC and SAML providers, and checking SSO entitlements.
Code Snippet:
/* @license Enterprise */

import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Issuer } from 'openid-client';
import { Repository } from 'typeorm';

import { BillingEntitlementKey } from 'src/engine/core-modules/billing/enums/billing-entitlement-key.enum';
import { BillingService } from 'src/engine/core-modules/billing/services/billing.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import {
  SSOException,
  SSOExceptionCode,
} from 'src/engine/core-modules/sso/sso.exception';
import {
  OIDCConfiguration,
  SAMLConfiguration,
  SSOConfiguration,
} from 'src/engine/core-modules/sso/types/SSOConfigurations.type';
import {
  IdentityProviderType,
  OIDCResponseType,
  WorkspaceSSOIdentityProvider,
} from 'src/engine/core-modules/sso/workspace-sso-identity-provider.entity';
import { ExceptionHandlerService } from 'src/engine/core-modules/exception-handler/exception-handler.service';

@Injectable()
export class SSOService {
  private readonly featureLookUpKey = BillingEntitlementKey.SSO;
  constructor(
    @InjectRepository(WorkspaceSSOIdentityProvider, 'core')
    private readonly workspaceSSOIdentityProviderRepository: Repository<WorkspaceSSOIdentityProvider>,
    private readonly environmentService: EnvironmentService,
    private readonly billingService: BillingService,
    private readonly exceptionHandlerService: ExceptionHandlerService,
  ) {}

  private async isSSOEnabled(workspaceId: string) {
    const isSSOBillingEnabled = await this.billingService.hasEntitlement(
      workspaceId,
      this.featureLookUpKey,
    );

    if (!isSSOBillingEnabled) {
      throw new SSOException(
        `No entitlement found for this workspace`,
        SSOExceptionCode.SSO_DISABLE,
      );
    }
  }

  private async getIssuerForOIDC(issuerUrl: string) {
    try {
      return await Issuer.discover(issuerUrl);
    } catch (err) {
      throw new SSOException(
        'Invalid issuer',
        SSOExceptionCode.INVALID_ISSUER_URL,
      );
    }
  }

  async createOIDCIdentityProvider(
    data: Pick<
      WorkspaceSSOIdentityProvider,
      'issuer' | 'clientID' | 'clientSecret' | 'name'
    >,
    workspaceId: string,
  ) {
    try {
      await this.isSSOEnabled(workspaceId);

      const issuer = await this.getIssuerForOIDC(data.issuer);

      const identityProvider =
        await this.workspaceSSOIdentityProviderRepository.save({
          type: IdentityProviderType.OIDC,
          clientID: data.clientID,
          clientSecret: data.clientSecret,
          issuer: issuer.metadata.issuer,
          name: data.name,
          workspaceId,
        });

      return {
        id: identityProvider.id,
        type: identityProvider.type,
        name: identityProvider.name,
        status: identityProvider.status,
        issuer: identityProvider.issuer,
      };
    } catch (err) {
      if (err instanceof SSOException) {
        return err;
      }

      this.exceptionHandlerService.captureExceptions([err]);

      return new SSOException(
        'Unknown SSO configuration error',
        SSOExceptionCode.UNKNOWN_SSO_CONFIGURATION_ERROR,
      );
    }
  }

  async createSAMLIdentityProvider(
    data: Pick<
      WorkspaceSSOIdentityProvider,
      'ssoURL' | 'certificate' | 'fingerprint' | 'id'
    >,
    workspaceId: string,
  ) {
    await this.isSSOEnabled(workspaceId);

    const identityProvider =
      await this.workspaceSSOIdentityProviderRepository.save({
        ...data,
        type: IdentityProviderType.SAML,
        workspaceId,
      });

    return {
      id: identityProvider.id,
      type: identityProvider.type,
      name: identityProvider.name,
      issuer: this.buildIssuerURL(identityProvider),
      status: identityProvider.status,
    };
  }

  async findSSOIdentityProviderById(identityProviderId: string) {
    return (await this.workspaceSSOIdentityProviderRepository.findOne({
      where: { id: identityProviderId },
      relations: ['workspace'],
    })) as (SSOConfiguration & WorkspaceSSOIdentityProvider) | null;
  }

  buildCallbackUrl(
    identityProvider: Pick<WorkspaceSSOIdentityProvider, 'type' | 'id'>,
  ) {
    const callbackURL = new URL(this.environmentService.get('SERVER_URL'));

    callbackURL.pathname = `/auth/${identityProvider.type.toLowerCase()}/callback`;

    if (identityProvider.type === IdentityProviderType.SAML) {
      callbackURL.pathname += `/${identityProvider.id}`;
    }

    return callbackURL.toString();
  }

  buildIssuerURL(
    identityProvider: Pick<WorkspaceSSOIdentityProvider, 'id' | 'type'>,
    searchParams?: Record<string, string | boolean>,
  ) {
    const authorizationUrl = new URL(this.environmentService.get('SERVER_URL'));

    authorizationUrl.pathname = `/auth/${identityProvider.type.toLowerCase()}/login/${identityProvider.id}`;

    if (searchParams) {
      Object.entries(searchParams).forEach(([key, value]) => {
        authorizationUrl.searchParams.append(key, value.toString());
      });
    }

    return authorizationUrl.toString();
  }

  private isOIDCIdentityProvider(
    identityProvider: WorkspaceSSOIdentityProvider,
  ): identityProvider is OIDCConfiguration & WorkspaceSSOIdentityProvider {
    return identityProvider.type === IdentityProviderType.OIDC;
  }

  isSAMLIdentityProvider(
    identityProvider: WorkspaceSSOIdentityProvider,
  ): identityProvider is SAMLConfiguration & WorkspaceSSOIdentityProvider {
    return identityProvider.type === IdentityProviderType.SAML;
  }

  getOIDCClient(
    identityProvider: WorkspaceSSOIdentityProvider,
    issuer: Issuer,
  ) {
    if (!this.isOIDCIdentityProvider(identityProvider)) {
      throw new SSOException(
        'Invalid Identity Provider type',
        SSOExceptionCode.INVALID_IDP_TYPE,
      );
    }

    return new issuer.Client({
      client_id: identityProvider.clientID,
      client_secret: identityProvider.clientSecret,
      redirect_uris: [this.buildCallbackUrl(identityProvider)],
      response_types: [OIDCResponseType.CODE],
    });
  }

  async getAuthorizationUrlForSSO(
    identityProviderId: string,
    searchParams: Record<string, string | boolean>,
  ) {
    const identityProvider =
      (await this.workspaceSSOIdentityProviderRepository.findOne({
        where: {
          id: identityProviderId,
        },
      })) as WorkspaceSSOIdentityProvider & SSOConfiguration;

    if (!identityProvider) {
      throw new SSOException(
        'Identity Provider not found',
        SSOExceptionCode.USER_NOT_FOUND,
      );
    }

    return {
      id: identityProvider.id,
      authorizationURL: this.buildIssuerURL(identityProvider, searchParams),
      type: identityProvider.type,
    };
  }

  async getSSOIdentityProviders(workspaceId: string) {
    return (await this.workspaceSSOIdentityProviderRepository.find({
      where: { workspaceId },
      select: ['id', 'name', 'type', 'issuer', 'status'],
    })) as Array<
      Pick<
        WorkspaceSSOIdentityProvider,
        'id' | 'name' | 'type' | 'issuer' | 'status'
      >
    >;
  }

  async deleteSSOIdentityProvider(
    identityProviderId: string,
    workspaceId: string,
  ) {
    const identityProvider =
      await this.workspaceSSOIdentityProviderRepository.findOne({
        where: {
          id: identityProviderId,
          workspaceId,
        },
      });

    if (!identityProvider) {
      throw new SSOException(
        'Identity Provider not found',
        SSOExceptionCode.IDENTITY_PROVIDER_NOT_FOUND,
      );
    }

    await this.workspaceSSOIdentityProviderRepository.delete({
      id: identityProvider.id,
    });

    return { identityProviderId: identityProvider.id };
  }

  async editSSOIdentityProvider(
    payload: Partial<WorkspaceSSOIdentityProvider>,
    workspaceId: string,
  ) {
    const ssoIdp = await this.workspaceSSOIdentityProviderRepository.findOne({
      where: {
        id: payload.id,
        workspaceId,
      },
    });

    if (!ssoIdp) {
      throw new SSOException(
        'Identity Provider not found',
        SSOExceptionCode.IDENTITY_PROVIDER_NOT_FOUND,
      );
    }

    const result = await this.workspaceSSOIdentityProviderRepository.save({
      ...ssoIdp,
      ...payload,
    });

    return {
      id: result.id,
      type: result.type,
      issuer: result.issuer,
      name: result.name,
      status: result.status,
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS command to sync customer data from Stripe for active workspaces, using repositories for Workspace and BillingCustomer entities.
Code Snippet:
/* @license Enterprise */

import { InjectRepository } from '@nestjs/typeorm';

import chalk from 'chalk';
import { Command } from 'nest-commander';
import { Repository } from 'typeorm';

import {
  ActiveOrSuspendedWorkspacesMigrationCommandRunner,
  RunOnWorkspaceArgs,
} from 'src/database/commands/command-runners/active-or-suspended-workspaces-migration.command-runner';
import { BillingCustomer } from 'src/engine/core-modules/billing/entities/billing-customer.entity';
import { StripeSubscriptionService } from 'src/engine/core-modules/billing/stripe/services/stripe-subscription.service';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';

@Command({
  name: 'billing:sync-customer-data',
  description: 'Sync customer data from Stripe for all active workspaces',
})
export class BillingSyncCustomerDataCommand extends ActiveOrSuspendedWorkspacesMigrationCommandRunner {
  constructor(
    @InjectRepository(Workspace, 'core')
    protected readonly workspaceRepository: Repository<Workspace>,
    private readonly stripeSubscriptionService: StripeSubscriptionService,
    @InjectRepository(BillingCustomer, 'core')
    protected readonly billingCustomerRepository: Repository<BillingCustomer>,
    protected readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {
    super(workspaceRepository, twentyORMGlobalManager);
  }

  override async runOnWorkspace({
    workspaceId,
    options,
  }: RunOnWorkspaceArgs): Promise<void> {
    const billingCustomer = await this.billingCustomerRepository.findOne({
      where: {
        workspaceId,
      },
    });

    if (!options.dryRun && !billingCustomer) {
      const stripeCustomerId =
        await this.stripeSubscriptionService.getStripeCustomerIdFromWorkspaceId(
          workspaceId,
        );

      if (stripeCustomerId) {
        await this.billingCustomerRepository.upsert(
          {
            stripeCustomerId,
            workspaceId,
          },
          {
            conflictPaths: ['workspaceId'],
          },
        );
      }
    }

    if (options.verbose) {
      this.logger.log(
        chalk.yellow(`Added ${workspaceId} to billingCustomer table`),
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a job to update the subscription quantity based on the number of workspace members.
Code Snippet:
/* @license Enterprise */

import { Logger, Scope } from '@nestjs/common';

import { BillingSubscriptionService } from 'src/engine/core-modules/billing/services/billing-subscription.service';
import { StripeSubscriptionItemService } from 'src/engine/core-modules/billing/stripe/services/stripe-subscription-item.service';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { TwentyORMManager } from 'src/engine/twenty-orm/twenty-orm.manager';
import { WorkspaceMemberWorkspaceEntity } from 'src/modules/workspace-member/standard-objects/workspace-member.workspace-entity';
export type UpdateSubscriptionQuantityJobData = { workspaceId: string };

@Processor({
  queueName: MessageQueue.billingQueue,
  scope: Scope.REQUEST,
})
export class UpdateSubscriptionQuantityJob {
  protected readonly logger = new Logger(UpdateSubscriptionQuantityJob.name);

  constructor(
    private readonly billingSubscriptionService: BillingSubscriptionService,
    private readonly stripeSubscriptionItemService: StripeSubscriptionItemService,
    private readonly twentyORMManager: TwentyORMManager,
  ) {}

  @Process(UpdateSubscriptionQuantityJob.name)
  async handle(data: UpdateSubscriptionQuantityJobData): Promise<void> {
    const workspaceMemberRepository =
      await this.twentyORMManager.getRepository<WorkspaceMemberWorkspaceEntity>(
        'workspaceMember',
      );

    const workspaceMembersCount = await workspaceMemberRepository.count();

    if (!workspaceMembersCount || workspaceMembersCount <= 0) {
      return;
    }

    try {
      const billingBaseProductSubscriptionItem =
        await this.billingSubscriptionService.getBaseProductCurrentBillingSubscriptionItemOrThrow(
          data.workspaceId,
        );

      await this.stripeSubscriptionItemService.updateSubscriptionItem(
        billingBaseProductSubscriptionItem.stripeSubscriptionItemId,
        workspaceMembersCount,
      );

      this.logger.log(
        `Updating workspace ${data.workspaceId} subscription quantity to ${workspaceMembersCount} members`,
      );
    } catch (e) {
      this.logger.warn(
        `Failed to update workspace ${data.workspaceId} subscription quantity to ${workspaceMembersCount} members. Error: ${e}`,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code processes Stripe product events, validates metadata, and upserts product data into a database.
Code Snippet:
/* @license Enterprise */

import { Injectable, Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import Stripe from 'stripe';
import { Repository } from 'typeorm';

import { BillingProduct } from 'src/engine/core-modules/billing/entities/billing-product.entity';
import { BillingPlanKey } from 'src/engine/core-modules/billing/enums/billing-plan-key.enum';
import { BillingUsageType } from 'src/engine/core-modules/billing/enums/billing-usage-type.enum';
import { BillingProductMetadata } from 'src/engine/core-modules/billing/types/billing-product-metadata.type';
import { isStripeValidProductMetadata } from 'src/engine/core-modules/billing/utils/is-stripe-valid-product-metadata.util';
import { transformStripeProductEventToDatabaseProduct } from 'src/engine/core-modules/billing/webhooks/utils/transform-stripe-product-event-to-database-product.util';
@Injectable()
export class BillingWebhookProductService {
  protected readonly logger = new Logger(BillingWebhookProductService.name);
  constructor(
    @InjectRepository(BillingProduct, 'core')
    private readonly billingProductRepository: Repository<BillingProduct>,
  ) {}

  async processStripeEvent(
    data: Stripe.ProductCreatedEvent.Data | Stripe.ProductUpdatedEvent.Data,
  ) {
    const metadata = data.object.metadata;
    const productRepositoryData = isStripeValidProductMetadata(metadata)
      ? {
          ...transformStripeProductEventToDatabaseProduct(data),
          metadata,
        }
      : transformStripeProductEventToDatabaseProduct(data);

    await this.billingProductRepository.upsert(productRepositoryData, {
      conflictPaths: ['stripeProductId'],
      skipUpdateIfNoValuesChanged: true,
    });

    return {
      stripeProductId: data.object.id,
    };
  }

  isStripeValidProductMetadata(
    metadata: Stripe.Metadata,
  ): metadata is BillingProductMetadata {
    if (Object.keys(metadata).length === 0) {
      return true;
    }
    const hasBillingPlanKey = this.isValidBillingPlanKey(metadata?.planKey);
    const hasPriceUsageBased = this.isValidPriceUsageBased(
      metadata?.priceUsageBased,
    );

    return hasBillingPlanKey && hasPriceUsageBased;
  }

  isValidBillingPlanKey(planKey?: string) {
    return Object.values(BillingPlanKey).includes(planKey as BillingPlanKey);
  }

  isValidPriceUsageBased(priceUsageBased?: string) {
    return Object.values(BillingUsageType).includes(
      priceUsageBased as BillingUsageType,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for handling billing usage, checking feature availability, and billing usage events for workspaces.
Code Snippet:
/* @license Enterprise */

import { Injectable, Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { Repository } from 'typeorm';

import {
  BillingException,
  BillingExceptionCode,
} from 'src/engine/core-modules/billing/billing.exception';
import { BillingCustomer } from 'src/engine/core-modules/billing/entities/billing-customer.entity';
import { BillingSubscriptionService } from 'src/engine/core-modules/billing/services/billing-subscription.service';
import { StripeBillingMeterEventService } from 'src/engine/core-modules/billing/stripe/services/stripe-billing-meter-event.service';
import { BillingUsageEvent } from 'src/engine/core-modules/billing/types/billing-usage-event.type';

@Injectable()
export class BillingUsageService {
  protected readonly logger = new Logger(BillingUsageService.name);
  constructor(
    @InjectRepository(BillingCustomer, 'core')
    private readonly billingCustomerRepository: Repository<BillingCustomer>,
    private readonly billingSubscriptionService: BillingSubscriptionService,
    private readonly stripeBillingMeterEventService: StripeBillingMeterEventService,
  ) {}

  async canFeatureBeUsed(workspaceId: string): Promise<boolean> {
    const billingSubscription =
      await this.billingSubscriptionService.getCurrentBillingSubscriptionOrThrow(
        {
          workspaceId,
        },
      );

    if (!billingSubscription) {
      return false;
    }

    return true;
  }

  async billUsage({
    workspaceId,
    billingEvents,
  }: {
    workspaceId: string;
    billingEvents: BillingUsageEvent[];
  }) {
    const workspaceStripeCustomer =
      await this.billingCustomerRepository.findOne({
        where: {
          workspaceId,
        },
      });

    if (!workspaceStripeCustomer) {
      throw new BillingException(
        'Stripe customer not found',
        BillingExceptionCode.BILLING_CUSTOMER_NOT_FOUND,
      );
    }

    try {
      await this.stripeBillingMeterEventService.sendBillingMeterEvent({
        eventName: billingEvents[0].eventName,
        value: billingEvents[0].value,
        stripeCustomerId: workspaceStripeCustomer.stripeCustomerId,
      });
    } catch (error) {
      throw new BillingException(
        `Failed to send billing meter events to Stripe: ${error}`,
        BillingExceptionCode.BILLING_METER_EVENT_FAILED,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for updating Stripe customer metadata with a workspace ID.
Code Snippet:
/* @license Enterprise */

import { Injectable, Logger } from '@nestjs/common';

import Stripe from 'stripe';

import { StripeSDKService } from 'src/engine/core-modules/billing/stripe/stripe-sdk/services/stripe-sdk.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';

@Injectable()
export class StripeCustomerService {
  protected readonly logger = new Logger(StripeCustomerService.name);
  private readonly stripe: Stripe;

  constructor(
    private readonly environmentService: EnvironmentService,
    private readonly stripeSDKService: StripeSDKService,
  ) {
    if (!this.environmentService.get('IS_BILLING_ENABLED')) {
      return;
    }
    this.stripe = this.stripeSDKService.getStripe(
      this.environmentService.get('BILLING_STRIPE_API_KEY'),
    );
  }

  async updateCustomerMetadataWorkspaceId(
    stripeCustomerId: string,
    workspaceId: string,
  ) {
    await this.stripe.customers.update(stripeCustomerId, {
      metadata: { workspaceId: workspaceId },
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a service for managing Stripe subscriptions, including canceling subscriptions, retrieving customer IDs, collecting invoices, and updating subscription items.
Code Snippet:
/* @license Enterprise */

import { Injectable, Logger } from '@nestjs/common';

import Stripe from 'stripe';

import { BillingSubscriptionItem } from 'src/engine/core-modules/billing/entities/billing-subscription-item.entity';
import { StripeSDKService } from 'src/engine/core-modules/billing/stripe/stripe-sdk/services/stripe-sdk.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';

@Injectable()
export class StripeSubscriptionService {
  protected readonly logger = new Logger(StripeSubscriptionService.name);
  private readonly stripe: Stripe;

  constructor(
    private readonly environmentService: EnvironmentService,
    private readonly stripeSDKService: StripeSDKService,
  ) {
    if (!this.environmentService.get('IS_BILLING_ENABLED')) {
      return;
    }
    this.stripe = this.stripeSDKService.getStripe(
      this.environmentService.get('BILLING_STRIPE_API_KEY'),
    );
  }

  async cancelSubscription(stripeSubscriptionId: string) {
    await this.stripe.subscriptions.cancel(stripeSubscriptionId);
  }

  async getStripeCustomerIdFromWorkspaceId(workspaceId: string) {
    const subscription = await this.stripe.subscriptions.search({
      query: `metadata['workspaceId']:'${workspaceId}'`,
      limit: 1,
    });
    const stripeCustomerId = subscription.data[0].customer
      ? String(subscription.data[0].customer)
      : undefined;

    return stripeCustomerId;
  }

  async collectLastInvoice(stripeSubscriptionId: string) {
    const subscription = await this.stripe.subscriptions.retrieve(
      stripeSubscriptionId,
      { expand: ['latest_invoice'] },
    );
    const latestInvoice = subscription.latest_invoice;

    if (
      !(
        latestInvoice &&
        typeof latestInvoice !== 'string' &&
        latestInvoice.status === 'draft'
      )
    ) {
      return;
    }
    await this.stripe.invoices.pay(latestInvoice.id);
  }

  async updateSubscriptionItems(
    stripeSubscriptionId: string,
    billingSubscriptionItems: BillingSubscriptionItem[],
  ) {
    const stripeSubscriptionItemsToUpdate = billingSubscriptionItems.map(
      (item) => ({
        id: item.stripeSubscriptionItemId,
        price: item.stripePriceId,
        quantity: item.quantity === null ? undefined : item.quantity,
      }),
    );

    await this.stripe.subscriptions.update(stripeSubscriptionId, {
      items: stripeSubscriptionItemsToUpdate,
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for sending billing meter events to Stripe.
Code Snippet:
/* @license Enterprise */

import { Injectable, Logger } from '@nestjs/common';

import Stripe from 'stripe';

import { BillingMeterEventName } from 'src/engine/core-modules/billing/enums/billing-meter-event-names';
import { StripeSDKService } from 'src/engine/core-modules/billing/stripe/stripe-sdk/services/stripe-sdk.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';

@Injectable()
export class StripeBillingMeterEventService {
  protected readonly logger = new Logger(StripeBillingMeterEventService.name);
  private readonly stripe: Stripe;

  constructor(
    private readonly environmentService: EnvironmentService,
    private readonly stripeSDKService: StripeSDKService,
  ) {
    if (!this.environmentService.get('IS_BILLING_ENABLED')) {
      return;
    }
    this.stripe = this.stripeSDKService.getStripe(
      this.environmentService.get('BILLING_STRIPE_API_KEY'),
    );
  }

  async sendBillingMeterEvent({
    eventName,
    value,
    stripeCustomerId,
  }: {
    eventName: BillingMeterEventName;
    value: number;
    stripeCustomerId: string;
  }) {
    await this.stripe.billing.meterEvents.create({
      event_name: eventName,
      payload: {
        value: value.toString(),
        stripe_customer_id: stripeCustomerId,
      },
    });
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines an OnboardingService for managing onboarding steps in a workspace, checking the status, and updating the status of specific onboarding tasks.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { WorkspaceActivationStatus } from 'twenty-shared';

import { BillingService } from 'src/engine/core-modules/billing/services/billing.service';
import { OnboardingStatus } from 'src/engine/core-modules/onboarding/enums/onboarding-status.enum';
import { UserVarsService } from 'src/engine/core-modules/user/user-vars/services/user-vars.service';
import { User } from 'src/engine/core-modules/user/user.entity';
import { Workspace } from 'src/engine/core-modules/workspace/workspace.entity';

export enum OnboardingStepKeys {
  ONBOARDING_CONNECT_ACCOUNT_PENDING = 'ONBOARDING_CONNECT_ACCOUNT_PENDING',
  ONBOARDING_INVITE_TEAM_PENDING = 'ONBOARDING_INVITE_TEAM_PENDING',
  ONBOARDING_CREATE_PROFILE_PENDING = 'ONBOARDING_CREATE_PROFILE_PENDING',
}

export type OnboardingKeyValueTypeMap = {
  [OnboardingStepKeys.ONBOARDING_CONNECT_ACCOUNT_PENDING]: boolean;
  [OnboardingStepKeys.ONBOARDING_INVITE_TEAM_PENDING]: boolean;
  [OnboardingStepKeys.ONBOARDING_CREATE_PROFILE_PENDING]: boolean;
};

@Injectable()
export class OnboardingService {
  constructor(
    private readonly billingService: BillingService,
    private readonly userVarsService: UserVarsService<OnboardingKeyValueTypeMap>,
  ) {}

  private isWorkspaceActivationPending(workspace: Workspace) {
    return (
      workspace.activationStatus === WorkspaceActivationStatus.PENDING_CREATION
    );
  }

  async getOnboardingStatus(user: User, workspace: Workspace) {
    if (
      await this.billingService.isSubscriptionIncompleteOnboardingStatus(
        workspace.id,
      )
    ) {
      return OnboardingStatus.PLAN_REQUIRED;
    }

    if (this.isWorkspaceActivationPending(workspace)) {
      return OnboardingStatus.WORKSPACE_ACTIVATION;
    }

    const userVars = await this.userVarsService.getAll({
      userId: user.id,
      workspaceId: workspace.id,
    });

    const isProfileCreationPending =
      userVars.get(OnboardingStepKeys.ONBOARDING_CREATE_PROFILE_PENDING) ===
      true;

    const isConnectAccountPending =
      userVars.get(OnboardingStepKeys.ONBOARDING_CONNECT_ACCOUNT_PENDING) ===
      true;

    const isInviteTeamPending =
      userVars.get(OnboardingStepKeys.ONBOARDING_INVITE_TEAM_PENDING) === true;

    if (isProfileCreationPending) {
      return OnboardingStatus.PROFILE_CREATION;
    }

    if (isConnectAccountPending) {
      return OnboardingStatus.SYNC_EMAIL;
    }

    if (isInviteTeamPending) {
      return OnboardingStatus.INVITE_TEAM;
    }

    return OnboardingStatus.COMPLETED;
  }

  async setOnboardingConnectAccountPending({
    userId,
    workspaceId,
    value,
  }: {
    userId: string;
    workspaceId: string;
    value: boolean;
  }) {
    if (!value) {
      await this.userVarsService.delete({
        userId,
        workspaceId,
        key: OnboardingStepKeys.ONBOARDING_CONNECT_ACCOUNT_PENDING,
      });

      return;
    }

    await this.userVarsService.set({
      userId,
      workspaceId: workspaceId,
      key: OnboardingStepKeys.ONBOARDING_CONNECT_ACCOUNT_PENDING,
      value: true,
    });
  }

  async setOnboardingInviteTeamPending({
    workspaceId,
    value,
  }: {
    workspaceId: string;
    value: boolean;
  }) {
    if (!value) {
      await this.userVarsService.delete({
        workspaceId,
        key: OnboardingStepKeys.ONBOARDING_INVITE_TEAM_PENDING,
      });

      return;
    }

    await this.userVarsService.set({
      workspaceId,
      key: OnboardingStepKeys.ONBOARDING_INVITE_TEAM_PENDING,
      value: true,
    });
  }

  async setOnboardingCreateProfilePending({
    userId,
    workspaceId,
    value,
  }: {
    userId: string;
    workspaceId: string;
    value: boolean;
  }) {
    if (!value) {
      await this.userVarsService.delete({
        userId,
        workspaceId,
        key: OnboardingStepKeys.ONBOARDING_CREATE_PROFILE_PENDING,
      });

      return;
    }

    await this.userVarsService.set({
      userId,
      workspaceId,
      key: OnboardingStepKeys.ONBOARDING_CREATE_PROFILE_PENDING,
      value: true,
    });
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_8>



=== New Entry ===

<CLUSTER_9>
Number of Code Snippets part of this cluster: 11
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service to seed custom objects, fields, and records into a workspace database.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { capitalize, FieldMetadataType, isDefined } from 'twenty-shared';

import { ObjectMetadataSeed } from 'src/engine/seeder/interfaces/object-metadata-seed';

import { DEV_SEED_WORKSPACE_MEMBER_IDS } from 'src/database/typeorm-seeds/workspace/workspace-members';
import { compositeTypeDefinitions } from 'src/engine/metadata-modules/field-metadata/composite-types';
import { CreateFieldInput } from 'src/engine/metadata-modules/field-metadata/dtos/create-field.input';
import { FieldMetadataService } from 'src/engine/metadata-modules/field-metadata/field-metadata.service';
import { isCompositeFieldMetadataType } from 'src/engine/metadata-modules/field-metadata/utils/is-composite-field-metadata-type.util';
import { ObjectMetadataService } from 'src/engine/metadata-modules/object-metadata/object-metadata.service';
import { computeTableName } from 'src/engine/utils/compute-table-name.util';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';

@Injectable()
export class SeederService {
  constructor(
    private readonly objectMetadataService: ObjectMetadataService,
    private readonly fieldMetadataService: FieldMetadataService,
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
  ) {}

  public async seedCustomObjects(
    dataSourceId: string,
    workspaceId: string,
    objectMetadataSeed: ObjectMetadataSeed,
    objectRecordSeeds: Record<string, any>[],
  ): Promise<void> {
    const createdObjectMetadata = await this.objectMetadataService.createOne({
      ...objectMetadataSeed,
      dataSourceId,
      workspaceId,
    });

    if (!createdObjectMetadata) {
      throw new Error("Object metadata couldn't be created");
    }

    await this.fieldMetadataService.createMany(
      objectMetadataSeed.fields.map((fieldMetadataSeed) => ({
        ...fieldMetadataSeed,
        objectMetadataId: createdObjectMetadata.id,
        workspaceId,
      })),
    );

    const objectMetadataAfterFieldCreation =
      await this.objectMetadataService.findOneWithinWorkspace(workspaceId, {
        where: { nameSingular: objectMetadataSeed.nameSingular },
      });

    if (!objectMetadataAfterFieldCreation) {
      throw new Error(
        "Object metadata couldn't be found after field creation.",
      );
    }

    const schemaName =
      this.workspaceDataSourceService.getSchemaName(workspaceId);

    const workspaceDataSource =
      await this.workspaceDataSourceService.connectToWorkspaceDataSource(
        workspaceId,
      );

    const entityManager = workspaceDataSource.createEntityManager();

    const filteredFieldMetadataSeeds = objectMetadataSeed.fields.filter(
      (field) =>
        objectMetadataAfterFieldCreation.fields.some(
          (f) => f.name === field.name || f.name === `name`,
        ),
    );

    if (filteredFieldMetadataSeeds.length === 0) {
      throw new Error('No fields found for seeding, check metadata file');
    }

    this.addNameFieldToFieldMetadataSeeds(filteredFieldMetadataSeeds);

    const objectRecordSeedsAsSQLFlattenedSeeds = objectRecordSeeds.map(
      (recordSeed) => {
        const objectRecordSeedsAsSQLFlattenedSeeds = {};

        for (const field of filteredFieldMetadataSeeds) {
          if (isCompositeFieldMetadataType(field.type)) {
            const compositeFieldTypeDefinition = compositeTypeDefinitions.get(
              field.type,
            );

            if (!isDefined(compositeFieldTypeDefinition)) {
              throw new Error(
                `Composite field type definition not found for ${field.type}`,
              );
            }

            const fieldNames = compositeFieldTypeDefinition.properties
              ?.map((property) => property.name)
              .filter(isDefined);

            for (const subFieldName of fieldNames) {
              const subFieldValue = recordSeed?.[field.name]?.[subFieldName];

              const subFieldValueAsSQLValue =
                this.turnCompositeSubFieldValueAsSQLValue(
                  field.type,
                  subFieldName,
                  subFieldValue,
                );

              const subFieldNameAsSQLColumnName = `${field.name}${capitalize(subFieldName)}`;

              objectRecordSeedsAsSQLFlattenedSeeds[
                subFieldNameAsSQLColumnName
              ] = subFieldValueAsSQLValue;
            }
          } else {
            const fieldValue = recordSeed[field.name];

            const fieldValueAsSQLValue = this.turnFieldValueAsSQLValue(
              field.type,
              fieldValue,
            );

            objectRecordSeedsAsSQLFlattenedSeeds[field.name] =
              fieldValueAsSQLValue;
          }
        }

        return objectRecordSeedsAsSQLFlattenedSeeds;
      },
    );

    if (!(objectRecordSeedsAsSQLFlattenedSeeds.length > 0)) {
      return;
    }

    const fieldMetadataNamesAsFlattenedSQLColumnNames = Object.keys(
      objectRecordSeedsAsSQLFlattenedSeeds[0],
    );

    const sqlColumnNames = [
      ...fieldMetadataNamesAsFlattenedSQLColumnNames,
      'position',
      'createdBySource',
      'createdByWorkspaceMemberId',
      'createdByName',
    ];

    const sqlValues = objectRecordSeedsAsSQLFlattenedSeeds.map(
      (flattenedSeed, index) => ({
        ...flattenedSeed,
        position: index,
        createdBySource: 'MANUAL',
        createdByWorkspaceMemberId: DEV_SEED_WORKSPACE_MEMBER_IDS.TIM,
        createdByName: 'Tim Apple',
      }),
    );

    await entityManager
      .createQueryBuilder()
      .insert()
      .into(
        `${schemaName}.${computeTableName(objectMetadataAfterFieldCreation.nameSingular, true)}`,
        sqlColumnNames,
      )
      .orIgnore()
      .values(sqlValues)
      .returning('*')
      .execute();
  }

  private addNameFieldToFieldMetadataSeeds(
    arrayOfMetadataFields: Pick<CreateFieldInput, 'name' | 'type' | 'label'>[],
  ) {
    arrayOfMetadataFields.unshift({
      name: 'name',
      type: FieldMetadataType.TEXT,
      label: 'Name',
    });
  }

  private turnCompositeSubFieldValueAsSQLValue(
    fieldType: FieldMetadataType,
    subFieldName: string,
    subFieldValue: any,
  ) {
    if (!isCompositeFieldMetadataType(fieldType)) {
      throw new Error(
        `${subFieldName} is not a sub field of a composite field type.`,
      );
    }

    const compositeFieldTypeDefinition =
      compositeTypeDefinitions.get(fieldType);

    const compositeSubFieldType =
      compositeFieldTypeDefinition?.properties.find(
        (property) => property.name === subFieldName,
      )?.type ?? null;

    if (!isDefined(compositeSubFieldType)) {
      throw new Error(
        `Cannot find ${subFieldName} in properties of composite type ${fieldType}.`,
      );
    }

    return this.turnFieldValueAsSQLValue(compositeSubFieldType, subFieldValue);
  }

  private turnFieldValueAsSQLValue(
    fieldType: FieldMetadataType,
    fieldValue: any,
  ) {
    if (fieldType === FieldMetadataType.RAW_JSON) {
      try {
        return JSON.stringify(fieldValue);
      } catch (error) {
        throw new Error(
          `Error while trying to turn field value as stringified JSON : ${error.message}`,
        );
      }
    }

    return fieldValue;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to create an EntitySchema for a given object metadata within a workspace, using provided field and relation factories, and stores it in a workspace storage.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { EntitySchema } from 'typeorm';

import { ObjectMetadataItemWithFieldMaps } from 'src/engine/metadata-modules/types/object-metadata-item-with-field-maps';
import { ObjectMetadataMaps } from 'src/engine/metadata-modules/types/object-metadata-maps';
import { EntitySchemaColumnFactory } from 'src/engine/twenty-orm/factories/entity-schema-column.factory';
import { EntitySchemaRelationFactory } from 'src/engine/twenty-orm/factories/entity-schema-relation.factory';
import { WorkspaceEntitiesStorage } from 'src/engine/twenty-orm/storage/workspace-entities.storage';
import { computeTableName } from 'src/engine/utils/compute-table-name.util';

@Injectable()
export class EntitySchemaFactory {
  constructor(
    private readonly entitySchemaColumnFactory: EntitySchemaColumnFactory,
    private readonly entitySchemaRelationFactory: EntitySchemaRelationFactory,
  ) {}

  async create(
    workspaceId: string,
    _metadataVersion: number,
    objectMetadata: ObjectMetadataItemWithFieldMaps,
    objectMetadataMaps: ObjectMetadataMaps,
  ): Promise<EntitySchema> {
    const columns = this.entitySchemaColumnFactory.create(
      objectMetadata.fieldsByName,
    );

    const relations = await this.entitySchemaRelationFactory.create(
      objectMetadata.fieldsByName,
      objectMetadataMaps,
    );

    const entitySchema = new EntitySchema({
      name: objectMetadata.nameSingular,
      tableName: computeTableName(
        objectMetadata.nameSingular,
        objectMetadata.isCustom,
      ),
      columns,
      relations,
    });

    WorkspaceEntitiesStorage.setEntitySchema(
      workspaceId,
      objectMetadata.nameSingular,
      entitySchema,
    );

    return entitySchema;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing remote tables, including syncing and unsyncing them with local metadata and handling schema changes.
Code Snippet:
import { Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import isEmpty from 'lodash.isempty';
import { plural } from 'pluralize';
import { Repository } from 'typeorm';

import { DataSourceService } from 'src/engine/metadata-modules/data-source/data-source.service';
import { CreateFieldInput } from 'src/engine/metadata-modules/field-metadata/dtos/create-field.input';
import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { FieldMetadataService } from 'src/engine/metadata-modules/field-metadata/field-metadata.service';
import { CreateObjectInput } from 'src/engine/metadata-modules/object-metadata/dtos/create-object.input';
import { ObjectMetadataService } from 'src/engine/metadata-modules/object-metadata/object-metadata.service';
import {
  RemoteServerEntity,
  RemoteServerType,
} from 'src/engine/metadata-modules/remote-server/remote-server.entity';
import { DistantTableService } from 'src/engine/metadata-modules/remote-server/remote-table/distant-table/distant-table.service';
import { sortDistantTables } from 'src/engine/metadata-modules/remote-server/remote-table/distant-table/utils/sort-distant-tables.util';
import { RemoteTableInput } from 'src/engine/metadata-modules/remote-server/remote-table/dtos/remote-table-input';
import {
  DistantTableUpdate,
  RemoteTableStatus,
} from 'src/engine/metadata-modules/remote-server/remote-table/dtos/remote-table.dto';
import { ForeignTableService } from 'src/engine/metadata-modules/remote-server/remote-table/foreign-table/foreign-table.service';
import { RemoteTableSchemaUpdateService } from 'src/engine/metadata-modules/remote-server/remote-table/remote-table-schema-update/remote-table-schema-update.service';
import { RemoteTableEntity } from 'src/engine/metadata-modules/remote-server/remote-table/remote-table.entity';
import {
  RemoteTableException,
  RemoteTableExceptionCode,
} from 'src/engine/metadata-modules/remote-server/remote-table/remote-table.exception';
import { fetchTableColumns } from 'src/engine/metadata-modules/remote-server/remote-table/utils/fetch-table-columns.util';
import { getRemoteTableLocalName } from 'src/engine/metadata-modules/remote-server/remote-table/utils/get-remote-table-local-name.util';
import {
  mapUdtNameToFieldSettings,
  mapUdtNameToFieldType,
} from 'src/engine/metadata-modules/remote-server/remote-table/utils/udt-name-mapper.util';
import { PostgresTableSchemaColumn } from 'src/engine/metadata-modules/remote-server/types/postgres-table-schema-column';
import { WorkspaceMetadataVersionService } from 'src/engine/metadata-modules/workspace-metadata-version/services/workspace-metadata-version.service';
import {
  WorkspaceMigrationColumnAction,
  WorkspaceMigrationColumnActionType,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';
import { camelCase } from 'src/utils/camel-case';
import { camelToTitleCase } from 'src/utils/camel-to-title-case';

export class RemoteTableService {
  private readonly logger = new Logger(RemoteTableService.name);

  constructor(
    @InjectRepository(RemoteTableEntity, 'metadata')
    private readonly remoteTableRepository: Repository<RemoteTableEntity>,
    @InjectRepository(RemoteServerEntity, 'metadata')
    private readonly remoteServerRepository: Repository<
      RemoteServerEntity<RemoteServerType>
    >,
    private readonly workspaceMetadataVersionService: WorkspaceMetadataVersionService,
    private readonly dataSourceService: DataSourceService,
    private readonly objectMetadataService: ObjectMetadataService,
    private readonly fieldMetadataService: FieldMetadataService,
    private readonly distantTableService: DistantTableService,
    private readonly foreignTableService: ForeignTableService,
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
    private readonly remoteTableSchemaUpdateService: RemoteTableSchemaUpdateService,
  ) {}

  public async findDistantTablesWithStatus(
    id: string,
    workspaceId: string,
    shouldFetchPendingSchemaUpdates?: boolean,
  ) {
    const remoteServer = await this.remoteServerRepository.findOne({
      where: {
        id,
        workspaceId,
      },
    });

    if (!remoteServer) {
      throw new RemoteTableException(
        'Remote server does not exist',
        RemoteTableExceptionCode.INVALID_REMOTE_TABLE_INPUT,
      );
    }

    const currentRemoteTables = await this.findRemoteTablesByServerId({
      remoteServerId: id,
      workspaceId,
    });

    const currentRemoteTableDistantNames = currentRemoteTables.map(
      (remoteTable) => remoteTable.distantTableName,
    );

    const distantTables = await this.distantTableService.fetchDistantTables(
      remoteServer,
      workspaceId,
    );

    const distantTablesWithStatus = Object.keys(distantTables).map(
      (tableName) => ({
        name: tableName,
        schema: remoteServer.schema,
        status: currentRemoteTableDistantNames.includes(tableName)
          ? RemoteTableStatus.SYNCED
          : RemoteTableStatus.NOT_SYNCED,
      }),
    );

    if (!shouldFetchPendingSchemaUpdates) {
      return distantTablesWithStatus.sort(sortDistantTables);
    }

    const schemaPendingUpdates =
      await this.remoteTableSchemaUpdateService.getSchemaUpdatesBetweenForeignAndDistantTables(
        {
          workspaceId,
          remoteTables: currentRemoteTables,
          distantTables,
        },
      );

    const distantTablesWithPendingUpdates =
      this.getDistantTablesWithPendingUpdates(
        schemaPendingUpdates,
        distantTablesWithStatus,
        remoteServer.schema,
      );

    return distantTablesWithPendingUpdates.sort(sortDistantTables);
  }

  public async findRemoteTablesByServerId({
    remoteServerId,
    workspaceId,
  }: {
    remoteServerId: string;
    workspaceId: string;
  }) {
    return this.remoteTableRepository.find({
      where: {
        remoteServerId,
        workspaceId,
      },
    });
  }

  public async syncRemoteTable(input: RemoteTableInput, workspaceId: string) {
    const remoteServer = await this.remoteServerRepository.findOne({
      where: {
        id: input.remoteServerId,
        workspaceId,
      },
    });

    if (!remoteServer) {
      throw new RemoteTableException(
        'Remote server does not exist',
        RemoteTableExceptionCode.INVALID_REMOTE_TABLE_INPUT,
      );
    }

    const currentRemoteTableWithSameDistantName =
      await this.remoteTableRepository.findOne({
        where: {
          distantTableName: input.name,
          remoteServerId: remoteServer.id,
          workspaceId,
        },
      });

    if (currentRemoteTableWithSameDistantName) {
      throw new RemoteTableException(
        'Remote server does not exist',
        RemoteTableExceptionCode.REMOTE_TABLE_ALREADY_EXISTS,
      );
    }

    const dataSourceMetatada =
      await this.dataSourceService.getLastDataSourceMetadataFromWorkspaceIdOrFail(
        workspaceId,
      );

    const workspaceDataSource =
      await this.workspaceDataSourceService.connectToWorkspaceDataSource(
        workspaceId,
      );

    const { baseName: localTableBaseName, suffix: localTableSuffix } =
      await getRemoteTableLocalName(
        input.name,
        dataSourceMetatada.schema,
        workspaceDataSource,
      );

    const localTableName = localTableSuffix
      ? `${localTableBaseName}${localTableSuffix}`
      : localTableBaseName;

    const remoteTableEntity = this.remoteTableRepository.create({
      distantTableName: input.name,
      localTableName,
      workspaceId,
      remoteServerId: remoteServer.id,
    });

    const distantTableColumns =
      await this.distantTableService.getDistantTableColumns(
        remoteServer,
        workspaceId,
        input.name,
      );

    if (!distantTableColumns) {
      throw new RemoteTableException(
        'Remote server does not exist',
        RemoteTableExceptionCode.REMOTE_TABLE_NOT_FOUND,
      );
    }

    // We only support remote tables with an id column for now.
    const distantTableIdColumn = distantTableColumns.find(
      (column) => column.columnName === 'id',
    );

    if (!distantTableIdColumn) {
      throw new RemoteTableException(
        'Remote server does not exist',
        RemoteTableExceptionCode.INVALID_REMOTE_TABLE_INPUT,
      );
    }

    await this.foreignTableService.createForeignTable(
      workspaceId,
      localTableName,
      remoteServer,
      input.name,
      distantTableColumns,
    );

    await this.createRemoteTableMetadata(
      workspaceId,
      localTableBaseName,
      localTableSuffix,
      distantTableColumns,
      distantTableIdColumn,
      dataSourceMetatada.id,
    );

    await this.remoteTableRepository.save(remoteTableEntity);

    await this.workspaceMetadataVersionService.incrementMetadataVersion(
      workspaceId,
    );

    return {
      id: remoteTableEntity.id,
      name: input.name,
      schema: remoteServer.schema,
      status: RemoteTableStatus.SYNCED,
    };
  }

  public async unsyncRemoteTable(input: RemoteTableInput, workspaceId: string) {
    const remoteServer = await this.remoteServerRepository.findOne({
      where: {
        id: input.remoteServerId,
        workspaceId,
      },
    });

    if (!remoteServer) {
      throw new RemoteTableException(
        'Remote server does not exist',
        RemoteTableExceptionCode.INVALID_REMOTE_TABLE_INPUT,
      );
    }

    const remoteTable = await this.remoteTableRepository.findOne({
      where: {
        distantTableName: input.name,
        remoteServerId: remoteServer.id,
        workspaceId,
      },
    });

    if (!remoteTable) {
      throw new RemoteTableException(
        'Remote table does not exist',
        RemoteTableExceptionCode.REMOTE_TABLE_NOT_FOUND,
      );
    }

    await this.unsyncOne(workspaceId, remoteTable, remoteServer);

    return {
      name: input.name,
      schema: remoteServer.schema,
      status: RemoteTableStatus.NOT_SYNCED,
    };
  }

  public async unsyncAll(
    workspaceId: string,
    remoteServer: RemoteServerEntity<RemoteServerType>,
  ) {
    const remoteTables = await this.remoteTableRepository.find({
      where: {
        remoteServerId: remoteServer.id,
        workspaceId,
      },
    });

    for (const remoteTable of remoteTables) {
      await this.unsyncOne(workspaceId, remoteTable, remoteServer);
    }
  }

  public async syncRemoteTableSchemaChanges(
    input: RemoteTableInput,
    workspaceId: string,
  ) {
    const remoteServer = await this.remoteServerRepository.findOne({
      where: {
        id: input.remoteServerId,
        workspaceId,
      },
    });

    if (!remoteServer) {
      throw new RemoteTableException(
        'Remote server does not exist',
        RemoteTableExceptionCode.INVALID_REMOTE_TABLE_INPUT,
      );
    }

    const remoteTable = await this.remoteTableRepository.findOne({
      where: {
        distantTableName: input.name,
        remoteServerId: remoteServer.id,
        workspaceId,
      },
    });

    if (!remoteTable) {
      throw new RemoteTableException(
        'Remote table does not exist',
        RemoteTableExceptionCode.REMOTE_TABLE_NOT_FOUND,
      );
    }

    const distantTableColumns =
      await this.distantTableService.getDistantTableColumns(
        remoteServer,
        workspaceId,
        remoteTable.distantTableName,
      );

    if (!distantTableColumns) {
      await this.unsyncOne(workspaceId, remoteTable, remoteServer);

      return {
        name: remoteTable.localTableName,
        status: RemoteTableStatus.NOT_SYNCED,
        schemaPendingUpdates: [],
      };
    }

    const foreignTableColumns = await fetchTableColumns(
      this.workspaceDataSourceService,
      workspaceId,
      remoteTable.localTableName,
    );

    const columnsUpdates =
      this.remoteTableSchemaUpdateService.computeForeignTableColumnsUpdates(
        foreignTableColumns,
        distantTableColumns,
      );

    if (isEmpty(columnsUpdates)) {
      this.logger.log(
        `No update to perform on table "${remoteTable.localTableName}" for workspace ${workspaceId}`,
      );

      return {
        name: remoteTable.localTableName,
        status: RemoteTableStatus.SYNCED,
        schemaPendingUpdates: [],
      };
    }

    const updatedTable = await this.updateForeignTableAndFieldsMetadata(
      remoteTable.localTableName,
      workspaceId,
      columnsUpdates,
    );

    return updatedTable;
  }

  private async unsyncOne(
    workspaceId: string,
    remoteTable: RemoteTableEntity,
    remoteServer: RemoteServerEntity<RemoteServerType>,
  ) {
    const currentForeignTableNames =
      await this.foreignTableService.fetchForeignTableNamesWithinWorkspace(
        workspaceId,
        remoteServer.foreignDataWrapperId,
      );

    if (!currentForeignTableNames.includes(remoteTable.localTableName)) {
      throw new RemoteTableException(
        'Foreign table does not exist',
        RemoteTableExceptionCode.NO_FOREIGN_TABLES_FOUND,
      );
    }

    const objectMetadata =
      await this.objectMetadataService.findOneWithinWorkspace(workspaceId, {
        where: { nameSingular: remoteTable.localTableName },
      });

    if (objectMetadata) {
      await this.objectMetadataService.deleteOneObject(
        { id: objectMetadata.id },
        workspaceId,
      );
    }

    await this.foreignTableService.deleteForeignTable(
      remoteTable.localTableName,
      workspaceId,
    );

    await this.remoteTableRepository.delete(remoteTable.id);

    await this.workspaceMetadataVersionService.incrementMetadataVersion(
      workspaceId,
    );
  }

  private async createRemoteTableMetadata(
    workspaceId: string,
    localTableBaseName: string,
    localTableSuffix: number | undefined,
    distantTableColumns: PostgresTableSchemaColumn[],
    distantTableIdColumn: PostgresTableSchemaColumn,
    dataSourceMetadataId: string,
  ) {
    const localTableNameSingular = localTableSuffix
      ? `${localTableBaseName}${localTableSuffix}`
      : localTableBaseName;

    const localTableNamePlural = localTableSuffix
      ? `${plural(localTableBaseName)}${localTableSuffix}`
      : plural(localTableBaseName);

    const objectMetadata = await this.objectMetadataService.createOne({
      nameSingular: camelCase(localTableNameSingular),
      namePlural: camelCase(localTableNamePlural),
      labelSingular: camelToTitleCase(camelCase(localTableBaseName)),
      labelPlural: camelToTitleCase(plural(camelCase(localTableBaseName))),
      description: 'Remote table',
      dataSourceId: dataSourceMetadataId,
      workspaceId: workspaceId,
      icon: 'IconPlug',
      isRemote: true,
      primaryKeyColumnType: distantTableIdColumn.udtName,
      primaryKeyFieldMetadataSettings: mapUdtNameToFieldSettings(
        distantTableIdColumn.udtName,
      ),
    } satisfies CreateObjectInput);

    for (const column of distantTableColumns) {
      const columnName = camelCase(column.columnName);

      // TODO: return error to the user when a column cannot be managed
      try {
        const field = await this.createFieldMetadataForForeignTableColumn(
          workspaceId,
          columnName,
          column.udtName,
          objectMetadata.id,
        );

        if (columnName === 'id') {
          await this.objectMetadataService.updateOne(objectMetadata.id, {
            labelIdentifierFieldMetadataId: field.id,
          });
        }
      } catch (error) {
        this.logger.error(
          `Could not create field ${columnName} for remote table ${localTableNameSingular}: ${error}`,
        );
      }
    }
  }

  private getDistantTablesWithPendingUpdates(
    schemaPendingUpdates: { [tablename: string]: DistantTableUpdate[] },
    distantTablesWithStatus: {
      name: string;
      schema: string;
      status: RemoteTableStatus;
    }[],
    remoteServerSchema: string,
  ) {
    const distantTablesWithUpdates = distantTablesWithStatus.map((table) => ({
      ...table,
      schemaPendingUpdates: schemaPendingUpdates[table.name] || [],
    }));

    const deletedTables = Object.entries(schemaPendingUpdates)
      .filter(([_tableName, updates]) =>
        updates.includes(DistantTableUpdate.TABLE_DELETED),
      )
      .map(([tableName, updates]) => ({
        name: tableName,
        schema: remoteServerSchema,
        status: RemoteTableStatus.SYNCED,
        schemaPendingUpdates: updates,
      }));

    return [...distantTablesWithUpdates, ...deletedTables];
  }

  private async updateForeignTableAndFieldsMetadata(
    foreignTableName: string,
    workspaceId: string,
    columnsUpdates: WorkspaceMigrationColumnAction[],
  ) {
    const updatedForeignTable =
      await this.foreignTableService.updateForeignTable(
        foreignTableName,
        workspaceId,
        columnsUpdates,
      );

    const objectMetadata =
      await this.objectMetadataService.findOneWithinWorkspace(workspaceId, {
        where: { nameSingular: foreignTableName },
      });

    if (!objectMetadata) {
      throw new RemoteTableException(
        `Cannot find associated object for table ${foreignTableName}`,
        RemoteTableExceptionCode.NO_OBJECT_METADATA_FOUND,
      );
    }
    for (const columnUpdate of columnsUpdates) {
      this.updateFieldMetadataFromColumnUpdate(
        columnUpdate,
        workspaceId,
        objectMetadata.id,
      );
    }

    return updatedForeignTable;
  }

  private async updateFieldMetadataFromColumnUpdate(
    columnUpdate: WorkspaceMigrationColumnAction,
    workspaceId: string,
    objectMetadataId: string,
  ) {
    if (columnUpdate.action === WorkspaceMigrationColumnActionType.CREATE) {
      await this.createFieldMetadataForForeignTableColumn(
        workspaceId,
        columnUpdate.columnName,
        columnUpdate.columnType,
        objectMetadataId,
      );
    }
    if (columnUpdate.action === WorkspaceMigrationColumnActionType.DROP) {
      const columnName = columnUpdate.columnName;

      const fieldMetadataToDelete =
        await this.fieldMetadataService.findOneWithinWorkspace(workspaceId, {
          where: {
            objectMetadataId: objectMetadataId,
            name: columnName,
          },
        });

      if (!fieldMetadataToDelete) {
        throw new RemoteTableException(
          `Cannot find associated field metadata for column ${columnName}`,
          RemoteTableExceptionCode.NO_FIELD_METADATA_FOUND,
        );
      }

      await this.fieldMetadataService.deleteOne(fieldMetadataToDelete.id);
    }
  }

  private async createFieldMetadataForForeignTableColumn(
    workspaceId: string,
    columnName: string,
    columnType: string,
    objectMetadataId: string,
  ): Promise<FieldMetadataEntity> {
    return this.fieldMetadataService.createOne({
      name: columnName,
      label: camelToTitleCase(columnName),
      description: 'Field of remote',
      type: mapUdtNameToFieldType(columnType),
      workspaceId: workspaceId,
      objectMetadataId: objectMetadataId,
      isRemoteCreation: true,
      isNullable: true,
      icon: 'IconPlug',
      settings: mapUdtNameToFieldSettings(columnType),
    } satisfies CreateFieldInput);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to manage foreign key metadata and migrations for remote table relations in a workspace, including creating and deleting foreign keys for specific objects like favorite, attachment, and timelineActivity.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { FieldMetadataType } from 'twenty-shared';
import { In, Repository } from 'typeorm';

import { FieldMetadataSettings } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata-settings.interface';

import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { createRelationForeignKeyFieldMetadataName } from 'src/engine/metadata-modules/relation-metadata/utils/create-relation-foreign-key-field-metadata-name.util';
import { buildMigrationsToCreateRemoteTableRelations } from 'src/engine/metadata-modules/remote-server/remote-table/remote-table-relations/utils/build-migrations-to-create-remote-table-relations.util';
import { buildMigrationsToRemoveRemoteTableRelations } from 'src/engine/metadata-modules/remote-server/remote-table/remote-table-relations/utils/build-migrations-to-remove-remote-table-relations.util';
import { mapUdtNameToFieldType } from 'src/engine/metadata-modules/remote-server/remote-table/utils/udt-name-mapper.util';
import { generateMigrationName } from 'src/engine/metadata-modules/workspace-migration/utils/generate-migration-name.util';
import { WorkspaceMigrationService } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.service';
import {
  ATTACHMENT_STANDARD_FIELD_IDS,
  FAVORITE_STANDARD_FIELD_IDS,
  TIMELINE_ACTIVITY_STANDARD_FIELD_IDS,
} from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-field-ids';
import { createForeignKeyDeterministicUuid } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/create-deterministic-uuid.util';

@Injectable()
export class RemoteTableRelationsService {
  constructor(
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,

    @InjectRepository(FieldMetadataEntity, 'metadata')
    private readonly fieldMetadataRepository: Repository<FieldMetadataEntity>,
    private readonly workspaceMigrationService: WorkspaceMigrationService,
  ) {}

  public async createForeignKeysMetadataAndMigrations(
    workspaceId: string,
    remoteObjectMetadata: ObjectMetadataEntity,
    objectPrimaryKeyFieldSettings:
      | FieldMetadataSettings<FieldMetadataType>
      | undefined,
    objectPrimaryKeyColumnType?: string,
  ) {
    const objectPrimaryKeyFieldType = mapUdtNameToFieldType(
      objectPrimaryKeyColumnType ?? 'uuid',
    );

    const favoriteObjectMetadata = await this.createFavoriteRelation(
      workspaceId,
      remoteObjectMetadata,
      objectPrimaryKeyFieldType,
      objectPrimaryKeyFieldSettings,
    );

    const attachmentObjectMetadata = await this.createAttachmentRelation(
      workspaceId,
      remoteObjectMetadata,
      objectPrimaryKeyFieldType,
      objectPrimaryKeyFieldSettings,
    );

    const timelineActivityObjectMetadata =
      await this.createTimelineActivityRelation(
        workspaceId,
        remoteObjectMetadata,
        objectPrimaryKeyFieldType,
        objectPrimaryKeyFieldSettings,
      );

    // create migration to add foreign key columns
    await this.workspaceMigrationService.createCustomMigration(
      generateMigrationName(
        `add-foreign-keys-${remoteObjectMetadata.nameSingular}`,
      ),
      workspaceId,
      buildMigrationsToCreateRemoteTableRelations(
        remoteObjectMetadata.nameSingular,
        [
          favoriteObjectMetadata,
          attachmentObjectMetadata,
          timelineActivityObjectMetadata,
        ],
        objectPrimaryKeyColumnType ?? 'uuid',
      ),
    );
  }

  public async deleteForeignKeysMetadataAndCreateMigrations(
    workspaceId: string,
    remoteObjectMetadata: ObjectMetadataEntity,
  ) {
    // find favorite, activityTarget, attachment, timelineActivity objects
    const favoriteObjectMetadata =
      await this.objectMetadataRepository.findOneByOrFail({
        nameSingular: 'favorite',
        workspaceId: workspaceId,
      });

    const attachmentObjectMetadata =
      await this.objectMetadataRepository.findOneByOrFail({
        nameSingular: 'attachment',
        workspaceId: workspaceId,
      });

    const timelineActivityObjectMetadata =
      await this.objectMetadataRepository.findOneByOrFail({
        nameSingular: 'timelineActivity',
        workspaceId: workspaceId,
      });

    // compute the target column name
    const targetColumnName = createRelationForeignKeyFieldMetadataName(
      remoteObjectMetadata.nameSingular,
    );

    // find the foreign key fields to delete
    const foreignKeyFieldsToDelete = await this.fieldMetadataRepository.find({
      where: {
        name: targetColumnName,
        objectMetadataId: In([
          favoriteObjectMetadata.id,
          attachmentObjectMetadata.id,
          timelineActivityObjectMetadata.id,
        ]),
        workspaceId,
      },
    });

    const foreignKeyFieldsToDeleteIds = foreignKeyFieldsToDelete.map(
      (field) => field.id,
    );

    await this.fieldMetadataRepository.delete(foreignKeyFieldsToDeleteIds);

    // create migration to drop foreign key columns
    await this.workspaceMigrationService.createCustomMigration(
      generateMigrationName(
        `delete-foreign-keys-${remoteObjectMetadata.nameSingular}`,
      ),
      workspaceId,
      buildMigrationsToRemoveRemoteTableRelations(targetColumnName, [
        favoriteObjectMetadata,
        attachmentObjectMetadata,
        timelineActivityObjectMetadata,
      ]),
    );
  }

  private async createAttachmentRelation(
    workspaceId: string,
    createdObjectMetadata: ObjectMetadataEntity,
    objectPrimaryKeyType: FieldMetadataType,
    objectPrimaryKeyFieldSettings:
      | FieldMetadataSettings<FieldMetadataType>
      | undefined,
  ) {
    const attachmentObjectMetadata =
      await this.objectMetadataRepository.findOneByOrFail({
        nameSingular: 'attachment',
        workspaceId: workspaceId,
      });

    await this.fieldMetadataRepository.save(
      // Foreign key
      {
        standardId: createForeignKeyDeterministicUuid({
          objectId: createdObjectMetadata.id,
          standardId: ATTACHMENT_STANDARD_FIELD_IDS.custom,
        }),
        objectMetadataId: attachmentObjectMetadata.id,
        workspaceId: workspaceId,
        isCustom: false,
        isActive: true,
        type: objectPrimaryKeyType,
        name: `${createdObjectMetadata.nameSingular}Id`,
        label: `${createdObjectMetadata.labelSingular} ID (foreign key)`,
        description: `Attachment ${createdObjectMetadata.labelSingular} id foreign key`,
        icon: undefined,
        isNullable: true,
        isSystem: true,
        defaultValue: undefined,
        settings: { ...objectPrimaryKeyFieldSettings, isForeignKey: true },
      },
    );

    return attachmentObjectMetadata;
  }

  private async createTimelineActivityRelation(
    workspaceId: string,
    createdObjectMetadata: ObjectMetadataEntity,
    objectPrimaryKeyType: FieldMetadataType,
    objectPrimaryKeyFieldSettings:
      | FieldMetadataSettings<FieldMetadataType>
      | undefined,
  ) {
    const timelineActivityObjectMetadata =
      await this.objectMetadataRepository.findOneByOrFail({
        nameSingular: 'timelineActivity',
        workspaceId: workspaceId,
      });

    await this.fieldMetadataRepository.save(
      // Foreign key
      {
        standardId: createForeignKeyDeterministicUuid({
          objectId: createdObjectMetadata.id,
          standardId: TIMELINE_ACTIVITY_STANDARD_FIELD_IDS.custom,
        }),
        objectMetadataId: timelineActivityObjectMetadata.id,
        workspaceId: workspaceId,
        isCustom: false,
        isActive: true,
        type: objectPrimaryKeyType,
        name: `${createdObjectMetadata.nameSingular}Id`,
        label: `${createdObjectMetadata.labelSingular} ID (foreign key)`,
        description: `Timeline Activity ${createdObjectMetadata.labelSingular} id foreign key`,
        icon: undefined,
        isNullable: true,
        isSystem: true,
        defaultValue: undefined,
        settings: { ...objectPrimaryKeyFieldSettings, isForeignKey: true },
      },
    );

    return timelineActivityObjectMetadata;
  }

  private async createFavoriteRelation(
    workspaceId: string,
    createdObjectMetadata: ObjectMetadataEntity,
    objectPrimaryKeyType: FieldMetadataType,
    objectPrimaryKeyFieldSettings:
      | FieldMetadataSettings<FieldMetadataType>
      | undefined,
  ) {
    const favoriteObjectMetadata =
      await this.objectMetadataRepository.findOneByOrFail({
        nameSingular: 'favorite',
        workspaceId: workspaceId,
      });

    await this.fieldMetadataRepository.save(
      // Foreign key
      {
        standardId: createForeignKeyDeterministicUuid({
          objectId: createdObjectMetadata.id,
          standardId: FAVORITE_STANDARD_FIELD_IDS.custom,
        }),
        objectMetadataId: favoriteObjectMetadata.id,
        workspaceId: workspaceId,
        isCustom: false,
        isActive: true,
        type: objectPrimaryKeyType,
        name: `${createdObjectMetadata.nameSingular}Id`,
        label: `${createdObjectMetadata.labelSingular} ID (foreign key)`,
        description: `Favorite ${createdObjectMetadata.labelSingular} id foreign key`,
        icon: undefined,
        isNullable: true,
        isSystem: true,
        defaultValue: undefined,
        settings: { ...objectPrimaryKeyFieldSettings, isForeignKey: true },
      },
    );

    return favoriteObjectMetadata;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service that updates related view groups based on changes in field metadata.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { EntityManager, In } from 'typeorm';

import {
  FieldMetadataComplexOption,
  FieldMetadataDefaultOption,
} from 'src/engine/metadata-modules/field-metadata/dtos/options.input';
import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { isSelectFieldMetadataType } from 'src/engine/metadata-modules/field-metadata/utils/is-select-field-metadata-type.util';
import { WorkspaceRepository } from 'src/engine/twenty-orm/repository/workspace.repository';
import { TwentyORMGlobalManager } from 'src/engine/twenty-orm/twenty-orm-global.manager';
import { ViewGroupWorkspaceEntity } from 'src/modules/view/standard-objects/view-group.workspace-entity';
import { ViewWorkspaceEntity } from 'src/modules/view/standard-objects/view.workspace-entity';

type Differences<T> = {
  created: T[];
  updated: { old: T; new: T }[];
  deleted: T[];
};

@Injectable()
export class FieldMetadataRelatedRecordsService {
  constructor(
    private readonly twentyORMGlobalManager: TwentyORMGlobalManager,
  ) {}

  public async updateRelatedViewGroups(
    oldFieldMetadata: FieldMetadataEntity,
    newFieldMetadata: FieldMetadataEntity,
    transactionManager?: EntityManager,
  ): Promise<void> {
    if (
      !isSelectFieldMetadataType(newFieldMetadata.type) ||
      !isSelectFieldMetadataType(oldFieldMetadata.type)
    ) {
      return;
    }

    const views = await this.getFieldMetadataViews(newFieldMetadata);

    const { created, updated, deleted } = this.getOptionsDifferences(
      oldFieldMetadata.options,
      newFieldMetadata.options,
    );

    const viewGroupRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace<ViewGroupWorkspaceEntity>(
        newFieldMetadata.workspaceId,
        'viewGroup',
      );

    for (const view of views) {
      if (view.viewGroups.length === 0) {
        continue;
      }

      const maxPosition = this.getMaxPosition(view.viewGroups);

      const viewGroupsToCreate = created.map((option, index) =>
        viewGroupRepository.create({
          fieldMetadataId: newFieldMetadata.id,
          fieldValue: option.value,
          position: maxPosition + index,
          isVisible: true,
          viewId: view.id,
        }),
      );

      await viewGroupRepository.insert(viewGroupsToCreate, transactionManager);

      for (const { old: oldOption, new: newOption } of updated) {
        const existingViewGroup = view.viewGroups.find(
          (group) => group.fieldValue === oldOption.value,
        );

        if (!existingViewGroup) {
          throw new Error(
            `View group not found for option "${oldOption.value}" during update.`,
          );
        }

        await viewGroupRepository.update(
          { id: existingViewGroup.id },
          { fieldValue: newOption.value },
          transactionManager,
        );
      }

      const valuesToDelete = deleted.map((option) => option.value);

      await viewGroupRepository.delete(
        {
          fieldMetadataId: newFieldMetadata.id,
          fieldValue: In(valuesToDelete),
        },
        transactionManager,
      );

      await this.syncNoValueViewGroup(
        newFieldMetadata,
        view,
        viewGroupRepository,
        transactionManager,
      );
    }
  }

  async syncNoValueViewGroup(
    fieldMetadata: FieldMetadataEntity,
    view: ViewWorkspaceEntity,
    viewGroupRepository: WorkspaceRepository<ViewGroupWorkspaceEntity>,
    transactionManager?: EntityManager,
  ): Promise<void> {
    const noValueGroup = view.viewGroups.find(
      (group) => group.fieldValue === '',
    );

    if (fieldMetadata.isNullable && !noValueGroup) {
      const maxPosition = this.getMaxPosition(view.viewGroups);
      const newGroup = viewGroupRepository.create({
        fieldMetadataId: fieldMetadata.id,
        fieldValue: '',
        position: maxPosition + 1,
        isVisible: true,
        viewId: view.id,
      });

      await viewGroupRepository.insert(newGroup, transactionManager);
    } else if (!fieldMetadata.isNullable && noValueGroup) {
      await viewGroupRepository.delete(
        { id: noValueGroup.id },
        transactionManager,
      );
    }
  }

  private getOptionsDifferences(
    oldOptions: (FieldMetadataDefaultOption | FieldMetadataComplexOption)[],
    newOptions: (FieldMetadataDefaultOption | FieldMetadataComplexOption)[],
  ): Differences<FieldMetadataDefaultOption | FieldMetadataComplexOption> {
    const differences: Differences<
      FieldMetadataDefaultOption | FieldMetadataComplexOption
    > = {
      created: [],
      updated: [],
      deleted: [],
    };

    const oldOptionsMap = new Map(oldOptions.map((opt) => [opt.id, opt]));
    const newOptionsMap = new Map(newOptions.map((opt) => [opt.id, opt]));

    for (const newOption of newOptions) {
      const oldOption = oldOptionsMap.get(newOption.id);

      if (!oldOption) {
        differences.created.push(newOption);
      } else if (oldOption.value !== newOption.value) {
        differences.updated.push({ old: oldOption, new: newOption });
      }
    }

    for (const oldOption of oldOptions) {
      if (!newOptionsMap.has(oldOption.id)) {
        differences.deleted.push(oldOption);
      }
    }

    return differences;
  }

  private async getFieldMetadataViews(
    fieldMetadata: FieldMetadataEntity,
  ): Promise<ViewWorkspaceEntity[]> {
    const viewRepository =
      await this.twentyORMGlobalManager.getRepositoryForWorkspace<ViewWorkspaceEntity>(
        fieldMetadata.workspaceId,
        'view',
      );

    return viewRepository.find({
      where: {
        viewGroups: {
          fieldMetadataId: fieldMetadata.id,
        },
      },
      relations: ['viewGroups'],
    });
  }

  private getMaxPosition(viewGroups: ViewGroupWorkspaceEntity[]): number {
    return viewGroups.reduce((max, group) => Math.max(max, group.position), 0);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code processes a collection of object metadata and generates maps for quick access by ID and name.
Code Snippet:
import { ObjectMetadataInterface } from 'src/engine/metadata-modules/field-metadata/interfaces/object-metadata.interface';

import { FieldMetadataMap } from 'src/engine/metadata-modules/types/field-metadata-map';
import { ObjectMetadataItemWithFieldMaps } from 'src/engine/metadata-modules/types/object-metadata-item-with-field-maps';
import { ObjectMetadataMaps } from 'src/engine/metadata-modules/types/object-metadata-maps';

export const generateObjectMetadataMaps = (
  objectMetadataCollection: ObjectMetadataInterface[],
): ObjectMetadataMaps => {
  const objectMetadataMaps: ObjectMetadataMaps = {
    byId: {},
    idByNameSingular: {},
  };

  for (const objectMetadata of objectMetadataCollection) {
    const fieldsByIdMap: FieldMetadataMap = {};
    const fieldsByNameMap: FieldMetadataMap = {};

    for (const fieldMetadata of objectMetadata.fields) {
      fieldsByNameMap[fieldMetadata.name] = fieldMetadata;
      fieldsByIdMap[fieldMetadata.id] = fieldMetadata;
    }

    const processedObjectMetadata: ObjectMetadataItemWithFieldMaps = {
      ...objectMetadata,
      fieldsById: fieldsByIdMap,
      fieldsByName: fieldsByNameMap,
    };

    objectMetadataMaps.byId[objectMetadata.id] = processedObjectMetadata;
    objectMetadataMaps.idByNameSingular[objectMetadata.nameSingular] =
      objectMetadata.id;
  }

  return objectMetadataMaps;
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a SearchService in a NestJS application that manages search vector fields for database objects, creating and updating them as needed.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { FieldMetadataType, isDefined } from 'twenty-shared';
import { Repository } from 'typeorm';

import { FieldMetadataInterface } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata.interface';

import { SEARCH_VECTOR_FIELD } from 'src/engine/metadata-modules/constants/search-vector-field.constants';
import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { IndexType } from 'src/engine/metadata-modules/index-metadata/index-metadata.entity';
import { IndexMetadataService } from 'src/engine/metadata-modules/index-metadata/index-metadata.service';
import { CreateObjectInput } from 'src/engine/metadata-modules/object-metadata/dtos/create-object.input';
import { DEFAULT_LABEL_IDENTIFIER_FIELD_NAME } from 'src/engine/metadata-modules/object-metadata/object-metadata.constants';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { TsVectorColumnActionFactory } from 'src/engine/metadata-modules/workspace-migration/factories/ts-vector-column-action.factory';
import { generateMigrationName } from 'src/engine/metadata-modules/workspace-migration/utils/generate-migration-name.util';
import {
  WorkspaceMigrationColumnActionType,
  WorkspaceMigrationTableActionType,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceMigrationFactory } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.factory';
import { WorkspaceMigrationService } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.service';
import { computeTableName } from 'src/engine/utils/compute-table-name.util';
import { CUSTOM_OBJECT_STANDARD_FIELD_IDS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-field-ids';
import {
  FieldTypeAndNameMetadata,
  getTsVectorColumnExpressionFromFields,
} from 'src/engine/workspace-manager/workspace-sync-metadata/utils/get-ts-vector-column-expression.util';
import { SearchableFieldType } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/is-searchable-field.util';

@Injectable()
export class SearchService {
  constructor(
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    private readonly tsVectorColumnActionFactory: TsVectorColumnActionFactory,
    private readonly indexMetadataService: IndexMetadataService,
    @InjectRepository(FieldMetadataEntity, 'metadata')
    private readonly fieldMetadataRepository: Repository<FieldMetadataEntity>,
    private readonly workspaceMigrationService: WorkspaceMigrationService,
    private readonly workspaceMigrationFactory: WorkspaceMigrationFactory,
  ) {}

  public async createSearchVectorFieldForObject(
    objectMetadataInput: CreateObjectInput,
    createdObjectMetadata: ObjectMetadataEntity,
  ) {
    const searchVectorFieldMetadata = await this.fieldMetadataRepository.save({
      standardId: CUSTOM_OBJECT_STANDARD_FIELD_IDS.searchVector,
      objectMetadataId: createdObjectMetadata.id,
      workspaceId: objectMetadataInput.workspaceId,
      isCustom: false,
      isActive: false,
      isSystem: true,
      type: FieldMetadataType.TS_VECTOR,
      name: SEARCH_VECTOR_FIELD.name,
      label: SEARCH_VECTOR_FIELD.label.message ?? '',
      description: SEARCH_VECTOR_FIELD.description.message ?? '',
      isNullable: true,
    });

    const searchableFieldForCustomObject =
      createdObjectMetadata.labelIdentifierFieldMetadataId
        ? createdObjectMetadata.fields.find(
            (field) =>
              field.id === createdObjectMetadata.labelIdentifierFieldMetadataId,
          )
        : createdObjectMetadata.fields.find(
            (field) => field.name === DEFAULT_LABEL_IDENTIFIER_FIELD_NAME,
          );

    if (!isDefined(searchableFieldForCustomObject)) {
      throw new Error(
        `No searchable field found for custom object (object name: ${createdObjectMetadata.nameSingular})`,
      );
    }

    await this.workspaceMigrationService.createCustomMigration(
      generateMigrationName(`create-${createdObjectMetadata.nameSingular}`),
      createdObjectMetadata.workspaceId,
      [
        {
          name: computeTableName(
            createdObjectMetadata.nameSingular,
            createdObjectMetadata.isCustom,
          ),
          action: WorkspaceMigrationTableActionType.ALTER,
          columns: this.tsVectorColumnActionFactory.handleCreateAction({
            ...searchVectorFieldMetadata,
            defaultValue: undefined,
            generatedType: 'STORED',
            asExpression: getTsVectorColumnExpressionFromFields([
              {
                type: searchableFieldForCustomObject.type as SearchableFieldType,
                name: searchableFieldForCustomObject.name,
              },
            ]),
            options: undefined,
          } as FieldMetadataInterface<FieldMetadataType.TS_VECTOR>),
        },
      ],
    );

    await this.indexMetadataService.createIndexMetadata(
      objectMetadataInput.workspaceId,
      createdObjectMetadata,
      [searchVectorFieldMetadata],
      false,
      false,
      IndexType.GIN,
    );
  }

  public async updateSearchVector(
    objectMetadataId: string,
    fieldMetadataNameAndTypeForSearch: FieldTypeAndNameMetadata[],
    workspaceId: string,
  ) {
    const objectMetadata = await this.objectMetadataRepository.findOneByOrFail({
      id: objectMetadataId,
    });

    const existingSearchVectorFieldMetadata =
      await this.fieldMetadataRepository.findOneByOrFail({
        name: SEARCH_VECTOR_FIELD.name,
        objectMetadataId,
      });

    await this.workspaceMigrationService.createCustomMigration(
      generateMigrationName(`update-${objectMetadata.nameSingular}`),
      workspaceId,
      [
        {
          name: computeTableName(
            objectMetadata.nameSingular,
            objectMetadata.isCustom,
          ),
          action: WorkspaceMigrationTableActionType.ALTER,
          columns: this.workspaceMigrationFactory.createColumnActions(
            WorkspaceMigrationColumnActionType.ALTER,
            existingSearchVectorFieldMetadata,
            {
              ...existingSearchVectorFieldMetadata,
              asExpression: getTsVectorColumnExpressionFromFields(
                fieldMetadataNameAndTypeForSearch,
              ),
              generatedType: 'STORED', // Not stored on fieldMetadata
              options: undefined,
            },
          ),
        },
      ],
    );

    // index needs to be recreated as typeorm deletes then recreates searchVector column at alter
    await this.indexMetadataService.createIndexCreationMigration(
      workspaceId,
      objectMetadata,
      [existingSearchVectorFieldMetadata],
      false,
      false,
      IndexType.GIN,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing object and field metadata relationships, including creating and updating relations and foreign keys in a metadata database.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { capitalize, FieldMetadataType } from 'twenty-shared';
import { In, Repository } from 'typeorm';

import { FieldMetadataSettings } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata-settings.interface';

import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { buildDescriptionForRelationFieldMetadataOnFromField } from 'src/engine/metadata-modules/object-metadata/utils/build-description-for-relation-field-on-from-field.util';
import { buildDescriptionForRelationFieldMetadataOnToField } from 'src/engine/metadata-modules/object-metadata/utils/build-description-for-relation-field-on-to-field.util';
import { buildNameLabelAndDescriptionForForeignKeyFieldMetadata } from 'src/engine/metadata-modules/object-metadata/utils/build-name-label-and-description-for-foreign-key-field-metadata.util';
import {
  RelationMetadataEntity,
  RelationMetadataType,
  RelationOnDeleteAction,
} from 'src/engine/metadata-modules/relation-metadata/relation-metadata.entity';
import { mapUdtNameToFieldType } from 'src/engine/metadata-modules/remote-server/remote-table/utils/udt-name-mapper.util';
import {
  CUSTOM_OBJECT_STANDARD_FIELD_IDS,
  STANDARD_OBJECT_FIELD_IDS,
} from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-field-ids';
import { STANDARD_OBJECT_ICONS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-object-icons';
import { STANDARD_OBJECT_IDS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-object-ids';
import {
  createForeignKeyDeterministicUuid,
  createRelationDeterministicUuid,
} from 'src/engine/workspace-manager/workspace-sync-metadata/utils/create-deterministic-uuid.util';

const DEFAULT_RELATIONS_OBJECTS_STANDARD_IDS = [
  STANDARD_OBJECT_IDS.timelineActivity,
  STANDARD_OBJECT_IDS.favorite,
  STANDARD_OBJECT_IDS.attachment,
  STANDARD_OBJECT_IDS.noteTarget,
  STANDARD_OBJECT_IDS.taskTarget,
];

@Injectable()
export class ObjectMetadataRelationService {
  constructor(
    @InjectRepository(ObjectMetadataEntity, 'metadata')
    private readonly objectMetadataRepository: Repository<ObjectMetadataEntity>,
    @InjectRepository(FieldMetadataEntity, 'metadata')
    private readonly fieldMetadataRepository: Repository<FieldMetadataEntity>,
    @InjectRepository(RelationMetadataEntity, 'metadata')
    private readonly relationMetadataRepository: Repository<RelationMetadataEntity>,
  ) {}

  public async createRelationsAndForeignKeysMetadata(
    workspaceId: string,
    createdObjectMetadata: ObjectMetadataEntity,
    { primaryKeyFieldMetadataSettings, primaryKeyColumnType },
  ) {
    const relatedObjectMetadataCollection = await Promise.all(
      DEFAULT_RELATIONS_OBJECTS_STANDARD_IDS.map(
        async (relationObjectMetadataStandardId) =>
          this.createRelationAndForeignKeyMetadata(
            workspaceId,
            createdObjectMetadata,
            mapUdtNameToFieldType(primaryKeyColumnType ?? 'uuid'),
            primaryKeyFieldMetadataSettings,
            relationObjectMetadataStandardId,
          ),
      ),
    );

    return relatedObjectMetadataCollection;
  }

  private async createRelationAndForeignKeyMetadata(
    workspaceId: string,
    createdObjectMetadata: ObjectMetadataEntity,
    objectPrimaryKeyType: FieldMetadataType,
    objectPrimaryKeyFieldSettings:
      | FieldMetadataSettings<FieldMetadataType>
      | undefined,
    relationObjectMetadataStandardId: string,
  ) {
    const relatedObjectMetadata =
      await this.objectMetadataRepository.findOneByOrFail({
        standardId: relationObjectMetadataStandardId,
        workspaceId: workspaceId,
        isCustom: false,
      });

    const relationFieldMetadataCollection =
      await this.createRelationFieldMetadas(
        workspaceId,
        createdObjectMetadata,
        relatedObjectMetadata,
        objectPrimaryKeyType,
        objectPrimaryKeyFieldSettings,
      );

    await this.createRelationMetadataFromFieldMetadatas(
      workspaceId,
      createdObjectMetadata,
      relatedObjectMetadata,
      relationFieldMetadataCollection,
    );

    return relatedObjectMetadata;
  }

  private async createRelationFieldMetadas(
    workspaceId: string,
    createdObjectMetadata: ObjectMetadataEntity,
    relatedObjectMetadata: ObjectMetadataEntity,
    objectPrimaryKeyType: FieldMetadataType,
    objectPrimaryKeyFieldSettings:
      | FieldMetadataSettings<FieldMetadataType>
      | undefined,
  ) {
    return this.fieldMetadataRepository.save([
      this.buildFromFieldMetadata(
        workspaceId,
        createdObjectMetadata,
        relatedObjectMetadata,
      ),
      this.buildToFieldMetadata(
        workspaceId,
        createdObjectMetadata,
        relatedObjectMetadata,
      ),
      this.buildForeignKeyFieldMetadata(
        workspaceId,
        createdObjectMetadata,
        relatedObjectMetadata,
        objectPrimaryKeyType,
        objectPrimaryKeyFieldSettings,
      ),
    ]);
  }

  public async updateRelationsAndForeignKeysMetadata(
    workspaceId: string,
    updatedObjectMetadata: ObjectMetadataEntity,
  ): Promise<
    {
      relatedObjectMetadata: ObjectMetadataEntity;
      foreignKeyFieldMetadata: FieldMetadataEntity;
      toFieldMetadata: FieldMetadataEntity;
      fromFieldMetadata: FieldMetadataEntity;
    }[]
  > {
    return await Promise.all(
      DEFAULT_RELATIONS_OBJECTS_STANDARD_IDS.map(
        async (relationObjectMetadataStandardId) =>
          this.updateRelationAndForeignKeyMetadata(
            workspaceId,
            updatedObjectMetadata,
            relationObjectMetadataStandardId,
          ),
      ),
    );
  }

  private async updateRelationAndForeignKeyMetadata(
    workspaceId: string,
    updatedObjectMetadata: ObjectMetadataEntity,
    relationObjectMetadataStandardId: string,
  ) {
    const relatedObjectMetadata =
      await this.objectMetadataRepository.findOneByOrFail({
        standardId: relationObjectMetadataStandardId,
        workspaceId: workspaceId,
        isCustom: false,
      });

    const toFieldMetadataUpdateCriteria = {
      standardId: createRelationDeterministicUuid({
        objectId: updatedObjectMetadata.id,
        standardId:
          STANDARD_OBJECT_FIELD_IDS[relatedObjectMetadata.nameSingular].custom,
      }),
      objectMetadataId: relatedObjectMetadata.id,
      workspaceId: workspaceId,
    };
    const toFieldMetadataUpdateData = this.buildToFieldMetadata(
      workspaceId,
      updatedObjectMetadata,
      relatedObjectMetadata,
      true,
    );
    const toFieldMetadataToUpdate =
      await this.fieldMetadataRepository.findOneBy(
        toFieldMetadataUpdateCriteria,
      );
    const toFieldMetadata = await this.fieldMetadataRepository.save({
      ...toFieldMetadataToUpdate,
      ...toFieldMetadataUpdateData,
    });

    const fromFieldMetadataUpdateCriteria = {
      standardId:
        CUSTOM_OBJECT_STANDARD_FIELD_IDS[relatedObjectMetadata.namePlural],
      objectMetadataId: updatedObjectMetadata.id,
      workspaceId: workspaceId,
    };
    const fromFieldMetadataUpdateData = this.buildFromFieldMetadata(
      workspaceId,
      updatedObjectMetadata,
      relatedObjectMetadata,
      true,
    );
    const fromFieldMetadataToUpdate =
      await this.fieldMetadataRepository.findOneBy(
        fromFieldMetadataUpdateCriteria,
      );
    const fromFieldMetadata = await this.fieldMetadataRepository.save({
      ...fromFieldMetadataToUpdate,
      ...fromFieldMetadataUpdateData,
    });

    const foreignKeyFieldMetadataUpdateCriteria = {
      standardId: createForeignKeyDeterministicUuid({
        objectId: updatedObjectMetadata.id,
        standardId:
          STANDARD_OBJECT_FIELD_IDS[relatedObjectMetadata.nameSingular].custom,
      }),
      objectMetadataId: relatedObjectMetadata.id,
      workspaceId: workspaceId,
    };
    const foreignKeyFieldMetadataUpdateData = this.buildForeignKeyFieldMetadata(
      workspaceId,
      updatedObjectMetadata,
      relatedObjectMetadata,
      FieldMetadataType.UUID,
      undefined,
      true,
    );
    const foreignKeyFieldMetadataToUpdate =
      await this.fieldMetadataRepository.findOneBy(
        foreignKeyFieldMetadataUpdateCriteria,
      );
    const foreignKeyFieldMetadata = await this.fieldMetadataRepository.save({
      ...foreignKeyFieldMetadataToUpdate,
      ...foreignKeyFieldMetadataUpdateData,
    });

    return {
      relatedObjectMetadata,
      foreignKeyFieldMetadata,
      toFieldMetadata,
      fromFieldMetadata,
    };
  }

  private buildFromFieldMetadata(
    workspaceId: string,
    objectMetadata: ObjectMetadataEntity,
    relatedObjectMetadata: ObjectMetadataEntity,
    isUpdate = false,
  ) {
    const relationObjectMetadataNamePlural = relatedObjectMetadata.namePlural;

    const { description } = buildDescriptionForRelationFieldMetadataOnFromField(
      {
        relationObjectMetadataNamePlural,
        targetObjectLabelSingular: objectMetadata.labelSingular,
      },
    );

    return {
      description,
      ...(!isUpdate
        ? {
            standardId:
              CUSTOM_OBJECT_STANDARD_FIELD_IDS[
                relationObjectMetadataNamePlural
              ],
            objectMetadataId: objectMetadata.id,
            workspaceId: workspaceId,
            isCustom: false,
            isActive: true,
            isSystem: true,
            type: FieldMetadataType.RELATION,
            name: relatedObjectMetadata.namePlural,
            label: capitalize(relationObjectMetadataNamePlural),
            description,
            icon:
              STANDARD_OBJECT_ICONS[relatedObjectMetadata.nameSingular] ||
              'IconBuildingSkyscraper',
            isNullable: true,
          }
        : {}),
    };
  }

  private buildToFieldMetadata(
    workspaceId: string,
    objectMetadata: ObjectMetadataEntity,
    relatedObjectMetadata: ObjectMetadataEntity,
    isUpdate = false,
  ) {
    const customStandardFieldId =
      STANDARD_OBJECT_FIELD_IDS[relatedObjectMetadata.nameSingular].custom;

    if (!customStandardFieldId) {
      throw new Error(
        `Custom standard field ID not found for ${relatedObjectMetadata.nameSingular}`,
      );
    }

    const { description } = buildDescriptionForRelationFieldMetadataOnToField({
      relationObjectMetadataNamePlural: relatedObjectMetadata.namePlural,
      targetObjectLabelSingular: objectMetadata.labelSingular,
    });

    return {
      name: objectMetadata.nameSingular,
      label: objectMetadata.labelSingular,
      description,
      ...(!isUpdate
        ? {
            standardId: createRelationDeterministicUuid({
              objectId: objectMetadata.id,
              standardId: customStandardFieldId,
            }),
            objectMetadataId: relatedObjectMetadata.id,
            workspaceId: workspaceId,
            isCustom: false,
            isActive: true,
            isSystem: true,
            type: FieldMetadataType.RELATION,
            name: objectMetadata.nameSingular,
            label: objectMetadata.labelSingular,
            description,
            icon: 'IconBuildingSkyscraper',
            isNullable: true,
          }
        : {}),
    };
  }

  private buildForeignKeyFieldMetadata(
    workspaceId: string,
    objectMetadata: ObjectMetadataEntity,
    relatedObjectMetadata: ObjectMetadataEntity,
    objectPrimaryKeyType: FieldMetadataType,
    objectPrimaryKeyFieldSettings:
      | FieldMetadataSettings<FieldMetadataType>
      | undefined,
    isUpdate = false,
  ) {
    const customStandardFieldId =
      STANDARD_OBJECT_FIELD_IDS[relatedObjectMetadata.nameSingular].custom;

    if (!customStandardFieldId) {
      throw new Error(
        `Custom standard field ID not found for ${relatedObjectMetadata.nameSingular}`,
      );
    }

    const { name, label, description } =
      buildNameLabelAndDescriptionForForeignKeyFieldMetadata({
        targetObjectNameSingular: objectMetadata.nameSingular,
        targetObjectLabelSingular: objectMetadata.labelSingular,
        relatedObjectLabelSingular: relatedObjectMetadata.labelSingular,
      });

    return {
      name,
      label,
      description,
      ...(!isUpdate
        ? {
            standardId: createForeignKeyDeterministicUuid({
              objectId: objectMetadata.id,
              standardId: customStandardFieldId,
            }),
            objectMetadataId: relatedObjectMetadata.id,
            workspaceId: workspaceId,
            isCustom: false,
            isActive: true,
            type: objectPrimaryKeyType,
            name,
            label,
            description,
            icon: undefined,
            isNullable: true,
            isSystem: true,
            defaultValue: undefined,
            settings: { ...objectPrimaryKeyFieldSettings, isForeignKey: true },
          }
        : {}),
    };
  }

  private async createRelationMetadataFromFieldMetadatas(
    workspaceId: string,
    createdObjectMetadata: ObjectMetadataEntity,
    relatedObjectMetadata: ObjectMetadataEntity,
    relationFieldMetadataCollection: FieldMetadataEntity[],
  ) {
    const relationFieldMetadataMap = relationFieldMetadataCollection.reduce(
      (acc, fieldMetadata: FieldMetadataEntity) => {
        if (fieldMetadata.type === FieldMetadataType.RELATION) {
          acc[fieldMetadata.objectMetadataId] = fieldMetadata;
        }

        return acc;
      },
      {},
    );

    await this.relationMetadataRepository.save([
      {
        workspaceId: workspaceId,
        relationType: RelationMetadataType.ONE_TO_MANY,
        fromObjectMetadataId: createdObjectMetadata.id,
        toObjectMetadataId: relatedObjectMetadata.id,
        fromFieldMetadataId:
          relationFieldMetadataMap[createdObjectMetadata.id].id,
        toFieldMetadataId:
          relationFieldMetadataMap[relatedObjectMetadata.id].id,
        onDeleteAction: RelationOnDeleteAction.CASCADE,
      },
    ]);
  }

  async updateObjectRelationshipsActivationStatus(
    objectMetadataId: string,
    isActive: boolean,
  ) {
    const affectedRelations = await this.relationMetadataRepository.find({
      where: [
        { fromObjectMetadataId: objectMetadataId },
        { toObjectMetadataId: objectMetadataId },
      ],
    });

    const affectedFieldIds = affectedRelations.reduce(
      (acc, { fromFieldMetadataId, toFieldMetadataId }) => {
        acc.push(fromFieldMetadataId, toFieldMetadataId);

        return acc;
      },
      [] as string[],
    );

    if (affectedFieldIds.length > 0) {
      await this.fieldMetadataRepository.update(
        { id: In(affectedFieldIds) },
        { isActive: isActive },
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing relation metadata in a NestJS application, including creating and deleting relations, validating inputs, and handling migrations.
Code Snippet:
import { Injectable, NotFoundException } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { TypeOrmQueryService } from '@ptc-org/nestjs-query-typeorm';
import camelCase from 'lodash.camelcase';
import { FieldMetadataType, isDefined } from 'twenty-shared';
import { FindOneOptions, In, Repository } from 'typeorm';
import { v4 as uuidV4 } from 'uuid';

import { FieldMetadataInterface } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata.interface';

import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { FieldMetadataService } from 'src/engine/metadata-modules/field-metadata/field-metadata.service';
import { IndexMetadataService } from 'src/engine/metadata-modules/index-metadata/index-metadata.service';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { ObjectMetadataService } from 'src/engine/metadata-modules/object-metadata/object-metadata.service';
import { CreateRelationInput } from 'src/engine/metadata-modules/relation-metadata/dtos/create-relation.input';
import {
  RelationMetadataException,
  RelationMetadataExceptionCode,
} from 'src/engine/metadata-modules/relation-metadata/relation-metadata.exception';
import { InvalidStringException } from 'src/engine/metadata-modules/utils/exceptions/invalid-string.exception';
import { validateFieldNameAvailabilityOrThrow } from 'src/engine/metadata-modules/utils/validate-field-name-availability.utils';
import { validateMetadataNameValidityOrThrow } from 'src/engine/metadata-modules/utils/validate-metadata-name-validity.utils';
import { WorkspaceMetadataVersionService } from 'src/engine/metadata-modules/workspace-metadata-version/services/workspace-metadata-version.service';
import { generateMigrationName } from 'src/engine/metadata-modules/workspace-migration/utils/generate-migration-name.util';
import {
  WorkspaceMigrationColumnActionType,
  WorkspaceMigrationColumnDrop,
  WorkspaceMigrationTableActionType,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceMigrationService } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.service';
import { computeObjectTargetTable } from 'src/engine/utils/compute-object-target-table.util';
import { WorkspaceCacheStorageService } from 'src/engine/workspace-cache-storage/workspace-cache-storage.service';
import { WorkspaceMigrationRunnerService } from 'src/engine/workspace-manager/workspace-migration-runner/workspace-migration-runner.service';
import { BASE_OBJECT_STANDARD_FIELD_IDS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-field-ids';

import {
  RelationMetadataEntity,
  RelationMetadataType,
  RelationOnDeleteAction,
} from './relation-metadata.entity';

@Injectable()
export class RelationMetadataService extends TypeOrmQueryService<RelationMetadataEntity> {
  constructor(
    @InjectRepository(RelationMetadataEntity, 'metadata')
    private readonly relationMetadataRepository: Repository<RelationMetadataEntity>,
    @InjectRepository(FieldMetadataEntity, 'metadata')
    private readonly fieldMetadataRepository: Repository<FieldMetadataEntity>,
    private readonly objectMetadataService: ObjectMetadataService,
    private readonly fieldMetadataService: FieldMetadataService,
    private readonly workspaceMigrationService: WorkspaceMigrationService,
    private readonly workspaceMigrationRunnerService: WorkspaceMigrationRunnerService,
    private readonly workspaceMetadataVersionService: WorkspaceMetadataVersionService,
    private readonly indexMetadataService: IndexMetadataService,
    private readonly workspaceCacheStorageService: WorkspaceCacheStorageService,
  ) {
    super(relationMetadataRepository);
  }

  override async createOne(
    relationMetadataInput: CreateRelationInput,
  ): Promise<RelationMetadataEntity> {
    const objectMetadataMap = await this.getObjectMetadataMap(
      relationMetadataInput,
    );

    try {
      validateMetadataNameValidityOrThrow(relationMetadataInput.fromName);
      validateMetadataNameValidityOrThrow(relationMetadataInput.toName);
    } catch (error) {
      if (error instanceof InvalidStringException) {
        throw new RelationMetadataException(
          `Characters used in name "${relationMetadataInput.fromName}" or "${relationMetadataInput.toName}" are not supported`,
          RelationMetadataExceptionCode.INVALID_RELATION_INPUT,
        );
      } else {
        throw error;
      }
    }

    await this.validateCreateRelationMetadataInput(
      relationMetadataInput,
      objectMetadataMap,
    );

    // NOTE: this logic is called to create relation through metadata graphql endpoint (so only for custom field relations)
    const isCustom = true;
    const columnName = `${camelCase(relationMetadataInput.toName)}Id`;

    const fromId = uuidV4();
    const toId = uuidV4();

    const createdRelationFieldsMetadata =
      await this.fieldMetadataRepository.save([
        this.createFieldMetadataForRelationMetadata(
          relationMetadataInput,
          'from',
          isCustom,
          fromId,
        ),
        this.createFieldMetadataForRelationMetadata(
          relationMetadataInput,
          'to',
          isCustom,
          toId,
        ),
        this.createForeignKeyFieldMetadata(relationMetadataInput, columnName),
      ]);

    const createdRelationMetadata = await super.createOne({
      ...relationMetadataInput,
      fromFieldMetadataId: fromId,
      toFieldMetadataId: toId,
    });

    await this.createWorkspaceCustomMigration(
      relationMetadataInput,
      objectMetadataMap,
      columnName,
    );

    const toObjectMetadata =
      objectMetadataMap[relationMetadataInput.toObjectMetadataId];

    const foreignKeyFieldMetadata = createdRelationFieldsMetadata.find(
      (fieldMetadata) => fieldMetadata.type === FieldMetadataType.UUID,
    );

    if (!foreignKeyFieldMetadata) {
      throw new RelationMetadataException(
        `ForeignKey field metadata not found`,
        RelationMetadataExceptionCode.RELATION_METADATA_NOT_FOUND,
      );
    }

    const deletedAtFieldMetadata = toObjectMetadata.fields.find(
      (fieldMetadata) =>
        fieldMetadata.standardId === BASE_OBJECT_STANDARD_FIELD_IDS.deletedAt,
    );

    this.throwIfDeletedAtFieldMetadataNotFound(deletedAtFieldMetadata);

    await this.indexMetadataService.createIndexMetadata(
      relationMetadataInput.workspaceId,
      toObjectMetadata,
      [
        foreignKeyFieldMetadata,
        deletedAtFieldMetadata as FieldMetadataEntity<FieldMetadataType>,
      ],
      false,
      false,
    );

    await this.workspaceMigrationRunnerService.executeMigrationFromPendingMigrations(
      relationMetadataInput.workspaceId,
    );

    await this.workspaceMetadataVersionService.incrementMetadataVersion(
      relationMetadataInput.workspaceId,
    );

    return createdRelationMetadata;
  }

  private async validateCreateRelationMetadataInput(
    relationMetadataInput: CreateRelationInput,
    objectMetadataMap: { [key: string]: ObjectMetadataEntity },
  ) {
    if (
      relationMetadataInput.relationType === RelationMetadataType.MANY_TO_MANY
    ) {
      throw new RelationMetadataException(
        'Many to many relations are not supported yet',
        RelationMetadataExceptionCode.INVALID_RELATION_INPUT,
      );
    }

    if (
      objectMetadataMap[relationMetadataInput.fromObjectMetadataId] ===
        undefined ||
      objectMetadataMap[relationMetadataInput.toObjectMetadataId] === undefined
    ) {
      throw new RelationMetadataException(
        "Can't find an existing object matching with fromObjectMetadataId or toObjectMetadataId",
        RelationMetadataExceptionCode.RELATION_METADATA_NOT_FOUND,
      );
    }

    await this.checkIfFieldMetadataRelationNameExists(
      relationMetadataInput,
      objectMetadataMap,
      'from',
    );
    await this.checkIfFieldMetadataRelationNameExists(
      relationMetadataInput,
      objectMetadataMap,
      'to',
    );

    validateFieldNameAvailabilityOrThrow(
      relationMetadataInput.fromName,
      objectMetadataMap[relationMetadataInput.fromObjectMetadataId],
    );
    validateFieldNameAvailabilityOrThrow(
      relationMetadataInput.toName,
      objectMetadataMap[relationMetadataInput.toObjectMetadataId],
    );
  }

  private async checkIfFieldMetadataRelationNameExists(
    relationMetadataInput: CreateRelationInput,
    objectMetadataMap: { [key: string]: ObjectMetadataEntity },
    relationDirection: 'from' | 'to',
  ) {
    const fieldAlreadyExists =
      await this.fieldMetadataService.findOneWithinWorkspace(
        relationMetadataInput.workspaceId,
        {
          where: {
            name: relationMetadataInput[`${relationDirection}Name`],
            objectMetadataId:
              relationMetadataInput[`${relationDirection}ObjectMetadataId`],
          },
        },
      );

    if (fieldAlreadyExists) {
      throw new RelationMetadataException(
        `Field on ${
          objectMetadataMap[
            relationMetadataInput[`${relationDirection}ObjectMetadataId`]
          ].nameSingular
        } already exists`,
        RelationMetadataExceptionCode.RELATION_ALREADY_EXISTS,
      );
    }
  }

  private async createWorkspaceCustomMigration(
    relationMetadataInput: CreateRelationInput,
    objectMetadataMap: { [key: string]: ObjectMetadataEntity },
    columnName: string,
  ) {
    await this.workspaceMigrationService.createCustomMigration(
      generateMigrationName(`create-${relationMetadataInput.fromName}`),
      relationMetadataInput.workspaceId,
      [
        // Create the column
        {
          name: computeObjectTargetTable(
            objectMetadataMap[relationMetadataInput.toObjectMetadataId],
          ),
          action: WorkspaceMigrationTableActionType.ALTER,
          columns: [
            {
              action: WorkspaceMigrationColumnActionType.CREATE,
              columnName,
              columnType: 'uuid',
              isNullable: true,
              defaultValue: null,
            },
          ],
        },
        // Create the foreignKey
        {
          name: computeObjectTargetTable(
            objectMetadataMap[relationMetadataInput.toObjectMetadataId],
          ),
          action: WorkspaceMigrationTableActionType.ALTER,
          columns: [
            {
              action: WorkspaceMigrationColumnActionType.CREATE_FOREIGN_KEY,
              columnName,
              referencedTableName: computeObjectTargetTable(
                objectMetadataMap[relationMetadataInput.fromObjectMetadataId],
              ),
              referencedTableColumnName: 'id',
              isUnique:
                relationMetadataInput.relationType ===
                RelationMetadataType.ONE_TO_ONE,
              onDelete: RelationOnDeleteAction.SET_NULL,
            },
          ],
        },
      ],
    );
  }

  private createFieldMetadataForRelationMetadata(
    relationMetadataInput: CreateRelationInput,
    relationDirection: 'from' | 'to',
    isCustom: boolean,
    id?: string,
  ) {
    return {
      ...(id && { id: id }),
      name: relationMetadataInput[`${relationDirection}Name`],
      label: relationMetadataInput[`${relationDirection}Label`],
      description: relationMetadataInput[`${relationDirection}Description`],
      icon: relationMetadataInput[`${relationDirection}Icon`],
      isCustom,
      isActive: true,
      isNullable: true,
      type: FieldMetadataType.RELATION,
      objectMetadataId:
        relationMetadataInput[`${relationDirection}ObjectMetadataId`],
      workspaceId: relationMetadataInput.workspaceId,
    };
  }

  private createForeignKeyFieldMetadata(
    relationMetadataInput: CreateRelationInput,
    columnName: string,
  ) {
    return {
      name: columnName,
      label: `${relationMetadataInput.toLabel} Foreign Key`,
      description: relationMetadataInput.toDescription
        ? `${relationMetadataInput.toDescription} Foreign Key`
        : undefined,
      icon: undefined,
      isCustom: true,
      isActive: true,
      isNullable: true,
      isSystem: true,
      type: FieldMetadataType.UUID,
      objectMetadataId: relationMetadataInput.toObjectMetadataId,
      workspaceId: relationMetadataInput.workspaceId,
      settings: { isForeignKey: true },
    };
  }

  private async getObjectMetadataMap(
    relationMetadataInput: CreateRelationInput,
  ): Promise<{ [key: string]: ObjectMetadataEntity }> {
    const objectMetadataEntries =
      await this.objectMetadataService.findManyWithinWorkspace(
        relationMetadataInput.workspaceId,
        {
          where: {
            id: In([
              relationMetadataInput.fromObjectMetadataId,
              relationMetadataInput.toObjectMetadataId,
            ]),
          },
        },
      );

    return objectMetadataEntries.reduce(
      (acc, curr) => {
        acc[curr.id] = curr;

        return acc;
      },
      {} as { [key: string]: ObjectMetadataEntity },
    );
  }

  public async findOneWithinWorkspace(
    workspaceId: string,
    options: FindOneOptions<RelationMetadataEntity>,
  ) {
    return this.relationMetadataRepository.findOne({
      ...options,
      where: {
        ...options.where,
        workspaceId,
      },
      relations: ['fromFieldMetadata', 'toFieldMetadata'],
    });
  }

  public async deleteOneRelation(
    id: string,
    workspaceId: string,
  ): Promise<RelationMetadataEntity> {
    // TODO: This logic is duplicated with the BeforeDeleteOneRelation hook
    const relationMetadata = await this.relationMetadataRepository.findOne({
      where: { id },
      relations: [
        'fromFieldMetadata',
        'toFieldMetadata',
        'fromObjectMetadata',
        'toObjectMetadata',
      ],
    });

    if (!relationMetadata) {
      throw new RelationMetadataException(
        'Relation does not exist',
        RelationMetadataExceptionCode.RELATION_METADATA_NOT_FOUND,
      );
    }

    const foreignKeyFieldMetadataName = `${camelCase(
      relationMetadata.toFieldMetadata.name,
    )}Id`;

    const foreignKeyFieldMetadata = await this.fieldMetadataRepository.findOne({
      where: {
        name: foreignKeyFieldMetadataName,
        objectMetadataId: relationMetadata.toObjectMetadataId,
        workspaceId: relationMetadata.workspaceId,
      },
    });

    if (!foreignKeyFieldMetadata) {
      throw new RelationMetadataException(
        `Foreign key fieldMetadata not found (${foreignKeyFieldMetadataName}) for relation ${relationMetadata.id}`,
        RelationMetadataExceptionCode.FOREIGN_KEY_NOT_FOUND,
      );
    }

    await super.deleteOne(id);

    // TODO: Move to a cdc scheduler
    await this.fieldMetadataService.deleteMany({
      id: {
        in: [
          relationMetadata.fromFieldMetadataId,
          relationMetadata.toFieldMetadataId,
          foreignKeyFieldMetadata.id,
        ],
      },
    });

    const columnName = `${camelCase(relationMetadata.toFieldMetadata.name)}Id`;
    const objectTargetTable = computeObjectTargetTable(
      relationMetadata.toObjectMetadata,
    );

    await this.deleteRelationWorkspaceCustomMigration(
      relationMetadata,
      objectTargetTable,
      columnName,
    );

    const deletedAtFieldMetadata = await this.fieldMetadataRepository.findOneBy(
      {
        objectMetadataId: relationMetadata.toObjectMetadataId,
        name: 'deletedAt',
      },
    );

    this.throwIfDeletedAtFieldMetadataNotFound(deletedAtFieldMetadata);

    await this.indexMetadataService.deleteIndexMetadata(
      workspaceId,
      relationMetadata.toObjectMetadata,
      [
        foreignKeyFieldMetadata,
        deletedAtFieldMetadata as FieldMetadataEntity<FieldMetadataType>,
      ],
    );

    await this.workspaceMigrationRunnerService.executeMigrationFromPendingMigrations(
      relationMetadata.workspaceId,
    );

    await this.workspaceMetadataVersionService.incrementMetadataVersion(
      workspaceId,
    );

    // TODO: Return id for delete endpoints
    return relationMetadata;
  }

  async findManyRelationMetadataByFieldMetadataIds(
    fieldMetadataItems: Array<
      Pick<FieldMetadataInterface, 'id' | 'type' | 'objectMetadataId'>
    >,
    workspaceId: string,
  ): Promise<(RelationMetadataEntity | NotFoundException)[]> {
    const metadataVersion =
      await this.workspaceCacheStorageService.getMetadataVersion(workspaceId);

    if (!metadataVersion) {
      throw new NotFoundException(
        `Metadata version not found for workspace ${workspaceId}`,
      );
    }

    const objectMetadataMaps =
      await this.workspaceCacheStorageService.getObjectMetadataMaps(
        workspaceId,
        metadataVersion,
      );

    if (!objectMetadataMaps) {
      throw new NotFoundException(
        `Object metadata map not found for workspace ${workspaceId} and metadata version ${metadataVersion}`,
      );
    }

    const mappedResult = fieldMetadataItems.map((fieldMetadataItem) => {
      const objectMetadata =
        objectMetadataMaps.byId[fieldMetadataItem.objectMetadataId];

      if (!objectMetadata) {
        return new NotFoundException(
          `Object metadata not found for field ${fieldMetadataItem.id}`,
        );
      }

      const fieldMetadata = objectMetadata.fieldsById[fieldMetadataItem.id];

      const relationMetadata =
        fieldMetadata.fromRelationMetadata ?? fieldMetadata.toRelationMetadata;

      if (!relationMetadata) {
        return new NotFoundException(
          `From object metadata not found for relation ${fieldMetadata?.id}`,
        );
      }

      const fromObjectMetadata =
        objectMetadataMaps.byId[relationMetadata.fromObjectMetadataId];

      const toObjectMetadata =
        objectMetadataMaps.byId[relationMetadata.toObjectMetadataId];

      const fromFieldMetadata =
        objectMetadataMaps.byId[fromObjectMetadata.id].fieldsById[
          relationMetadata.fromFieldMetadataId
        ];

      const toFieldMetadata =
        objectMetadataMaps.byId[toObjectMetadata.id].fieldsById[
          relationMetadata.toFieldMetadataId
        ];

      return {
        ...relationMetadata,
        fromObjectMetadata,
        toObjectMetadata,
        fromFieldMetadata,
        toFieldMetadata,
      };
    });

    return mappedResult as (RelationMetadataEntity | NotFoundException)[];
  }

  private async deleteRelationWorkspaceCustomMigration(
    relationMetadata: RelationMetadataEntity,
    objectTargetTable: string,
    columnName: string,
  ) {
    await this.workspaceMigrationService.createCustomMigration(
      generateMigrationName(
        `delete-relation-from-${relationMetadata.fromObjectMetadata.nameSingular}-to-${relationMetadata.toObjectMetadata.nameSingular}`,
      ),
      relationMetadata.workspaceId,
      [
        // Delete the column
        {
          name: objectTargetTable,
          action: WorkspaceMigrationTableActionType.ALTER,
          columns: [
            {
              action: WorkspaceMigrationColumnActionType.DROP,
              columnName,
            } satisfies WorkspaceMigrationColumnDrop,
          ],
        },
      ],
    );
  }

  private throwIfDeletedAtFieldMetadataNotFound(
    deletedAtFieldMetadata?: FieldMetadataEntity<FieldMetadataType> | null,
  ) {
    if (!isDefined(deletedAtFieldMetadata)) {
      throw new RelationMetadataException(
        `Deleted field metadata not found`,
        RelationMetadataExceptionCode.RELATION_METADATA_NOT_FOUND,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing index metadata, including creating, recomputing, and deleting index metadata, and generating workspace migrations for these actions.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import isEmpty from 'lodash.isempty';
import { Repository } from 'typeorm';
import { isDefined } from 'twenty-shared';

import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import {
  IndexMetadataEntity,
  IndexType,
} from 'src/engine/metadata-modules/index-metadata/index-metadata.entity';
import { generateDeterministicIndexName } from 'src/engine/metadata-modules/index-metadata/utils/generate-deterministic-index-name';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { generateMigrationName } from 'src/engine/metadata-modules/workspace-migration/utils/generate-migration-name.util';
import {
  WorkspaceMigrationIndexAction,
  WorkspaceMigrationIndexActionType,
  WorkspaceMigrationTableAction,
  WorkspaceMigrationTableActionType,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceMigrationService } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.service';
import { computeObjectTargetTable } from 'src/engine/utils/compute-object-target-table.util';

@Injectable()
export class IndexMetadataService {
  constructor(
    @InjectRepository(IndexMetadataEntity, 'metadata')
    private readonly indexMetadataRepository: Repository<IndexMetadataEntity>,
    private readonly workspaceMigrationService: WorkspaceMigrationService,
  ) {}

  async createIndexMetadata(
    workspaceId: string,
    objectMetadata: ObjectMetadataEntity,
    fieldMetadataToIndex: Partial<FieldMetadataEntity>[],
    isUnique: boolean,
    isCustom: boolean,
    indexType?: IndexType,
    indexWhereClause?: string,
  ) {
    const tableName = computeObjectTargetTable(objectMetadata);

    const columnNames: string[] = fieldMetadataToIndex.map(
      (fieldMetadata) => fieldMetadata.name as string,
    );

    if (isEmpty(columnNames)) {
      throw new Error('Column names must not be empty');
    }

    const indexName = `IDX_${generateDeterministicIndexName([tableName, ...columnNames])}`;

    let result: IndexMetadataEntity;

    const existingIndex = await this.indexMetadataRepository.findOne({
      where: {
        name: indexName,
        workspaceId,
        objectMetadataId: objectMetadata.id,
      },
    });

    if (existingIndex) {
      throw new Error(
        `Index ${indexName} on object metadata ${objectMetadata.nameSingular} already exists`,
      );
    }

    try {
      result = await this.indexMetadataRepository.save({
        name: indexName,
        indexFieldMetadatas: fieldMetadataToIndex.map(
          (fieldMetadata, index) => ({
            fieldMetadataId: fieldMetadata.id,
            order: index,
          }),
        ),
        workspaceId,
        objectMetadataId: objectMetadata.id,
        ...(isDefined(indexType) ? { indexType } : {}),
        isCustom,
      });
    } catch (error) {
      throw new Error(
        `Failed to create index ${indexName} on object metadata ${objectMetadata.nameSingular}`,
      );
    }

    if (!result) {
      throw new Error(
        `Failed to return saved index ${indexName} on object metadata ${objectMetadata.nameSingular}`,
      );
    }

    await this.createIndexCreationMigration(
      workspaceId,
      objectMetadata,
      fieldMetadataToIndex,
      isUnique,
      isCustom,
      indexType,
      indexWhereClause,
    );
  }

  async recomputeIndexMetadataForObject(
    workspaceId: string,
    updatedObjectMetadata: ObjectMetadataEntity,
  ) {
    const indexesToRecompute = await this.indexMetadataRepository.find({
      where: {
        objectMetadataId: updatedObjectMetadata.id,
        workspaceId,
      },
      relations: ['indexFieldMetadatas.fieldMetadata'],
    });

    const recomputedIndexes: {
      indexMetadata: IndexMetadataEntity;
      previousName: string;
      newName: string;
    }[] = [];

    for (const index of indexesToRecompute) {
      const previousIndexName = index.name;
      const tableName = computeObjectTargetTable(updatedObjectMetadata);

      const indexFieldsMetadataOrdered = index.indexFieldMetadatas.sort(
        (a, b) => a.order - b.order,
      );

      const columnNames = indexFieldsMetadataOrdered.map(
        (indexFieldMetadata) => indexFieldMetadata.fieldMetadata.name,
      );

      const newIndexName = `IDX_${generateDeterministicIndexName([
        tableName,
        ...columnNames,
      ])}`;

      await this.indexMetadataRepository.update(index.id, {
        name: newIndexName,
      });

      recomputedIndexes.push({
        indexMetadata: index,
        previousName: previousIndexName,
        newName: newIndexName,
      });
    }

    return recomputedIndexes;
  }

  async deleteIndexMetadata(
    workspaceId: string,
    objectMetadata: ObjectMetadataEntity,
    fieldMetadataToIndex: Partial<FieldMetadataEntity>[],
  ) {
    const tableName = computeObjectTargetTable(objectMetadata);

    const columnNames: string[] = fieldMetadataToIndex.map(
      (fieldMetadata) => fieldMetadata.name as string,
    );

    if (isEmpty(columnNames)) {
      throw new Error('Column names must not be empty');
    }

    const indexName = `IDX_${generateDeterministicIndexName([tableName, ...columnNames])}`;

    const indexMetadata = await this.indexMetadataRepository.findOne({
      where: {
        name: indexName,
        objectMetadataId: objectMetadata.id,
        workspaceId,
      },
    });

    if (!indexMetadata) {
      throw new Error(`Index metadata with name ${indexName} not found`);
    }

    try {
      await this.indexMetadataRepository.delete(indexMetadata.id);
    } catch (error) {
      throw new Error(
        `Failed to delete index metadata with name ${indexName} (error: ${error.message})`,
      );
    }
  }

  async createIndexCreationMigration(
    workspaceId: string,
    objectMetadata: ObjectMetadataEntity,
    fieldMetadataToIndex: Partial<FieldMetadataEntity>[],
    isUnique: boolean,
    isCustom: boolean,
    indexType?: IndexType,
    indexWhereClause?: string,
  ) {
    const tableName = computeObjectTargetTable(objectMetadata);

    const columnNames: string[] = fieldMetadataToIndex.map(
      (fieldMetadata) => fieldMetadata.name as string,
    );

    const indexName = `IDX_${generateDeterministicIndexName([tableName, ...columnNames])}`;

    const migration = {
      name: tableName,
      action: WorkspaceMigrationTableActionType.ALTER_INDEXES,
      indexes: [
        {
          action: WorkspaceMigrationIndexActionType.CREATE,
          columns: columnNames,
          name: indexName,
          isUnique,
          where: indexWhereClause,
          type: indexType,
        },
      ],
    } satisfies WorkspaceMigrationTableAction;

    await this.workspaceMigrationService.createCustomMigration(
      generateMigrationName(`create-${objectMetadata.nameSingular}-index`),
      workspaceId,
      [migration],
    );
  }

  async createIndexRecomputeMigrations(
    workspaceId: string,
    objectMetadata: ObjectMetadataEntity,
    recomputedIndexes: {
      indexMetadata: IndexMetadataEntity;
      previousName: string;
      newName: string;
    }[],
  ) {
    for (const recomputedIndex of recomputedIndexes) {
      const { previousName, newName, indexMetadata } = recomputedIndex;

      const tableName = computeObjectTargetTable(objectMetadata);

      const indexFieldsMetadataOrdered = indexMetadata.indexFieldMetadatas.sort(
        (a, b) => a.order - b.order,
      );

      const columnNames = indexFieldsMetadataOrdered.map(
        (indexFieldMetadata) => indexFieldMetadata.fieldMetadata.name,
      );

      const migration = {
        name: tableName,
        action: WorkspaceMigrationTableActionType.ALTER_INDEXES,
        indexes: [
          {
            action: WorkspaceMigrationIndexActionType.DROP,
            name: previousName,
            columns: [],
            isUnique: indexMetadata.isUnique,
          } satisfies WorkspaceMigrationIndexAction,
          {
            action: WorkspaceMigrationIndexActionType.CREATE,
            columns: columnNames,
            name: newName,
            isUnique: indexMetadata.isUnique,
            where: indexMetadata.indexWhereClause,
            type: indexMetadata.indexType,
          } satisfies WorkspaceMigrationIndexAction,
        ],
      } satisfies WorkspaceMigrationTableAction;

      await this.workspaceMigrationService.createCustomMigration(
        generateMigrationName(`update-${objectMetadata.nameSingular}-index`),
        workspaceId,
        [migration],
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to synchronize workspace object metadata with standard metadata definitions, ensuring fields have correct identifiers and types.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { FieldMetadataType } from 'twenty-shared';
import { EntityManager, Repository } from 'typeorm';

import { FeatureFlagMap } from 'src/engine/core-modules/feature-flag/interfaces/feature-flag-map.interface';
import { WorkspaceSyncContext } from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/workspace-sync-context.interface';

import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { StandardObjectFactory } from 'src/engine/workspace-manager/workspace-sync-metadata/factories/standard-object.factory';
import { standardObjectMetadataDefinitions } from 'src/engine/workspace-manager/workspace-sync-metadata/standard-objects';
import { WorkspaceSyncStorage } from 'src/engine/workspace-manager/workspace-sync-metadata/storage/workspace-sync.storage';
import { mapObjectMetadataByUniqueIdentifier } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/sync-metadata.util';

@Injectable()
export class WorkspaceSyncObjectMetadataIdentifiersService {
  constructor(private readonly standardObjectFactory: StandardObjectFactory) {}

  async synchronize(
    context: WorkspaceSyncContext,
    manager: EntityManager,
    _storage: WorkspaceSyncStorage,
    workspaceFeatureFlagsMap: FeatureFlagMap,
  ): Promise<void> {
    const objectMetadataRepository =
      manager.getRepository(ObjectMetadataEntity);

    const originalObjectMetadataCollection =
      await this.getOriginalObjectMetadataCollection(
        context.workspaceId,
        objectMetadataRepository,
      );

    const standardObjectMetadataMap = this.createStandardObjectMetadataMap(
      context,
      workspaceFeatureFlagsMap,
    );

    await this.processObjectMetadataCollection(
      originalObjectMetadataCollection,
      standardObjectMetadataMap,
      objectMetadataRepository,
    );
  }

  private async getOriginalObjectMetadataCollection(
    workspaceId: string,
    objectMetadataRepository: Repository<ObjectMetadataEntity>,
  ): Promise<ObjectMetadataEntity[]> {
    return await objectMetadataRepository.find({
      where: { workspaceId, isCustom: false, isRemote: false },
      relations: ['fields'],
    });
  }

  private createStandardObjectMetadataMap(
    context: WorkspaceSyncContext,
    workspaceFeatureFlagsMap: FeatureFlagMap,
  ): Record<string, any> {
    const standardObjectMetadataCollection = this.standardObjectFactory.create(
      standardObjectMetadataDefinitions,
      context,
      workspaceFeatureFlagsMap,
    );

    return mapObjectMetadataByUniqueIdentifier(
      standardObjectMetadataCollection,
    );
  }

  private async processObjectMetadataCollection(
    originalObjectMetadataCollection: ObjectMetadataEntity[],
    standardObjectMetadataMap: Record<string, any>,
    objectMetadataRepository: Repository<ObjectMetadataEntity>,
  ): Promise<void> {
    for (const objectMetadata of originalObjectMetadataCollection) {
      const objectStandardId = objectMetadata.standardId;

      if (!objectStandardId) {
        throw new Error(
          `Object ${objectMetadata.nameSingular} is missing standardId`,
        );
      }

      const labelIdentifierFieldMetadata = this.findIdentifierFieldMetadata(
        objectMetadata,
        objectStandardId,
        standardObjectMetadataMap,
        'labelIdentifierStandardId',
      );

      const imageIdentifierFieldMetadata = this.findIdentifierFieldMetadata(
        objectMetadata,
        objectStandardId,
        standardObjectMetadataMap,
        'imageIdentifierStandardId',
      );

      this.validateFieldMetadata(
        objectMetadata,
        labelIdentifierFieldMetadata,
        imageIdentifierFieldMetadata,
      );

      // TODO: Add image identifier field metadata
      await objectMetadataRepository.save({
        ...objectMetadata,
        labelIdentifierFieldMetadataId:
          labelIdentifierFieldMetadata?.id ?? null,
        imageIdentifierFieldMetadataId:
          imageIdentifierFieldMetadata?.id ?? null,
      });
    }
  }

  private findIdentifierFieldMetadata(
    objectMetadata: ObjectMetadataEntity,
    objectStandardId: string,
    standardObjectMetadataMap: Record<string, any>,
    standardIdFieldName: string,
  ): FieldMetadataEntity | undefined {
    const identifierFieldMetadata = objectMetadata.fields.find(
      (field) =>
        field.standardId ===
          standardObjectMetadataMap[objectStandardId][standardIdFieldName] &&
        field.standardId !== null,
    );

    if (
      !identifierFieldMetadata &&
      standardObjectMetadataMap[objectStandardId][standardIdFieldName]
    ) {
      throw new Error(
        `Identifier field for object ${objectMetadata.nameSingular} does not exist`,
      );
    }

    return identifierFieldMetadata;
  }

  private validateFieldMetadata(
    objectMetadata: ObjectMetadataEntity,
    labelIdentifierFieldMetadata: FieldMetadataEntity | undefined,
    imageIdentifierFieldMetadata: FieldMetadataEntity | undefined,
  ): void {
    if (
      labelIdentifierFieldMetadata &&
      ![
        FieldMetadataType.UUID,
        FieldMetadataType.TEXT,
        FieldMetadataType.FULL_NAME,
      ].includes(labelIdentifierFieldMetadata.type)
    ) {
      throw new Error(
        `Label identifier field for object ${objectMetadata.nameSingular} has invalid type ${labelIdentifierFieldMetadata.type}`,
      );
    }

    if (
      imageIdentifierFieldMetadata &&
      imageIdentifierFieldMetadata.type !== FieldMetadataType.TEXT
    ) {
      throw new Error(
        `Image identifier field for object ${objectMetadata.nameSingular} has invalid type ${imageIdentifierFieldMetadata.type}`,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_9>



=== New Entry ===

<CLUSTER_10>
Number of Code Snippets part of this cluster: 11
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code generates a configuration script for the frontend by reading environment variables and writing it to the index.html file.
Code Snippet:
import * as fs from 'fs';
import * as path from 'path';

import { config } from 'dotenv';
config({ path: process.env.NODE_ENV === 'test' ? '.env.test' : '.env' });

export function generateFrontConfig(): void {
  const configObject = {
    window: {
      _env_: {
        REACT_APP_SERVER_BASE_URL: process.env.SERVER_URL,
      },
    },
  };

  const configString = `<!-- BEGIN: Twenty Config -->
    <script id="twenty-env-config">
      window._env_ = ${JSON.stringify(configObject.window._env_, null, 2)};
    </script>
    <!-- END: Twenty Config -->`;

  const distPath = path.join(__dirname, '../..', 'front');
  const indexPath = path.join(distPath, 'index.html');

  if (!fs.existsSync(indexPath)) {
    // eslint-disable-next-line no-console
    console.log(
      'Frontend build not found, assuming it is served independently',
    );

    return;
  }

  let indexContent = fs.readFileSync(indexPath, 'utf8');

  indexContent = indexContent.replace(
    /<!-- BEGIN: Twenty Config -->[\s\S]*?<!-- END: Twenty Config -->/,
    configString,
  );

  fs.writeFileSync(indexPath, indexContent, 'utf8');
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS service for logging commands, handling directory creation and writing log data to JSON files.
Code Snippet:
/* eslint-disable no-console */
import { Injectable } from '@nestjs/common';

import { existsSync } from 'fs';
import fs from 'fs/promises';
import { join as joinPath } from 'path';

import { kebabCase } from 'src/utils/kebab-case';

@Injectable()
export class CommandLogger {
  constructor(private readonly className: string) {}

  async createSubDirectory(subDirectory: string): Promise<void> {
    const path = `./logs/${kebabCase(this.className)}/${subDirectory}`;

    if (existsSync(path) === false) {
      await fs.mkdir(path, { recursive: true });
    }

    return;
  }

  async writeLog(
    fileName: string,
    data: unknown,
    append = false,
  ): Promise<string> {
    const path = `./logs/${kebabCase(this.className)}`;

    if (existsSync(path) === false) {
      await fs.mkdir(path, { recursive: true });
    }

    try {
      const logFilePath = `${path}/${fileName}.json`;

      await fs.writeFile(logFilePath, JSON.stringify(data, null, 2), {
        flag: append ? 'a' : 'w',
      });

      const absoluteLogFilePath = joinPath(process.cwd(), logFilePath);

      return absoluteLogFilePath;
    } catch (err) {
      console.error(
        `Error writing to file ${path}/${fileName}.json: ${err?.message}`,
      );

      throw err;
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS module for file storage that can use either a local file system or AWS S3 as the storage driver.
Code Snippet:
import { DynamicModule, Global } from '@nestjs/common';

import { FileStorageService } from 'src/engine/core-modules/file-storage/file-storage.service';
import {
  FileStorageModuleAsyncOptions,
  FileStorageModuleOptions,
} from 'src/engine/core-modules/file-storage/interfaces';
import { STORAGE_DRIVER } from 'src/engine/core-modules/file-storage/file-storage.constants';
import { LocalDriver } from 'src/engine/core-modules/file-storage/drivers/local.driver';
import { S3Driver } from 'src/engine/core-modules/file-storage/drivers/s3.driver';

@Global()
export class FileStorageModule {
  static forRoot(options: FileStorageModuleOptions): DynamicModule {
    const provider = {
      provide: STORAGE_DRIVER,
      useValue:
        options.type === 's3'
          ? new S3Driver(options.options)
          : new LocalDriver(options.options),
    };

    return {
      module: FileStorageModule,
      providers: [FileStorageService, provider],
      exports: [FileStorageService],
    };
  }

  static forRootAsync(options: FileStorageModuleAsyncOptions): DynamicModule {
    const provider = {
      provide: STORAGE_DRIVER,
      useFactory: async (...args: any[]) => {
        const config = await options.useFactory(...args);

        return config?.type === 's3'
          ? new S3Driver(config.options)
          : new LocalDriver(config.options);
      },
      inject: options.inject || [],
    };

    return {
      module: FileStorageModule,
      imports: options.imports || [],
      providers: [FileStorageService, provider],
      exports: [FileStorageService],
    };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a LocalDriver class for file storage operations such as creating folders, writing, deleting, reading, moving, copying, and downloading files.
Code Snippet:
import { createReadStream, existsSync } from 'fs';
import * as fs from 'fs/promises';
import { dirname, join } from 'path';
import { Readable } from 'stream';

import {
  FileStorageException,
  FileStorageExceptionCode,
} from 'src/engine/core-modules/file-storage/interfaces/file-storage-exception';
import { StorageDriver } from 'src/engine/core-modules/file-storage/drivers/interfaces/storage-driver.interface';

export interface LocalDriverOptions {
  storagePath: string;
}

export class LocalDriver implements StorageDriver {
  private options: LocalDriverOptions;

  constructor(options: LocalDriverOptions) {
    this.options = options;
  }

  async createFolder(path: string) {
    return fs.mkdir(path, { recursive: true });
  }

  async write(params: {
    file: Buffer | Uint8Array | string;
    name: string;
    folder: string;
    mimeType: string | undefined;
  }): Promise<void> {
    const filePath = join(
      `${this.options.storagePath}/`,
      params.folder,
      params.name,
    );
    const folderPath = dirname(filePath);

    await this.createFolder(folderPath);

    await fs.writeFile(filePath, params.file);
  }

  async delete(params: {
    folderPath: string;
    filename?: string;
  }): Promise<void> {
    const filePath = join(
      `${this.options.storagePath}/`,
      params.folderPath,
      params.filename || '',
    );

    await fs.rm(filePath, { recursive: true });
  }

  async read(params: {
    folderPath: string;
    filename: string;
  }): Promise<Readable> {
    const filePath = join(
      `${this.options.storagePath}/`,
      params.folderPath,
      params.filename,
    );

    if (!existsSync(filePath)) {
      throw new FileStorageException(
        'File not found',
        FileStorageExceptionCode.FILE_NOT_FOUND,
      );
    }

    try {
      return createReadStream(filePath);
    } catch (error) {
      if (error.code === 'ENOENT') {
        throw new FileStorageException(
          'File not found',
          FileStorageExceptionCode.FILE_NOT_FOUND,
        );
      }

      throw error;
    }
  }

  async move(params: {
    from: { folderPath: string; filename: string };
    to: { folderPath: string; filename: string };
  }): Promise<void> {
    const fromPath = join(
      `${this.options.storagePath}/`,
      params.from.folderPath,
      params.from.filename,
    );

    const toPath = join(
      `${this.options.storagePath}/`,
      params.to.folderPath,
      params.to.filename,
    );

    await this.createFolder(dirname(toPath));

    try {
      await fs.rename(fromPath, toPath);
    } catch (error) {
      if (error.code === 'ENOENT') {
        throw new FileStorageException(
          'File not found',
          FileStorageExceptionCode.FILE_NOT_FOUND,
        );
      }

      throw error;
    }
  }

  async copy(
    params: {
      from: { folderPath: string; filename?: string };
      to: { folderPath: string; filename?: string };
    },
    toInMemory = false,
  ): Promise<void> {
    if (!params.from.filename && params.to.filename) {
      throw new Error('Cannot copy folder to file');
    }
    const fromPath = join(
      this.options.storagePath,
      params.from.folderPath,
      params.from.filename || '',
    );

    const toPath = join(
      toInMemory ? '' : this.options.storagePath,
      params.to.folderPath,
      params.to.filename || '',
    );

    await this.createFolder(dirname(toPath));

    try {
      await fs.cp(fromPath, toPath, { recursive: true });
    } catch (error) {
      if (error.code === 'ENOENT') {
        throw new FileStorageException(
          'File not found',
          FileStorageExceptionCode.FILE_NOT_FOUND,
        );
      }

      throw error;
    }
  }

  async download(params: {
    from: { folderPath: string; filename?: string };
    to: { folderPath: string; filename?: string };
  }): Promise<void> {
    await this.copy(params, true);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code implements a storage driver for Amazon S3, providing methods to write, delete, read, move, copy, and download files and directories.
Code Snippet:
import fs from 'fs';
import { mkdir } from 'fs/promises';
import { join } from 'path';
import { Readable } from 'stream';
import { pipeline } from 'stream/promises';

import {
  CopyObjectCommand,
  CreateBucketCommandInput,
  DeleteObjectCommand,
  DeleteObjectsCommand,
  GetObjectCommand,
  HeadBucketCommandInput,
  HeadObjectCommand,
  ListObjectsV2Command,
  NotFound,
  PutObjectCommand,
  S3,
  S3ClientConfig,
} from '@aws-sdk/client-s3';
import { isDefined } from 'twenty-shared';

import { StorageDriver } from 'src/engine/core-modules/file-storage/drivers/interfaces/storage-driver.interface';
import {
  FileStorageException,
  FileStorageExceptionCode,
} from 'src/engine/core-modules/file-storage/interfaces/file-storage-exception';

export interface S3DriverOptions extends S3ClientConfig {
  bucketName: string;
  endpoint?: string;
  region: string;
}

export class S3Driver implements StorageDriver {
  private s3Client: S3;
  private bucketName: string;

  constructor(options: S3DriverOptions) {
    const { bucketName, region, endpoint, ...s3Options } = options;

    if (!bucketName || !region) {
      return;
    }

    this.s3Client = new S3({ ...s3Options, region, endpoint });
    this.bucketName = bucketName;
  }

  public get client(): S3 {
    return this.s3Client;
  }

  async write(params: {
    file: Buffer | Uint8Array | string;
    name: string;
    folder: string;
    mimeType: string | undefined;
  }): Promise<void> {
    const command = new PutObjectCommand({
      Key: `${params.folder}/${params.name}`,
      Body: params.file,
      ContentType: params.mimeType,
      Bucket: this.bucketName,
    });

    await this.s3Client.send(command);
  }

  private async emptyS3Directory(folderPath) {
    const listParams = {
      Bucket: this.bucketName,
      Prefix: folderPath,
    };

    const listObjectsCommand = new ListObjectsV2Command(listParams);
    const listedObjects = await this.s3Client.send(listObjectsCommand);

    if (listedObjects.Contents?.length === 0) return;

    const deleteParams = {
      Bucket: this.bucketName,
      Delete: {
        Objects: listedObjects.Contents?.map(({ Key }) => {
          return { Key };
        }),
      },
    };

    const deleteObjectCommand = new DeleteObjectsCommand(deleteParams);

    await this.s3Client.send(deleteObjectCommand);

    if (listedObjects.IsTruncated) {
      await this.emptyS3Directory(folderPath);
    }
  }

  async delete(params: {
    folderPath: string;
    filename?: string;
  }): Promise<void> {
    if (params.filename) {
      const deleteCommand = new DeleteObjectCommand({
        Key: `${params.folderPath}/${params.filename}`,
        Bucket: this.bucketName,
      });

      await this.s3Client.send(deleteCommand);
    } else {
      await this.emptyS3Directory(params.folderPath);
      const deleteEmptyFolderCommand = new DeleteObjectCommand({
        Key: `${params.folderPath}`,
        Bucket: this.bucketName,
      });

      await this.s3Client.send(deleteEmptyFolderCommand);
    }
  }

  async read(params: {
    folderPath: string;
    filename: string;
  }): Promise<Readable> {
    const command = new GetObjectCommand({
      Key: `${params.folderPath}/${params.filename}`,
      Bucket: this.bucketName,
    });

    try {
      const file = await this.s3Client.send(command);

      if (!file || !file.Body || !(file.Body instanceof Readable)) {
        throw new Error('Unable to get file stream');
      }

      return Readable.from(file.Body);
    } catch (error) {
      if (error.name === 'NoSuchKey') {
        throw new FileStorageException(
          'File not found',
          FileStorageExceptionCode.FILE_NOT_FOUND,
        );
      }

      throw error;
    }
  }

  async move(params: {
    from: { folderPath: string; filename: string };
    to: { folderPath: string; filename: string };
  }): Promise<void> {
    const fromKey = `${params.from.folderPath}/${params.from.filename}`;
    const toKey = `${params.to.folderPath}/${params.to.filename}`;

    try {
      // Check if the source file exists
      await this.s3Client.send(
        new HeadObjectCommand({
          Bucket: this.bucketName,
          Key: fromKey,
        }),
      );

      // Copy the object to the new location
      await this.s3Client.send(
        new CopyObjectCommand({
          CopySource: `${this.bucketName}/${fromKey}`,
          Bucket: this.bucketName,
          Key: toKey,
        }),
      );

      // Delete the original object
      await this.s3Client.send(
        new DeleteObjectCommand({
          Bucket: this.bucketName,
          Key: fromKey,
        }),
      );
    } catch (error) {
      if (error.name === 'NotFound') {
        throw new FileStorageException(
          'File not found',
          FileStorageExceptionCode.FILE_NOT_FOUND,
        );
      }
      // For other errors, throw the original error
      throw error;
    }
  }

  extractFolderAndFilePaths(objectKey: string | undefined) {
    if (!isDefined(objectKey)) {
      return;
    }

    const result = /(?<folder>.*)\/(?<file>.*)/.exec(objectKey);

    if (!isDefined(result) || !isDefined(result.groups)) {
      return;
    }

    const fromFolderPath = result.groups.folder;
    const filename = result.groups.file;

    return { fromFolderPath, filename };
  }

  async copy(params: {
    from: { folderPath: string; filename?: string };
    to: { folderPath: string; filename?: string };
  }): Promise<void> {
    if (!params.from.filename && params.to.filename) {
      throw new Error('Cannot copy folder to file');
    }

    const fromKey = `${params.from.folderPath}/${params.from.filename || ''}`;
    const toKey = `${params.to.folderPath}/${params.to.filename || ''}`;

    if (isDefined(params.from.filename)) {
      try {
        // Check if the source file exists
        await this.s3Client.send(
          new HeadObjectCommand({
            Bucket: this.bucketName,
            Key: fromKey,
          }),
        );

        // Copy the object to the new location
        await this.s3Client.send(
          new CopyObjectCommand({
            CopySource: `${this.bucketName}/${fromKey}`,
            Bucket: this.bucketName,
            Key: toKey,
          }),
        );

        return;
      } catch (error) {
        if (error.name === 'NotFound') {
          throw new FileStorageException(
            'File not found',
            FileStorageExceptionCode.FILE_NOT_FOUND,
          );
        }
        // For other errors, throw the original error
        throw error;
      }
    }

    const listedObjects = await this.s3Client.send(
      new ListObjectsV2Command({
        Bucket: this.bucketName,
        Prefix: fromKey,
      }),
    );

    if (!listedObjects.Contents || listedObjects.Contents.length === 0) {
      throw new Error(`No objects found in the source folder ${fromKey}.`);
    }

    for (const object of listedObjects.Contents) {
      const folderAndFilePaths = this.extractFolderAndFilePaths(object.Key);

      if (!isDefined(folderAndFilePaths)) {
        continue;
      }

      const { fromFolderPath, filename } = folderAndFilePaths;

      const toFolderPath = fromFolderPath.replace(
        params.from.folderPath,
        params.to.folderPath,
      );

      if (!isDefined(toFolderPath)) {
        continue;
      }

      await this.copy({
        from: {
          folderPath: fromFolderPath,
          filename,
        },
        to: { folderPath: toFolderPath, filename },
      });
    }
  }

  async download(params: {
    from: { folderPath: string; filename?: string };
    to: { folderPath: string; filename?: string };
  }): Promise<void> {
    if (!params.from.filename && params.to.filename) {
      throw new Error('Cannot copy folder to file');
    }

    if (isDefined(params.from.filename)) {
      try {
        const dir = params.to.folderPath;

        await mkdir(dir, { recursive: true });

        const fileStream = await this.read({
          folderPath: params.from.folderPath,
          filename: params.from.filename,
        });

        const toPath = join(
          params.to.folderPath,
          params.to.filename || params.from.filename,
        );

        await pipeline(fileStream, fs.createWriteStream(toPath));

        return;
      } catch (error) {
        if (error.name === 'NotFound') {
          throw new FileStorageException(
            'File not found',
            FileStorageExceptionCode.FILE_NOT_FOUND,
          );
        }
        // For other errors, throw the original error
        throw error;
      }
    }

    const listedObjects = await this.s3Client.send(
      new ListObjectsV2Command({
        Bucket: this.bucketName,
        Prefix: params.from.folderPath,
      }),
    );

    if (!listedObjects.Contents || listedObjects.Contents.length === 0) {
      throw new Error(
        `No objects found in the source folder ${params.from.folderPath}.`,
      );
    }

    for (const object of listedObjects.Contents) {
      const folderAndFilePaths = this.extractFolderAndFilePaths(object.Key);

      if (!isDefined(folderAndFilePaths)) {
        continue;
      }

      const { fromFolderPath, filename } = folderAndFilePaths;
      const toFolderPath = fromFolderPath.replace(
        params.from.folderPath,
        params.to.folderPath,
      );

      if (!isDefined(toFolderPath)) {
        continue;
      }

      await this.download({
        from: {
          folderPath: fromFolderPath,
          filename,
        },
        to: { folderPath: toFolderPath, filename },
      });
    }
  }

  async checkBucketExists(args: HeadBucketCommandInput) {
    try {
      await this.s3Client.headBucket(args);

      return true;
    } catch (error) {
      if (error instanceof NotFound) {
        return false;
      }

      throw error;
    }
  }

  async createBucket(args: CreateBucketCommandInput) {
    const exist = await this.checkBucketExists({
      Bucket: args.Bucket,
    });

    if (exist) {
      return;
    }

    return this.s3Client.createBucket(args);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for uploading files and images, including sanitizing SVG files and cropping images to specified sizes before storing them.
Code Snippet:
import { Injectable } from '@nestjs/common';

import DOMPurify from 'dompurify';
import { JSDOM } from 'jsdom';
import sharp from 'sharp';
import { v4 as uuidV4 } from 'uuid';

import { FileFolder } from 'src/engine/core-modules/file/interfaces/file-folder.interface';

import { settings } from 'src/engine/constants/settings';
import { FileStorageService } from 'src/engine/core-modules/file-storage/file-storage.service';
import { FileService } from 'src/engine/core-modules/file/services/file.service';
import { getCropSize } from 'src/utils/image';

@Injectable()
export class FileUploadService {
  constructor(
    private readonly fileStorage: FileStorageService,
    private readonly fileService: FileService,
  ) {}

  private async _uploadFile({
    file,
    filename,
    mimeType,
    folder,
  }: {
    file: Buffer | Uint8Array | string;
    filename: string;
    mimeType: string | undefined;
    folder: string;
  }) {
    await this.fileStorage.write({
      file,
      name: filename,
      mimeType,
      folder,
    });
  }

  private _sanitizeFile({
    file,
    ext,
    mimeType,
  }: {
    file: Buffer | Uint8Array | string;
    ext: string;
    mimeType: string | undefined;
  }): Buffer | Uint8Array | string {
    if (ext === 'svg' || mimeType === 'image/svg+xml') {
      const window = new JSDOM('').window;
      const purify = DOMPurify(window);

      return purify.sanitize(file.toString());
    }

    return file;
  }

  async uploadFile({
    file,
    filename,
    mimeType,
    fileFolder,
    workspaceId,
  }: {
    file: Buffer | Uint8Array | string;
    filename: string;
    mimeType: string | undefined;
    fileFolder: FileFolder;
    workspaceId: string;
  }) {
    const ext = filename.split('.')?.[1];
    const id = uuidV4();
    const name = `${id}${ext ? `.${ext}` : ''}`;
    const folder = this.getWorkspaceFolderName(workspaceId, fileFolder);

    await this._uploadFile({
      file: this._sanitizeFile({ file, ext, mimeType }),
      filename: name,
      mimeType,
      folder,
    });

    const signedPayload = await this.fileService.encodeFileToken({
      workspaceId: workspaceId,
    });

    return {
      id,
      mimeType,
      path: `${fileFolder}/${name}?token=${signedPayload}`,
    };
  }

  async uploadImage({
    file,
    filename,
    mimeType,
    fileFolder,
    workspaceId,
  }: {
    file: Buffer | Uint8Array | string;
    filename: string;
    mimeType: string | undefined;
    fileFolder: FileFolder;
    workspaceId: string;
  }) {
    const ext = filename.split('.')?.[1];
    const id = uuidV4();
    const name = `${id}${ext ? `.${ext}` : ''}`;

    const cropSizes = settings.storage.imageCropSizes[fileFolder];

    if (!cropSizes) {
      throw new Error(`No crop sizes found for ${fileFolder}`);
    }

    const sizes = cropSizes.map((shortSize) => getCropSize(shortSize));
    const images = await Promise.all(
      sizes.map((size) =>
        sharp(file).resize({
          [size?.type || 'width']: size?.value ?? undefined,
        }),
      ),
    );

    const paths: Array<string> = [];

    await Promise.all(
      images.map(async (image, index) => {
        const buffer = await image.toBuffer();
        const folder = this.getWorkspaceFolderName(workspaceId, fileFolder);

        paths.push(`${fileFolder}/${cropSizes[index]}/${name}`);

        return this._uploadFile({
          file: buffer,
          filename: `${cropSizes[index]}/${name}`,
          mimeType,
          folder,
        });
      }),
    );

    return {
      id,
      mimeType,
      paths,
    };
  }

  private getWorkspaceFolderName(workspaceId: string, fileFolder: FileFolder) {
    return `workspace-${workspaceId}/${fileFolder}`;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a LambdaDriver class that manages AWS Lambda functions, including creating, deleting, building, and executing them. It handles layer management, dependency builds, and code transpilation.
Code Snippet:
import * as fs from 'fs/promises';
import { join } from 'path';

import ts, { transpileModule } from 'typescript';
import {
  CreateFunctionCommandInput,
  CreateFunctionCommand,
  DeleteFunctionCommand,
  GetFunctionCommand,
  InvokeCommand,
  InvokeCommandInput,
  Lambda,
  LambdaClientConfig,
  ListLayerVersionsCommand,
  ListLayerVersionsCommandInput,
  PublishLayerVersionCommand,
  PublishLayerVersionCommandInput,
  ResourceNotFoundException,
  waitUntilFunctionUpdatedV2,
} from '@aws-sdk/client-lambda';
import { AssumeRoleCommand, STSClient } from '@aws-sdk/client-sts';
import { isDefined } from 'twenty-shared';

import {
  ServerlessDriver,
  ServerlessExecuteResult,
} from 'src/engine/core-modules/serverless/drivers/interfaces/serverless-driver.interface';

import { FileStorageService } from 'src/engine/core-modules/file-storage/file-storage.service';
import { COMMON_LAYER_NAME } from 'src/engine/core-modules/serverless/drivers/constants/common-layer-name';
import { copyAndBuildDependencies } from 'src/engine/core-modules/serverless/drivers/utils/copy-and-build-dependencies';
import { createZipFile } from 'src/engine/core-modules/serverless/drivers/utils/create-zip-file';
import {
  LambdaBuildDirectoryManager,
  NODE_LAYER_SUBFOLDER,
} from 'src/engine/core-modules/serverless/drivers/utils/lambda-build-directory-manager';
import { getServerlessFolder } from 'src/engine/core-modules/serverless/utils/serverless-get-folder.utils';
import { ServerlessFunctionExecutionStatus } from 'src/engine/metadata-modules/serverless-function/dtos/serverless-function-execution-result.dto';
import {
  ServerlessFunctionEntity,
  ServerlessFunctionRuntime,
} from 'src/engine/metadata-modules/serverless-function/serverless-function.entity';
import {
  ServerlessFunctionException,
  ServerlessFunctionExceptionCode,
} from 'src/engine/metadata-modules/serverless-function/serverless-function.exception';
import { copyExecutor } from 'src/engine/core-modules/serverless/drivers/utils/copy-executor';
import { INDEX_FILE_NAME } from 'src/engine/core-modules/serverless/drivers/constants/index-file-name';
import { readFileContent } from 'src/engine/core-modules/file-storage/utils/read-file-content';

const UPDATE_FUNCTION_DURATION_TIMEOUT_IN_SECONDS = 60;
const CREDENTIALS_DURATION_IN_SECONDS = 10 * 60 * 60; // 10h
const LAMBDA_EXECUTOR_DESCRIPTION = 'User script executor';

export interface LambdaDriverOptions extends LambdaClientConfig {
  fileStorageService: FileStorageService;
  region: string;
  lambdaRole: string;
  subhostingRole?: string;
}

export class LambdaDriver implements ServerlessDriver {
  private lambdaClient: Lambda | undefined;
  private credentialsExpiry: Date | null = null;
  private readonly options: LambdaDriverOptions;
  private readonly fileStorageService: FileStorageService;

  constructor(options: LambdaDriverOptions) {
    this.options = options;
    this.lambdaClient = undefined;
    this.fileStorageService = options.fileStorageService;
  }

  private async getLambdaClient() {
    if (
      !isDefined(this.lambdaClient) ||
      (isDefined(this.options.subhostingRole) &&
        isDefined(this.credentialsExpiry) &&
        new Date() >= this.credentialsExpiry)
    ) {
      this.lambdaClient = new Lambda({
        ...this.options,
        ...(isDefined(this.options.subhostingRole) && {
          credentials: await this.getAssumeRoleCredentials(),
        }),
      });
    }

    return this.lambdaClient;
  }

  private async getAssumeRoleCredentials() {
    const stsClient = new STSClient({ region: this.options.region });

    this.credentialsExpiry = new Date(
      Date.now() + (CREDENTIALS_DURATION_IN_SECONDS - 60 * 5) * 1000,
    );

    const assumeRoleCommand = new AssumeRoleCommand({
      RoleArn: 'arn:aws:iam::820242914089:role/LambdaDeploymentRole',
      RoleSessionName: 'LambdaSession',
      DurationSeconds: CREDENTIALS_DURATION_IN_SECONDS,
    });

    const { Credentials } = await stsClient.send(assumeRoleCommand);

    if (
      !isDefined(Credentials) ||
      !isDefined(Credentials.AccessKeyId) ||
      !isDefined(Credentials.SecretAccessKey) ||
      !isDefined(Credentials.SessionToken)
    ) {
      throw new Error('Failed to assume role');
    }

    return {
      accessKeyId: Credentials.AccessKeyId,
      secretAccessKey: Credentials.SecretAccessKey,
      sessionToken: Credentials.SessionToken,
    };
  }

  private async waitFunctionUpdates(
    serverlessFunction: ServerlessFunctionEntity,
    maxWaitTime: number = UPDATE_FUNCTION_DURATION_TIMEOUT_IN_SECONDS,
  ) {
    const waitParams = {
      FunctionName: serverlessFunction.id,
    };

    await waitUntilFunctionUpdatedV2(
      { client: await this.getLambdaClient(), maxWaitTime },
      waitParams,
    );
  }

  private async createLayerIfNotExists(version: number): Promise<string> {
    const listLayerParams: ListLayerVersionsCommandInput = {
      LayerName: COMMON_LAYER_NAME,
      MaxItems: 1,
    };
    const listLayerCommand = new ListLayerVersionsCommand(listLayerParams);
    const listLayerResult = await (
      await this.getLambdaClient()
    ).send(listLayerCommand);

    if (
      isDefined(listLayerResult.LayerVersions) &&
      listLayerResult.LayerVersions.length > 0 &&
      listLayerResult.LayerVersions?.[0].Description === `${version}` &&
      isDefined(listLayerResult.LayerVersions[0].LayerVersionArn)
    ) {
      return listLayerResult.LayerVersions[0].LayerVersionArn;
    }

    const lambdaBuildDirectoryManager = new LambdaBuildDirectoryManager();
    const { sourceTemporaryDir, lambdaZipPath } =
      await lambdaBuildDirectoryManager.init();

    const nodeDependenciesFolder = join(
      sourceTemporaryDir,
      NODE_LAYER_SUBFOLDER,
    );

    await copyAndBuildDependencies(nodeDependenciesFolder);

    await createZipFile(sourceTemporaryDir, lambdaZipPath);

    const params: PublishLayerVersionCommandInput = {
      LayerName: COMMON_LAYER_NAME,
      Content: {
        ZipFile: await fs.readFile(lambdaZipPath),
      },
      CompatibleRuntimes: [ServerlessFunctionRuntime.NODE18],
      Description: `${version}`,
    };

    const command = new PublishLayerVersionCommand(params);

    const result = await (await this.getLambdaClient()).send(command);

    await lambdaBuildDirectoryManager.clean();

    if (!isDefined(result.LayerVersionArn)) {
      throw new Error('new layer version arn if undefined');
    }

    return result.LayerVersionArn;
  }

  private async getLambdaExecutor(
    serverlessFunction: ServerlessFunctionEntity,
  ) {
    try {
      const getFunctionCommand: GetFunctionCommand = new GetFunctionCommand({
        FunctionName: serverlessFunction.id,
      });

      return await (await this.getLambdaClient()).send(getFunctionCommand);
    } catch (error) {
      if (!(error instanceof ResourceNotFoundException)) {
        throw error;
      }
    }
  }

  async delete(serverlessFunction: ServerlessFunctionEntity) {
    const lambdaExecutor = await this.getLambdaExecutor(serverlessFunction);

    if (isDefined(lambdaExecutor)) {
      const deleteFunctionCommand = new DeleteFunctionCommand({
        FunctionName: serverlessFunction.id,
      });

      await (await this.getLambdaClient()).send(deleteFunctionCommand);
    }
  }

  async build(serverlessFunction: ServerlessFunctionEntity) {
    const lambdaExecutor = await this.getLambdaExecutor(serverlessFunction);

    if (isDefined(lambdaExecutor)) {
      if (
        lambdaExecutor.Configuration?.Description ===
        LAMBDA_EXECUTOR_DESCRIPTION
      ) {
        return;
      }
      await this.delete(serverlessFunction);
    }

    const layerArn = await this.createLayerIfNotExists(
      serverlessFunction.layerVersion,
    );

    const lambdaBuildDirectoryManager = new LambdaBuildDirectoryManager();

    const { sourceTemporaryDir, lambdaZipPath } =
      await lambdaBuildDirectoryManager.init();

    await copyExecutor(sourceTemporaryDir);

    await createZipFile(sourceTemporaryDir, lambdaZipPath);

    const params: CreateFunctionCommandInput = {
      Code: {
        ZipFile: await fs.readFile(lambdaZipPath),
      },
      FunctionName: serverlessFunction.id,
      Layers: [layerArn],
      Handler: 'index.handler',
      Role: this.options.lambdaRole,
      Runtime: serverlessFunction.runtime,
      Description: LAMBDA_EXECUTOR_DESCRIPTION,
      Timeout: serverlessFunction.timeoutSeconds,
    };

    const command = new CreateFunctionCommand(params);

    await (await this.getLambdaClient()).send(command);

    await lambdaBuildDirectoryManager.clean();
  }

  async execute(
    serverlessFunction: ServerlessFunctionEntity,
    payload: object,
    version: string,
  ): Promise<ServerlessExecuteResult> {
    await this.build(serverlessFunction);
    await this.waitFunctionUpdates(serverlessFunction);

    const startTime = Date.now();

    const computedVersion =
      version === 'latest' ? serverlessFunction.latestVersion : version;

    const folderPath = getServerlessFolder({
      serverlessFunction,
      version: computedVersion,
    });

    const tsCodeStream = await this.fileStorageService.read({
      folderPath: join(folderPath, 'src'),
      filename: INDEX_FILE_NAME,
    });

    const tsCode = await readFileContent(tsCodeStream);

    const compiledCode = transpileModule(tsCode, {
      compilerOptions: {
        module: ts.ModuleKind.ESNext,
        target: ts.ScriptTarget.ES2017,
      },
    }).outputText;

    const executorPayload = {
      params: payload,
      code: compiledCode,
    };

    const params: InvokeCommandInput = {
      FunctionName: serverlessFunction.id,
      Payload: JSON.stringify(executorPayload),
    };

    const command = new InvokeCommand(params);

    try {
      const result = await (await this.getLambdaClient()).send(command);

      const parsedResult = result.Payload
        ? JSON.parse(result.Payload.transformToString())
        : {};

      const duration = Date.now() - startTime;

      if (result.FunctionError) {
        return {
          data: null,
          duration,
          status: ServerlessFunctionExecutionStatus.ERROR,
          error: parsedResult,
        };
      }

      return {
        data: parsedResult,
        duration,
        status: ServerlessFunctionExecutionStatus.SUCCESS,
      };
    } catch (error) {
      if (error instanceof ResourceNotFoundException) {
        throw new ServerlessFunctionException(
          `Function Version '${version}' does not exist`,
          ServerlessFunctionExceptionCode.SERVERLESS_FUNCTION_NOT_FOUND,
        );
      }
      throw error;
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a LocalDriver class for executing serverless functions locally. It handles building, executing, and cleaning up serverless functions, including managing dependencies and compiling TypeScript code.
Code Snippet:
import { promises as fs } from 'fs';
import { join } from 'path';

import ts, { transpileModule } from 'typescript';
import { v4 } from 'uuid';

import {
  ServerlessDriver,
  ServerlessExecuteResult,
} from 'src/engine/core-modules/serverless/drivers/interfaces/serverless-driver.interface';

import { FileStorageService } from 'src/engine/core-modules/file-storage/file-storage.service';
import { getServerlessFolder } from 'src/engine/core-modules/serverless/utils/serverless-get-folder.utils';
import { ServerlessFunctionEntity } from 'src/engine/metadata-modules/serverless-function/serverless-function.entity';
import { COMMON_LAYER_NAME } from 'src/engine/core-modules/serverless/drivers/constants/common-layer-name';
import { copyAndBuildDependencies } from 'src/engine/core-modules/serverless/drivers/utils/copy-and-build-dependencies';
import { SERVERLESS_TMPDIR_FOLDER } from 'src/engine/core-modules/serverless/drivers/constants/serverless-tmpdir-folder';
import { INDEX_FILE_NAME } from 'src/engine/core-modules/serverless/drivers/constants/index-file-name';
import { readFileContent } from 'src/engine/core-modules/file-storage/utils/read-file-content';
import { ServerlessFunctionExecutionStatus } from 'src/engine/metadata-modules/serverless-function/dtos/serverless-function-execution-result.dto';

export interface LocalDriverOptions {
  fileStorageService: FileStorageService;
}

export class LocalDriver implements ServerlessDriver {
  private readonly fileStorageService: FileStorageService;

  constructor(options: LocalDriverOptions) {
    this.fileStorageService = options.fileStorageService;
  }

  private getInMemoryLayerFolderPath = (version: number) => {
    return join(SERVERLESS_TMPDIR_FOLDER, COMMON_LAYER_NAME, `${version}`);
  };

  private async createLayerIfNotExists(version: number) {
    const inMemoryLastVersionLayerFolderPath =
      this.getInMemoryLayerFolderPath(version);

    try {
      await fs.access(inMemoryLastVersionLayerFolderPath);
    } catch (e) {
      await copyAndBuildDependencies(inMemoryLastVersionLayerFolderPath);
    }
  }

  async delete() {}

  async build(serverlessFunction: ServerlessFunctionEntity) {
    await this.createLayerIfNotExists(serverlessFunction.layerVersion);
  }

  private async executeWithTimeout<T>(
    fn: () => Promise<T>,
    timeoutMs: number,
  ): Promise<T> {
    return new Promise<T>((resolve, reject) => {
      const timer = setTimeout(() => {
        reject(new Error(`Task timed out after ${timeoutMs / 1_000} seconds`));
      }, timeoutMs);

      fn()
        .then((result) => {
          clearTimeout(timer);
          resolve(result);
        })
        .catch((err) => {
          clearTimeout(timer);
          reject(err);
        });
    });
  }

  async execute(
    serverlessFunction: ServerlessFunctionEntity,
    payload: object,
    version: string,
  ): Promise<ServerlessExecuteResult> {
    await this.build(serverlessFunction);

    const startTime = Date.now();

    const computedVersion =
      version === 'latest' ? serverlessFunction.latestVersion : version;

    const folderPath = getServerlessFolder({
      serverlessFunction,
      version: computedVersion,
    });

    const tsCodeStream = await this.fileStorageService.read({
      folderPath: join(folderPath, 'src'),
      filename: INDEX_FILE_NAME,
    });

    const tsCode = await readFileContent(tsCodeStream);

    const compiledCode = transpileModule(tsCode, {
      compilerOptions: {
        module: ts.ModuleKind.CommonJS,
        target: ts.ScriptTarget.ES2017,
      },
    }).outputText;

    const compiledCodeFolderPath = join(
      SERVERLESS_TMPDIR_FOLDER,
      `compiled-code-${v4()}`,
    );

    const compiledCodeFilePath = join(compiledCodeFolderPath, 'main.js');

    await fs.mkdir(compiledCodeFolderPath, { recursive: true });

    await fs.writeFile(compiledCodeFilePath, compiledCode, 'utf8');

    try {
      await fs.symlink(
        join(
          this.getInMemoryLayerFolderPath(serverlessFunction.layerVersion),
          'node_modules',
        ),
        join(compiledCodeFolderPath, 'node_modules'),
        'dir',
      );
    } catch (err) {
      if (err.code !== 'EEXIST') {
        throw err;
      }
    }

    try {
      const mainFile = await import(compiledCodeFilePath);

      const result = await this.executeWithTimeout<object | null>(
        () => mainFile.main(payload),
        serverlessFunction.timeoutSeconds * 1_000,
      );

      const duration = Date.now() - startTime;

      return {
        data: result,
        duration,
        status: ServerlessFunctionExecutionStatus.SUCCESS,
      };
    } catch (error) {
      return {
        data: null,
        duration: Date.now() - startTime,
        error: {
          errorType: 'UnhandledError',
          errorMessage: error.message || 'Unknown error',
          stackTrace: error.stack ? error.stack.split('\n') : [],
        },
        status: ServerlessFunctionExecutionStatus.ERROR,
      };
    } finally {
      await fs.rm(compiledCodeFolderPath, { recursive: true, force: true });
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines an asynchronous function to copy an executor file to a specified build directory, ensuring the directory exists.
Code Snippet:
import { promises as fs } from 'fs';

import { getExecutorFilePath } from 'src/engine/core-modules/serverless/drivers/utils/get-executor-file-path';

export const copyExecutor = async (buildDirectory: string) => {
  await fs.mkdir(buildDirectory, {
    recursive: true,
  });
  await fs.cp(getExecutorFilePath(), buildDirectory, {
    recursive: true,
  });
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a function to create a zip file from a specified source directory and output path.
Code Snippet:
import fs from 'fs';
import { pipeline } from 'stream/promises';

import archiver from 'archiver';

export const createZipFile = async (
  sourceDir: string,
  outPath: string,
): Promise<void> => {
  const output = fs.createWriteStream(outPath);
  const archive = archiver('zip', {
    zlib: { level: 9 }, // Compression level
  });

  const p = pipeline(archive, output);

  archive.directory(sourceDir, false);
  archive.finalize();

  return p;
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code copies dependencies from specified directories to a build directory, runs 'yarn' to build them, and then removes all files and directories from the build directory except 'node_modules'.
Code Snippet:
import { statSync, promises as fs } from 'fs';
import { promisify } from 'util';
import { exec } from 'child_process';
import { join } from 'path';

import { getLayerDependenciesDirName } from 'src/engine/core-modules/serverless/drivers/utils/get-layer-dependencies-dir-name';

const execPromise = promisify(exec);

export const copyAndBuildDependencies = async (buildDirectory: string) => {
  await fs.mkdir(buildDirectory, {
    recursive: true,
  });

  await fs.cp(getLayerDependenciesDirName('latest'), buildDirectory, {
    recursive: true,
  });
  await fs.cp(getLayerDependenciesDirName('engine'), buildDirectory, {
    recursive: true,
  });

  try {
    await execPromise('yarn', { cwd: buildDirectory });
  } catch (error: any) {
    throw new Error(error.stdout);
  }
  const objects = await fs.readdir(buildDirectory);

  objects.forEach((object) => {
    const fullPath = join(buildDirectory, object);

    if (object === 'node_modules') return;

    if (statSync(fullPath).isDirectory()) {
      fs.rm(fullPath, { recursive: true, force: true });
    } else {
      fs.rm(fullPath);
    }
  });
};

============================================ CODE SNIPPET END ============================================


</CLUSTER_10>



=== New Entry ===

<CLUSTER_11>
Number of Code Snippets part of this cluster: 10
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code constructs an SQL query to update a remote server entity in a metadata table, handling various options and fields.
Code Snippet:
import {
  ForeignDataWrapperOptions,
  RemoteServerEntity,
  RemoteServerType,
} from 'src/engine/metadata-modules/remote-server/remote-server.entity';
import {
  RemoteServerException,
  RemoteServerExceptionCode,
} from 'src/engine/metadata-modules/remote-server/remote-server.exception';
import { UserMappingOptions } from 'src/engine/metadata-modules/remote-server/types/user-mapping-options';

export type DeepPartial<T> = {
  [P in keyof T]?: DeepPartial<T[P]>;
};

export const buildUpdateRemoteServerRawQuery = (
  remoteServerToUpdate: DeepPartial<RemoteServerEntity<RemoteServerType>> &
    Pick<RemoteServerEntity<RemoteServerType>, 'workspaceId' | 'id'>,
): [any[], string] => {
  const options: string[] = [];

  const [parameters, parametersPositions] =
    buildParametersAndPositions(remoteServerToUpdate);

  if (remoteServerToUpdate.userMappingOptions) {
    const userMappingOptionsQuery = buildJsonRawQuery(
      remoteServerToUpdate.userMappingOptions,
      parametersPositions,
      'userMappingOptions',
    );

    options.push(userMappingOptionsQuery);
  }

  if (remoteServerToUpdate.foreignDataWrapperOptions) {
    const foreignDataWrapperOptionsQuery = buildJsonRawQuery(
      remoteServerToUpdate.foreignDataWrapperOptions,
      parametersPositions,
      'foreignDataWrapperOptions',
    );

    options.push(foreignDataWrapperOptionsQuery);
  }

  if (remoteServerToUpdate.schema) {
    options.push(`"schema" = $${parametersPositions['schema']}`);
  }

  if (remoteServerToUpdate.label) {
    options.push(`"label" = $${parametersPositions['label']}`);
  }

  if (options.length < 1) {
    throw new RemoteServerException(
      'No fields to update',
      RemoteServerExceptionCode.INVALID_REMOTE_SERVER_INPUT,
    );
  }

  const rawQuery = `UPDATE metadata."remoteServer" SET ${options.join(
    ', ',
  )} WHERE "id"= $1 RETURNING *`;

  return [parameters, rawQuery];
};

const buildParametersAndPositions = (
  remoteServerToUpdate: DeepPartial<RemoteServerEntity<RemoteServerType>> &
    Pick<RemoteServerEntity<RemoteServerType>, 'workspaceId' | 'id'>,
): [any[], object] => {
  const parameters: any[] = [remoteServerToUpdate.id];
  const parametersPositions = {};

  if (remoteServerToUpdate.userMappingOptions) {
    Object.entries(remoteServerToUpdate.userMappingOptions).forEach(
      ([key, value]) => {
        parameters.push(value);
        parametersPositions[key] = parameters.length;
      },
    );
  }

  if (remoteServerToUpdate.foreignDataWrapperOptions) {
    Object.entries(remoteServerToUpdate.foreignDataWrapperOptions).forEach(
      ([key, value]) => {
        parameters.push(value);
        parametersPositions[key] = parameters.length;
      },
    );
  }

  if (remoteServerToUpdate.schema) {
    parameters.push(remoteServerToUpdate.schema);
    parametersPositions['schema'] = parameters.length;
  }

  if (remoteServerToUpdate.label) {
    parameters.push(remoteServerToUpdate.label);
    parametersPositions['label'] = parameters.length;
  }

  return [parameters, parametersPositions];
};

const buildJsonRawQuery = (
  options:
    | Partial<UserMappingOptions>
    | Partial<ForeignDataWrapperOptions<RemoteServerType>>,
  parametersPositions: object,
  objectName: string,
): string => {
  const buildJsonSet = (
    opts:
      | Partial<UserMappingOptions>
      | Partial<ForeignDataWrapperOptions<RemoteServerType>>,
  ): string => {
    const [[firstKey, _], ...followingOptions] = Object.entries(opts);

    let query = `jsonb_set("${objectName}", '{${firstKey}}', to_jsonb($${parametersPositions[firstKey]}::text))`;

    followingOptions.forEach(([key, _]) => {
      query = `jsonb_set(${query}, '{${key}}', to_jsonb($${parametersPositions[key]}::text))`;
    });

    return query;
  };

  return `"${objectName}" = ${buildJsonSet(options)}`;
};

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for managing foreign tables in a workspace, including fetching, creating, updating, and deleting foreign tables.
Code Snippet:
import { Injectable } from '@nestjs/common';

import {
  RemoteServerEntity,
  RemoteServerType,
} from 'src/engine/metadata-modules/remote-server/remote-server.entity';
import { RemoteTableStatus } from 'src/engine/metadata-modules/remote-server/remote-table/dtos/remote-table.dto';
import {
  ForeignTableException,
  ForeignTableExceptionCode,
} from 'src/engine/metadata-modules/remote-server/remote-table/foreign-table/foreign-table.exception';
import { getForeignTableColumnName } from 'src/engine/metadata-modules/remote-server/remote-table/foreign-table/utils/get-foreign-table-column-name.util';
import { PostgresTableSchemaColumn } from 'src/engine/metadata-modules/remote-server/types/postgres-table-schema-column';
import { WorkspaceMetadataVersionService } from 'src/engine/metadata-modules/workspace-metadata-version/services/workspace-metadata-version.service';
import { generateMigrationName } from 'src/engine/metadata-modules/workspace-migration/utils/generate-migration-name.util';
import {
  ReferencedTable,
  WorkspaceMigrationColumnAction,
  WorkspaceMigrationForeignColumnDefinition,
  WorkspaceMigrationForeignTable,
  WorkspaceMigrationTableActionType,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceMigrationService } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.service';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';
import { WorkspaceMigrationRunnerService } from 'src/engine/workspace-manager/workspace-migration-runner/workspace-migration-runner.service';

@Injectable()
export class ForeignTableService {
  constructor(
    private readonly workspaceMigrationService: WorkspaceMigrationService,
    private readonly workspaceMigrationRunnerService: WorkspaceMigrationRunnerService,
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
    private readonly workspaceMetadataVersionService: WorkspaceMetadataVersionService,
  ) {}

  public async fetchForeignTableNamesWithinWorkspace(
    workspaceId: string,
    foreignDataWrapperId: string,
  ): Promise<string[]> {
    const workspaceDataSource =
      await this.workspaceDataSourceService.connectToWorkspaceDataSource(
        workspaceId,
      );

    return (
      await workspaceDataSource.query(
        `SELECT foreign_table_name, foreign_server_name FROM information_schema.foreign_tables WHERE foreign_server_name = $1`,
        [foreignDataWrapperId],
      )
    ).map((foreignTable) => foreignTable.foreign_table_name);
  }

  public async createForeignTable(
    workspaceId: string,
    localTableName: string,
    remoteServer: RemoteServerEntity<RemoteServerType>,
    distantTableName: string,
    distantTableColumns: PostgresTableSchemaColumn[],
  ) {
    const referencedTable: ReferencedTable = this.buildReferencedTable(
      remoteServer,
      distantTableName,
    );

    const workspaceMigration =
      await this.workspaceMigrationService.createCustomMigration(
        generateMigrationName(`create-foreign-table-${localTableName}`),
        workspaceId,
        [
          {
            name: localTableName,
            action: WorkspaceMigrationTableActionType.CREATE_FOREIGN_TABLE,
            foreignTable: {
              columns: distantTableColumns.map(
                (column) =>
                  ({
                    columnName: getForeignTableColumnName(column.columnName),
                    columnType: column.dataType,
                    distantColumnName: column.columnName,
                    isNullable: false,
                    defaultValue: null,
                  }) satisfies WorkspaceMigrationForeignColumnDefinition,
              ),
              referencedTable,
              foreignDataWrapperId: remoteServer.foreignDataWrapperId,
            } satisfies WorkspaceMigrationForeignTable,
          },
        ],
      );

    // TODO: This should be done in a transaction. Waiting for a global refactoring of transaction management.
    try {
      await this.workspaceMigrationRunnerService.executeMigrationFromPendingMigrations(
        workspaceId,
      );
    } catch (exception) {
      this.workspaceMigrationService.deleteById(workspaceMigration.id);

      throw new ForeignTableException(
        'Could not create foreign table. The table may already exists or a column type may not be supported.',
        ForeignTableExceptionCode.INVALID_FOREIGN_TABLE_INPUT,
      );
    }
  }

  public async updateForeignTable(
    foreignTableName: string,
    workspaceId: string,
    columnsUpdates: WorkspaceMigrationColumnAction[],
  ) {
    const workspaceMigration =
      await this.workspaceMigrationService.createCustomMigration(
        generateMigrationName(`alter-foreign-table-${foreignTableName}`),
        workspaceId,
        [
          {
            name: foreignTableName,
            action: WorkspaceMigrationTableActionType.ALTER_FOREIGN_TABLE,
            columns: columnsUpdates,
          },
        ],
      );

    // TODO: This should be done in a transaction. Waiting for a global refactoring of transaction management.
    try {
      await this.workspaceMigrationRunnerService.executeMigrationFromPendingMigrations(
        workspaceId,
      );

      await this.workspaceMetadataVersionService.incrementMetadataVersion(
        workspaceId,
      );

      return {
        name: foreignTableName,
        status: RemoteTableStatus.SYNCED,
        schemaPendingUpdates: [],
      };
    } catch (exception) {
      this.workspaceMigrationService.deleteById(workspaceMigration.id);

      throw new ForeignTableException(
        'Could not alter foreign table.',
        ForeignTableExceptionCode.FOREIGN_TABLE_MUTATION_NOT_ALLOWED,
      );
    }
  }

  public async deleteForeignTable(
    foreignTableName: string,
    workspaceId: string,
  ) {
    await this.workspaceMigrationService.createCustomMigration(
      generateMigrationName(`drop-foreign-table-${foreignTableName}`),
      workspaceId,
      [
        {
          name: foreignTableName,
          action: WorkspaceMigrationTableActionType.DROP_FOREIGN_TABLE,
        },
      ],
    );

    return this.workspaceMigrationRunnerService.executeMigrationFromPendingMigrations(
      workspaceId,
    );
  }

  private buildReferencedTable(
    remoteServer: RemoteServerEntity<RemoteServerType>,
    distantTableName: string,
  ): ReferencedTable {
    switch (remoteServer.foreignDataWrapperType) {
      case RemoteServerType.POSTGRES_FDW:
        return {
          table_name: distantTableName,
          schema_name: remoteServer.schema,
        };
      case RemoteServerType.STRIPE_FDW:
        return { object: distantTableName };
      default:
        throw new ForeignTableException(
          'Foreign data wrapper not supported',
          ForeignTableExceptionCode.INVALID_FOREIGN_TABLE_INPUT,
        );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code generates migration actions to create foreign key relationships in remote tables.
Code Snippet:
import { computeColumnName } from 'src/engine/metadata-modules/field-metadata/utils/compute-column-name.util';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import {
  WorkspaceMigrationColumnActionType,
  WorkspaceMigrationColumnCreate,
  WorkspaceMigrationTableAction,
  WorkspaceMigrationTableActionType,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { computeObjectTargetTable } from 'src/engine/utils/compute-object-target-table.util';

export const buildMigrationsToCreateRemoteTableRelations = (
  createdObjectNameSingular: string,
  targetObjectMetadataList: ObjectMetadataEntity[],
  primaryKeyColumnType: string,
): WorkspaceMigrationTableAction[] =>
  targetObjectMetadataList.map((targetObjectMetadata) => ({
    name: computeObjectTargetTable(targetObjectMetadata),
    action: WorkspaceMigrationTableActionType.ALTER,
    columns: [
      {
        action: WorkspaceMigrationColumnActionType.CREATE,
        columnName: computeColumnName(createdObjectNameSingular, {
          isForeignKey: true,
        }),
        columnType: primaryKeyColumnType,
        isNullable: true,
        defaultValue: null,
      } satisfies WorkspaceMigrationColumnCreate,
    ],
  }));

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for executing workspace migrations, including creating, altering, and dropping tables, columns, indexes, and foreign tables in a database.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { isDefined } from 'class-validator';
import {
  QueryRunner,
  Table,
  TableColumn,
  TableForeignKey,
  TableIndex,
  TableUnique,
} from 'typeorm';

import { IndexType } from 'src/engine/metadata-modules/index-metadata/index-metadata.entity';
import {
  WorkspaceMigrationColumnAction,
  WorkspaceMigrationColumnActionType,
  WorkspaceMigrationColumnAlter,
  WorkspaceMigrationColumnCreate,
  WorkspaceMigrationColumnCreateRelation,
  WorkspaceMigrationColumnDrop,
  WorkspaceMigrationColumnDropRelation,
  WorkspaceMigrationForeignTable,
  WorkspaceMigrationIndexAction,
  WorkspaceMigrationIndexActionType,
  WorkspaceMigrationTableAction,
  WorkspaceMigrationTableActionType,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceMigrationService } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.service';
import { WorkspaceDataSourceService } from 'src/engine/workspace-datasource/workspace-datasource.service';
import { WorkspaceMigrationEnumService } from 'src/engine/workspace-manager/workspace-migration-runner/services/workspace-migration-enum.service';
import { convertOnDeleteActionToOnDelete } from 'src/engine/workspace-manager/workspace-migration-runner/utils/convert-on-delete-action-to-on-delete.util';
import { tableDefaultColumns } from 'src/engine/workspace-manager/workspace-migration-runner/utils/table-default-column.util';

import { WorkspaceMigrationTypeService } from './services/workspace-migration-type.service';

@Injectable()
export class WorkspaceMigrationRunnerService {
  private readonly logger = new Logger(WorkspaceMigrationRunnerService.name);

  constructor(
    private readonly workspaceDataSourceService: WorkspaceDataSourceService,
    private readonly workspaceMigrationService: WorkspaceMigrationService,
    private readonly workspaceMigrationEnumService: WorkspaceMigrationEnumService,
    private readonly workspaceMigrationTypeService: WorkspaceMigrationTypeService,
  ) {}

  /**
   * Executes pending migrations for a given workspace
   *
   * @param workspaceId string
   * @returns Promise<WorkspaceMigrationTableAction[]>
   */
  public async executeMigrationFromPendingMigrations(
    workspaceId: string,
  ): Promise<WorkspaceMigrationTableAction[]> {
    const workspaceDataSource =
      await this.workspaceDataSourceService.connectToWorkspaceDataSource(
        workspaceId,
      );

    if (!workspaceDataSource) {
      throw new Error('Workspace data source not found');
    }

    const pendingMigrations =
      await this.workspaceMigrationService.getPendingMigrations(workspaceId);

    if (pendingMigrations.length === 0) {
      return [];
    }

    const flattenedPendingMigrations: WorkspaceMigrationTableAction[] =
      pendingMigrations.reduce((acc, pendingMigration) => {
        return [...acc, ...pendingMigration.migrations];
      }, []);

    const queryRunner = workspaceDataSource?.createQueryRunner();

    await queryRunner.connect();
    await queryRunner.startTransaction();

    const schemaName =
      this.workspaceDataSourceService.getSchemaName(workspaceId);

    await queryRunner.query(`SET LOCAL search_path TO ${schemaName}`);

    try {
      // Loop over each migration and create or update the table
      for (const migration of flattenedPendingMigrations) {
        await this.handleTableChanges(queryRunner, schemaName, migration);
      }

      await queryRunner.commitTransaction();
    } catch (error) {
      this.logger.error(
        `Error executing migration: ${error.message}`,
        error.stack,
      );

      await queryRunner.rollbackTransaction();
      throw error;
    } finally {
      await queryRunner.release();
    }

    // Update appliedAt date for each migration
    // TODO: Should be done after the migration is successful
    for (const pendingMigration of pendingMigrations) {
      await this.workspaceMigrationService.setAppliedAtForMigration(
        workspaceId,
        pendingMigration,
      );
    }

    return flattenedPendingMigrations;
  }

  /**
   * Handles table changes for a given migration
   *
   * @param queryRunner QueryRunner
   * @param schemaName string
   * @param tableMigration WorkspaceMigrationTableAction
   */
  private async handleTableChanges(
    queryRunner: QueryRunner,
    schemaName: string,
    tableMigration: WorkspaceMigrationTableAction,
  ) {
    switch (tableMigration.action) {
      case WorkspaceMigrationTableActionType.CREATE:
        await this.createTable(
          queryRunner,
          schemaName,
          tableMigration.name,
          tableMigration.columns,
        );
        break;
      case WorkspaceMigrationTableActionType.ALTER: {
        if (tableMigration.newName) {
          await this.renameTable(
            queryRunner,
            schemaName,
            tableMigration.name,
            tableMigration.newName,
          );

          break;
        }

        if (tableMigration.columns && tableMigration.columns.length > 0) {
          await this.handleColumnChanges(
            queryRunner,
            schemaName,
            tableMigration.newName ?? tableMigration.name,
            tableMigration.columns,
          );

          break;
        }

        break;
      }
      case WorkspaceMigrationTableActionType.DROP:
        await queryRunner.dropTable(`${schemaName}.${tableMigration.name}`);
        break;
      case 'create_foreign_table':
        await this.createForeignTable(
          queryRunner,
          schemaName,
          tableMigration.name,
          tableMigration?.foreignTable,
        );
        break;
      case 'drop_foreign_table':
        await queryRunner.query(
          `DROP FOREIGN TABLE ${schemaName}."${tableMigration.name}"`,
        );
        break;
      case WorkspaceMigrationTableActionType.ALTER_FOREIGN_TABLE:
        await this.alterForeignTable(
          queryRunner,
          schemaName,
          tableMigration.name,
          tableMigration.columns,
        );
        break;

      case WorkspaceMigrationTableActionType.ALTER_INDEXES:
        if (tableMigration.indexes && tableMigration.indexes.length > 0) {
          await this.handleIndexesChanges(
            queryRunner,
            schemaName,
            tableMigration.newName ?? tableMigration.name,
            tableMigration.indexes,
          );
        }
        break;
      default:
        throw new Error(
          `Migration table action ${tableMigration.action} not supported`,
        );
    }
  }

  /**
   * Handles index changes for a given table
   *
   * @param queryRunner QueryRunner
   * @param schemaName string
   * @param tableName string
   * @param indexes WorkspaceMigrationIndexAction[]
   */
  private async handleIndexesChanges(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    indexes: WorkspaceMigrationIndexAction[],
  ) {
    for (const index of indexes) {
      switch (index.action) {
        case WorkspaceMigrationIndexActionType.CREATE:
          await this.createIndex(queryRunner, schemaName, tableName, index);
          break;
        case WorkspaceMigrationIndexActionType.DROP:
          await this.dropIndex(queryRunner, schemaName, tableName, index.name);
          break;
        default:
          throw new Error(`Migration index action not supported`);
      }
    }
  }

  /**
   * Creates an index on a table
   *
   * @param queryRunner QueryRunner
   * @param schemaName string
   * @param tableName string
   * @param index WorkspaceMigrationIndexAction
   */
  private async createIndex(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    index: WorkspaceMigrationIndexAction,
  ) {
    try {
      if (isDefined(index.type) && index.type !== IndexType.BTREE) {
        const quotedColumns = index.columns.map((column) => `"${column}"`);

        await queryRunner.query(`
          CREATE INDEX "${index.name}" ON "${schemaName}"."${tableName}" USING ${index.type} (${quotedColumns.join(', ')})
        `);
      } else {
        await queryRunner.createIndex(
          `${schemaName}.${tableName}`,
          new TableIndex({
            name: index.name,
            columnNames: index.columns,
            isUnique: index.isUnique,
            where: index.where ?? undefined,
          }),
        );
      }
    } catch (error) {
      // Ignore error if index already exists
      if (error.code === '42P07') {
        return;
      }
      throw error;
    }
  }

  /**
   * Drops an index from a table
   *
   * @param queryRunner QueryRunner
   * @param schemaName string
   * @param tableName string
   * @param indexName string
   */
  private async dropIndex(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    indexName: string,
  ) {
    try {
      await queryRunner.dropIndex(`${schemaName}.${tableName}`, indexName);
    } catch (error) {
      // Ignore error if index does not exist
      if (
        error.message ===
        `Supplied index ${indexName} was not found in table ${schemaName}.${tableName}`
      ) {
        return;
      }
      throw error;
    }
  }

  /**
   * Creates a table with columns from migration
   *
   * @param queryRunner QueryRunner
   * @param schemaName string
   * @param tableName string
   * @param columns WorkspaceMigrationColumnAction[]
   */
  private async createTable(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    columns?: WorkspaceMigrationColumnAction[],
  ) {
    const tableColumns: TableColumn[] = [];

    if (columns && columns.length > 0) {
      const createColumns = columns.filter(
        (column) => column.action === WorkspaceMigrationColumnActionType.CREATE,
      ) as WorkspaceMigrationColumnCreate[];

      for (const column of createColumns) {
        tableColumns.push(
          this.createTableColumnFromMigration(tableName, column),
        );
      }
    }

    await queryRunner.createTable(
      new Table({
        name: tableName,
        schema: schemaName,
        columns: tableColumns.length > 0 ? tableColumns : tableDefaultColumns(),
      }),
      true,
    );

    if (columns && columns.length > 0) {
      const nonCreateColumns = columns.filter(
        (column) => column.action !== WorkspaceMigrationColumnActionType.CREATE,
      );

      if (nonCreateColumns.length > 0) {
        await this.handleColumnChanges(
          queryRunner,
          schemaName,
          tableName,
          nonCreateColumns,
        );
      }
    }
  }

  /**
   * Creates a TableColumn object from a migration column
   *
   * @param tableName string
   * @param column WorkspaceMigrationColumnCreate
   * @returns TableColumn
   */
  private createTableColumnFromMigration(
    tableName: string,
    column: WorkspaceMigrationColumnCreate,
  ): TableColumn {
    const enumName = column.enum?.length
      ? `${tableName}_${column.columnName}_enum`
      : undefined;

    return new TableColumn({
      name: column.columnName,
      type: column.columnType,
      default: column.defaultValue,
      isPrimary: column.columnName === 'id',
      enum: column.enum?.filter(
        (value): value is string => typeof value === 'string',
      ),
      enumName: enumName,
      isArray: column.isArray,
      isNullable: column.isNullable,
      asExpression: column.asExpression,
      generatedType: column.generatedType,
    });
  }

  /**
   * Rename a table
   * @param queryRunner QueryRunner
   * @param schemaName string
   * @param oldTableName string
   * @param newTableName string
   */
  private async renameTable(
    queryRunner: QueryRunner,
    schemaName: string,
    oldTableName: string,
    newTableName: string,
  ) {
    await queryRunner.renameTable(
      `${schemaName}.${oldTableName}`,
      newTableName,
    );
  }

  /**
   * Handles column changes for a given migration
   *
   * @param queryRunner QueryRunner
   * @param schemaName string
   * @param tableName string
   * @param columnMigrations WorkspaceMigrationColumnAction[]
   */
  private async handleColumnChanges(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    columnMigrations?: WorkspaceMigrationColumnAction[],
  ) {
    if (!columnMigrations || columnMigrations.length === 0) {
      return;
    }

    const columnsByAction = this.groupColumnsByAction(columnMigrations);

    if (columnsByAction.create.length > 0) {
      await this.handleCreateColumns(
        queryRunner,
        schemaName,
        tableName,
        columnsByAction.create,
      );
    }

    if (columnsByAction.drop.length > 0) {
      await this.handleDropColumns(
        queryRunner,
        schemaName,
        tableName,
        columnsByAction.drop,
      );
    }

    await this.handleOtherColumnActions(
      queryRunner,
      schemaName,
      tableName,
      columnsByAction.alter,
      columnsByAction.createForeignKey,
      columnsByAction.dropForeignKey,
      columnsByAction.createComment,
    );
  }

  private groupColumnsByAction(
    columnMigrations: WorkspaceMigrationColumnAction[],
  ) {
    return columnMigrations.reduce(
      (acc, column) => {
        switch (column.action) {
          case WorkspaceMigrationColumnActionType.CREATE:
            acc.create.push(column as WorkspaceMigrationColumnCreate);
            break;
          case WorkspaceMigrationColumnActionType.ALTER:
            acc.alter.push(column as WorkspaceMigrationColumnAlter);
            break;
          case WorkspaceMigrationColumnActionType.CREATE_FOREIGN_KEY:
            acc.createForeignKey.push(
              column as WorkspaceMigrationColumnCreateRelation,
            );
            break;
          case WorkspaceMigrationColumnActionType.DROP_FOREIGN_KEY:
            acc.dropForeignKey.push(
              column as WorkspaceMigrationColumnDropRelation,
            );
            break;
          case WorkspaceMigrationColumnActionType.DROP:
            acc.drop.push(column as WorkspaceMigrationColumnDrop);
            break;
          case WorkspaceMigrationColumnActionType.CREATE_COMMENT:
            acc.createComment.push(
              column as {
                action: WorkspaceMigrationColumnActionType.CREATE_COMMENT;
                comment: string;
              },
            );
            break;
        }

        return acc;
      },
      {
        create: [] as WorkspaceMigrationColumnCreate[],
        alter: [] as WorkspaceMigrationColumnAlter[],
        createForeignKey: [] as WorkspaceMigrationColumnCreateRelation[],
        dropForeignKey: [] as WorkspaceMigrationColumnDropRelation[],
        drop: [] as WorkspaceMigrationColumnDrop[],
        createComment: [] as {
          action: WorkspaceMigrationColumnActionType.CREATE_COMMENT;
          comment: string;
        }[],
      },
    );
  }

  private async handleCreateColumns(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    createColumns: WorkspaceMigrationColumnCreate[],
  ) {
    if (createColumns.length === 0) return;

    const table = await queryRunner.getTable(`${schemaName}.${tableName}`);

    if (!table) {
      throw new Error(`Table "${tableName}" not found`);
    }

    const existingColumns = new Set(table.columns.map((column) => column.name));

    const columnsToCreate = createColumns.filter(
      (column) => !existingColumns.has(column.columnName),
    );

    if (columnsToCreate.length === 0) return;

    const tableColumns = columnsToCreate.map((column) =>
      this.createTableColumnFromMigration(tableName, column),
    );

    await queryRunner.addColumns(`${schemaName}.${tableName}`, tableColumns);
  }

  private async handleDropColumns(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    dropColumns: WorkspaceMigrationColumnDrop[],
  ) {
    if (dropColumns.length === 0) return;

    const columnNames = dropColumns.map((column) => column.columnName);

    await queryRunner.dropColumns(`${schemaName}.${tableName}`, columnNames);
  }

  private async handleOtherColumnActions(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    alterColumns: WorkspaceMigrationColumnAlter[],
    createForeignKeyColumns: WorkspaceMigrationColumnCreateRelation[],
    dropForeignKeyColumns: WorkspaceMigrationColumnDropRelation[],
    createCommentColumns: {
      action: WorkspaceMigrationColumnActionType.CREATE_COMMENT;
      comment: string;
    }[],
  ) {
    for (const column of alterColumns) {
      await this.alterColumn(queryRunner, schemaName, tableName, column);
    }

    for (const column of createForeignKeyColumns) {
      await this.createRelation(queryRunner, schemaName, tableName, column);
    }

    for (const column of dropForeignKeyColumns) {
      await this.dropRelation(queryRunner, schemaName, tableName, column);
    }

    for (const column of createCommentColumns) {
      await this.createComment(
        queryRunner,
        schemaName,
        tableName,
        column.comment,
      );
    }
  }

  private async alterColumn(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    migrationColumn: WorkspaceMigrationColumnAlter,
  ) {
    const enumValues = migrationColumn.alteredColumnDefinition.enum;

    // TODO: Maybe we can do something better if we can recreate the old `TableColumn` object
    if (enumValues) {
      // This is returning the old enum values to avoid TypeORM dropping the enum type
      await this.workspaceMigrationEnumService.alterEnum(
        queryRunner,
        schemaName,
        tableName,
        migrationColumn,
      );

      return;
    }

    if (
      migrationColumn.currentColumnDefinition.columnType !==
      migrationColumn.alteredColumnDefinition.columnType
    ) {
      await this.workspaceMigrationTypeService.alterType(
        queryRunner,
        schemaName,
        tableName,
        migrationColumn,
      );

      migrationColumn.currentColumnDefinition.columnType =
        migrationColumn.alteredColumnDefinition.columnType;

      return;
    }

    await queryRunner.changeColumn(
      `${schemaName}.${tableName}`,
      new TableColumn({
        name: migrationColumn.currentColumnDefinition.columnName,
        type: migrationColumn.currentColumnDefinition.columnType,
        default: migrationColumn.currentColumnDefinition.defaultValue,
        enum: migrationColumn.currentColumnDefinition.enum?.filter(
          (value): value is string => typeof value === 'string',
        ),
        isArray: migrationColumn.currentColumnDefinition.isArray,
        isNullable: migrationColumn.currentColumnDefinition.isNullable,
        /* For now unique constraints are created at a higher level
        as we need to handle soft-delete and a bug on empty strings
        */
        // isUnique: migrationColumn.currentColumnDefinition.isUnique,
      }),
      new TableColumn({
        name: migrationColumn.alteredColumnDefinition.columnName,
        type: migrationColumn.alteredColumnDefinition.columnType,
        default: migrationColumn.alteredColumnDefinition.defaultValue,
        enum: migrationColumn.currentColumnDefinition.enum?.filter(
          (value): value is string => typeof value === 'string',
        ),
        isArray: migrationColumn.alteredColumnDefinition.isArray,
        isNullable: migrationColumn.alteredColumnDefinition.isNullable,
        asExpression: migrationColumn.alteredColumnDefinition.asExpression,
        generatedType: migrationColumn.alteredColumnDefinition.generatedType,
        /* For now unique constraints are created at a higher level
        as we need to handle soft-delete and a bug on empty strings
        */
        // isUnique: migrationColumn.alteredColumnDefinition.isUnique,
      }),
    );
  }

  private async createRelation(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    migrationColumn: WorkspaceMigrationColumnCreateRelation,
  ) {
    await queryRunner.createForeignKey(
      `${schemaName}.${tableName}`,
      new TableForeignKey({
        columnNames: [migrationColumn.columnName],
        referencedColumnNames: [migrationColumn.referencedTableColumnName],
        referencedTableName: migrationColumn.referencedTableName,
        referencedSchema: schemaName,
        onDelete: convertOnDeleteActionToOnDelete(migrationColumn.onDelete),
      }),
    );

    // Create unique constraint if for one to one relation
    if (migrationColumn.isUnique) {
      await queryRunner.createUniqueConstraint(
        `${schemaName}.${tableName}`,
        new TableUnique({
          name: `UNIQUE_${tableName}_${migrationColumn.columnName}`,
          columnNames: [migrationColumn.columnName],
        }),
      );
    }
  }

  private async dropRelation(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    migrationColumn: WorkspaceMigrationColumnDropRelation,
  ) {
    const foreignKeyName = await this.getForeignKeyName(
      queryRunner,
      schemaName,
      tableName,
      migrationColumn.columnName,
    );

    if (!foreignKeyName) {
      // Todo: Remove this temporary hack tied to 0.32 upgrade
      if (migrationColumn.columnName === 'activityId') {
        return;
      }
      throw new Error(
        `Foreign key not found for column ${migrationColumn.columnName}`,
      );
    }

    await queryRunner.dropForeignKey(
      `${schemaName}.${tableName}`,
      foreignKeyName,
    );
  }

  private async getForeignKeyName(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    columnName: string,
  ): Promise<string | undefined> {
    const foreignKeys = await queryRunner.query(
      `
      SELECT
        tc.constraint_name AS constraint_name
      FROM
        information_schema.table_constraints AS tc
      JOIN
        information_schema.key_column_usage AS kcu
        ON tc.constraint_name = kcu.constraint_name
        AND tc.table_schema = kcu.table_schema
      WHERE
        tc.constraint_type = 'FOREIGN KEY'
        AND tc.table_schema = $1
        AND tc.table_name = $2
        AND kcu.column_name = $3
    `,
      [schemaName, tableName, columnName],
    );

    return foreignKeys[0]?.constraint_name;
  }

  private async createComment(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    comment: string,
  ) {
    await queryRunner.query(`
      COMMENT ON TABLE "${schemaName}"."${tableName}" IS e'${comment}';
    `);
  }

  private async createForeignTable(
    queryRunner: QueryRunner,
    schemaName: string,
    name: string,
    foreignTable: WorkspaceMigrationForeignTable | undefined,
  ) {
    if (!foreignTable) {
      return;
    }

    const foreignTableColumns = foreignTable.columns
      .map(
        (column) =>
          `"${column.columnName}" ${column.columnType} OPTIONS (column_name '${column.distantColumnName}')`,
      )
      .join(', ');

    const serverOptions = Object.entries(foreignTable.referencedTable)
      .map(([key, value]) => `${key} '${value}'`)
      .join(', ');

    await queryRunner.query(
      `CREATE FOREIGN TABLE ${schemaName}."${name}" (${foreignTableColumns}) SERVER "${foreignTable.foreignDataWrapperId}" OPTIONS (${serverOptions})`,
    );

    await queryRunner.query(`
      COMMENT ON FOREIGN TABLE "${schemaName}"."${name}" IS '@graphql({"primary_key_columns": ["id"], "totalCount": {"enabled": true}})';
    `);
  }

  private async alterForeignTable(
    queryRunner: QueryRunner,
    schemaName: string,
    name: string,
    columns: WorkspaceMigrationColumnAction[] | undefined,
  ) {
    const columnUpdatesQuery = columns
      ?.map((column) => {
        switch (column.action) {
          case WorkspaceMigrationColumnActionType.DROP:
            return `DROP COLUMN "${column.columnName}"`;
          case WorkspaceMigrationColumnActionType.CREATE:
            return `ADD COLUMN "${column.columnName}" ${column.columnType}`;
          default:
            return '';
        }
      })
      .filter(Boolean)
      .join(', ');

    await queryRunner.query(
      `ALTER FOREIGN TABLE ${schemaName}."${name}" ${columnUpdatesQuery};`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for altering enum columns in a database schema, including renaming columns, migrating enum values, and handling exceptions.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { isDefined } from 'class-validator';
import { QueryRunner, TableColumn } from 'typeorm';
import { v4 } from 'uuid';

import { serializeDefaultValue } from 'src/engine/metadata-modules/field-metadata/utils/serialize-default-value';
import { unserializeDefaultValue } from 'src/engine/metadata-modules/field-metadata/utils/unserialize-default-value';
import {
  WorkspaceMigrationColumnAlter,
  WorkspaceMigrationRenamedEnum,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import {
  WorkspaceMigrationException,
  WorkspaceMigrationExceptionCode,
} from 'src/engine/metadata-modules/workspace-migration/workspace-migration.exception';

@Injectable()
export class WorkspaceMigrationEnumService {
  async alterEnum(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    migrationColumn: WorkspaceMigrationColumnAlter,
  ) {
    const oldEnumTypeName = await this.getEnumTypeName(
      queryRunner,
      schemaName,
      tableName,
      migrationColumn.currentColumnDefinition.columnName,
    );

    // Rename column name
    if (
      migrationColumn.currentColumnDefinition.columnName !==
      migrationColumn.alteredColumnDefinition.columnName
    ) {
      await this.renameColumn(
        queryRunner,
        schemaName,
        tableName,
        migrationColumn.currentColumnDefinition.columnName,
        migrationColumn.alteredColumnDefinition.columnName,
      );
    }

    const columnDefinition = migrationColumn.alteredColumnDefinition;
    const tempEnumTypeName = `${oldEnumTypeName}_temp`;
    const newEnumTypeName = `${tableName}_${columnDefinition.columnName}_enum`;
    const enumValues =
      columnDefinition.enum?.map((enumValue) => {
        if (typeof enumValue === 'string') {
          return enumValue;
        }

        return enumValue.to;
      }) ?? [];
    const renamedEnumValues = columnDefinition.enum?.filter(
      (enumValue): enumValue is WorkspaceMigrationRenamedEnum =>
        typeof enumValue !== 'string',
    );

    const oldColumnName = `old_${v4()}`;

    // Rename old column
    await this.renameColumn(
      queryRunner,
      schemaName,
      tableName,
      columnDefinition.columnName,
      oldColumnName,
    );
    await this.renameEnumType(
      queryRunner,
      schemaName,
      oldEnumTypeName,
      tempEnumTypeName,
    );

    await queryRunner.addColumn(
      `${schemaName}.${tableName}`,
      new TableColumn({
        name: columnDefinition.columnName,
        type: columnDefinition.columnType,
        default: columnDefinition.defaultValue,
        enum: enumValues,
        enumName: newEnumTypeName,
        isArray: columnDefinition.isArray,
        isNullable: columnDefinition.isNullable,
        isUnique: columnDefinition.isUnique,
      }),
    );

    await this.migrateEnumValues(
      queryRunner,
      schemaName,
      migrationColumn,
      tableName,
      oldColumnName,
      enumValues,
      renamedEnumValues,
    );

    // Drop old column
    await queryRunner.query(`
      ALTER TABLE "${schemaName}"."${tableName}"
      DROP COLUMN "${oldColumnName}"
    `);
    // Drop temp enum type
    await this.dropOldEnumType(queryRunner, schemaName, tempEnumTypeName);
  }

  private async renameColumn(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    oldColumnName: string,
    newColumnName: string,
  ) {
    await queryRunner.query(`
      ALTER TABLE "${schemaName}"."${tableName}"
      RENAME COLUMN "${oldColumnName}" TO "${newColumnName}"
    `);
  }

  private migrateEnumValue({
    value,
    renamedEnumValues,
    allEnumValues,
    defaultValueFallback,
  }: {
    value: string;
    renamedEnumValues?: WorkspaceMigrationRenamedEnum[];
    allEnumValues?: string[];
    defaultValueFallback?: string;
  }) {
    if (renamedEnumValues?.find((enumVal) => enumVal?.from === value)?.to) {
      return renamedEnumValues?.find((enumVal) => enumVal?.from === value)?.to;
    }

    if (allEnumValues?.includes(value)) {
      return value;
    }

    if (isDefined(defaultValueFallback)) {
      return defaultValueFallback;
    }

    return null;
  }

  private async migrateEnumValues(
    queryRunner: QueryRunner,
    schemaName: string,
    migrationColumn: WorkspaceMigrationColumnAlter,
    tableName: string,
    oldColumnName: string,
    enumValues: string[],
    renamedEnumValues?: WorkspaceMigrationRenamedEnum[],
  ) {
    const columnDefinition = migrationColumn.alteredColumnDefinition;

    const values = await queryRunner.query(
      `SELECT id, "${oldColumnName}" FROM "${schemaName}"."${tableName}"`,
    );

    for (const value of values) {
      let val = value[oldColumnName];

      if (/^\{.*\}$/.test(val)) {
        val = serializeDefaultValue(
          val
            .slice(1, -1)
            .split(',')
            .map((v: string) => v.trim())
            .map((v: string) =>
              this.migrateEnumValue({
                value: v,
                renamedEnumValues: renamedEnumValues,
                allEnumValues: enumValues,
              }),
            )
            .filter((v: string | null) => isDefined(v)),
        );
      } else if (typeof val === 'string') {
        const migratedValue = this.migrateEnumValue({
          value: val,
          renamedEnumValues: renamedEnumValues,
          allEnumValues: enumValues,
          defaultValueFallback: columnDefinition.isNullable
            ? null
            : unserializeDefaultValue(columnDefinition.defaultValue),
        });

        val = isDefined(migratedValue) ? `'${migratedValue}'` : null;
      }

      await queryRunner.query(`
        UPDATE "${schemaName}"."${tableName}"
        SET "${columnDefinition.columnName}" = ${val}
        WHERE id='${value.id}'
      `);
    }
  }

  private async dropOldEnumType(
    queryRunner: QueryRunner,
    schemaName: string,
    oldEnumTypeName: string,
  ) {
    await queryRunner.query(
      `DROP TYPE IF EXISTS "${schemaName}"."${oldEnumTypeName}"`,
    );
  }

  private async renameEnumType(
    queryRunner: QueryRunner,
    schemaName: string,
    oldEnumTypeName: string,
    newEnumTypeName: string,
  ) {
    await queryRunner.query(`
      ALTER TYPE "${schemaName}"."${oldEnumTypeName}"
      RENAME TO "${newEnumTypeName}"
    `);
  }

  private async getEnumTypeName(
    queryRunner: QueryRunner,
    schemaName: string,
    tableName: string,
    columnName: string,
  ): Promise<string> {
    const [result] = await queryRunner.query(
      `SELECT udt_name, data_type FROM information_schema.columns WHERE table_schema = $1 AND table_name = $2 AND column_name = $3`,
      [schemaName, tableName, columnName],
    );

    if (!result) {
      throw new WorkspaceMigrationException(
        `Enum type name not found for column ${columnName} in table ${tableName} while trying to alter enum`,
        WorkspaceMigrationExceptionCode.ENUM_TYPE_NAME_NOT_FOUND,
      );
    }

    const enumTypeName =
      result.data_type === 'ARRAY'
        ? result.udt_name.replace(/^_/, '')
        : result.udt_name;

    return enumTypeName;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service to fix workspace health issues related to column default values by creating workspace migrations and metadata updates.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { EntityManager } from 'typeorm';

import {
  WorkspaceHealthColumnIssue,
  WorkspaceHealthIssueType,
} from 'src/engine/workspace-manager/workspace-health/interfaces/workspace-health-issue.interface';
import { WorkspaceMigrationBuilderAction } from 'src/engine/workspace-manager/workspace-migration-builder/interfaces/workspace-migration-builder-action.interface';
import { FieldMetadataDefaultValue } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata-default-value.interface';

import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { WorkspaceMigrationEntity } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceMigrationFieldFactory } from 'src/engine/workspace-manager/workspace-migration-builder/factories/workspace-migration-field.factory';
import { FieldMetadataEntity } from 'src/engine/metadata-modules/field-metadata/field-metadata.entity';
import {
  FieldMetadataDefaultValueFunctionNames,
  fieldMetadataDefaultValueFunctionName,
} from 'src/engine/metadata-modules/field-metadata/dtos/default-value.input';

import {
  AbstractWorkspaceFixer,
  CompareEntity,
} from './abstract-workspace.fixer';

type WorkspaceDefaultValueFixerType =
  | WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_CONFLICT
  | WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_NOT_VALID;

@Injectable()
export class WorkspaceDefaultValueFixer extends AbstractWorkspaceFixer<WorkspaceDefaultValueFixerType> {
  constructor(
    private readonly workspaceMigrationFieldFactory: WorkspaceMigrationFieldFactory,
  ) {
    super(
      WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_CONFLICT,
      WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_NOT_VALID,
    );
  }

  async createWorkspaceMigrations(
    manager: EntityManager,
    objectMetadataCollection: ObjectMetadataEntity[],
    issues: WorkspaceHealthColumnIssue<WorkspaceDefaultValueFixerType>[],
  ): Promise<Partial<WorkspaceMigrationEntity>[]> {
    if (issues.length <= 0) {
      return [];
    }
    const splittedIssues = this.splitIssuesByType(issues);
    const issueNeedingMigration =
      splittedIssues[WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_CONFLICT] ??
      [];

    return this.fixColumnDefaultValueConflictIssues(
      objectMetadataCollection,
      issueNeedingMigration as WorkspaceHealthColumnIssue<WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_CONFLICT>[],
    );
  }

  async createMetadataUpdates(
    manager: EntityManager,
    objectMetadataCollection: ObjectMetadataEntity[],
    issues: WorkspaceHealthColumnIssue<WorkspaceDefaultValueFixerType>[],
  ): Promise<CompareEntity<FieldMetadataEntity>[]> {
    if (issues.length <= 0) {
      return [];
    }

    const splittedIssues = this.splitIssuesByType(issues);
    const issueNeedingMetadataUpdate =
      splittedIssues[WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_NOT_VALID] ??
      [];

    return this.fixColumnDefaultValueNotValidIssues(
      manager,
      issueNeedingMetadataUpdate as WorkspaceHealthColumnIssue<WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_NOT_VALID>[],
    );
  }

  private async fixColumnDefaultValueConflictIssues(
    objectMetadataCollection: ObjectMetadataEntity[],
    issues: WorkspaceHealthColumnIssue<WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_CONFLICT>[],
  ): Promise<Partial<WorkspaceMigrationEntity>[]> {
    const fieldMetadataUpdateCollection = issues.map((issue) => {
      const oldDefaultValue =
        this.computeFieldMetadataDefaultValueFromColumnDefault(
          issue.columnStructure?.columnDefault,
        );

      return {
        current: {
          ...issue.fieldMetadata,
          defaultValue: oldDefaultValue,
        },
        altered: issue.fieldMetadata,
      };
    });

    return this.workspaceMigrationFieldFactory.create(
      objectMetadataCollection,
      fieldMetadataUpdateCollection,
      WorkspaceMigrationBuilderAction.UPDATE,
    );
  }

  private async fixColumnDefaultValueNotValidIssues(
    manager: EntityManager,
    issues: WorkspaceHealthColumnIssue<WorkspaceHealthIssueType.COLUMN_DEFAULT_VALUE_NOT_VALID>[],
  ): Promise<CompareEntity<FieldMetadataEntity>[]> {
    const fieldMetadataRepository = manager.getRepository(FieldMetadataEntity);
    const updatedEntities: CompareEntity<FieldMetadataEntity>[] = [];

    for (const issue of issues) {
      const currentDefaultValue:
        | FieldMetadataDefaultValue
        // Old format for default values
        // TODO: Remove this after all workspaces are migrated
        | { type: FieldMetadataDefaultValueFunctionNames }
        | null = issue.fieldMetadata.defaultValue;
      let alteredDefaultValue: FieldMetadataDefaultValue | null = null;

      // Check if it's an old function default value
      // eslint-disable-next-line @typescript-eslint/ban-ts-comment
      // @ts-expect-error
      if (currentDefaultValue && 'type' in currentDefaultValue) {
        alteredDefaultValue =
          currentDefaultValue.type as FieldMetadataDefaultValueFunctionNames;
      }

      // Check if it's an old string default value
      if (currentDefaultValue) {
        for (const key of Object.keys(currentDefaultValue)) {
          if (key === 'type') {
            continue;
          }

          const value = currentDefaultValue[key];

          const newValue =
            typeof value === 'string' &&
            !value.startsWith("'") &&
            !Object.values(fieldMetadataDefaultValueFunctionName).includes(
              value as FieldMetadataDefaultValueFunctionNames,
            )
              ? `'${value}'`
              : value;

          alteredDefaultValue = {
            ...(currentDefaultValue as any),
            ...(alteredDefaultValue as any),
            [key]: newValue,
          };
        }
      }

      // Old formart default values
      if (
        alteredDefaultValue &&
        typeof alteredDefaultValue === 'object' &&
        'value' in alteredDefaultValue
      ) {
        // eslint-disable-next-line @typescript-eslint/ban-ts-comment
        // @ts-expect-error
        alteredDefaultValue = alteredDefaultValue.value;
      }

      if (alteredDefaultValue === null) {
        continue;
      }

      await fieldMetadataRepository.update(issue.fieldMetadata.id, {
        defaultValue: alteredDefaultValue,
      });
      const alteredEntity = await fieldMetadataRepository.findOne({
        where: {
          id: issue.fieldMetadata.id,
        },
      });

      updatedEntities.push({
        current: issue.fieldMetadata,
        altered: alteredEntity as FieldMetadataEntity | null,
      });
    }

    return updatedEntities;
  }

  private computeFieldMetadataDefaultValueFromColumnDefault(
    columnDefault: string | undefined,
  ): FieldMetadataDefaultValue {
    if (
      columnDefault === undefined ||
      columnDefault === null ||
      columnDefault === 'NULL'
    ) {
      return null;
    }

    if (!isNaN(Number(columnDefault))) {
      return +columnDefault;
    }

    if (columnDefault === 'true') {
      return true;
    }

    if (columnDefault === 'false') {
      return false;
    }

    if (columnDefault === '') {
      return "''";
    }

    if (columnDefault === 'now()') {
      return 'now';
    }

    if (columnDefault.startsWith('public.uuid_generate_v4')) {
      return 'uuid';
    }

    return columnDefault;
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for synchronizing workspace relation metadata, comparing existing metadata with standard and custom definitions, and generating workspace migrations based on the comparison results.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { EntityManager } from 'typeorm';

import { FeatureFlagMap } from 'src/engine/core-modules/feature-flag/interfaces/feature-flag-map.interface';
import { WorkspaceMigrationBuilderAction } from 'src/engine/workspace-manager/workspace-migration-builder/interfaces/workspace-migration-builder-action.interface';
import { ComparatorAction } from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/comparator.interface';
import { WorkspaceSyncContext } from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/workspace-sync-context.interface';

import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { RelationMetadataEntity } from 'src/engine/metadata-modules/relation-metadata/relation-metadata.entity';
import { WorkspaceMigrationEntity } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { CustomWorkspaceEntity } from 'src/engine/twenty-orm/custom.workspace-entity';
import { WorkspaceMigrationRelationFactory } from 'src/engine/workspace-manager/workspace-migration-builder/factories/workspace-migration-relation.factory';
import { WorkspaceRelationComparator } from 'src/engine/workspace-manager/workspace-sync-metadata/comparators/workspace-relation.comparator';
import { StandardRelationFactory } from 'src/engine/workspace-manager/workspace-sync-metadata/factories/standard-relation.factory';
import { WorkspaceMetadataUpdaterService } from 'src/engine/workspace-manager/workspace-sync-metadata/services/workspace-metadata-updater.service';
import { standardObjectMetadataDefinitions } from 'src/engine/workspace-manager/workspace-sync-metadata/standard-objects';
import { WorkspaceSyncStorage } from 'src/engine/workspace-manager/workspace-sync-metadata/storage/workspace-sync.storage';
import { mapObjectMetadataByUniqueIdentifier } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/sync-metadata.util';

@Injectable()
export class WorkspaceSyncRelationMetadataService {
  constructor(
    private readonly standardRelationFactory: StandardRelationFactory,
    private readonly workspaceRelationComparator: WorkspaceRelationComparator,
    private readonly workspaceMetadataUpdaterService: WorkspaceMetadataUpdaterService,
    private readonly workspaceMigrationRelationFactory: WorkspaceMigrationRelationFactory,
  ) {}

  async synchronize(
    context: WorkspaceSyncContext,
    manager: EntityManager,
    storage: WorkspaceSyncStorage,
    workspaceFeatureFlagsMap: FeatureFlagMap,
  ): Promise<Partial<WorkspaceMigrationEntity>[]> {
    const objectMetadataRepository =
      manager.getRepository(ObjectMetadataEntity);

    // Retrieve object metadata collection from DB
    const originalObjectMetadataCollection =
      await objectMetadataRepository.find({
        where: {
          workspaceId: context.workspaceId,
        },
        relations: ['dataSource', 'fields'],
      });
    const customObjectMetadataCollection =
      originalObjectMetadataCollection.filter(
        (objectMetadata) => objectMetadata.isCustom,
      );

    // Create map of object metadata & field metadata by unique identifier
    const originalObjectMetadataMap = mapObjectMetadataByUniqueIdentifier(
      originalObjectMetadataCollection,
      // Relation are based on the singular name
      (objectMetadata) => objectMetadata.nameSingular,
    );

    const relationMetadataRepository = manager.getRepository(
      RelationMetadataEntity,
    );

    // Retrieve relation metadata collection from DB
    const originalRelationMetadataCollection =
      await relationMetadataRepository.find({
        where: {
          workspaceId: context.workspaceId,
          fromFieldMetadata: { isCustom: false },
        },
      });

    // Create standard relation metadata collection
    const standardRelationMetadataCollection =
      this.standardRelationFactory.create(
        standardObjectMetadataDefinitions,
        context,
        originalObjectMetadataMap,
        workspaceFeatureFlagsMap,
      );

    const customRelationMetadataCollection =
      this.standardRelationFactory.create(
        customObjectMetadataCollection.map((objectMetadata) => ({
          object: objectMetadata,
          metadata: CustomWorkspaceEntity,
        })),
        context,
        originalObjectMetadataMap,
        workspaceFeatureFlagsMap,
      );

    const relationComparatorResults = this.workspaceRelationComparator.compare(
      originalRelationMetadataCollection,
      [
        ...standardRelationMetadataCollection,
        ...customRelationMetadataCollection,
      ],
    );

    for (const relationComparatorResult of relationComparatorResults) {
      if (relationComparatorResult.action === ComparatorAction.CREATE) {
        storage.addCreateRelationMetadata(relationComparatorResult.object);
      } else if (relationComparatorResult.action === ComparatorAction.UPDATE) {
        storage.addUpdateRelationMetadata(relationComparatorResult.object);
      } else if (relationComparatorResult.action === ComparatorAction.DELETE) {
        storage.addDeleteRelationMetadata(relationComparatorResult.object);
      }
    }

    const metadataRelationUpdaterResult =
      await this.workspaceMetadataUpdaterService.updateRelationMetadata(
        manager,
        storage,
      );

    // Create migrations
    const createRelationWorkspaceMigrations =
      await this.workspaceMigrationRelationFactory.create(
        originalObjectMetadataCollection,
        metadataRelationUpdaterResult.createdRelationMetadataCollection,
        WorkspaceMigrationBuilderAction.CREATE,
      );

    const updateRelationWorkspaceMigrations =
      await this.workspaceMigrationRelationFactory.create(
        originalObjectMetadataCollection,
        metadataRelationUpdaterResult.updatedRelationMetadataCollection,
        WorkspaceMigrationBuilderAction.UPDATE,
      );

    return [
      ...createRelationWorkspaceMigrations,
      ...updateRelationWorkspaceMigrations,
    ];
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for synchronizing index metadata in a workspace, comparing existing metadata with standard definitions, and generating migrations for any discrepancies.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { Any, EntityManager } from 'typeorm';

import { FeatureFlagMap } from 'src/engine/core-modules/feature-flag/interfaces/feature-flag-map.interface';
import { WorkspaceMigrationBuilderAction } from 'src/engine/workspace-manager/workspace-migration-builder/interfaces/workspace-migration-builder-action.interface';
import { ComparatorAction } from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/comparator.interface';
import { WorkspaceSyncContext } from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/workspace-sync-context.interface';

import { IndexMetadataEntity } from 'src/engine/metadata-modules/index-metadata/index-metadata.entity';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { WorkspaceMigrationEntity } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceMigrationIndexFactory } from 'src/engine/workspace-manager/workspace-migration-builder/factories/workspace-migration-index.factory';
import { WorkspaceIndexComparator } from 'src/engine/workspace-manager/workspace-sync-metadata/comparators/workspace-index.comparator';
import { StandardIndexFactory } from 'src/engine/workspace-manager/workspace-sync-metadata/factories/standard-index.factory';
import { WorkspaceMetadataUpdaterService } from 'src/engine/workspace-manager/workspace-sync-metadata/services/workspace-metadata-updater.service';
import { standardObjectMetadataDefinitions } from 'src/engine/workspace-manager/workspace-sync-metadata/standard-objects';
import { WorkspaceSyncStorage } from 'src/engine/workspace-manager/workspace-sync-metadata/storage/workspace-sync.storage';
import { mapObjectMetadataByUniqueIdentifier } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/sync-metadata.util';

@Injectable()
export class WorkspaceSyncIndexMetadataService {
  private readonly logger = new Logger(WorkspaceSyncIndexMetadataService.name);

  constructor(
    private readonly standardIndexFactory: StandardIndexFactory,
    private readonly workspaceIndexComparator: WorkspaceIndexComparator,
    private readonly workspaceMetadataUpdaterService: WorkspaceMetadataUpdaterService,
    private readonly workspaceMigrationIndexFactory: WorkspaceMigrationIndexFactory,
  ) {}

  async synchronize(
    context: WorkspaceSyncContext,
    manager: EntityManager,
    storage: WorkspaceSyncStorage,
    workspaceFeatureFlagsMap: FeatureFlagMap,
  ): Promise<Partial<WorkspaceMigrationEntity>[]> {
    this.logger.log('Syncing index metadata');

    const objectMetadataRepository =
      manager.getRepository(ObjectMetadataEntity);

    // Retrieve object metadata collection from DB
    const originalObjectMetadataCollection =
      await objectMetadataRepository.find({
        where: {
          workspaceId: context.workspaceId,
          // We're only interested in standard fields
          fields: { isCustom: false },
        },
        relations: ['dataSource', 'fields', 'indexMetadatas'],
      });

    // Create map of object metadata & field metadata by unique identifier
    const originalStandardObjectMetadataMap =
      mapObjectMetadataByUniqueIdentifier(
        originalObjectMetadataCollection.filter(
          (objectMetadata) => !objectMetadata.isCustom,
        ),
        // Relation are based on the singular name
        (objectMetadata) => objectMetadata.nameSingular,
      );

    const originalCustomObjectMetadataMap = mapObjectMetadataByUniqueIdentifier(
      originalObjectMetadataCollection.filter(
        (objectMetadata) => objectMetadata.isCustom,
      ),
      (objectMetadata) => objectMetadata.nameSingular,
    );

    const indexMetadataRepository = manager.getRepository(IndexMetadataEntity);

    const originalIndexMetadataCollection = await indexMetadataRepository.find({
      where: {
        workspaceId: context.workspaceId,
        objectMetadataId: Any(
          Object.values(originalObjectMetadataCollection).map(
            (object) => object.id,
          ),
        ),
        isCustom: false,
      },
      relations: ['indexFieldMetadatas.fieldMetadata'],
    });

    // Generate index metadata from models
    const standardIndexMetadataCollection = this.standardIndexFactory.create(
      standardObjectMetadataDefinitions,
      context,
      originalStandardObjectMetadataMap,
      originalCustomObjectMetadataMap,
      workspaceFeatureFlagsMap,
    );

    const indexComparatorResults = this.workspaceIndexComparator.compare(
      originalIndexMetadataCollection,
      standardIndexMetadataCollection,
    );

    for (const indexComparatorResult of indexComparatorResults) {
      if (indexComparatorResult.action === ComparatorAction.CREATE) {
        storage.addCreateIndexMetadata(indexComparatorResult.object);
      } else if (indexComparatorResult.action === ComparatorAction.DELETE) {
        storage.addDeleteIndexMetadata(indexComparatorResult.object);
      }
    }

    const metadataIndexUpdaterResult =
      await this.workspaceMetadataUpdaterService.updateIndexMetadata(
        manager,
        storage,
        originalObjectMetadataCollection,
      );

    // Create migrations
    const createIndexWorkspaceMigrations =
      await this.workspaceMigrationIndexFactory.create(
        originalObjectMetadataCollection,
        metadataIndexUpdaterResult.createdIndexMetadataCollection,
        WorkspaceMigrationBuilderAction.CREATE,
      );

    const deleteIndexWorkspaceMigrations =
      await this.workspaceMigrationIndexFactory.create(
        originalObjectMetadataCollection,
        storage.indexMetadataDeleteCollection,
        WorkspaceMigrationBuilderAction.DELETE,
      );

    return [
      ...createIndexWorkspaceMigrations,
      ...deleteIndexWorkspaceMigrations,
    ];
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for synchronizing workspace field metadata, comparing standard and custom object metadata, and generating migrations based on the differences.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { EntityManager } from 'typeorm';

import { FeatureFlagMap } from 'src/engine/core-modules/feature-flag/interfaces/feature-flag-map.interface';
import { WorkspaceMigrationBuilderAction } from 'src/engine/workspace-manager/workspace-migration-builder/interfaces/workspace-migration-builder-action.interface';
import {
  ComparatorAction,
  FieldComparatorResult,
} from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/comparator.interface';
import { WorkspaceSyncContext } from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/workspace-sync-context.interface';

import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { WorkspaceMigrationEntity } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { CustomWorkspaceEntity } from 'src/engine/twenty-orm/custom.workspace-entity';
import { WorkspaceMigrationFieldFactory } from 'src/engine/workspace-manager/workspace-migration-builder/factories/workspace-migration-field.factory';
import { WorkspaceFieldComparator } from 'src/engine/workspace-manager/workspace-sync-metadata/comparators/workspace-field.comparator';
import { StandardFieldFactory } from 'src/engine/workspace-manager/workspace-sync-metadata/factories/standard-field.factory';
import { WorkspaceMetadataUpdaterService } from 'src/engine/workspace-manager/workspace-sync-metadata/services/workspace-metadata-updater.service';
import { standardObjectMetadataDefinitions } from 'src/engine/workspace-manager/workspace-sync-metadata/standard-objects';
import { WorkspaceSyncStorage } from 'src/engine/workspace-manager/workspace-sync-metadata/storage/workspace-sync.storage';
import { computeStandardFields } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/compute-standard-fields.util';
import { mapObjectMetadataByUniqueIdentifier } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/sync-metadata.util';

@Injectable()
export class WorkspaceSyncFieldMetadataService {
  private readonly logger = new Logger(WorkspaceSyncFieldMetadataService.name);

  constructor(
    private readonly standardFieldFactory: StandardFieldFactory,
    private readonly workspaceFieldComparator: WorkspaceFieldComparator,
    private readonly workspaceMetadataUpdaterService: WorkspaceMetadataUpdaterService,
    private readonly workspaceMigrationFieldFactory: WorkspaceMigrationFieldFactory,
  ) {}

  async synchronize(
    context: WorkspaceSyncContext,
    manager: EntityManager,
    storage: WorkspaceSyncStorage,
    workspaceFeatureFlagsMap: FeatureFlagMap,
  ): Promise<Partial<WorkspaceMigrationEntity>[]> {
    const objectMetadataRepository =
      manager.getRepository(ObjectMetadataEntity);

    // Retrieve object metadata collection from DB
    const originalObjectMetadataCollection =
      await objectMetadataRepository.find({
        where: {
          workspaceId: context.workspaceId,
          // We're only interested in standard fields
        },
        relations: ['dataSource', 'fields'],
      });
    const customObjectMetadataCollection =
      originalObjectMetadataCollection.filter(
        (objectMetadata) => objectMetadata.isCustom,
      );

    await this.synchronizeStandardObjectFields(
      context,
      originalObjectMetadataCollection,
      customObjectMetadataCollection,
      storage,
      workspaceFeatureFlagsMap,
    );

    await this.synchronizeCustomObjectFields(
      context,
      customObjectMetadataCollection,
      storage,
      workspaceFeatureFlagsMap,
    );

    this.logger.log('Updating workspace metadata');

    const metadataFieldUpdaterResult =
      await this.workspaceMetadataUpdaterService.updateFieldMetadata(
        manager,
        storage,
      );

    this.logger.log('Generating migrations');

    const deleteFieldWorkspaceMigrations =
      await this.workspaceMigrationFieldFactory.create(
        originalObjectMetadataCollection,
        storage.fieldMetadataDeleteCollection,
        WorkspaceMigrationBuilderAction.DELETE,
      );

    const updateFieldWorkspaceMigrations =
      await this.workspaceMigrationFieldFactory.create(
        originalObjectMetadataCollection,
        metadataFieldUpdaterResult.updatedFieldMetadataCollection,
        WorkspaceMigrationBuilderAction.UPDATE,
      );

    const createFieldWorkspaceMigrations =
      await this.workspaceMigrationFieldFactory.create(
        originalObjectMetadataCollection,
        metadataFieldUpdaterResult.createdFieldMetadataCollection,
        WorkspaceMigrationBuilderAction.CREATE,
      );

    this.logger.log('Saving migrations');

    return [
      ...deleteFieldWorkspaceMigrations,
      ...updateFieldWorkspaceMigrations,
      ...createFieldWorkspaceMigrations,
    ];
  }

  /**
   * This can be optimized to avoid import of standardObjectFactory here.
   * We should refactor the logic of the factory, so this one only create the objects and not the fields.
   * Then standardFieldFactory should be used to create the fields of standard objects.
   */
  private async synchronizeStandardObjectFields(
    context: WorkspaceSyncContext,
    originalObjectMetadataCollection: ObjectMetadataEntity[],
    customObjectMetadataCollection: ObjectMetadataEntity[],
    storage: WorkspaceSyncStorage,
    workspaceFeatureFlagsMap: FeatureFlagMap,
  ): Promise<void> {
    // Create standard field metadata map
    const standardObjectStandardFieldMetadataMap =
      this.standardFieldFactory.create(
        standardObjectMetadataDefinitions,
        context,
        workspaceFeatureFlagsMap,
      );

    // Create map of original and standard object metadata by standard ids
    const originalObjectMetadataMap = mapObjectMetadataByUniqueIdentifier(
      originalObjectMetadataCollection,
    );

    // Loop over all standard objects and compare them with the objects in DB
    for (const [
      standardObjectId,
      standardFieldMetadataCollection,
    ] of standardObjectStandardFieldMetadataMap) {
      const originalObjectMetadata =
        originalObjectMetadataMap[standardObjectId];

      const computedStandardFieldMetadataCollection = computeStandardFields(
        standardFieldMetadataCollection,
        originalObjectMetadata,
        // We need to provide this for generated relations with custom objects
        customObjectMetadataCollection,
      );

      const fieldComparatorResults = this.workspaceFieldComparator.compare(
        originalObjectMetadata.id,
        originalObjectMetadata.fields,
        computedStandardFieldMetadataCollection,
      );

      this.storeComparatorResults(fieldComparatorResults, storage);
    }
  }

  private async synchronizeCustomObjectFields(
    context: WorkspaceSyncContext,
    customObjectMetadataCollection: ObjectMetadataEntity[],
    storage: WorkspaceSyncStorage,
    workspaceFeatureFlagsMap: FeatureFlagMap,
  ): Promise<void> {
    // Create standard field metadata collection
    const customObjectStandardFieldMetadataCollection =
      this.standardFieldFactory.create(
        CustomWorkspaceEntity,
        context,
        workspaceFeatureFlagsMap,
      );

    // Loop over all custom objects from the DB and compare their fields with standard fields
    for (const customObjectMetadata of customObjectMetadataCollection) {
      // Also, maybe it's better to refactor a bit and move generation part into a separate module ?
      const standardFieldMetadataCollection = computeStandardFields(
        customObjectStandardFieldMetadataCollection,
        customObjectMetadata,
      );

      /**
       * COMPARE FIELD METADATA
       */
      const fieldComparatorResults = this.workspaceFieldComparator.compare(
        customObjectMetadata.id,
        customObjectMetadata.fields,
        standardFieldMetadataCollection,
      );

      this.storeComparatorResults(fieldComparatorResults, storage);
    }
  }

  private storeComparatorResults(
    fieldComparatorResults: FieldComparatorResult[],
    storage: WorkspaceSyncStorage,
  ): void {
    for (const fieldComparatorResult of fieldComparatorResults) {
      switch (fieldComparatorResult.action) {
        case ComparatorAction.CREATE: {
          storage.addCreateFieldMetadata(fieldComparatorResult.object);
          break;
        }
        case ComparatorAction.UPDATE: {
          storage.addUpdateFieldMetadata(fieldComparatorResult.object);
          break;
        }
        case ComparatorAction.DELETE: {
          storage.addDeleteFieldMetadata(fieldComparatorResult.object);
          break;
        }
      }
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for synchronizing workspace object metadata with standard object metadata, comparing them, and generating migrations based on the differences.
Code Snippet:
import { Injectable, Logger } from '@nestjs/common';

import { EntityManager } from 'typeorm';

import { FeatureFlagMap } from 'src/engine/core-modules/feature-flag/interfaces/feature-flag-map.interface';
import { WorkspaceMigrationBuilderAction } from 'src/engine/workspace-manager/workspace-migration-builder/interfaces/workspace-migration-builder-action.interface';
import { ComparatorAction } from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/comparator.interface';
import { WorkspaceSyncContext } from 'src/engine/workspace-manager/workspace-sync-metadata/interfaces/workspace-sync-context.interface';

import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { RelationMetadataEntity } from 'src/engine/metadata-modules/relation-metadata/relation-metadata.entity';
import { WorkspaceMigrationEntity } from 'src/engine/metadata-modules/workspace-migration/workspace-migration.entity';
import { WorkspaceMigrationObjectFactory } from 'src/engine/workspace-manager/workspace-migration-builder/factories/workspace-migration-object.factory';
import { WorkspaceObjectComparator } from 'src/engine/workspace-manager/workspace-sync-metadata/comparators/workspace-object.comparator';
import { StandardObjectFactory } from 'src/engine/workspace-manager/workspace-sync-metadata/factories/standard-object.factory';
import { WorkspaceMetadataUpdaterService } from 'src/engine/workspace-manager/workspace-sync-metadata/services/workspace-metadata-updater.service';
import { standardObjectMetadataDefinitions } from 'src/engine/workspace-manager/workspace-sync-metadata/standard-objects';
import { WorkspaceSyncStorage } from 'src/engine/workspace-manager/workspace-sync-metadata/storage/workspace-sync.storage';
import { mapObjectMetadataByUniqueIdentifier } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/sync-metadata.util';

@Injectable()
export class WorkspaceSyncObjectMetadataService {
  private readonly logger = new Logger(WorkspaceSyncObjectMetadataService.name);

  constructor(
    private readonly standardObjectFactory: StandardObjectFactory,
    private readonly workspaceObjectComparator: WorkspaceObjectComparator,
    private readonly workspaceMetadataUpdaterService: WorkspaceMetadataUpdaterService,
    private readonly workspaceMigrationObjectFactory: WorkspaceMigrationObjectFactory,
  ) {}

  async synchronize(
    context: WorkspaceSyncContext,
    manager: EntityManager,
    storage: WorkspaceSyncStorage,
    workspaceFeatureFlagsMap: FeatureFlagMap,
  ): Promise<Partial<WorkspaceMigrationEntity>[]> {
    const objectMetadataRepository =
      manager.getRepository(ObjectMetadataEntity);

    const relationMetadataRepository = manager.getRepository(
      RelationMetadataEntity,
    );

    // Retrieve object metadata collection from DB
    const originalObjectMetadataCollection =
      await objectMetadataRepository.find({
        where: {
          workspaceId: context.workspaceId,
          fields: { isCustom: false },
        },
        relations: ['dataSource', 'fields'],
      });

    // Retrieve relation metadata collection from DB
    const originalRelationMetadataCollection =
      await relationMetadataRepository.find({
        where: {
          workspaceId: context.workspaceId,
        },
        relations: ['toObjectMetadata', 'toFieldMetadata'],
      });

    const relationMetadataByFromObjectMetadataId: Record<
      string,
      RelationMetadataEntity[]
    > = originalRelationMetadataCollection.reduce(
      (acc, relationMetadata) => {
        const fromObjectMetadataId = relationMetadata.fromObjectMetadataId;

        if (!acc[fromObjectMetadataId]) {
          acc[fromObjectMetadataId] = [];
        }

        acc[fromObjectMetadataId].push(relationMetadata);

        return acc;
      },
      {} as Record<string, RelationMetadataEntity[]>,
    );

    // Create standard object metadata collection
    const standardObjectMetadataCollection = this.standardObjectFactory.create(
      standardObjectMetadataDefinitions,
      context,
      workspaceFeatureFlagsMap,
    );

    // Create map of original and standard object metadata by standard ids
    const originalObjectMetadataMap = mapObjectMetadataByUniqueIdentifier(
      originalObjectMetadataCollection,
    );
    const standardObjectMetadataMap = mapObjectMetadataByUniqueIdentifier(
      standardObjectMetadataCollection,
    );

    this.logger.log('Comparing standard objects and fields metadata');

    // Store object that need to be deleted
    for (const originalObjectMetadata of originalObjectMetadataCollection.filter(
      (object) => !object.isCustom,
    )) {
      if (
        originalObjectMetadata.standardId &&
        !standardObjectMetadataMap[originalObjectMetadata.standardId]
      ) {
        storage.addDeleteObjectMetadata(originalObjectMetadata);
      }
    }

    // Loop over all standard objects and compare them with the objects in DB
    for (const standardObjectId in standardObjectMetadataMap) {
      const originalObjectMetadata =
        originalObjectMetadataMap[standardObjectId];
      const standardObjectMetadata =
        standardObjectMetadataMap[standardObjectId];

      /**
       * COMPARE OBJECT METADATA
       */
      const objectComparatorResult = this.workspaceObjectComparator.compare(
        originalObjectMetadata,
        standardObjectMetadata,
      );

      if (objectComparatorResult.action === ComparatorAction.CREATE) {
        storage.addCreateObjectMetadata(standardObjectMetadata);
        continue;
      }

      if (objectComparatorResult.action === ComparatorAction.UPDATE) {
        storage.addUpdateObjectMetadata(objectComparatorResult.object);
      }
    }

    this.logger.log('Updating workspace metadata');

    // Apply changes to DB
    const metadataObjectUpdaterResult =
      await this.workspaceMetadataUpdaterService.updateObjectMetadata(
        manager,
        storage,
      );

    this.logger.log('Generating migrations');

    // Create migrations
    const createObjectWorkspaceMigrations =
      await this.workspaceMigrationObjectFactory.create(
        metadataObjectUpdaterResult.createdObjectMetadataCollection,
        WorkspaceMigrationBuilderAction.CREATE,
      );

    const updateObjectWorkspaceMigrations =
      await this.workspaceMigrationObjectFactory.create(
        metadataObjectUpdaterResult.updatedObjectMetadataCollection,
        WorkspaceMigrationBuilderAction.UPDATE,
      );

    const deleteObjectWorkspaceMigrations =
      await this.workspaceMigrationObjectFactory.create(
        storage.objectMetadataDeleteCollection,
        WorkspaceMigrationBuilderAction.DELETE,
        relationMetadataByFromObjectMetadataId,
      );

    this.logger.log('Saving migrations');

    return [
      ...createObjectWorkspaceMigrations,
      ...updateObjectWorkspaceMigrations,
      ...deleteObjectWorkspaceMigrations,
    ];
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_11>



=== New Entry ===

<CLUSTER_12>
Number of Code Snippets part of this cluster: 9
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: This code defines a TypeORM migration to create and drop a table for tracking generated columns and materialized views in a database schema.
Code Snippet:
import { MigrationInterface, QueryRunner } from 'typeorm';

export class AddTypeormGeneratedColumns1728314605995
  implements MigrationInterface
{
  name = 'AddTypeormGeneratedColumnsAndMaterializedViews1728314605995';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(`
                CREATE TABLE "core"."_typeorm_generated_columns_and_materialized_views" (
                    "type" character varying NOT NULL,
                    "database" character varying,
                    "schema" character varying,
                    "table" character varying,
                    "name" character varying,
                    "value" text
                )
            `);
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `DROP TABLE "core"."_typeorm_generated_columns_and_materialized_views"`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a database migration to alter the default value of the 'isMicrosoftAuthEnabled' column in the 'workspace' table within the 'core' schema.
Code Snippet:
import { MigrationInterface, QueryRunner } from 'typeorm';

export class WorkspaceEntityDefaultMicrosoftAuthEnabled1737630672873
  implements MigrationInterface
{
  name = 'WorkspaceEntityDefaultMicrosoftAuthEnabled1737630672873';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "core"."workspace" ALTER COLUMN "isMicrosoftAuthEnabled" SET DEFAULT true`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "core"."workspace" ALTER COLUMN "isMicrosoftAuthEnabled" SET DEFAULT false`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a database migration to add and remove a 'defaultRoleId' column in the 'workspace' table within the 'core' schema.
Code Snippet:
import { MigrationInterface, QueryRunner } from 'typeorm';

export class AddDefaultRoleToWorkspace1740390801418
  implements MigrationInterface
{
  name = 'AddDefaultRoleToWorkspace1740390801418';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "core"."workspace" ADD "defaultRoleId" uuid`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "core"."workspace" DROP COLUMN "defaultRoleId"`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a database migration to modify the schema of the 'userWorkspace' and 'user' tables in a PostgreSQL database. It includes adding constraints, altering column types, and setting default values.
Code Snippet:
import { MigrationInterface, QueryRunner } from 'typeorm';

export class AddMissingMigration1711557405330 implements MigrationInterface {
  name = 'AddMissingMigration1711557405330';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" DROP CONSTRAINT "FK_37fdc7357af701e595c5c3a9bd6"`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" DROP CONSTRAINT "FK_cb488f32c6a0827b938edadf221"`,
    );

    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE USING "createdAt"::TIMESTAMP WITH TIME ZONE`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ALTER COLUMN "createdAt" SET DEFAULT now()`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ALTER COLUMN "createdAt" SET NOT NULL;`,
    );

    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE USING "updatedAt"::TIMESTAMP WITH TIME ZONE`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ALTER COLUMN "updatedAt" SET DEFAULT now()`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ALTER COLUMN "updatedAt" SET NOT NULL;`,
    );

    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ALTER COLUMN "deletedAt" TYPE TIMESTAMP WITH TIME ZONE USING "deletedAt"::TIMESTAMP WITH TIME ZONE`,
    );

    await queryRunner.query(
      `ALTER TABLE "core"."user" DROP CONSTRAINT "FK_2ec910029395fa7655621c88908"`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."user" ALTER COLUMN "defaultWorkspaceId" SET NOT NULL`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ADD CONSTRAINT "IndexOnUserIdAndWorkspaceIdUnique" UNIQUE ("userId", "workspaceId")`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ADD CONSTRAINT "FK_a2da2ea7d6cd1e5a4c5cb1791f8" FOREIGN KEY ("userId") REFERENCES "core"."user"("id") ON DELETE CASCADE ON UPDATE NO ACTION`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ADD CONSTRAINT "FK_22f5e76f493c3fb20237cfc48b0" FOREIGN KEY ("workspaceId") REFERENCES "core"."workspace"("id") ON DELETE CASCADE ON UPDATE NO ACTION`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."user" ADD CONSTRAINT "FK_2ec910029395fa7655621c88908" FOREIGN KEY ("defaultWorkspaceId") REFERENCES "core"."workspace"("id") ON DELETE SET NULL ON UPDATE NO ACTION`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "core"."user" DROP CONSTRAINT "FK_2ec910029395fa7655621c88908"`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" DROP CONSTRAINT "FK_22f5e76f493c3fb20237cfc48b0"`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" DROP CONSTRAINT "FK_a2da2ea7d6cd1e5a4c5cb1791f8"`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" DROP CONSTRAINT "IndexOnUserIdAndWorkspaceIdUnique"`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."user" ALTER COLUMN "defaultWorkspaceId" DROP NOT NULL`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."user" ADD CONSTRAINT "FK_2ec910029395fa7655621c88908" FOREIGN KEY ("defaultWorkspaceId") REFERENCES "core"."workspace"("id") ON DELETE SET NULL ON UPDATE NO ACTION`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" DROP COLUMN "deletedAt"`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ADD "deletedAt" TIMESTAMP`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" DROP COLUMN "updatedAt"`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ADD "updatedAt" TIMESTAMP NOT NULL DEFAULT now()`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" DROP COLUMN "createdAt"`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ADD "createdAt" TIMESTAMP NOT NULL DEFAULT now()`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ADD CONSTRAINT "FK_cb488f32c6a0827b938edadf221" FOREIGN KEY ("userId") REFERENCES "core"."user"("id") ON DELETE CASCADE ON UPDATE NO ACTION`,
    );
    await queryRunner.query(
      `ALTER TABLE "core"."userWorkspace" ADD CONSTRAINT "FK_37fdc7357af701e595c5c3a9bd6" FOREIGN KEY ("workspaceId") REFERENCES "core"."workspace"("id") ON DELETE CASCADE ON UPDATE NO ACTION`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a migration script to add and remove columns in the 'objectMetadata' table within the 'metadata' schema.
Code Snippet:
import { MigrationInterface, QueryRunner } from 'typeorm';

export class AddIdentifierFieldToObjectMetadata1700565712112
  implements MigrationInterface
{
  name = 'AddIdentifierFieldToObjectMetadata1700565712112';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "metadata"."objectMetadata" ADD "labelIdentifierFieldMetadataId" character varying`,
    );
    await queryRunner.query(
      `ALTER TABLE "metadata"."objectMetadata" ADD "imageIdentifierFieldMetadataId" character varying`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "metadata"."objectMetadata" DROP COLUMN "imageIdentifierFieldMetadataId"`,
    );
    await queryRunner.query(
      `ALTER TABLE "metadata"."objectMetadata" DROP COLUMN "labelIdentifierFieldMetadataId"`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a database migration to create and drop a 'remoteServer' table in the 'metadata' schema.
Code Snippet:
import { MigrationInterface, QueryRunner } from 'typeorm';

export class AddRemoteServerTable1711374137222 implements MigrationInterface {
  name = 'AddRemoteServerTable1711374137222';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `CREATE TABLE "metadata"."remoteServer" ("id" uuid NOT NULL DEFAULT uuid_generate_v4(), "foreignDataWrapperId" uuid NOT NULL DEFAULT uuid_generate_v4(), "foreignDataWrapperType" character varying, "foreignDataWrapperOptions" jsonb, "userMappingOptions" jsonb, "workspaceId" uuid NOT NULL, "createdAt" TIMESTAMP NOT NULL DEFAULT now(), "updatedAt" TIMESTAMP NOT NULL DEFAULT now(), CONSTRAINT "PK_8e5d208498fa2c9710bb934023a" PRIMARY KEY ("id"))`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(`DROP TABLE "metadata"."remoteServer"`);
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a TypeORM migration to add and remove an 'isRemote' boolean field from the 'objectMetadata' table in a PostgreSQL database.
Code Snippet:
import { MigrationInterface, QueryRunner } from 'typeorm';

export class AddIsRemoteField1711466822763 implements MigrationInterface {
  name = 'AddIsRemoteField1711466822763';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "metadata"."objectMetadata" ADD "isRemote" boolean NOT NULL DEFAULT false`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "metadata"."objectMetadata" DROP COLUMN "isRemote"`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a TypeORM migration to add a 'latestVersionInputSchema' column of type jsonb to the 'serverlessFunction' table in the 'metadata' schema and provides a rollback to remove the column.
Code Snippet:
import { MigrationInterface, QueryRunner } from 'typeorm';

export class AddInputSchemaToFunction1730803174864
  implements MigrationInterface
{
  name = 'AddInputSchemaToFunction1730803174864';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "metadata"."serverlessFunction" ADD "latestVersionInputSchema" jsonb`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "metadata"."serverlessFunction" DROP COLUMN "latestVersionInputSchema"`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a database migration to add and remove an 'isSearchable' column in the 'objectMetadata' table.
Code Snippet:
import { MigrationInterface, QueryRunner } from 'typeorm';

export class AddIsSearchableColumnInObjectMetadataTable1740478150675
  implements MigrationInterface
{
  name = 'AddIsSearchableColumnInObjectMetadataTable1740478150675';

  public async up(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "metadata"."objectMetadata" ADD "isSearchable" boolean NOT NULL DEFAULT false`,
    );
  }

  public async down(queryRunner: QueryRunner): Promise<void> {
    await queryRunner.query(
      `ALTER TABLE "metadata"."objectMetadata" DROP COLUMN "isSearchable"`,
    );
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_12>



=== New Entry ===

<CLUSTER_13>
Number of Code Snippets part of this cluster: 9
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code defines a decorator 'WorkspaceIsUnique' to mark a property as unique, adding metadata and indexes for ORM purposes.
Code Snippet:
import { generateDeterministicIndexName } from 'src/engine/metadata-modules/index-metadata/utils/generate-deterministic-index-name';
import { metadataArgsStorage } from 'src/engine/twenty-orm/storage/metadata-args.storage';
import { convertClassNameToObjectMetadataName } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/convert-class-to-object-metadata-name.util';
import { TypedReflect } from 'src/utils/typed-reflect';

export function WorkspaceIsUnique(): PropertyDecorator {
  return (target: any, propertyKey: string | symbol) => {
    if (propertyKey === undefined) {
      throw new Error('This decorator should be used with a field not a class');
    }

    const gate = TypedReflect.getMetadata(
      'workspace:gate-metadata-args',
      target,
      propertyKey.toString(),
    );

    const columns = [propertyKey.toString()];

    metadataArgsStorage.addIndexes({
      name: `IDX_UNIQUE_${generateDeterministicIndexName([
        convertClassNameToObjectMetadataName(target.constructor.name),
        ...columns,
      ])}`,
      columns,
      target: target.constructor,
      gate,
      isUnique: true,
      whereClause: null,
    });

    return TypedReflect.defineMetadata(
      'workspace:is-unique-metadata-args',
      true,
      target,
      propertyKey.toString(),
    );
  };
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a TypeScript decorator `WorkspaceField` to annotate class properties with metadata for workspace fields, including options like type, label, description, default value, and more. It uses metadata storage to keep track of these annotations.
Code Snippet:
import { MessageDescriptor } from '@lingui/core';
import { FieldMetadataType } from 'twenty-shared';

import { FieldMetadataDefaultValue } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata-default-value.interface';
import { FieldMetadataOptions } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata-options.interface';
import { FieldMetadataSettings } from 'src/engine/metadata-modules/field-metadata/interfaces/field-metadata-settings.interface';

import { generateDefaultValue } from 'src/engine/metadata-modules/field-metadata/utils/generate-default-value';
import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import { metadataArgsStorage } from 'src/engine/twenty-orm/storage/metadata-args.storage';
import { TypedReflect } from 'src/utils/typed-reflect';

export interface WorkspaceFieldOptions<
  T extends FieldMetadataType = FieldMetadataType,
> {
  standardId: string;
  type: T;
  label:
    | MessageDescriptor
    | ((objectMetadata: ObjectMetadataEntity) => MessageDescriptor);
  description?:
    | MessageDescriptor
    | ((objectMetadata: ObjectMetadataEntity) => MessageDescriptor);
  icon?: string;
  defaultValue?: FieldMetadataDefaultValue<T>;
  options?: FieldMetadataOptions<T>;
  settings?: FieldMetadataSettings<T>;
  isActive?: boolean;
  generatedType?: 'STORED' | 'VIRTUAL';
  asExpression?: string;
}

export function WorkspaceField<T extends FieldMetadataType>(
  options: WorkspaceFieldOptions<T>,
): PropertyDecorator {
  return (object, propertyKey) => {
    const isPrimary =
      TypedReflect.getMetadata(
        'workspace:is-primary-field-metadata-args',
        object,
        propertyKey.toString(),
      ) ?? false;
    const isNullable =
      TypedReflect.getMetadata(
        'workspace:is-nullable-metadata-args',
        object,
        propertyKey.toString(),
      ) ?? false;
    const isSystem =
      TypedReflect.getMetadata(
        'workspace:is-system-metadata-args',
        object,
        propertyKey.toString(),
      ) ?? false;
    const gate = TypedReflect.getMetadata(
      'workspace:gate-metadata-args',
      object,
      propertyKey.toString(),
    );
    const isDeprecated =
      TypedReflect.getMetadata(
        'workspace:is-deprecated-field-metadata-args',
        object,
        propertyKey.toString(),
      ) ?? false;
    const isUnique =
      TypedReflect.getMetadata(
        'workspace:is-unique-metadata-args',
        object,
        propertyKey.toString(),
      ) ?? false;

    const defaultValue = (options.defaultValue ??
      generateDefaultValue(options.type)) as FieldMetadataDefaultValue | null;

    metadataArgsStorage.addFields({
      target: object.constructor,
      standardId: options.standardId,
      name: propertyKey.toString(),
      label:
        typeof options.label === 'function'
          ? (objectMetadata: ObjectMetadataEntity) =>
              (
                options.label as (
                  obj: ObjectMetadataEntity,
                ) => MessageDescriptor
              )(objectMetadata).message ?? ''
          : (options.label.message ?? ''),
      type: options.type,
      description:
        typeof options.description === 'function'
          ? (objectMetadata: ObjectMetadataEntity) =>
              (
                options.description as (
                  obj: ObjectMetadataEntity,
                ) => MessageDescriptor
              )(objectMetadata).message ?? ''
          : (options.description?.message ?? ''),
      icon: options.icon,
      defaultValue,
      options: options.options,
      settings: options.settings,
      isPrimary,
      isNullable,
      isSystem,
      gate,
      isDeprecated,
      isUnique,
      isActive: options.isActive,
      asExpression: options.asExpression,
      generatedType: options.generatedType,
    });
  };
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a decorator function for workspace entities, configuring metadata for these entities and storing them in a metadata storage.
Code Snippet:
import { MessageDescriptor } from '@lingui/core';

import { metadataArgsStorage } from 'src/engine/twenty-orm/storage/metadata-args.storage';
import { BASE_OBJECT_STANDARD_FIELD_IDS } from 'src/engine/workspace-manager/workspace-sync-metadata/constants/standard-field-ids';
import { convertClassNameToObjectMetadataName } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/convert-class-to-object-metadata-name.util';
import { TypedReflect } from 'src/utils/typed-reflect';

interface WorkspaceEntityOptions {
  standardId: string;
  namePlural: string;
  labelSingular: MessageDescriptor;
  labelPlural: MessageDescriptor;
  description?: MessageDescriptor;
  icon?: string;
  shortcut?: string;
  labelIdentifierStandardId?: string;
  imageIdentifierStandardId?: string;
}

export function WorkspaceEntity(
  options: WorkspaceEntityOptions,
): ClassDecorator {
  return (target) => {
    const isAuditLogged =
      TypedReflect.getMetadata(
        'workspace:is-audit-logged-metadata-args',
        target,
      ) ?? true;
    const isSystem =
      TypedReflect.getMetadata('workspace:is-system-metadata-args', target) ??
      false;
    const gate = TypedReflect.getMetadata(
      'workspace:gate-metadata-args',
      target,
    );
    const duplicateCriteria = TypedReflect.getMetadata(
      'workspace:duplicate-criteria-metadata-args',
      target,
    );
    const isSearchable =
      TypedReflect.getMetadata(
        'workspace:is-searchable-metadata-args',
        target,
      ) ?? false;

    const objectName = convertClassNameToObjectMetadataName(target.name);

    metadataArgsStorage.addEntities({
      target,
      standardId: options.standardId,
      nameSingular: objectName,
      namePlural: options.namePlural,
      labelSingular: options.labelSingular?.message ?? '',
      labelPlural: options.labelPlural?.message ?? '',
      description: options.description?.message ?? '',
      labelIdentifierStandardId:
        options.labelIdentifierStandardId ?? BASE_OBJECT_STANDARD_FIELD_IDS.id,
      imageIdentifierStandardId: options.imageIdentifierStandardId ?? null,
      icon: options.icon,
      shortcut: options.shortcut,
      isAuditLogged,
      isSystem,
      gate,
      duplicateCriteria,
      isSearchable,
    });
  };
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a decorator function `WorkspaceJoinColumn` to add join column metadata and register an index for the join column in a metadata storage.
Code Snippet:
import { WorkspaceFieldIndex } from 'src/engine/twenty-orm/decorators/workspace-field-index.decorator';
import { metadataArgsStorage } from 'src/engine/twenty-orm/storage/metadata-args.storage';

export function WorkspaceJoinColumn(
  relationPropertyKey: string,
): PropertyDecorator {
  return (object, propertyKey) => {
    metadataArgsStorage.addJoinColumns({
      target: object.constructor,
      relationName: relationPropertyKey,
      joinColumn: propertyKey.toString(),
    });

    // Register index for join column
    WorkspaceFieldIndex()(object, propertyKey);
  };
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a decorator function for workspace dynamic relations in a TypeORM-based application, configuring metadata for entity relationships.
Code Snippet:
import { ObjectType } from 'typeorm';

import { WorkspaceDynamicRelationMetadataArgsFactory } from 'src/engine/twenty-orm/interfaces/workspace-dynamic-relation-metadata-args.interface';

import {
  RelationMetadataType,
  RelationOnDeleteAction,
} from 'src/engine/metadata-modules/relation-metadata/relation-metadata.entity';
import { metadataArgsStorage } from 'src/engine/twenty-orm/storage/metadata-args.storage';
import { TypedReflect } from 'src/utils/typed-reflect';

interface WorkspaceBaseDynamicRelationOptions<TClass> {
  type: RelationMetadataType;
  argsFactory: WorkspaceDynamicRelationMetadataArgsFactory;
  inverseSideTarget: () => ObjectType<TClass>;
  inverseSideFieldKey?: keyof TClass;
  onDelete?: RelationOnDeleteAction;
}

export function WorkspaceDynamicRelation<TClass extends object>(
  args: WorkspaceBaseDynamicRelationOptions<TClass>,
): PropertyDecorator {
  return (target, propertyKey) => {
    const isSystem =
      TypedReflect.getMetadata(
        'workspace:is-system-metadata-args',
        target,
        propertyKey.toString(),
      ) ?? false;

    const gate = TypedReflect.getMetadata(
      'workspace:gate-metadata-args',
      target,
      propertyKey.toString(),
    );

    metadataArgsStorage.addDynamicRelations({
      target: target.constructor,
      argsFactory: args.argsFactory,
      type: args.type,
      inverseSideTarget: args.inverseSideTarget,
      inverseSideFieldKey: args.inverseSideFieldKey as string | undefined,
      onDelete: args.onDelete,
      isSystem,
      isNullable: true,
      isPrimary: false,
      gate,
    });
  };
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a decorator function named WorkspaceCustomEntity that adds metadata of a class to a storage system using TypedReflect and metadataArgsStorage.
Code Snippet:
import { metadataArgsStorage } from 'src/engine/twenty-orm/storage/metadata-args.storage';
import { TypedReflect } from 'src/utils/typed-reflect';

export function WorkspaceCustomEntity(): ClassDecorator {
  return (target) => {
    const gate = TypedReflect.getMetadata(
      'workspace:gate-metadata-args',
      target,
    );

    metadataArgsStorage.addExtendedEntities({
      target,
      gate,
    });
  };
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a decorator function to add indexing metadata for a workspace field in an ORM system.
Code Snippet:
import { generateDeterministicIndexName } from 'src/engine/metadata-modules/index-metadata/utils/generate-deterministic-index-name';
import { WorkspaceIndexOptions } from 'src/engine/twenty-orm/decorators/workspace-index.decorator';
import { metadataArgsStorage } from 'src/engine/twenty-orm/storage/metadata-args.storage';
import { getColumnsForIndex } from 'src/engine/twenty-orm/utils/get-default-columns-for-index.util';
import { convertClassNameToObjectMetadataName } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/convert-class-to-object-metadata-name.util';
import { TypedReflect } from 'src/utils/typed-reflect';

export function WorkspaceFieldIndex(
  options?: WorkspaceIndexOptions,
): PropertyDecorator {
  return (target: any, propertyKey: string | symbol) => {
    if (propertyKey === undefined) {
      throw new Error('This decorator should be used with a field not a class');
    }

    const gate = TypedReflect.getMetadata(
      'workspace:gate-metadata-args',
      target,
      propertyKey.toString(),
    );

    const additionalDefaultColumnsForIndex = getColumnsForIndex(
      options?.indexType,
    );

    const columns = [
      propertyKey.toString(),
      ...additionalDefaultColumnsForIndex,
    ];

    metadataArgsStorage.addIndexes({
      name: `IDX_${generateDeterministicIndexName([
        convertClassNameToObjectMetadataName(target.constructor.name),
        ...columns,
      ])}`,
      columns,
      target: target.constructor,
      gate,
      isUnique: options?.isUnique ?? false,
      whereClause: options?.indexWhereClause ?? null,
      type: options?.indexType,
    });
  };
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a decorator function `WorkspaceIndex` to add index metadata to a class, which is stored in `metadataArgsStorage`.
Code Snippet:
import { IndexType } from 'src/engine/metadata-modules/index-metadata/index-metadata.entity';
import { generateDeterministicIndexName } from 'src/engine/metadata-modules/index-metadata/utils/generate-deterministic-index-name';
import { metadataArgsStorage } from 'src/engine/twenty-orm/storage/metadata-args.storage';
import { convertClassNameToObjectMetadataName } from 'src/engine/workspace-manager/workspace-sync-metadata/utils/convert-class-to-object-metadata-name.util';
import { TypedReflect } from 'src/utils/typed-reflect';

export type WorkspaceIndexOptions = {
  isUnique?: boolean;
  indexWhereClause?: string;
  indexType?: IndexType;
};

export function WorkspaceIndex(
  columns: string[],
  options: WorkspaceIndexOptions,
): ClassDecorator {
  if (!Array.isArray(columns) || columns.length === 0) {
    throw new Error('Class level WorkspaceIndex should be used with columns');
  }

  return (target: any) => {
    const gate = TypedReflect.getMetadata(
      'workspace:gate-metadata-args',
      target,
    );

    metadataArgsStorage.addIndexes({
      name: `IDX_${
        options?.isUnique ? 'UNIQUE_' : ''
      }${generateDeterministicIndexName([
        convertClassNameToObjectMetadataName(target.name),
        ...columns,
      ])}`,
      columns,
      target: target,
      gate,
      isUnique: options?.isUnique ?? false,
      whereClause: options?.indexWhereClause ?? null,
      type: options?.indexType,
    });
  };
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a decorator function `WorkspaceRelation` for setting up workspace relationships in an application, using TypeORM and custom metadata storage.
Code Snippet:
import { MessageDescriptor } from '@lingui/core';
import { ObjectType } from 'typeorm';

import { ObjectMetadataEntity } from 'src/engine/metadata-modules/object-metadata/object-metadata.entity';
import {
  RelationMetadataType,
  RelationOnDeleteAction,
} from 'src/engine/metadata-modules/relation-metadata/relation-metadata.entity';
import { metadataArgsStorage } from 'src/engine/twenty-orm/storage/metadata-args.storage';
import { TypedReflect } from 'src/utils/typed-reflect';

interface WorkspaceRelationOptions<TClass> {
  standardId: string;
  label:
    | MessageDescriptor
    | ((objectMetadata: ObjectMetadataEntity) => MessageDescriptor);
  description?:
    | MessageDescriptor
    | ((objectMetadata: ObjectMetadataEntity) => MessageDescriptor);
  icon?: string;
  type: RelationMetadataType;
  inverseSideTarget: () => ObjectType<TClass>;
  inverseSideFieldKey?: keyof TClass;
  onDelete?: RelationOnDeleteAction;
}

export function WorkspaceRelation<TClass extends object>(
  options: WorkspaceRelationOptions<TClass>,
): PropertyDecorator {
  return (object, propertyKey) => {
    const isPrimary =
      TypedReflect.getMetadata(
        'workspace:is-primary-field-metadata-args',
        object,
        propertyKey.toString(),
      ) ?? false;
    const isNullable =
      TypedReflect.getMetadata(
        'workspace:is-nullable-metadata-args',
        object,
        propertyKey.toString(),
      ) ?? false;
    const isSystem =
      TypedReflect.getMetadata(
        'workspace:is-system-metadata-args',
        object,
        propertyKey.toString(),
      ) ?? false;
    const gate = TypedReflect.getMetadata(
      'workspace:gate-metadata-args',
      object,
      propertyKey.toString(),
    );

    metadataArgsStorage.addRelations({
      target: object.constructor,
      standardId: options.standardId,
      name: propertyKey.toString(),
      label:
        typeof options.label === 'function'
          ? (objectMetadata: ObjectMetadataEntity) =>
              (
                options.label as (
                  obj: ObjectMetadataEntity,
                ) => MessageDescriptor
              )(objectMetadata).message ?? ''
          : (options.label.message ?? ''),
      type: options.type,
      description:
        typeof options.description === 'function'
          ? (objectMetadata: ObjectMetadataEntity) =>
              (
                options.description as (
                  obj: ObjectMetadataEntity,
                ) => MessageDescriptor
              )(objectMetadata).message ?? ''
          : (options.description?.message ?? ''),
      icon: options.icon,
      inverseSideTarget: options.inverseSideTarget,
      inverseSideFieldKey: options.inverseSideFieldKey as string | undefined,
      onDelete: options.onDelete,
      isPrimary,
      isNullable,
      isSystem,
      gate,
    });
  };
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_13>



=== New Entry ===

<CLUSTER_14>
Number of Code Snippets part of this cluster: 5
Code Snippets:
============================================ CODE SNIPPET START ============================================
Summary: The code defines a NestJS processor class that handles webhook calls, generates signatures for secure communication, and logs the response using an analytics service.
Code Snippet:
import { HttpService } from '@nestjs/axios';
import { Logger } from '@nestjs/common';

import crypto from 'crypto';

import { AnalyticsService } from 'src/engine/core-modules/analytics/analytics.service';
import { Process } from 'src/engine/core-modules/message-queue/decorators/process.decorator';
import { Processor } from 'src/engine/core-modules/message-queue/decorators/processor.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';

export type CallWebhookJobData = {
  targetUrl: string;
  eventName: string;
  objectMetadata: { id: string; nameSingular: string };
  workspaceId: string;
  webhookId: string;
  eventDate: Date;
  record: any;
  updatedFields?: string[];
  secret?: string;
};

@Processor(MessageQueue.webhookQueue)
export class CallWebhookJob {
  private readonly logger = new Logger(CallWebhookJob.name);
  constructor(
    private readonly httpService: HttpService,
    private readonly analyticsService: AnalyticsService,
  ) {}

  private generateSignature(
    payload: CallWebhookJobData,
    secret: string,
    timestamp: string,
  ): string {
    return crypto
      .createHmac('sha256', secret)
      .update(`${timestamp}:${JSON.stringify(payload)}`)
      .digest('hex');
  }

  @Process(CallWebhookJob.name)
  async handle(data: CallWebhookJobData): Promise<void> {
    const commonPayload = {
      url: data.targetUrl,
      webhookId: data.webhookId,
      eventName: data.eventName,
    };

    try {
      const headers: Record<string, string> = {
        'Content-Type': 'application/json',
      };

      const { secret, ...payloadWithoutSecret } = data;

      if (secret) {
        headers['X-Twenty-Webhook-Timestamp'] = Date.now().toString();
        headers['X-Twenty-Webhook-Signature'] = this.generateSignature(
          payloadWithoutSecret,
          secret,
          headers['X-Twenty-Webhook-Timestamp'],
        );
        headers['X-Twenty-Webhook-Nonce'] = crypto
          .randomBytes(16)
          .toString('hex');
      }

      const response = await this.httpService.axiosRef.post(
        data.targetUrl,
        payloadWithoutSecret,
        { headers },
      );

      const success = response.status >= 200 && response.status < 300;
      const eventInput = {
        action: 'webhook.response',
        payload: {
          status: response.status,
          success,
          ...commonPayload,
        },
      };

      this.analyticsService.create(eventInput, 'webhook', data.workspaceId);
    } catch (err) {
      const eventInput = {
        action: 'webhook.response',
        payload: {
          success: false,
          ...commonPayload,
          ...(err.response && { status: err.response.status }),
        },
      };

      this.analyticsService.create(eventInput, 'webhook', data.workspaceId);
      this.logger.error(
        `Error calling webhook on targetUrl '${data.targetUrl}': ${err}`,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a service for tracking messaging telemetry events and sending them to an analytics service.
Code Snippet:
import { Injectable } from '@nestjs/common';

import { AnalyticsService } from 'src/engine/core-modules/analytics/analytics.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';

type MessagingTelemetryTrackInput = {
  eventName: string;
  workspaceId?: string;
  userId?: string;
  connectedAccountId?: string;
  messageChannelId?: string;
  message?: string;
};

@Injectable()
export class MessagingTelemetryService {
  constructor(
    private readonly analyticsService: AnalyticsService,
    private readonly environmentService: EnvironmentService,
  ) {}

  public async track({
    eventName,
    workspaceId,
    userId,
    connectedAccountId,
    messageChannelId,
    message,
  }: MessagingTelemetryTrackInput): Promise<void> {
    await this.analyticsService.create(
      {
        action: 'monitoring',
        payload: {
          eventName: `messaging.${eventName}`,
          workspaceId,
          userId,
          connectedAccountId,
          messageChannelId,
          message,
        },
      },
      userId,
      workspaceId,
    );
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: This code defines a service for managing serverless functions, including creating, updating, deleting, and executing functions, as well as handling function versions and code storage.
Code Snippet:
import { Injectable } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';

import { basename, dirname, join } from 'path';

import deepEqual from 'deep-equal';
import { IsNull, Not, Repository } from 'typeorm';
import { isDefined } from 'twenty-shared';

import { FileStorageExceptionCode } from 'src/engine/core-modules/file-storage/interfaces/file-storage-exception';
import { ServerlessExecuteResult } from 'src/engine/core-modules/serverless/drivers/interfaces/serverless-driver.interface';

import { AnalyticsService } from 'src/engine/core-modules/analytics/analytics.service';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { FileStorageService } from 'src/engine/core-modules/file-storage/file-storage.service';
import { readFileContent } from 'src/engine/core-modules/file-storage/utils/read-file-content';
import { InjectMessageQueue } from 'src/engine/core-modules/message-queue/decorators/message-queue.decorator';
import { MessageQueue } from 'src/engine/core-modules/message-queue/message-queue.constants';
import { MessageQueueService } from 'src/engine/core-modules/message-queue/services/message-queue.service';
import { ENV_FILE_NAME } from 'src/engine/core-modules/serverless/drivers/constants/env-file-name';
import { INDEX_FILE_NAME } from 'src/engine/core-modules/serverless/drivers/constants/index-file-name';
import { LAST_LAYER_VERSION } from 'src/engine/core-modules/serverless/drivers/layers/last-layer-version';
import { getBaseTypescriptProjectFiles } from 'src/engine/core-modules/serverless/drivers/utils/get-base-typescript-project-files';
import { getLayerDependencies } from 'src/engine/core-modules/serverless/drivers/utils/get-last-layer-dependencies';
import { ServerlessService } from 'src/engine/core-modules/serverless/serverless.service';
import { getServerlessFolder } from 'src/engine/core-modules/serverless/utils/serverless-get-folder.utils';
import { ThrottlerService } from 'src/engine/core-modules/throttler/throttler.service';
import { CreateServerlessFunctionInput } from 'src/engine/metadata-modules/serverless-function/dtos/create-serverless-function.input';
import { UpdateServerlessFunctionInput } from 'src/engine/metadata-modules/serverless-function/dtos/update-serverless-function.input';
import {
  ServerlessFunctionEntity,
  ServerlessFunctionSyncStatus,
} from 'src/engine/metadata-modules/serverless-function/serverless-function.entity';
import {
  ServerlessFunctionException,
  ServerlessFunctionExceptionCode,
} from 'src/engine/metadata-modules/serverless-function/serverless-function.exception';

@Injectable()
export class ServerlessFunctionService {
  constructor(
    private readonly fileStorageService: FileStorageService,
    private readonly serverlessService: ServerlessService,
    @InjectRepository(ServerlessFunctionEntity, 'metadata')
    private readonly serverlessFunctionRepository: Repository<ServerlessFunctionEntity>,
    private readonly throttlerService: ThrottlerService,
    private readonly environmentService: EnvironmentService,
    private readonly analyticsService: AnalyticsService,
    @InjectMessageQueue(MessageQueue.serverlessFunctionQueue)
    private readonly messageQueueService: MessageQueueService,
  ) {}

  async findManyServerlessFunctions(where) {
    return this.serverlessFunctionRepository.findBy(where);
  }

  async findOneOrFail({
    workspaceId,
    id,
  }: {
    workspaceId: string;
    id: string;
  }) {
    const serverlessFunction =
      await this.serverlessFunctionRepository.findOneBy({
        id,
        workspaceId,
      });

    if (!serverlessFunction) {
      throw new ServerlessFunctionException(
        `Function does not exist`,
        ServerlessFunctionExceptionCode.SERVERLESS_FUNCTION_NOT_FOUND,
      );
    }

    return serverlessFunction;
  }

  async hasServerlessFunctionPublishedVersion(serverlessFunctionId: string) {
    return await this.serverlessFunctionRepository.exists({
      where: {
        id: serverlessFunctionId,
        latestVersion: Not(IsNull()),
      },
    });
  }

  async getServerlessFunctionSourceCode(
    workspaceId: string,
    id: string,
    version: string,
  ): Promise<{ [filePath: string]: string } | undefined> {
    const serverlessFunction = await this.findOneOrFail({
      id,
      workspaceId,
    });

    try {
      const folderPath = getServerlessFolder({
        serverlessFunction,
        version,
      });

      const indexFileStream = await this.fileStorageService.read({
        folderPath: join(folderPath, 'src'),
        filename: INDEX_FILE_NAME,
      });

      const envFileStream = await this.fileStorageService.read({
        folderPath: folderPath,
        filename: ENV_FILE_NAME,
      });

      return {
        '.env': await readFileContent(envFileStream),
        'src/index.ts': await readFileContent(indexFileStream),
      };
    } catch (error) {
      if (error.code === FileStorageExceptionCode.FILE_NOT_FOUND) {
        return;
      }
      throw error;
    }
  }

  async executeOneServerlessFunction(
    id: string,
    workspaceId: string,
    payload: object,
    version = 'latest',
  ): Promise<ServerlessExecuteResult> {
    await this.throttleExecution(workspaceId);

    const functionToExecute = await this.findOneOrFail({
      id,
      workspaceId,
    });

    const resultServerlessFunction = await this.serverlessService.execute(
      functionToExecute,
      payload,
      version,
    );

    const eventInput = {
      action: 'serverlessFunction.executed',
      payload: {
        duration: resultServerlessFunction.duration,
        status: resultServerlessFunction.status,
        ...(resultServerlessFunction.error && {
          errorType: resultServerlessFunction.error.errorType,
        }),
        functionId: functionToExecute.id,
        functionName: functionToExecute.name,
      },
    };

    this.analyticsService.create(
      eventInput,
      'serverless-function',
      workspaceId,
    );

    return resultServerlessFunction;
  }

  async publishOneServerlessFunction(id: string, workspaceId: string) {
    const existingServerlessFunction = await this.findOneOrFail({
      id,
      workspaceId,
    });

    if (isDefined(existingServerlessFunction.latestVersion)) {
      const latestCode = await this.getServerlessFunctionSourceCode(
        workspaceId,
        id,
        'latest',
      );
      const draftCode = await this.getServerlessFunctionSourceCode(
        workspaceId,
        id,
        'draft',
      );

      if (deepEqual(latestCode, draftCode)) {
        throw new ServerlessFunctionException(
          'Cannot publish a new version when code has not changed',
          ServerlessFunctionExceptionCode.SERVERLESS_FUNCTION_CODE_UNCHANGED,
        );
      }
    }

    const newVersion = existingServerlessFunction.latestVersion
      ? `${parseInt(existingServerlessFunction.latestVersion, 10) + 1}`
      : '1';

    const draftFolderPath = getServerlessFolder({
      serverlessFunction: existingServerlessFunction,
      version: 'draft',
    });
    const newFolderPath = getServerlessFolder({
      serverlessFunction: existingServerlessFunction,
      version: newVersion,
    });

    await this.fileStorageService.copy({
      from: { folderPath: draftFolderPath },
      to: { folderPath: newFolderPath },
    });

    const newPublishedVersions = [
      ...existingServerlessFunction.publishedVersions,
      newVersion,
    ];

    await this.serverlessFunctionRepository.update(
      existingServerlessFunction.id,
      {
        latestVersion: newVersion,
        publishedVersions: newPublishedVersions,
      },
    );

    return this.serverlessFunctionRepository.findOneBy({
      id: existingServerlessFunction.id,
    });
  }

  async deleteOneServerlessFunction({
    id,
    workspaceId,
    isHardDeletion = true,
  }: {
    id: string;
    workspaceId: string;
    isHardDeletion?: boolean;
  }) {
    const existingServerlessFunction = await this.findOneOrFail({
      id,
      workspaceId,
    });

    if (isHardDeletion) {
      await this.serverlessFunctionRepository.delete(id);
      await this.fileStorageService.delete({
        folderPath: getServerlessFolder({
          serverlessFunction: existingServerlessFunction,
        }),
      });
    }

    await this.serverlessService.delete(existingServerlessFunction);

    return existingServerlessFunction;
  }

  async updateOneServerlessFunction(
    serverlessFunctionInput: UpdateServerlessFunctionInput,
    workspaceId: string,
  ) {
    const existingServerlessFunction = await this.findOneOrFail({
      id: serverlessFunctionInput.id,
      workspaceId,
    });

    await this.serverlessFunctionRepository.update(
      existingServerlessFunction.id,
      {
        name: serverlessFunctionInput.name,
        description: serverlessFunctionInput.description,
        timeoutSeconds: serverlessFunctionInput.timeoutSeconds,
      },
    );

    const fileFolder = getServerlessFolder({
      serverlessFunction: existingServerlessFunction,
      version: 'draft',
    });

    for (const key of Object.keys(serverlessFunctionInput.code)) {
      await this.fileStorageService.write({
        file: serverlessFunctionInput.code[key],
        name: basename(key),
        mimeType: undefined,
        folder: join(fileFolder, dirname(key)),
      });
    }

    return this.serverlessFunctionRepository.findOneBy({
      id: existingServerlessFunction.id,
    });
  }

  async getAvailablePackages(serverlessFunctionId: string) {
    const serverlessFunction =
      await this.serverlessFunctionRepository.findOneBy({
        id: serverlessFunctionId,
      });
    const { packageJson, yarnLock } = await getLayerDependencies(
      serverlessFunction?.layerVersion || 'latest',
    );

    const packageVersionRegex = /^"([^@]+)@.*?":\n\s+version: (.+)$/gm;
    const versions: Record<string, string> = {};

    let match: RegExpExecArray | null;

    while ((match = packageVersionRegex.exec(yarnLock)) !== null) {
      const packageName = match[1].split('@', 1)[0];
      const version = match[2];

      if (packageJson.dependencies[packageName]) {
        versions[packageName] = version;
      }
    }

    return versions;
  }

  async createOneServerlessFunction(
    serverlessFunctionInput: CreateServerlessFunctionInput,
    workspaceId: string,
  ) {
    const serverlessFunctionToCreate =
      await this.serverlessFunctionRepository.create({
        ...serverlessFunctionInput,
        workspaceId,
        layerVersion: LAST_LAYER_VERSION,
        syncStatus: ServerlessFunctionSyncStatus.NOT_READY,
      });

    const createdServerlessFunction =
      await this.serverlessFunctionRepository.save(serverlessFunctionToCreate);

    const draftFileFolder = getServerlessFolder({
      serverlessFunction: createdServerlessFunction,
      version: 'draft',
    });

    for (const file of await getBaseTypescriptProjectFiles) {
      await this.fileStorageService.write({
        file: file.content,
        name: file.name,
        mimeType: undefined,
        folder: join(draftFileFolder, file.path),
      });
    }

    await this.serverlessService.build(createdServerlessFunction);

    return this.serverlessFunctionRepository.findOneBy({
      id: createdServerlessFunction.id,
    });
  }

  async usePublishedVersionAsDraft({
    id,
    version,
    workspaceId,
  }: {
    id: string;
    version: string;
    workspaceId: string;
  }) {
    if (version === 'draft') {
      return;
    }

    const serverlessFunction = await this.findOneOrFail({
      id,
      workspaceId,
    });

    await this.fileStorageService.copy({
      from: {
        folderPath: getServerlessFolder({
          serverlessFunction: serverlessFunction,
          version,
        }),
      },
      to: {
        folderPath: getServerlessFolder({
          serverlessFunction: serverlessFunction,
          version: 'draft',
        }),
      },
    });
  }

  private async throttleExecution(workspaceId: string) {
    try {
      await this.throttlerService.throttle(
        `${workspaceId}-serverless-function-execution`,
        this.environmentService.get('SERVERLESS_FUNCTION_EXEC_THROTTLE_LIMIT'),
        this.environmentService.get('SERVERLESS_FUNCTION_EXEC_THROTTLE_TTL'),
      );
    } catch (error) {
      throw new ServerlessFunctionException(
        'Serverless function execution rate limit exceeded',
        ServerlessFunctionExceptionCode.SERVERLESS_FUNCTION_EXECUTION_LIMIT_REACHED,
      );
    }
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines a TelemetryService that sends event data to a remote server if telemetry is enabled.
Code Snippet:
import { HttpService } from '@nestjs/axios';
import { Injectable, Logger } from '@nestjs/common';

import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';

type CreateEventInput = {
  action: string;
  payload: object;
};

@Injectable()
export class TelemetryService {
  private readonly logger = new Logger(TelemetryService.name);

  constructor(
    private readonly environmentService: EnvironmentService,
    private readonly httpService: HttpService,
  ) {}

  async create(
    createEventInput: CreateEventInput,
    userId: string | null | undefined,
    workspaceId: string | null | undefined,
  ) {
    if (!this.environmentService.get('TELEMETRY_ENABLED')) {
      return { success: true };
    }

    const data = {
      action: createEventInput.action,
      timestamp: new Date().toISOString(),
      version: '1',
      payload: {
        userId: userId,
        workspaceId: workspaceId,
        ...createEventInput.payload,
      },
    };

    try {
      await this.httpService.axiosRef.post(`/selfHostingEvent`, data);
    } catch (error) {
      this.logger.error('Error occurred:', error);
      if (error.response) {
        this.logger.error(
          `Error response body: ${JSON.stringify(error.response.data)}`,
        );
      }

      return { success: false };
    }

    return { success: true };
  }
}

============================================ CODE SNIPPET END ============================================


============================================ CODE SNIPPET START ============================================
Summary: The code defines an AnalyticsService in a NestJS application that sends event data to a Tinybird data ingestion endpoint and generates JWTs for analytics access.
Code Snippet:
import { HttpService } from '@nestjs/axios';
import { Injectable, Logger } from '@nestjs/common';

import { AxiosRequestConfig } from 'axios';

import { AnalyticsTinybirdJwtMap } from 'src/engine/core-modules/analytics/entities/analytics-tinybird-jwts.entity';
import { EnvironmentService } from 'src/engine/core-modules/environment/environment.service';
import { JwtWrapperService } from 'src/engine/core-modules/jwt/services/jwt-wrapper.service';

type CreateEventInput = {
  action: string;
  payload: object;
};

@Injectable()
export class AnalyticsService {
  private readonly logger = new Logger(AnalyticsService.name);
  private readonly defaultDatasource = 'event';

  constructor(
    private readonly jwtWrapperService: JwtWrapperService,
    private readonly environmentService: EnvironmentService,
    private readonly httpService: HttpService,
  ) {}

  async create(
    createEventInput: CreateEventInput,
    userId: string | null | undefined,
    workspaceId: string | null | undefined,
  ) {
    if (!this.environmentService.get('ANALYTICS_ENABLED')) {
      return { success: true };
    }

    let data;

    switch (createEventInput.action) {
      case 'pageview':
        data = {
          timestamp: new Date().toISOString(),
          version: '1',
          userId: userId,
          workspaceId: workspaceId,
          ...createEventInput.payload,
        };
        break;
      default:
        data = {
          action: createEventInput.action,
          timestamp: new Date().toISOString(),
          version: '1',
          userId: userId,
          workspaceId: workspaceId,
          payload: {
            ...createEventInput.payload,
          },
        };
        break;
    }

    const config: AxiosRequestConfig = {
      headers: {
        Authorization:
          'Bearer ' + this.environmentService.get('TINYBIRD_INGEST_TOKEN'),
      },
    };

    const datasource =
      createEventInput.action === 'pageview'
        ? 'pageview'
        : this.defaultDatasource;

    try {
      await this.httpService.axiosRef.post(
        `/events?name=${datasource}`,
        data,
        config,
      );
    } catch (error) {
      this.logger.error('Error occurred:', error);
      if (error.response) {
        this.logger.error(
          `Error response body: ${JSON.stringify(error.response.data)}`,
        );
      }

      return { success: false };
    }

    return { success: true };
  }

  generateWorkspaceJwt(
    workspaceId: string | undefined,
  ): AnalyticsTinybirdJwtMap | null {
    if (!this.environmentService.get('ANALYTICS_ENABLED')) {
      return null;
    }

    const jwtPayload = {
      name: 'analytics_jwt',
      workspace_id: this.environmentService.get('TINYBIRD_WORKSPACE_UUID'),
      scopes: [
        {
          type: 'PIPES:READ',
          resource: '',
          fixed_params: { workspaceId },
        },
      ],
    };

    const jwtOptions = {
      secret: this.environmentService.get('TINYBIRD_GENERATE_JWT_TOKEN'),
      expiresIn: '7d',
    };

    const analyticsProperties = [
      'getWebhookAnalytics',
      'getPageviewsAnalytics',
      'getUsersAnalytics',
      'getServerlessFunctionDuration',
      'getServerlessFunctionSuccessRate',
      'getServerlessFunctionErrorCount',
    ];

    return analyticsProperties.reduce(
      (acc, property) => ({
        ...acc,
        [property]: this.jwtWrapperService.sign(
          {
            ...jwtPayload,
            scopes: [
              {
                ...jwtPayload.scopes[0],
                resource: property,
              },
            ],
          },
          jwtOptions,
        ),
      }),
      {},
    ) as AnalyticsTinybirdJwtMap;
  }
}

============================================ CODE SNIPPET END ============================================


</CLUSTER_14>